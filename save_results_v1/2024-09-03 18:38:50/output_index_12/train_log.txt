Epoch 1, Training Loss: 0.5370117425918579, Validation Loss: 0.5352717041969299
Epoch 2, Training Loss: 0.5352717638015747, Validation Loss: 0.5335417985916138
Epoch 3, Training Loss: 0.5335417985916138, Validation Loss: 0.5318652987480164
Epoch 4, Training Loss: 0.5318652987480164, Validation Loss: 0.5302045941352844
Epoch 5, Training Loss: 0.5302046537399292, Validation Loss: 0.5285631418228149
Epoch 6, Training Loss: 0.5285631418228149, Validation Loss: 0.5269421935081482
Epoch 7, Training Loss: 0.526942253112793, Validation Loss: 0.5252926349639893
Epoch 8, Training Loss: 0.5252925753593445, Validation Loss: 0.5236088037490845
Epoch 9, Training Loss: 0.5236088037490845, Validation Loss: 0.5219253301620483
Epoch 10, Training Loss: 0.5219253301620483, Validation Loss: 0.520226001739502
Epoch 11, Training Loss: 0.520226001739502, Validation Loss: 0.5185189247131348
Epoch 12, Training Loss: 0.5185189247131348, Validation Loss: 0.516752302646637
Epoch 13, Training Loss: 0.516752302646637, Validation Loss: 0.5149378180503845
Epoch 14, Training Loss: 0.5149378180503845, Validation Loss: 0.5130869746208191
Epoch 15, Training Loss: 0.5130869746208191, Validation Loss: 0.5112011432647705
Epoch 16, Training Loss: 0.5112010836601257, Validation Loss: 0.5092760920524597
Epoch 17, Training Loss: 0.5092760324478149, Validation Loss: 0.5072802305221558
Epoch 18, Training Loss: 0.5072802901268005, Validation Loss: 0.5052134990692139
Epoch 19, Training Loss: 0.5052134990692139, Validation Loss: 0.5031842589378357
Epoch 20, Training Loss: 0.5031842589378357, Validation Loss: 0.5011721253395081
Epoch 21, Training Loss: 0.5011721849441528, Validation Loss: 0.49907445907592773
Epoch 22, Training Loss: 0.49907445907592773, Validation Loss: 0.49689874053001404
Epoch 23, Training Loss: 0.49689874053001404, Validation Loss: 0.49463409185409546
Epoch 24, Training Loss: 0.49463409185409546, Validation Loss: 0.49227166175842285
Epoch 25, Training Loss: 0.49227166175842285, Validation Loss: 0.4898035526275635
Epoch 26, Training Loss: 0.4898035526275635, Validation Loss: 0.4872342050075531
Epoch 27, Training Loss: 0.4872342050075531, Validation Loss: 0.4845612943172455
Epoch 28, Training Loss: 0.4845612943172455, Validation Loss: 0.48174232244491577
Epoch 29, Training Loss: 0.48174232244491577, Validation Loss: 0.4787396788597107
Epoch 30, Training Loss: 0.4787396788597107, Validation Loss: 0.47555190324783325
Epoch 31, Training Loss: 0.4755518436431885, Validation Loss: 0.4721876084804535
Epoch 32, Training Loss: 0.4721876084804535, Validation Loss: 0.4686164855957031
Epoch 33, Training Loss: 0.4686164855957031, Validation Loss: 0.4649183452129364
Epoch 34, Training Loss: 0.4649183452129364, Validation Loss: 0.46101731061935425
Epoch 35, Training Loss: 0.46101731061935425, Validation Loss: 0.456831157207489
Epoch 36, Training Loss: 0.456831157207489, Validation Loss: 0.4523654878139496
Epoch 37, Training Loss: 0.4523654878139496, Validation Loss: 0.4476253390312195
Epoch 38, Training Loss: 0.4476253390312195, Validation Loss: 0.4426107406616211
Epoch 39, Training Loss: 0.4426107406616211, Validation Loss: 0.4372369050979614
Epoch 40, Training Loss: 0.4372369050979614, Validation Loss: 0.43147414922714233
Epoch 41, Training Loss: 0.4314741790294647, Validation Loss: 0.42532944679260254
Epoch 42, Training Loss: 0.42532944679260254, Validation Loss: 0.4187534749507904
Epoch 43, Training Loss: 0.4187534749507904, Validation Loss: 0.4117072522640228
Epoch 44, Training Loss: 0.4117072522640228, Validation Loss: 0.4041965901851654
Epoch 45, Training Loss: 0.4041965901851654, Validation Loss: 0.39621588587760925
Epoch 46, Training Loss: 0.39621588587760925, Validation Loss: 0.3876894414424896
Epoch 47, Training Loss: 0.3876894414424896, Validation Loss: 0.3786463141441345
Epoch 48, Training Loss: 0.3786463439464569, Validation Loss: 0.36903485655784607
Epoch 49, Training Loss: 0.36903485655784607, Validation Loss: 0.3589596748352051
Epoch 50, Training Loss: 0.35895973443984985, Validation Loss: 0.3483752906322479
Epoch 51, Training Loss: 0.3483752906322479, Validation Loss: 0.3373166024684906
Epoch 52, Training Loss: 0.3373166024684906, Validation Loss: 0.3259184956550598
Epoch 53, Training Loss: 0.3259184956550598, Validation Loss: 0.3141794204711914
Epoch 54, Training Loss: 0.3141794204711914, Validation Loss: 0.30216285586357117
Epoch 55, Training Loss: 0.30216285586357117, Validation Loss: 0.29006361961364746
Epoch 56, Training Loss: 0.29006361961364746, Validation Loss: 0.2779759466648102
Epoch 57, Training Loss: 0.2779759466648102, Validation Loss: 0.2660864591598511
Epoch 58, Training Loss: 0.2660864591598511, Validation Loss: 0.2546360194683075
Epoch 59, Training Loss: 0.2546360194683075, Validation Loss: 0.24393151700496674
Epoch 60, Training Loss: 0.24393151700496674, Validation Loss: 0.234047994017601
Epoch 61, Training Loss: 0.23404797911643982, Validation Loss: 0.22537365555763245
Epoch 62, Training Loss: 0.22537362575531006, Validation Loss: 0.21787208318710327
Epoch 63, Training Loss: 0.21787208318710327, Validation Loss: 0.21154789626598358
Epoch 64, Training Loss: 0.21154794096946716, Validation Loss: 0.2061292827129364
Epoch 65, Training Loss: 0.2061292827129364, Validation Loss: 0.2014768421649933
Epoch 66, Training Loss: 0.20147685706615448, Validation Loss: 0.19736135005950928
Epoch 67, Training Loss: 0.19736135005950928, Validation Loss: 0.19327537715435028
Epoch 68, Training Loss: 0.19327537715435028, Validation Loss: 0.18883678317070007
Epoch 69, Training Loss: 0.18883678317070007, Validation Loss: 0.18384191393852234
Epoch 70, Training Loss: 0.18384191393852234, Validation Loss: 0.17817485332489014
Epoch 71, Training Loss: 0.17817485332489014, Validation Loss: 0.17185913026332855
Epoch 72, Training Loss: 0.17185914516448975, Validation Loss: 0.16510026156902313
Epoch 73, Training Loss: 0.16510027647018433, Validation Loss: 0.1581147462129593
Epoch 74, Training Loss: 0.1581147313117981, Validation Loss: 0.15112309157848358
Epoch 75, Training Loss: 0.15112309157848358, Validation Loss: 0.14434239268302917
Epoch 76, Training Loss: 0.14434239268302917, Validation Loss: 0.13782797753810883
Epoch 77, Training Loss: 0.13782797753810883, Validation Loss: 0.13164466619491577
Epoch 78, Training Loss: 0.13164466619491577, Validation Loss: 0.12585189938545227
Epoch 79, Training Loss: 0.12585189938545227, Validation Loss: 0.12049585580825806
Epoch 80, Training Loss: 0.12049585580825806, Validation Loss: 0.11537354439496994
Epoch 81, Training Loss: 0.11537353694438934, Validation Loss: 0.11049463599920273
Epoch 82, Training Loss: 0.11049464344978333, Validation Loss: 0.1056964248418808
Epoch 83, Training Loss: 0.1056964248418808, Validation Loss: 0.10098496079444885
Epoch 84, Training Loss: 0.10098496079444885, Validation Loss: 0.09621753543615341
Epoch 85, Training Loss: 0.09621753543615341, Validation Loss: 0.0913836881518364
Epoch 86, Training Loss: 0.0913836881518364, Validation Loss: 0.08655717968940735
Epoch 87, Training Loss: 0.08655717223882675, Validation Loss: 0.08194918930530548
Epoch 88, Training Loss: 0.08194918930530548, Validation Loss: 0.07744559645652771
Epoch 89, Training Loss: 0.07744558900594711, Validation Loss: 0.07293610274791718
Epoch 90, Training Loss: 0.07293610274791718, Validation Loss: 0.06856999546289444
Epoch 91, Training Loss: 0.06856998801231384, Validation Loss: 0.06440459191799164
Epoch 92, Training Loss: 0.06440459191799164, Validation Loss: 0.06038685888051987
Epoch 93, Training Loss: 0.06038685888051987, Validation Loss: 0.056534312665462494
Epoch 94, Training Loss: 0.0565343014895916, Validation Loss: 0.05283860117197037
Epoch 95, Training Loss: 0.052838604897260666, Validation Loss: 0.049184687435626984
Epoch 96, Training Loss: 0.049184687435626984, Validation Loss: 0.045556165277957916
Epoch 97, Training Loss: 0.04555615782737732, Validation Loss: 0.041938431560993195
Epoch 98, Training Loss: 0.0419384241104126, Validation Loss: 0.03831922635436058
Epoch 99, Training Loss: 0.038319215178489685, Validation Loss: 0.03471986949443817
Epoch 100, Training Loss: 0.03471986949443817, Validation Loss: 0.03117690235376358
Epoch 101, Training Loss: 0.03117690235376358, Validation Loss: 0.027758803218603134
Epoch 102, Training Loss: 0.027758797630667686, Validation Loss: 0.024496158584952354
Epoch 103, Training Loss: 0.024496160447597504, Validation Loss: 0.021483056247234344
Epoch 104, Training Loss: 0.021483059972524643, Validation Loss: 0.018745634704828262
Epoch 105, Training Loss: 0.01874563843011856, Validation Loss: 0.016264580190181732
Epoch 106, Training Loss: 0.016264580190181732, Validation Loss: 0.014071227982640266
Epoch 107, Training Loss: 0.014071224257349968, Validation Loss: 0.012155103497207165
Epoch 108, Training Loss: 0.012155103497207165, Validation Loss: 0.010498803108930588
Epoch 109, Training Loss: 0.010498802177608013, Validation Loss: 0.009083155542612076
Epoch 110, Training Loss: 0.009083153679966927, Validation Loss: 0.007892712950706482
Epoch 111, Training Loss: 0.00789271667599678, Validation Loss: 0.006876601837575436
Epoch 112, Training Loss: 0.006876601837575436, Validation Loss: 0.0060296570882201195
Epoch 113, Training Loss: 0.006029660813510418, Validation Loss: 0.005295487120747566
Epoch 114, Training Loss: 0.005295488052070141, Validation Loss: 0.004668877925723791
Epoch 115, Training Loss: 0.00466887978836894, Validation Loss: 0.004100612364709377
Epoch 116, Training Loss: 0.004100614693015814, Validation Loss: 0.003566951025277376
Epoch 117, Training Loss: 0.0035669500939548016, Validation Loss: 0.0030636503361165524
Epoch 118, Training Loss: 0.0030636515002697706, Validation Loss: 0.0025922327768057585
Epoch 119, Training Loss: 0.0025922362692654133, Validation Loss: 0.0021710230503231287
Epoch 120, Training Loss: 0.0021710230503231287, Validation Loss: 0.0017926741857081652
Epoch 121, Training Loss: 0.0017926752334460616, Validation Loss: 0.0014607649063691497
Epoch 122, Training Loss: 0.0014607644407078624, Validation Loss: 0.001182622043415904
Epoch 123, Training Loss: 0.0011826225090771914, Validation Loss: 0.0009597420576028526
Epoch 124, Training Loss: 0.0009597420576028526, Validation Loss: 0.0007904094527475536
Epoch 125, Training Loss: 0.0007904101512394845, Validation Loss: 0.0006688889116048813
Epoch 126, Training Loss: 0.0006688879220746458, Validation Loss: 0.0005859583616256714
Epoch 127, Training Loss: 0.0005859589437022805, Validation Loss: 0.0005308557883836329
Epoch 128, Training Loss: 0.000530856428667903, Validation Loss: 0.000492958293762058
Epoch 129, Training Loss: 0.0004929581191390753, Validation Loss: 0.0004629226168617606
Epoch 130, Training Loss: 0.00046292258775793016, Validation Loss: 0.00043510491377674043
Epoch 131, Training Loss: 0.00043510552495718, Validation Loss: 0.0004063075757585466
Epoch 132, Training Loss: 0.0004063076339662075, Validation Loss: 0.000375760137103498
Epoch 133, Training Loss: 0.00037576048634946346, Validation Loss: 0.0003431835793890059
Epoch 134, Training Loss: 0.00034318334655836225, Validation Loss: 0.0003093474661000073
Epoch 135, Training Loss: 0.0003093483974225819, Validation Loss: 0.0002754128072410822
Epoch 136, Training Loss: 0.0002754121378529817, Validation Loss: 0.00024330191081389785
Epoch 137, Training Loss: 0.00024330170708708465, Validation Loss: 0.00021326294518075883
Epoch 138, Training Loss: 0.00021326314890757203, Validation Loss: 0.00018637694302015007
Epoch 139, Training Loss: 0.000186377321369946, Validation Loss: 0.000163478369358927
Epoch 140, Training Loss: 0.0001634785148780793, Validation Loss: 0.00014504845603369176
Epoch 141, Training Loss: 0.00014504833961836994, Validation Loss: 0.00013114194734953344
Epoch 142, Training Loss: 0.00013114184548612684, Validation Loss: 0.00012102084292564541
Epoch 143, Training Loss: 0.00012102055188734084, Validation Loss: 0.0001141200409620069
Epoch 144, Training Loss: 0.00011411996092647314, Validation Loss: 0.00010978640057146549
Epoch 145, Training Loss: 0.00010978612408507615, Validation Loss: 0.00010666841990314424
Epoch 146, Training Loss: 0.00010666885646060109, Validation Loss: 0.00010379000741522759
Epoch 147, Training Loss: 0.00010378965816926211, Validation Loss: 0.00010050635319203138
Epoch 148, Training Loss: 0.00010050617856904864, Validation Loss: 9.647313709137961e-05
Epoch 149, Training Loss: 9.64730279520154e-05, Validation Loss: 9.159886394627392e-05
Epoch 150, Training Loss: 9.15992641239427e-05, Validation Loss: 8.596622501499951e-05
Epoch 151, Training Loss: 8.596628322266042e-05, Validation Loss: 7.974646723596379e-05
Epoch 152, Training Loss: 7.97463144408539e-05, Validation Loss: 7.314546382986009e-05
Epoch 153, Training Loss: 7.314543472602963e-05, Validation Loss: 6.63427053950727e-05
Epoch 154, Training Loss: 6.63428072584793e-05, Validation Loss: 5.957306711934507e-05
Epoch 155, Training Loss: 5.9572757891146466e-05, Validation Loss: 5.303230864228681e-05
Epoch 156, Training Loss: 5.303223952068947e-05, Validation Loss: 4.688492845161818e-05
Epoch 157, Training Loss: 4.688498665927909e-05, Validation Loss: 4.1248549678130075e-05
Epoch 158, Training Loss: 4.1248764318879694e-05, Validation Loss: 3.6178549635224044e-05
Epoch 159, Training Loss: 3.617852053139359e-05, Validation Loss: 3.166382521158084e-05
Epoch 160, Training Loss: 3.166392707498744e-05, Validation Loss: 2.7638070605462417e-05
Epoch 161, Training Loss: 2.7638101528282277e-05, Validation Loss: 2.400840457994491e-05
Epoch 162, Training Loss: 2.4008228137972765e-05, Validation Loss: 2.0685545678134076e-05
Epoch 163, Training Loss: 2.0685602066805586e-05, Validation Loss: 1.761000748956576e-05
Epoch 164, Training Loss: 1.7609938367968425e-05, Validation Loss: 1.4763181752641685e-05
Epoch 165, Training Loss: 1.4763230865355581e-05, Validation Loss: 1.2163661267550196e-05
Epoch 166, Training Loss: 1.2163763130956795e-05, Validation Loss: 9.849755770119373e-06
Epoch 167, Training Loss: 9.849658454186283e-06, Validation Loss: 7.860441655793693e-06
Epoch 168, Training Loss: 7.860508048906922e-06, Validation Loss: 6.2210506257542875e-06
Epoch 169, Training Loss: 6.221132025530096e-06, Validation Loss: 4.934368007525336e-06
Epoch 170, Training Loss: 4.934440767101478e-06, Validation Loss: 3.982475391239859e-06
Epoch 171, Training Loss: 3.982474481745157e-06, Validation Loss: 3.3316187000309583e-06
Epoch 172, Training Loss: 3.3315968721581157e-06, Validation Loss: 2.9380476007645484e-06
Epoch 173, Training Loss: 2.9380460091488203e-06, Validation Loss: 2.7532830699783517e-06
Epoch 174, Training Loss: 2.753230319285649e-06, Validation Loss: 2.725880904108635e-06
Epoch 175, Training Loss: 2.7258483896730468e-06, Validation Loss: 2.8037202355335467e-06
Epoch 176, Training Loss: 2.8037334232067224e-06, Validation Loss: 2.936238161055371e-06
Epoch 177, Training Loss: 2.936169948952738e-06, Validation Loss: 3.077722794841975e-06
Epoch 178, Training Loss: 3.07775098917773e-06, Validation Loss: 3.1922097605274757e-06
Epoch 179, Training Loss: 3.1922968446451705e-06, Validation Loss: 3.2553762139286846e-06
Epoch 180, Training Loss: 3.255352339692763e-06, Validation Loss: 3.255703177273972e-06
Epoch 181, Training Loss: 3.2557049962633755e-06, Validation Loss: 3.1923352707963204e-06
Epoch 182, Training Loss: 3.1923188998916885e-06, Validation Loss: 3.0714090826222673e-06
Epoch 183, Training Loss: 3.071370429097442e-06, Validation Loss: 2.902247388192336e-06
Epoch 184, Training Loss: 2.902248979808064e-06, Validation Loss: 2.694581326068146e-06
Epoch 185, Training Loss: 2.6945576792059e-06, Validation Loss: 2.457855771353934e-06
Epoch 186, Training Loss: 2.457857362969662e-06, Validation Loss: 2.201233428422711e-06
Epoch 187, Training Loss: 2.2012377485225443e-06, Validation Loss: 1.934762394739664e-06
Epoch 188, Training Loss: 1.9348015030118404e-06, Validation Loss: 1.6695676094968803e-06
Epoch 189, Training Loss: 1.6695624935891828e-06, Validation Loss: 1.4168697362038074e-06
Epoch 190, Training Loss: 1.4168892903398955e-06, Validation Loss: 1.1869803984154714e-06
Epoch 191, Training Loss: 1.1869972240674542e-06, Validation Loss: 9.872826467471896e-07
Epoch 192, Training Loss: 9.87294697551988e-07, Validation Loss: 8.213038995563693e-07
Epoch 193, Training Loss: 8.212940656449064e-07, Validation Loss: 6.887232189001224e-07
Epoch 194, Training Loss: 6.88740556142875e-07, Validation Loss: 5.861332965650945e-07
Epoch 195, Training Loss: 5.861753606950515e-07, Validation Loss: 5.083967380414833e-07
Epoch 196, Training Loss: 5.083933274363517e-07, Validation Loss: 4.497713632645173e-07
Epoch 197, Training Loss: 4.497940153669333e-07, Validation Loss: 4.049222184221435e-07
Epoch 198, Training Loss: 4.0492722064300324e-07, Validation Loss: 3.6922278923157137e-07
Epoch 199, Training Loss: 3.692294399115781e-07, Validation Loss: 3.390878191567026e-07
Epoch 200, Training Loss: 3.391071459191153e-07, Validation Loss: 3.119159259767912e-07
Epoch 201, Training Loss: 3.1191524385576486e-07, Validation Loss: 2.8599589541045134e-07
Epoch 202, Training Loss: 2.8600112500498653e-07, Validation Loss: 2.6073112735502946e-07
Epoch 203, Training Loss: 2.6075412051795865e-07, Validation Loss: 2.3633867840544553e-07
Epoch 204, Training Loss: 2.3634981971554225e-07, Validation Loss: 2.1359983293223195e-07
Epoch 205, Training Loss: 2.136076489023253e-07, Validation Loss: 1.9339682921781787e-07
Epoch 206, Training Loss: 1.933849915758401e-07, Validation Loss: 1.7630324578021828e-07
Epoch 207, Training Loss: 1.7628978810080298e-07, Validation Loss: 1.6230197275035607e-07
Epoch 208, Training Loss: 1.623168657260976e-07, Validation Loss: 1.5074269299475418e-07
Epoch 209, Training Loss: 1.5075697490374296e-07, Validation Loss: 1.4060054809306166e-07
Epoch 210, Training Loss: 1.406221770139382e-07, Validation Loss: 1.3082927807772649e-07
Epoch 211, Training Loss: 1.3084570582577726e-07, Validation Loss: 1.2064496957009396e-07
Epoch 212, Training Loss: 1.2064120369359443e-07, Validation Loss: 1.0966788011046447e-07
Epoch 213, Training Loss: 1.0967490737812113e-07, Validation Loss: 9.809155443463169e-08
Epoch 214, Training Loss: 9.807554590679501e-08, Validation Loss: 8.629841374840908e-08
Epoch 215, Training Loss: 8.629520209524344e-08, Validation Loss: 7.486213604579461e-08
Epoch 216, Training Loss: 7.484972286420088e-08, Validation Loss: 6.432178167870006e-08
Epoch 217, Training Loss: 6.431250199057104e-08, Validation Loss: 5.506681688416393e-08
Epoch 218, Training Loss: 5.5081635252918204e-08, Validation Loss: 4.7421423232663074e-08
Epoch 219, Training Loss: 4.742060966123063e-08, Validation Loss: 4.146515664160688e-08
Epoch 220, Training Loss: 4.14674161675066e-08, Validation Loss: 3.718176344591484e-08
Epoch 221, Training Loss: 3.7179169964929315e-08, Validation Loss: 3.4351685940237076e-08
Epoch 222, Training Loss: 3.435144435570692e-08, Validation Loss: 3.2647623271486736e-08
Epoch 223, Training Loss: 3.2647093917148595e-08, Validation Loss: 3.161909134519192e-08
Epoch 224, Training Loss: 3.162480766150111e-08, Validation Loss: 3.0807740358795854e-08
Epoch 225, Training Loss: 3.080451804748918e-08, Validation Loss: 2.9817122992881195e-08
Epoch 226, Training Loss: 2.981794011702732e-08, Validation Loss: 2.8388063455508927e-08
Epoch 227, Training Loss: 2.8389107953330495e-08, Validation Loss: 2.64242174807805e-08
Epoch 228, Training Loss: 2.641307617068378e-08, Validation Loss: 2.3965412765392102e-08
Epoch 229, Training Loss: 2.3964098261330946e-08, Validation Loss: 2.119180919635255e-08
Epoch 230, Training Loss: 2.1184430210041683e-08, Validation Loss: 1.8260029932548605e-08
Epoch 231, Training Loss: 1.8265829737629247e-08, Validation Loss: 1.53960737492298e-08
Epoch 232, Training Loss: 1.5395341890211967e-08, Validation Loss: 1.2755853262547134e-08
Epoch 233, Training Loss: 1.2753043954205623e-08, Validation Loss: 1.0465667443781967e-08
Epoch 234, Training Loss: 1.0464908939411544e-08, Validation Loss: 8.608548540678385e-09
Epoch 235, Training Loss: 8.6115248265628e-09, Validation Loss: 7.2102563919429485e-09
Epoch 236, Training Loss: 7.213794006588614e-09, Validation Loss: 6.249173623018578e-09
Epoch 237, Training Loss: 6.2490652652513745e-09, Validation Loss: 5.651356715929978e-09
Epoch 238, Training Loss: 5.6531881398314e-09, Validation Loss: 5.309386263974147e-09
Epoch 239, Training Loss: 5.307647654717584e-09, Validation Loss: 5.103840017284256e-09
Epoch 240, Training Loss: 5.105940115157637e-09, Validation Loss: 4.937666275850461e-09
Epoch 241, Training Loss: 4.936442365988114e-09, Validation Loss: 4.730038138944792e-09
Epoch 242, Training Loss: 4.729851177387445e-09, Validation Loss: 4.451450763554021e-09
Epoch 243, Training Loss: 4.45263959036879e-09, Validation Loss: 4.103810624656035e-09
Epoch 244, Training Loss: 4.106117224011996e-09, Validation Loss: 3.718709562505751e-09
Epoch 245, Training Loss: 3.719804908541846e-09, Validation Loss: 3.332589981752676e-09
Epoch 246, Training Loss: 3.3314369041193004e-09, Validation Loss: 2.9753675079291497e-09
Epoch 247, Training Loss: 2.975878654609687e-09, Validation Loss: 2.673680610243423e-09
Epoch 248, Training Loss: 2.6724022994528696e-09, Validation Loss: 2.431047807505138e-09
Epoch 249, Training Loss: 2.4326389791440306e-09, Validation Loss: 2.2492403495277813e-09
Epoch 250, Training Loss: 2.2502204544139204e-09, Validation Loss: 2.1131998373391525e-09
Epoch 251, Training Loss: 2.113597963315783e-09, Validation Loss: 2.0054042870754074e-09
Epoch 252, Training Loss: 2.0042663084751666e-09, Validation Loss: 1.9003691953400903e-09
Epoch 253, Training Loss: 1.8995904849106182e-09, Validation Loss: 1.7819112851924501e-09
Epoch 254, Training Loss: 1.7817803898978468e-09, Validation Loss: 1.6348884468442293e-09
Epoch 255, Training Loss: 1.6342651676382047e-09, Validation Loss: 1.4583232399445478e-09
Epoch 256, Training Loss: 1.4577534734883102e-09, Validation Loss: 1.2571547136630556e-09
Epoch 257, Training Loss: 1.2577716645978398e-09, Validation Loss: 1.047136266585369e-09
Epoch 258, Training Loss: 1.0477928524821323e-09, Validation Loss: 8.441001231318523e-10
Epoch 259, Training Loss: 8.436324971938802e-10, Validation Loss: 6.630962445797195e-10
Epoch 260, Training Loss: 6.627050019858416e-10, Validation Loss: 5.152197557478644e-10
Epoch 261, Training Loss: 5.150800896913665e-10, Validation Loss: 4.036937450990763e-10
Epoch 262, Training Loss: 4.040865420051887e-10, Validation Loss: 3.278097238101907e-10
Epoch 263, Training Loss: 3.2762281776399504e-10, Validation Loss: 2.8088487091793013e-10
Epoch 264, Training Loss: 2.805789767190703e-10, Validation Loss: 2.558694922605298e-10
Epoch 265, Training Loss: 2.563398937560635e-10, Validation Loss: 2.460419645800016e-10
Epoch 266, Training Loss: 2.459762393769438e-10, Validation Loss: 2.430710632772559e-10
Epoch 267, Training Loss: 2.434372148307773e-10, Validation Loss: 2.4355506500484125e-10
Epoch 268, Training Loss: 2.4346144544828974e-10, Validation Loss: 2.430857737323322e-10
Epoch 269, Training Loss: 2.4362895034713006e-10, Validation Loss: 2.4007518195645616e-10
Epoch 270, Training Loss: 2.40048619870592e-10, Validation Loss: 2.3307397678529185e-10
Epoch 271, Training Loss: 2.3295751439000867e-10, Validation Loss: 2.2380235165098128e-10
Epoch 272, Training Loss: 2.2408611077828766e-10, Validation Loss: 2.1311713505056673e-10
Epoch 273, Training Loss: 2.1368933011967073e-10, Validation Loss: 2.0284759982835965e-10
Epoch 274, Training Loss: 2.028038292856138e-10, Validation Loss: 1.9308610266222104e-10
Epoch 275, Training Loss: 1.9284578101075311e-10, Validation Loss: 1.8367950216369167e-10
Epoch 276, Training Loss: 1.8286527847521938e-10, Validation Loss: 1.729832665997577e-10
Epoch 277, Training Loss: 1.728931858790972e-10, Validation Loss: 1.6193694996058383e-10
Epoch 278, Training Loss: 1.618660483426737e-10, Validation Loss: 1.4945120141440782e-10
Epoch 279, Training Loss: 1.4902754030821086e-10, Validation Loss: 1.3561454736965572e-10
Epoch 280, Training Loss: 1.3540177312698631e-10, Validation Loss: 1.2033825325108438e-10
Epoch 281, Training Loss: 1.2038407770642578e-10, Validation Loss: 1.0412700562900667e-10
Epoch 282, Training Loss: 1.0388438720365656e-10, Validation Loss: 8.762850861598892e-11
Epoch 283, Training Loss: 8.759985792305969e-11, Validation Loss: 7.182377609327162e-11
Epoch 284, Training Loss: 7.173030919238599e-11, Validation Loss: 5.7117404556050744e-11
Epoch 285, Training Loss: 5.7141274351080185e-11, Validation Loss: 4.4202443788554646e-11
Epoch 286, Training Loss: 4.3982512076823355e-11, Validation Loss: 3.32824566517953e-11
Epoch 287, Training Loss: 3.323850569780795e-11, Validation Loss: 2.5007293111278805e-11
Epoch 288, Training Loss: 2.5026033328989783e-11, Validation Loss: 1.9107571427867676e-11
Epoch 289, Training Loss: 1.9130315387361208e-11, Validation Loss: 1.578441197191971e-11
Epoch 290, Training Loss: 1.56849429278072e-11, Validation Loss: 1.4139736256857383e-11
Epoch 291, Training Loss: 1.4043491196324975e-11, Validation Loss: 1.3671994092412376e-11
Epoch 292, Training Loss: 1.3761223063846195e-11, Validation Loss: 1.4277926063677171e-11
Epoch 293, Training Loss: 1.4207607312854975e-11, Validation Loss: 1.469246772856092e-11
Epoch 294, Training Loss: 1.482341333014503e-11, Validation Loss: 1.5190040197898824e-11
Epoch 295, Training Loss: 1.5291134677908325e-11, Validation Loss: 1.5417443363641148e-11
Epoch 296, Training Loss: 1.543017102978439e-11, Validation Loss: 1.5271566997099306e-11
Epoch 297, Training Loss: 1.5177808662669712e-11, Validation Loss: 1.4560228023263733e-11
Epoch 298, Training Loss: 1.4712831647445412e-11, Validation Loss: 1.3840616153171226e-11
Epoch 299, Training Loss: 1.3931890363583221e-11, Validation Loss: 1.2816535159554387e-11
Epoch 300, Training Loss: 1.285768193304282e-11, Validation Loss: 1.1786828457704956e-11
Epoch 301, Training Loss: 1.165507967915147e-11, Validation Loss: 1.0525941229744262e-11
Epoch 302, Training Loss: 1.0616041032363022e-11, Validation Loss: 9.504607170751633e-12
Epoch 303, Training Loss: 9.550759488829996e-12, Validation Loss: 8.530003092754868e-12
Epoch 304, Training Loss: 8.48062765845814e-12, Validation Loss: 7.626685741279893e-12
Epoch 305, Training Loss: 7.615223555912376e-12, Validation Loss: 6.858495542327869e-12
Epoch 306, Training Loss: 6.8121007966437386e-12, Validation Loss: 6.106422659191146e-12
Epoch 307, Training Loss: 6.140308747570877e-12, Validation Loss: 5.572312576640481e-12
Epoch 308, Training Loss: 5.565764862880407e-12, Validation Loss: 5.0169464936578034e-12
Epoch 309, Training Loss: 5.062894114366001e-12, Validation Loss: 4.567469666372226e-12
Epoch 310, Training Loss: 4.561426757143661e-12, Validation Loss: 4.226174965538121e-12
Epoch 311, Training Loss: 4.112555348351199e-12, Validation Loss: 3.816913365234376e-12
Epoch 312, Training Loss: 3.76056911305378e-12, Validation Loss: 3.4623371877873232e-12
Epoch 313, Training Loss: 3.48224183863155e-12, Validation Loss: 3.1774043032090082e-12
Epoch 314, Training Loss: 3.1874520384223004e-12, Validation Loss: 2.9074182297805784e-12
Epoch 315, Training Loss: 2.8341734341352787e-12, Validation Loss: 2.5072652287683184e-12
Epoch 316, Training Loss: 2.5157460750019345e-12, Validation Loss: 2.201003268531565e-12
Epoch 317, Training Loss: 2.1770922738195697e-12, Validation Loss: 1.8718841580944723e-12
Epoch 318, Training Loss: 1.8738209768554004e-12, Validation Loss: 1.5683135129104797e-12
Epoch 319, Training Loss: 1.5724043161274848e-12, Validation Loss: 1.25251230827933e-12
Epoch 320, Training Loss: 1.2725821915346436e-12, Validation Loss: 9.97216415346558e-13
Epoch 321, Training Loss: 9.843712216878187e-13, Validation Loss: 8.037960488177509e-13
Epoch 322, Training Loss: 8.201634900742438e-13, Validation Loss: 6.103979084334799e-13
Epoch 323, Training Loss: 6.105084970550734e-13, Validation Loss: 5.126471621340334e-13
Epoch 324, Training Loss: 5.092941042852961e-13, Validation Loss: 4.3776657646099615e-13
Epoch 325, Training Loss: 4.3301828594154157e-13, Validation Loss: 4.0800324815730427e-13
Epoch 326, Training Loss: 3.9930309492924865e-13, Validation Loss: 3.797162779518859e-13
Epoch 327, Training Loss: 3.76680295028492e-13, Validation Loss: 3.6167678010498583e-13
Epoch 328, Training Loss: 3.583189246616353e-13, Validation Loss: 3.7353331690768987e-13
Epoch 329, Training Loss: 3.6286194860478405e-13, Validation Loss: 3.8698457958084853e-13
Epoch 330, Training Loss: 3.764696887564867e-13, Validation Loss: 3.804058305335867e-13
Epoch 331, Training Loss: 3.873846501824957e-13, Validation Loss: 3.557680408952657e-13
Epoch 332, Training Loss: 3.4899768621907135e-13, Validation Loss: 3.4116782207486984e-13
Epoch 333, Training Loss: 3.5500039865209165e-13, Validation Loss: 3.1549047228851546e-13
Epoch 334, Training Loss: 3.0804113600180205e-13, Validation Loss: 2.976448297900558e-13
Epoch 335, Training Loss: 2.9711796174433647e-13, Validation Loss: 2.7659794485206113e-13
Epoch 336, Training Loss: 2.7084809547071875e-13, Validation Loss: 2.439751688437103e-13
Epoch 337, Training Loss: 2.446500846960825e-13, Validation Loss: 2.3533367095318614e-13
Epoch 338, Training Loss: 2.2270900401633043e-13, Validation Loss: 2.178900506202841e-13
Epoch 339, Training Loss: 2.0865579229700781e-13, Validation Loss: 1.9006923313892587e-13
Epoch 340, Training Loss: 1.8469492428507817e-13, Validation Loss: 1.8335208568434624e-13
Epoch 341, Training Loss: 1.672689628950605e-13, Validation Loss: 1.6317191196303649e-13
Epoch 342, Training Loss: 1.5318004026668164e-13, Validation Loss: 1.4851092361087281e-13
Epoch 343, Training Loss: 1.4496100175266646e-13, Validation Loss: 1.2237623024310973e-13
Epoch 344, Training Loss: 1.3845477227821673e-13, Validation Loss: 1.206379017949094e-13
Epoch 345, Training Loss: 1.2291251729520253e-13, Validation Loss: 1.365527564070254e-13
Epoch 346, Training Loss: 1.1157631622012859e-13, Validation Loss: 1.1531121652148812e-13
Epoch 347, Training Loss: 9.815938209825625e-14, Validation Loss: 1.0435336134703016e-13
Epoch 348, Training Loss: 9.563203907155676e-14, Validation Loss: 8.806994575890487e-14
Epoch 349, Training Loss: 8.668418630466967e-14, Validation Loss: 6.882171156748218e-14
Epoch 350, Training Loss: 7.529963658896646e-14, Validation Loss: 7.311688689400075e-14
Epoch 351, Training Loss: 7.086814316804857e-14, Validation Loss: 5.381652290687225e-14
Epoch 352, Training Loss: 6.382444079537988e-14, Validation Loss: 5.64104833808074e-14
Epoch 353, Training Loss: 5.608323728383338e-14, Validation Loss: 5.710116082226213e-14
Epoch 354, Training Loss: 5.047147798981598e-14, Validation Loss: 4.797068436381523e-14
Epoch 355, Training Loss: 4.03972170927476e-14, Validation Loss: 4.300222965257852e-14
Epoch 356, Training Loss: 3.4538981375474564e-14, Validation Loss: 3.223826031974707e-14
Epoch 357, Training Loss: 2.8766834698828667e-14, Validation Loss: 2.6173097841591594e-14
Epoch 358, Training Loss: 2.543667045658976e-14, Validation Loss: 2.3630896162931368e-14
Epoch 359, Training Loss: 2.1084178104596382e-14, Validation Loss: 2.164485462337242e-14
Epoch 360, Training Loss: 1.8676527609607502e-14, Validation Loss: 1.7483400388236883e-14
Epoch 361, Training Loss: 1.699717128926092e-14, Validation Loss: 1.5133392179374552e-14
Epoch 362, Training Loss: 1.1092678255705379e-14, Validation Loss: 1.540826453515394e-14
Epoch 363, Training Loss: 1.4557426715900573e-14, Validation Loss: 1.3263856633578645e-14
Epoch 364, Training Loss: 1.2788587293907205e-14, Validation Loss: 1.1669500916521979e-14
Epoch 365, Training Loss: 9.326295229259048e-15, Validation Loss: 1.1633035301109734e-14
Epoch 366, Training Loss: 1.0077214500955455e-14, Validation Loss: 1.3634328515916942e-14
Epoch 367, Training Loss: 1.0366768478809602e-14, Validation Loss: 8.986533373456403e-15
Epoch 368, Training Loss: 1.0285886996742183e-14, Validation Loss: 9.74099408990528e-15
Epoch 369, Training Loss: 9.811151287827512e-15, Validation Loss: 6.464715542671851e-15
Epoch 370, Training Loss: 8.50035001425959e-15, Validation Loss: 7.776274910727566e-15
Epoch 371, Training Loss: 6.393745193120255e-15, Validation Loss: 4.920088706432011e-15
Epoch 372, Training Loss: 6.823884617361987e-15, Validation Loss: 4.6298117859573835e-15
Epoch 373, Training Loss: 6.05836546227023e-15, Validation Loss: 4.670903048294584e-15
Epoch 374, Training Loss: 5.5425744899186176e-15, Validation Loss: 2.894003896049854e-15
Epoch 375, Training Loss: 6.003287991907967e-15, Validation Loss: 3.274522647933771e-15
Epoch 376, Training Loss: 4.862924146887713e-15, Validation Loss: 4.361110065198744e-15
Epoch 377, Training Loss: 4.791222384386163e-15, Validation Loss: 5.739393183124995e-15
Epoch 378, Training Loss: 3.5005156969424283e-15, Validation Loss: 5.580042568823938e-15
Epoch 379, Training Loss: 3.690829177113893e-15, Validation Loss: 5.31817174526843e-15
Epoch 380, Training Loss: 2.225060261230481e-15, Validation Loss: 4.254063311874166e-15
Epoch 381, Training Loss: 1.6907653247505059e-15, Validation Loss: 4.1667490380888246e-15
Epoch 382, Training Loss: 2.141793534383594e-15, Validation Loss: 3.8999628823404e-15
Epoch 383, Training Loss: 2.038721906680481e-15, Validation Loss: 3.789663522498366e-15
Epoch 384, Training Loss: 1.8797056586353526e-15, Validation Loss: 3.883338590201114e-15
Epoch 385, Training Loss: 2.873123898625325e-15, Validation Loss: 4.1030699481471936e-15
Epoch 386, Training Loss: 2.2797762602825037e-15, Validation Loss: 5.9922202359026684e-15
Epoch 387, Training Loss: 1.2649630268360716e-15, Validation Loss: 4.953554554661555e-15
Epoch 388, Training Loss: 2.4786911482750987e-15, Validation Loss: 5.193524494332856e-15
Epoch 389, Training Loss: 2.8481872486581586e-15, Validation Loss: 7.122537423135539e-15
Epoch 390, Training Loss: 2.980098654149386e-15, Validation Loss: 5.0175944806387165e-15
Epoch 391, Training Loss: 3.736365668358284e-15, Validation Loss: 5.415821938592642e-15
Epoch 392, Training Loss: 1.854190696923448e-15, Validation Loss: 8.569405222317444e-15
Epoch 393, Training Loss: 4.039291755350734e-15, Validation Loss: 8.739985799433199e-15
Epoch 394, Training Loss: 3.754219005304036e-15, Validation Loss: 9.154151029322662e-15
Epoch 395, Training Loss: 3.258738612478161e-15, Validation Loss: 9.365209616921805e-15
Epoch 396, Training Loss: 3.3004441854603576e-15, Validation Loss: 1.0073555318623317e-14
Epoch 397, Training Loss: 3.291842777639227e-15, Validation Loss: 6.1460685241783615e-15
Epoch 398, Training Loss: 3.231199877297029e-15, Validation Loss: 7.110719619455447e-15
Epoch 399, Training Loss: 3.5198144956126703e-15, Validation Loss: 6.502843036726609e-15
Epoch 400, Training Loss: 3.065316944906747e-15, Validation Loss: 3.2915808327002886e-15
Epoch 401, Training Loss: 3.3654241062507344e-15, Validation Loss: 5.633457737027215e-15
Epoch 402, Training Loss: 3.0786164209698234e-15, Validation Loss: 6.3373217874048045e-15
Epoch 403, Training Loss: 3.171135076941332e-15, Validation Loss: 6.695831023429029e-15
Epoch 404, Training Loss: 3.561447859036114e-15, Validation Loss: 5.664718758495056e-15
Epoch 405, Training Loss: 5.678967123217294e-15, Validation Loss: 6.954919343752806e-15
Epoch 406, Training Loss: 5.187389858212366e-15, Validation Loss: 7.640135540280119e-15
Epoch 407, Training Loss: 2.5269743556091987e-15, Validation Loss: 4.5340403117101816e-15
Epoch 408, Training Loss: 2.2228194355685196e-15, Validation Loss: 7.507862875236887e-15
Epoch 409, Training Loss: 2.974533012411215e-15, Validation Loss: 8.198860495145684e-15
Epoch 410, Training Loss: 2.1881249660489835e-15, Validation Loss: 7.985562352434e-15
Epoch 411, Training Loss: 2.073055116648013e-15, Validation Loss: 5.250987209474587e-15
Epoch 412, Training Loss: 2.558777689921519e-15, Validation Loss: 4.724607054732875e-15
Epoch 413, Training Loss: 2.506735985642215e-15, Validation Loss: 4.455119710915657e-15
Epoch 414, Training Loss: 1.5005962636965484e-15, Validation Loss: 4.677308734958195e-15
Epoch 415, Training Loss: 1.4526022122348173e-15, Validation Loss: 3.398600692728791e-15
Epoch 416, Training Loss: 1.46062530831121e-15, Validation Loss: 4.8955226333792685e-15
Epoch 417, Training Loss: 2.5592835803492668e-15, Validation Loss: 5.389195881412177e-15
Epoch 418, Training Loss: 3.672397740181639e-15, Validation Loss: 2.9121551768348033e-15
Epoch 419, Training Loss: 2.2673441459574156e-15, Validation Loss: 4.713810349270698e-15
Epoch 420, Training Loss: 1.5607333794901172e-15, Validation Loss: 3.2269352781658404e-15
Epoch 421, Training Loss: 3.0437773205745436e-15, Validation Loss: 4.134195867859947e-15
Epoch 422, Training Loss: 3.577494051188899e-15, Validation Loss: 8.395832924831988e-15
Epoch 423, Training Loss: 5.413409588758862e-15, Validation Loss: 9.095505009153616e-15
Epoch 424, Training Loss: 5.96852110107144e-15, Validation Loss: 9.095505009153616e-15
Epoch 425, Training Loss: 4.182984965621795e-15, Validation Loss: 7.13382159605886e-15
Epoch 426, Training Loss: 3.42144114790974e-15, Validation Loss: 5.238636198554199e-15
Epoch 427, Training Loss: 2.6408155837201767e-15, Validation Loss: 4.588114895062896e-15
Epoch 428, Training Loss: 2.066116222744106e-15, Validation Loss: 4.437049533535407e-15
Epoch 429, Training Loss: 1.2895382054929974e-15, Validation Loss: 4.4601790387096066e-15
Epoch 430, Training Loss: 2.101967103994881e-15, Validation Loss: 4.602426363739705e-15
Epoch 431, Training Loss: 2.616601664615255e-15, Validation Loss: 6.025622556661168e-15
Epoch 432, Training Loss: 2.541430455161751e-15, Validation Loss: 9.078012931759867e-15
Epoch 433, Training Loss: 1.4919226463166644e-15, Validation Loss: 9.003419822292864e-15
Epoch 434, Training Loss: 2.4379251465896437e-15, Validation Loss: 9.003419822292864e-15
Epoch 435, Training Loss: 1.5781528238086387e-15, Validation Loss: 9.003419822292864e-15
Epoch 436, Training Loss: 2.133264336121217e-15, Validation Loss: 9.51227317128999e-15
Epoch 437, Training Loss: 2.9780024593631686e-15, Validation Loss: 9.51227317128999e-15
Epoch 438, Training Loss: 3.4001185757702706e-15, Validation Loss: 9.796767821350187e-15
Epoch 439, Training Loss: 2.9097699320553352e-15, Validation Loss: 7.168660908212377e-15
Epoch 440, Training Loss: 2.9490180506993105e-15, Validation Loss: 4.115005489406954e-15
Epoch 441, Training Loss: 2.0886676279318044e-15, Validation Loss: 7.012607793174981e-15
Epoch 442, Training Loss: 1.6492042767649344e-15, Validation Loss: 6.0069742792944174e-15
Epoch 443, Training Loss: 1.4774666526432305e-15, Validation Loss: 8.491242716010712e-15
Epoch 444, Training Loss: 2.3043514389394296e-15, Validation Loss: 5.292846307178474e-15
Epoch 445, Training Loss: 2.2841130689724458e-15, Validation Loss: 7.41152219484913e-15
Epoch 446, Training Loss: 1.422533707277592e-15, Validation Loss: 7.74574530220968e-15
Epoch 447, Training Loss: 1.3994040962242741e-15, Validation Loss: 8.19388248251467e-15
Epoch 448, Training Loss: 1.2617826298773685e-15, Validation Loss: 1.0021124826221223e-14
Epoch 449, Training Loss: 1.3485188036762089e-15, Validation Loss: 7.296343501714438e-15
Epoch 450, Training Loss: 2.039517058859716e-15, Validation Loss: 7.16464936017418e-15
Epoch 451, Training Loss: 1.1860331086791269e-15, Validation Loss: 6.655796858210002e-15
Epoch 452, Training Loss: 1.2166798195019715e-15, Validation Loss: 6.17141174996021e-15
Epoch 453, Training Loss: 3.29834799067414e-15, Validation Loss: 9.779637427024916e-15
Epoch 454, Training Loss: 1.1964414495349877e-15, Validation Loss: 1.0644107394531394e-14
Epoch 455, Training Loss: 7.75481850738243e-16, Validation Loss: 8.958533852351964e-15
Epoch 456, Training Loss: 1.5011744695621679e-15, Validation Loss: 9.857843979044906e-15
Epoch 457, Training Loss: 1.535868939081704e-15, Validation Loss: 1.0135399735201195e-14
Epoch 458, Training Loss: 1.797812183954202e-15, Validation Loss: 1.2739653353511377e-14
Epoch 459, Training Loss: 3.2688576915825343e-15, Validation Loss: 9.98650320153515e-15
Epoch 460, Training Loss: 3.1329711604698423e-15, Validation Loss: 9.133740923425622e-15
Epoch 461, Training Loss: 2.8265032052084485e-15, Validation Loss: 1.09826317351981e-14
Epoch 462, Training Loss: 2.343093667155657e-15, Validation Loss: 1.177474984241601e-14
Epoch 463, Training Loss: 4.228738297300683e-15, Validation Loss: 8.808371851462722e-15
Epoch 464, Training Loss: 4.227654095128198e-15, Validation Loss: 9.178446475348757e-15
Epoch 465, Training Loss: 4.27225080331761e-15, Validation Loss: 9.311441659495996e-15
Epoch 466, Training Loss: 3.402576030108492e-15, Validation Loss: 6.838738187125038e-15
Epoch 467, Training Loss: 2.8405256238920066e-15, Validation Loss: 7.81018333367205e-15
Epoch 468, Training Loss: 3.554653384249713e-15, Validation Loss: 1.1324661098200545e-14
Epoch 469, Training Loss: 6.142970924690253e-16, Validation Loss: 7.402703734835266e-15
Epoch 470, Training Loss: 1.3694801162636742e-15, Validation Loss: 8.01419376011709e-15
Epoch 471, Training Loss: 2.7057955045105535e-15, Validation Loss: 8.01419376011709e-15
Epoch 472, Training Loss: 2.7057955045105535e-15, Validation Loss: 7.977764567121577e-15
Epoch 473, Training Loss: 1.974320297634842e-15, Validation Loss: 7.998581248833299e-15
Epoch 474, Training Loss: 4.209222658195944e-15, Validation Loss: 8.472739281277942e-15
Epoch 475, Training Loss: 3.1822661486594376e-15, Validation Loss: 9.566338437280286e-15
Epoch 476, Training Loss: 1.4805024187261899e-15, Validation Loss: 6.484312496939527e-15
Epoch 477, Training Loss: 2.2033037964637806e-15, Validation Loss: 7.728687752717872e-15
Epoch 478, Training Loss: 2.7160592144906707e-15, Validation Loss: 9.327777536916743e-15
Epoch 479, Training Loss: 9.51845439422258e-16, Validation Loss: 5.9161541361403905e-15
Epoch 480, Training Loss: 8.853476355904014e-16, Validation Loss: 5.9161541361403905e-15
Epoch 481, Training Loss: 8.853476355904014e-16, Validation Loss: 5.9161541361403905e-15
Epoch 482, Training Loss: 8.853476355904014e-16, Validation Loss: 5.9161541361403905e-15
Epoch 483, Training Loss: 8.622180245370834e-16, Validation Loss: 5.738128139418271e-15
Epoch 484, Training Loss: 1.86835774648275e-15, Validation Loss: 5.27820957784992e-15
Epoch 485, Training Loss: 2.3141816798087893e-15, Validation Loss: 5.27820957784992e-15
Epoch 486, Training Loss: 2.3141816798087893e-15, Validation Loss: 5.162561628462448e-15
Epoch 487, Training Loss: 2.7160592144906707e-15, Validation Loss: 5.007448296480031e-15
Epoch 488, Training Loss: 2.6033021885521783e-15, Validation Loss: 9.488817981947572e-15
Epoch 489, Training Loss: 1.3931879331826116e-15, Validation Loss: 6.403900694641361e-15
Epoch 490, Training Loss: 3.3823376601415083e-15, Validation Loss: 6.432812893746465e-15
Epoch 491, Training Loss: 3.1701230843276e-15, Validation Loss: 4.033111802967566e-15
Epoch 492, Training Loss: 3.3551601845123805e-15, Validation Loss: 4.18316538363956e-15
Epoch 493, Training Loss: 2.5889907198753696e-15, Validation Loss: 4.908424639231846e-15
Epoch 494, Training Loss: 1.3971633764414313e-15, Validation Loss: 4.908424639231846e-15
Epoch 495, Training Loss: 1.781693782242663e-15, Validation Loss: 4.26108352094101e-15
Epoch 496, Training Loss: 1.6255686694047504e-15, Validation Loss: 4.6058598117914e-15
Epoch 497, Training Loss: 2.114182377885472e-15, Validation Loss: 5.380703105566532e-15
Epoch 498, Training Loss: 1.4954644087064898e-15, Validation Loss: 4.571743442258365e-15
Epoch 499, Training Loss: 1.3821290710232595e-15, Validation Loss: 7.566924788583035e-15
Epoch 500, Training Loss: 1.3896462766719046e-15, Validation Loss: 7.511268794717797e-15
