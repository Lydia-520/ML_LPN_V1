Epoch 1, Training Loss: 0.5313335061073303, Validation Loss: 0.529883086681366
Epoch 2, Training Loss: 0.5298831462860107, Validation Loss: 0.5284286141395569
Epoch 3, Training Loss: 0.5284286141395569, Validation Loss: 0.5269831418991089
Epoch 4, Training Loss: 0.5269831418991089, Validation Loss: 0.5255379676818848
Epoch 5, Training Loss: 0.5255379676818848, Validation Loss: 0.5241135954856873
Epoch 6, Training Loss: 0.5241135358810425, Validation Loss: 0.522678554058075
Epoch 7, Training Loss: 0.522678554058075, Validation Loss: 0.521210789680481
Epoch 8, Training Loss: 0.5212107300758362, Validation Loss: 0.5197327733039856
Epoch 9, Training Loss: 0.5197327733039856, Validation Loss: 0.5182608366012573
Epoch 10, Training Loss: 0.5182608366012573, Validation Loss: 0.5168004035949707
Epoch 11, Training Loss: 0.5168004631996155, Validation Loss: 0.5153213739395142
Epoch 12, Training Loss: 0.5153214335441589, Validation Loss: 0.5138246417045593
Epoch 13, Training Loss: 0.5138246417045593, Validation Loss: 0.5123011469841003
Epoch 14, Training Loss: 0.5123011469841003, Validation Loss: 0.5107452273368835
Epoch 15, Training Loss: 0.5107451677322388, Validation Loss: 0.5092016458511353
Epoch 16, Training Loss: 0.5092015862464905, Validation Loss: 0.507622241973877
Epoch 17, Training Loss: 0.5076223015785217, Validation Loss: 0.5059979557991028
Epoch 18, Training Loss: 0.5059979557991028, Validation Loss: 0.5043314099311829
Epoch 19, Training Loss: 0.5043314099311829, Validation Loss: 0.5026209354400635
Epoch 20, Training Loss: 0.5026209354400635, Validation Loss: 0.5008312463760376
Epoch 21, Training Loss: 0.5008312463760376, Validation Loss: 0.49906274676322937
Epoch 22, Training Loss: 0.49906277656555176, Validation Loss: 0.497244268655777
Epoch 23, Training Loss: 0.497244268655777, Validation Loss: 0.495366632938385
Epoch 24, Training Loss: 0.495366632938385, Validation Loss: 0.49339449405670166
Epoch 25, Training Loss: 0.4933944642543793, Validation Loss: 0.491354376077652
Epoch 26, Training Loss: 0.491354376077652, Validation Loss: 0.48926934599876404
Epoch 27, Training Loss: 0.48926934599876404, Validation Loss: 0.4871768355369568
Epoch 28, Training Loss: 0.4871768057346344, Validation Loss: 0.4850742816925049
Epoch 29, Training Loss: 0.4850742816925049, Validation Loss: 0.4828844666481018
Epoch 30, Training Loss: 0.4828844666481018, Validation Loss: 0.48060858249664307
Epoch 31, Training Loss: 0.48060858249664307, Validation Loss: 0.4782209098339081
Epoch 32, Training Loss: 0.4782209098339081, Validation Loss: 0.4757285714149475
Epoch 33, Training Loss: 0.4757285714149475, Validation Loss: 0.47309252619743347
Epoch 34, Training Loss: 0.47309252619743347, Validation Loss: 0.47037073969841003
Epoch 35, Training Loss: 0.47037073969841003, Validation Loss: 0.4674791395664215
Epoch 36, Training Loss: 0.4674791395664215, Validation Loss: 0.46435776352882385
Epoch 37, Training Loss: 0.46435776352882385, Validation Loss: 0.4609983265399933
Epoch 38, Training Loss: 0.4609982967376709, Validation Loss: 0.4573892652988434
Epoch 39, Training Loss: 0.4573892652988434, Validation Loss: 0.45354658365249634
Epoch 40, Training Loss: 0.4535466134548187, Validation Loss: 0.4494459629058838
Epoch 41, Training Loss: 0.4494459629058838, Validation Loss: 0.44504860043525696
Epoch 42, Training Loss: 0.44504860043525696, Validation Loss: 0.4403161108493805
Epoch 43, Training Loss: 0.4403160810470581, Validation Loss: 0.4352604150772095
Epoch 44, Training Loss: 0.4352603852748871, Validation Loss: 0.42985785007476807
Epoch 45, Training Loss: 0.42985785007476807, Validation Loss: 0.42408183217048645
Epoch 46, Training Loss: 0.42408183217048645, Validation Loss: 0.4178909361362457
Epoch 47, Training Loss: 0.4178909361362457, Validation Loss: 0.41127723455429077
Epoch 48, Training Loss: 0.41127723455429077, Validation Loss: 0.4042547941207886
Epoch 49, Training Loss: 0.4042547941207886, Validation Loss: 0.3966898024082184
Epoch 50, Training Loss: 0.3966898024082184, Validation Loss: 0.38859081268310547
Epoch 51, Training Loss: 0.38859081268310547, Validation Loss: 0.37994301319122314
Epoch 52, Training Loss: 0.37994304299354553, Validation Loss: 0.37078285217285156
Epoch 53, Training Loss: 0.3707828223705292, Validation Loss: 0.3611154556274414
Epoch 54, Training Loss: 0.3611154556274414, Validation Loss: 0.350885808467865
Epoch 55, Training Loss: 0.350885808467865, Validation Loss: 0.340133398771286
Epoch 56, Training Loss: 0.340133398771286, Validation Loss: 0.32893505692481995
Epoch 57, Training Loss: 0.32893499732017517, Validation Loss: 0.317272424697876
Epoch 58, Training Loss: 0.3172723948955536, Validation Loss: 0.30520638823509216
Epoch 59, Training Loss: 0.30520638823509216, Validation Loss: 0.29282644391059875
Epoch 60, Training Loss: 0.29282644391059875, Validation Loss: 0.2802905738353729
Epoch 61, Training Loss: 0.2802905738353729, Validation Loss: 0.26763463020324707
Epoch 62, Training Loss: 0.26763463020324707, Validation Loss: 0.255098819732666
Epoch 63, Training Loss: 0.255098819732666, Validation Loss: 0.24293464422225952
Epoch 64, Training Loss: 0.24293464422225952, Validation Loss: 0.23137716948986053
Epoch 65, Training Loss: 0.23137721419334412, Validation Loss: 0.2206103354692459
Epoch 66, Training Loss: 0.2206103503704071, Validation Loss: 0.21079698204994202
Epoch 67, Training Loss: 0.21079698204994202, Validation Loss: 0.2023434191942215
Epoch 68, Training Loss: 0.2023434042930603, Validation Loss: 0.1954207867383957
Epoch 69, Training Loss: 0.1954207718372345, Validation Loss: 0.1900729089975357
Epoch 70, Training Loss: 0.1900729089975357, Validation Loss: 0.18621090054512024
Epoch 71, Training Loss: 0.18621090054512024, Validation Loss: 0.18352162837982178
Epoch 72, Training Loss: 0.18352164328098297, Validation Loss: 0.18147116899490356
Epoch 73, Training Loss: 0.18147116899490356, Validation Loss: 0.17953947186470032
Epoch 74, Training Loss: 0.17953942716121674, Validation Loss: 0.17705589532852173
Epoch 75, Training Loss: 0.17705588042736053, Validation Loss: 0.17387141287326813
Epoch 76, Training Loss: 0.17387141287326813, Validation Loss: 0.16992340981960297
Epoch 77, Training Loss: 0.16992338001728058, Validation Loss: 0.16526086628437042
Epoch 78, Training Loss: 0.16526086628437042, Validation Loss: 0.16011179983615875
Epoch 79, Training Loss: 0.16011181473731995, Validation Loss: 0.15477527678012848
Epoch 80, Training Loss: 0.15477527678012848, Validation Loss: 0.14952269196510315
Epoch 81, Training Loss: 0.14952269196510315, Validation Loss: 0.1445821076631546
Epoch 82, Training Loss: 0.1445821076631546, Validation Loss: 0.14004050195217133
Epoch 83, Training Loss: 0.14004051685333252, Validation Loss: 0.13594016432762146
Epoch 84, Training Loss: 0.13594017922878265, Validation Loss: 0.1322825849056244
Epoch 85, Training Loss: 0.132282555103302, Validation Loss: 0.12898357212543488
Epoch 86, Training Loss: 0.12898357212543488, Validation Loss: 0.12594573199748993
Epoch 87, Training Loss: 0.12594573199748993, Validation Loss: 0.12302999198436737
Epoch 88, Training Loss: 0.12302999198436737, Validation Loss: 0.12014172226190567
Epoch 89, Training Loss: 0.12014172971248627, Validation Loss: 0.11720709502696991
Epoch 90, Training Loss: 0.11720708012580872, Validation Loss: 0.11419600248336792
Epoch 91, Training Loss: 0.11419600248336792, Validation Loss: 0.11109483987092972
Epoch 92, Training Loss: 0.11109483987092972, Validation Loss: 0.10789071768522263
Epoch 93, Training Loss: 0.10789071768522263, Validation Loss: 0.10463768243789673
Epoch 94, Training Loss: 0.10463767498731613, Validation Loss: 0.10133484750986099
Epoch 95, Training Loss: 0.10133486241102219, Validation Loss: 0.09801805019378662
Epoch 96, Training Loss: 0.09801804274320602, Validation Loss: 0.0946933925151825
Epoch 97, Training Loss: 0.0946933776140213, Validation Loss: 0.0914028063416481
Epoch 98, Training Loss: 0.0914028063416481, Validation Loss: 0.0882442370057106
Epoch 99, Training Loss: 0.0882442519068718, Validation Loss: 0.08512985706329346
Epoch 100, Training Loss: 0.08512987196445465, Validation Loss: 0.08200418949127197
Epoch 101, Training Loss: 0.08200418204069138, Validation Loss: 0.0788387581706047
Epoch 102, Training Loss: 0.0788387581706047, Validation Loss: 0.0756208524107933
Epoch 103, Training Loss: 0.0756208524107933, Validation Loss: 0.07229579240083694
Epoch 104, Training Loss: 0.07229579985141754, Validation Loss: 0.06889766454696655
Epoch 105, Training Loss: 0.06889766454696655, Validation Loss: 0.0654480829834938
Epoch 106, Training Loss: 0.0654480829834938, Validation Loss: 0.06199648976325989
Epoch 107, Training Loss: 0.06199648603796959, Validation Loss: 0.05844572186470032
Epoch 108, Training Loss: 0.05844571441411972, Validation Loss: 0.05485003814101219
Epoch 109, Training Loss: 0.054850030690431595, Validation Loss: 0.05125340446829796
Epoch 110, Training Loss: 0.05125339329242706, Validation Loss: 0.047721005976200104
Epoch 111, Training Loss: 0.0477210134267807, Validation Loss: 0.04426068812608719
Epoch 112, Training Loss: 0.04426069185137749, Validation Loss: 0.040952637791633606
Epoch 113, Training Loss: 0.040952637791633606, Validation Loss: 0.03773890808224678
Epoch 114, Training Loss: 0.03773890808224678, Validation Loss: 0.034638967365026474
Epoch 115, Training Loss: 0.034638967365026474, Validation Loss: 0.03168727084994316
Epoch 116, Training Loss: 0.03168727084994316, Validation Loss: 0.02886052615940571
Epoch 117, Training Loss: 0.028860528022050858, Validation Loss: 0.026191608980298042
Epoch 118, Training Loss: 0.026191607117652893, Validation Loss: 0.023704981431365013
Epoch 119, Training Loss: 0.023704983294010162, Validation Loss: 0.021422479301691055
Epoch 120, Training Loss: 0.021422479301691055, Validation Loss: 0.019357973709702492
Epoch 121, Training Loss: 0.019357973709702492, Validation Loss: 0.01753128133714199
Epoch 122, Training Loss: 0.01753128319978714, Validation Loss: 0.015941256657242775
Epoch 123, Training Loss: 0.015941252931952477, Validation Loss: 0.014577236026525497
Epoch 124, Training Loss: 0.014577233232557774, Validation Loss: 0.013412865810096264
Epoch 125, Training Loss: 0.013412869535386562, Validation Loss: 0.012399541214108467
Epoch 126, Training Loss: 0.012399539351463318, Validation Loss: 0.011499675922095776
Epoch 127, Training Loss: 0.011499673128128052, Validation Loss: 0.010671135038137436
Epoch 128, Training Loss: 0.010671130381524563, Validation Loss: 0.00987392570823431
Epoch 129, Training Loss: 0.009873923845589161, Validation Loss: 0.009082146920263767
Epoch 130, Training Loss: 0.009082146920263767, Validation Loss: 0.008277296088635921
Epoch 131, Training Loss: 0.00827729795128107, Validation Loss: 0.007459655869752169
Epoch 132, Training Loss: 0.007459653541445732, Validation Loss: 0.006633478682488203
Epoch 133, Training Loss: 0.00663347914814949, Validation Loss: 0.0058204978704452515
Epoch 134, Training Loss: 0.005820496939122677, Validation Loss: 0.005037968512624502
Epoch 135, Training Loss: 0.005037968046963215, Validation Loss: 0.004311529453843832
Epoch 136, Training Loss: 0.004311529919505119, Validation Loss: 0.0036475276574492455
Epoch 137, Training Loss: 0.0036475269589573145, Validation Loss: 0.0030561420135200024
Epoch 138, Training Loss: 0.0030561445746570826, Validation Loss: 0.0025419772136956453
Epoch 139, Training Loss: 0.002541978843510151, Validation Loss: 0.002105333376675844
Epoch 140, Training Loss: 0.002105331514030695, Validation Loss: 0.001743328757584095
Epoch 141, Training Loss: 0.0017433302709832788, Validation Loss: 0.0014470047317445278
Epoch 142, Training Loss: 0.0014470049645751715, Validation Loss: 0.0012074214173480868
Epoch 143, Training Loss: 0.0012074223486706614, Validation Loss: 0.0010141524253413081
Epoch 144, Training Loss: 0.0010141521925106645, Validation Loss: 0.0008577100234106183
Epoch 145, Training Loss: 0.000857710198033601, Validation Loss: 0.0007337424904108047
Epoch 146, Training Loss: 0.0007337420829571784, Validation Loss: 0.0006319404346868396
Epoch 147, Training Loss: 0.0006319410749711096, Validation Loss: 0.0005460779066197574
Epoch 148, Training Loss: 0.0005460777319967747, Validation Loss: 0.00047256870311684906
Epoch 149, Training Loss: 0.00047256721882149577, Validation Loss: 0.0004074863390997052
Epoch 150, Training Loss: 0.00040748651372268796, Validation Loss: 0.00034912946284748614
Epoch 151, Training Loss: 0.00034912998671643436, Validation Loss: 0.00029695159173570573
Epoch 152, Training Loss: 0.00029695211560465395, Validation Loss: 0.00025056328740902245
Epoch 153, Training Loss: 0.0002505627926439047, Validation Loss: 0.0002092054346576333
Epoch 154, Training Loss: 0.00020920521637890488, Validation Loss: 0.0001740212319418788
Epoch 155, Training Loss: 0.0001740208244882524, Validation Loss: 0.00014645783812738955
Epoch 156, Training Loss: 0.0001464577653678134, Validation Loss: 0.0001246799511136487
Epoch 157, Training Loss: 0.0001246802567038685, Validation Loss: 0.00010864470095839351
Epoch 158, Training Loss: 0.00010864460637094453, Validation Loss: 9.807321475818753e-05
Epoch 159, Training Loss: 9.807337482925504e-05, Validation Loss: 9.232464071828872e-05
Epoch 160, Training Loss: 9.232480078935623e-05, Validation Loss: 9.050485823536292e-05
Epoch 161, Training Loss: 9.050487278727815e-05, Validation Loss: 9.127836528932676e-05
Epoch 162, Training Loss: 9.127814701059833e-05, Validation Loss: 9.350628533866256e-05
Epoch 163, Training Loss: 9.35060961637646e-05, Validation Loss: 9.610816778149456e-05
Epoch 164, Training Loss: 9.6107782155741e-05, Validation Loss: 9.811373456614092e-05
Epoch 165, Training Loss: 9.811347263166681e-05, Validation Loss: 9.882688755169511e-05
Epoch 166, Training Loss: 9.882686572382227e-05, Validation Loss: 9.79140677372925e-05
Epoch 167, Training Loss: 9.79141186689958e-05, Validation Loss: 9.505229536443949e-05
Epoch 168, Training Loss: 9.505188063485548e-05, Validation Loss: 9.03266336536035e-05
Epoch 169, Training Loss: 9.032683010445908e-05, Validation Loss: 8.404276013607159e-05
Epoch 170, Training Loss: 8.404308027820662e-05, Validation Loss: 7.665055454708636e-05
Epoch 171, Training Loss: 7.665053999517113e-05, Validation Loss: 6.866174953756854e-05
Epoch 172, Training Loss: 6.8661778641399e-05, Validation Loss: 6.057444625184871e-05
Epoch 173, Training Loss: 6.057418795535341e-05, Validation Loss: 5.2823674195678905e-05
Epoch 174, Training Loss: 5.28235177625902e-05, Validation Loss: 4.572725447360426e-05
Epoch 175, Training Loss: 4.572726902551949e-05, Validation Loss: 3.947426375816576e-05
Epoch 176, Training Loss: 3.947431468986906e-05, Validation Loss: 3.417753032408655e-05
Epoch 177, Training Loss: 3.41772501997184e-05, Validation Loss: 2.9750608518952504e-05
Epoch 178, Training Loss: 2.975051938847173e-05, Validation Loss: 2.6081523174070753e-05
Epoch 179, Training Loss: 2.6081517717102543e-05, Validation Loss: 2.302029861311894e-05
Epoch 180, Training Loss: 2.302021675859578e-05, Validation Loss: 2.0411422156030312e-05
Epoch 181, Training Loss: 2.0411596779013053e-05, Validation Loss: 1.8119033484254032e-05
Epoch 182, Training Loss: 1.811920083127916e-05, Validation Loss: 1.603998498467263e-05
Epoch 183, Training Loss: 1.6039906768128276e-05, Validation Loss: 1.4110223673924338e-05
Epoch 184, Training Loss: 1.4110211850493215e-05, Validation Loss: 1.2304016308917198e-05
Epoch 185, Training Loss: 1.230388352269074e-05, Validation Loss: 1.06235638668295e-05
Epoch 186, Training Loss: 1.0623311936797109e-05, Validation Loss: 9.08949823497096e-06
Epoch 187, Training Loss: 9.089431841857731e-06, Validation Loss: 7.728656783001497e-06
Epoch 188, Training Loss: 7.728534001216758e-06, Validation Loss: 6.563504030054901e-06
Epoch 189, Training Loss: 6.563551323779393e-06, Validation Loss: 5.6057892834360246e-06
Epoch 190, Training Loss: 5.605788828688674e-06, Validation Loss: 4.852303391089663e-06
Epoch 191, Training Loss: 4.852267466048943e-06, Validation Loss: 4.285605427867267e-06
Epoch 192, Training Loss: 4.2855722313106526e-06, Validation Loss: 3.8760927054681815e-06
Epoch 193, Training Loss: 3.876176378980745e-06, Validation Loss: 3.586909542718786e-06
Epoch 194, Training Loss: 3.586838374758372e-06, Validation Loss: 3.3781577712943545e-06
Epoch 195, Training Loss: 3.3782023365347413e-06, Validation Loss: 3.2136601930687902e-06
Epoch 196, Training Loss: 3.2136701975105098e-06, Validation Loss: 3.0629093998868484e-06
Epoch 197, Training Loss: 3.0629273624072084e-06, Validation Loss: 2.9040404569968814e-06
Epoch 198, Training Loss: 2.904095708800014e-06, Validation Loss: 2.7242917894909624e-06
Epoch 199, Training Loss: 2.7242563191975933e-06, Validation Loss: 2.5194610770995496e-06
Epoch 200, Training Loss: 2.519519284760463e-06, Validation Loss: 2.29311467592197e-06
Epoch 201, Training Loss: 2.2930876184545923e-06, Validation Loss: 2.053895968856523e-06
Epoch 202, Training Loss: 2.053822299785679e-06, Validation Loss: 1.8130301668861648e-06
Epoch 203, Training Loss: 1.8130689340978279e-06, Validation Loss: 1.582726667948009e-06
Epoch 204, Training Loss: 1.5827040442673024e-06, Validation Loss: 1.3733745163335698e-06
Epoch 205, Training Loss: 1.373356894873723e-06, Validation Loss: 1.1925951639568666e-06
Epoch 206, Training Loss: 1.1926306342502357e-06, Validation Loss: 1.0445306770634488e-06
Epoch 207, Training Loss: 1.0445457974128658e-06, Validation Loss: 9.293806328969367e-07
Epoch 208, Training Loss: 9.293414677813416e-07, Validation Loss: 8.442782473139232e-07
Epoch 209, Training Loss: 8.442374337391811e-07, Validation Loss: 7.838417559469235e-07
Epoch 210, Training Loss: 7.838510214241978e-07, Validation Loss: 7.414378728753945e-07
Epoch 211, Training Loss: 7.414293463625654e-07, Validation Loss: 7.099626486706256e-07
Epoch 212, Training Loss: 7.099574759195093e-07, Validation Loss: 6.828784648860164e-07
Epoch 213, Training Loss: 6.828884124843171e-07, Validation Loss: 6.549491899932036e-07
Epoch 214, Training Loss: 6.549470867867058e-07, Validation Loss: 6.225526476555387e-07
Epoch 215, Training Loss: 6.225414495020232e-07, Validation Loss: 5.83919245400466e-07
Epoch 216, Training Loss: 5.839039545207925e-07, Validation Loss: 5.388574209064245e-07
Epoch 217, Training Loss: 5.388689601204533e-07, Validation Loss: 4.886657052338705e-07
Epoch 218, Training Loss: 4.886619535682257e-07, Validation Loss: 4.3545335870476265e-07
Epoch 219, Training Loss: 4.354400573447492e-07, Validation Loss: 3.8182238881745434e-07
Epoch 220, Training Loss: 3.8182463413249934e-07, Validation Loss: 3.302817788153334e-07
Epoch 221, Training Loss: 3.3029343171619985e-07, Validation Loss: 2.830281573551474e-07
Epoch 222, Training Loss: 2.8301511179051886e-07, Validation Loss: 2.4146038413164206e-07
Epoch 223, Training Loss: 2.414513460280432e-07, Validation Loss: 2.062588890794359e-07
Epoch 224, Training Loss: 2.0625437002763647e-07, Validation Loss: 1.774133551180057e-07
Epoch 225, Training Loss: 1.773998832277357e-07, Validation Loss: 1.542463508030778e-07
Epoch 226, Training Loss: 1.5424225807691982e-07, Validation Loss: 1.3579058588675252e-07
Epoch 227, Training Loss: 1.3579852975453832e-07, Validation Loss: 1.2088700884760328e-07
Epoch 228, Training Loss: 1.208884157222201e-07, Validation Loss: 1.0844211573157736e-07
Epoch 229, Training Loss: 1.084382716953769e-07, Validation Loss: 9.752711349619858e-08
Epoch 230, Training Loss: 9.754138119433264e-08, Validation Loss: 8.76059900178916e-08
Epoch 231, Training Loss: 8.760257941275995e-08, Validation Loss: 7.82814382205288e-08
Epoch 232, Training Loss: 7.827630810197661e-08, Validation Loss: 6.950137532157896e-08
Epoch 233, Training Loss: 6.950470066158232e-08, Validation Loss: 6.137736363598378e-08
Epoch 234, Training Loss: 6.137840813380535e-08, Validation Loss: 5.4065868226871316e-08
Epoch 235, Training Loss: 5.406467096236156e-08, Validation Loss: 4.777051643145569e-08
Epoch 236, Training Loss: 4.776364548320089e-08, Validation Loss: 4.258526331568646e-08
Epoch 237, Training Loss: 4.258538410795154e-08, Validation Loss: 3.85203371422449e-08
Epoch 238, Training Loss: 3.852403551718453e-08, Validation Loss: 3.5475551385388826e-08
Epoch 239, Training Loss: 3.548095506289428e-08, Validation Loss: 3.3247189890062145e-08
Epoch 240, Training Loss: 3.324524300296616e-08, Validation Loss: 3.1578291981304574e-08
Epoch 241, Training Loss: 3.157273908982461e-08, Validation Loss: 3.018668692789106e-08
Epoch 242, Training Loss: 3.018457661596585e-08, Validation Loss: 2.8860831946531107e-08
Epoch 243, Training Loss: 2.886319094841383e-08, Validation Loss: 2.7409532421529548e-08
Epoch 244, Training Loss: 2.740541127366214e-08, Validation Loss: 2.5731486275049065e-08
Epoch 245, Training Loss: 2.5731287323083052e-08, Validation Loss: 2.379990782230834e-08
Epoch 246, Training Loss: 2.3797566583994012e-08, Validation Loss: 2.1649865900030818e-08
Epoch 247, Training Loss: 2.1652414972095357e-08, Validation Loss: 1.936788684986368e-08
Epoch 248, Training Loss: 1.93669951187303e-08, Validation Loss: 1.7060893142684108e-08
Epoch 249, Training Loss: 1.7052283141083535e-08, Validation Loss: 1.4820236593493519e-08
Epoch 250, Training Loss: 1.4822879812470546e-08, Validation Loss: 1.2755968725741695e-08
Epoch 251, Training Loss: 1.2756531830859785e-08, Validation Loss: 1.0923929316675185e-08
Epoch 252, Training Loss: 1.0924326332428791e-08, Validation Loss: 9.379066412407155e-09
Epoch 253, Training Loss: 9.377259857501485e-09, Validation Loss: 8.114964700212113e-09
Epoch 254, Training Loss: 8.112964522410948e-09, Validation Loss: 7.113601707686712e-09
Epoch 255, Training Loss: 7.117831657410534e-09, Validation Loss: 6.355687975911906e-09
Epoch 256, Training Loss: 6.357635307097098e-09, Validation Loss: 5.775339317892758e-09
Epoch 257, Training Loss: 5.778988398930096e-09, Validation Loss: 5.333765429327286e-09
Epoch 258, Training Loss: 5.329821028965398e-09, Validation Loss: 4.9639652388577815e-09
Epoch 259, Training Loss: 4.968663258608785e-09, Validation Loss: 4.6432320210954e-09
Epoch 260, Training Loss: 4.643878614984942e-09, Validation Loss: 4.332098679782348e-09
Epoch 261, Training Loss: 4.329651304146864e-09, Validation Loss: 4.011345922094733e-09
Epoch 262, Training Loss: 4.014449217493166e-09, Validation Loss: 3.6806826475555e-09
Epoch 263, Training Loss: 3.680436622133243e-09, Validation Loss: 3.3401446053460404e-09
Epoch 264, Training Loss: 3.3401172938596346e-09, Validation Loss: 3.001102477639961e-09
Epoch 265, Training Loss: 2.99971336659155e-09, Validation Loss: 2.674877652708574e-09
Epoch 266, Training Loss: 2.6746300729740824e-09, Validation Loss: 2.3779576086013776e-09
Epoch 267, Training Loss: 2.3762702916485523e-09, Validation Loss: 2.1143067296947038e-09
Epoch 268, Training Loss: 2.1132002814283624e-09, Validation Loss: 1.890343881427725e-09
Epoch 269, Training Loss: 1.8907249099697765e-09, Validation Loss: 1.7061206891710867e-09
Epoch 270, Training Loss: 1.7076103864255288e-09, Validation Loss: 1.556482165376849e-09
Epoch 271, Training Loss: 1.557517670391917e-09, Validation Loss: 1.4323039421171302e-09
Epoch 272, Training Loss: 1.4326422270727335e-09, Validation Loss: 1.3222902772724865e-09
Epoch 273, Training Loss: 1.3235715856652064e-09, Validation Loss: 1.217940637232573e-09
Epoch 274, Training Loss: 1.218020351245741e-09, Validation Loss: 1.10915421291935e-09
Epoch 275, Training Loss: 1.10873177305848e-09, Validation Loss: 9.941366618804182e-10
Epoch 276, Training Loss: 9.94432092227271e-10, Validation Loss: 8.730658973554739e-10
Epoch 277, Training Loss: 8.730056122452368e-10, Validation Loss: 7.505425170251101e-10
Epoch 278, Training Loss: 7.495158937942392e-10, Validation Loss: 6.274811226170129e-10
Epoch 279, Training Loss: 6.277610653526722e-10, Validation Loss: 5.161679972331967e-10
Epoch 280, Training Loss: 5.147049453313457e-10, Validation Loss: 4.1688072438539336e-10
Epoch 281, Training Loss: 4.1584921617321413e-10, Validation Loss: 3.344171606300961e-10
Epoch 282, Training Loss: 3.340904497495245e-10, Validation Loss: 2.7322966111853475e-10
Epoch 283, Training Loss: 2.7317462181208896e-10, Validation Loss: 2.3115985514632342e-10
Epoch 284, Training Loss: 2.3219830225240656e-10, Validation Loss: 2.068712007252671e-10
Epoch 285, Training Loss: 2.066905674391606e-10, Validation Loss: 1.9566878672883092e-10
Epoch 286, Training Loss: 1.9575388532366844e-10, Validation Loss: 1.9367250858604024e-10
Epoch 287, Training Loss: 1.9341407642148312e-10, Validation Loss: 1.9589319055768328e-10
Epoch 288, Training Loss: 1.965542312243329e-10, Validation Loss: 1.9957756280941652e-10
Epoch 289, Training Loss: 2.0041392156944227e-10, Validation Loss: 2.0188613281124645e-10
Epoch 290, Training Loss: 2.0212514995066044e-10, Validation Loss: 2.014086536439308e-10
Epoch 291, Training Loss: 2.0105000997361344e-10, Validation Loss: 1.9635836012721342e-10
Epoch 292, Training Loss: 1.95939209302054e-10, Validation Loss: 1.8774490295747626e-10
Epoch 293, Training Loss: 1.8803210377615898e-10, Validation Loss: 1.7650070294195075e-10
Epoch 294, Training Loss: 1.7633113025272706e-10, Validation Loss: 1.6230658483884497e-10
Epoch 295, Training Loss: 1.6287036996853743e-10, Validation Loss: 1.4809049819763942e-10
Epoch 296, Training Loss: 1.484111722405146e-10, Validation Loss: 1.330694443524294e-10
Epoch 297, Training Loss: 1.329415744155682e-10, Validation Loss: 1.184137510268357e-10
Epoch 298, Training Loss: 1.187097781185642e-10, Validation Loss: 1.0515756321272107e-10
Epoch 299, Training Loss: 1.0503770769831888e-10, Validation Loss: 9.271128309507048e-11
Epoch 300, Training Loss: 9.277088819370505e-11, Validation Loss: 8.149089736342319e-11
Epoch 301, Training Loss: 8.151870845019005e-11, Validation Loss: 7.109320770970484e-11
Epoch 302, Training Loss: 7.107293920061153e-11, Validation Loss: 6.152302972628476e-11
Epoch 303, Training Loss: 6.131856827851223e-11, Validation Loss: 5.2671995237618674e-11
Epoch 304, Training Loss: 5.28182914072417e-11, Validation Loss: 4.48177155110141e-11
Epoch 305, Training Loss: 4.460013608431623e-11, Validation Loss: 3.742754023372541e-11
Epoch 306, Training Loss: 3.7484078341254445e-11, Validation Loss: 3.1063727978786204e-11
Epoch 307, Training Loss: 3.0785072407946146e-11, Validation Loss: 2.519847698556621e-11
Epoch 308, Training Loss: 2.5040412451882155e-11, Validation Loss: 2.0073182699364978e-11
Epoch 309, Training Loss: 2.0178731949260786e-11, Validation Loss: 1.627345307120276e-11
Epoch 310, Training Loss: 1.5924185581273065e-11, Validation Loss: 1.2947831175280644e-11
Epoch 311, Training Loss: 1.2941903625163231e-11, Validation Loss: 1.0770683823990712e-11
Epoch 312, Training Loss: 1.0800174123082318e-11, Validation Loss: 9.426541144885725e-12
Epoch 313, Training Loss: 9.432241446227785e-12, Validation Loss: 8.892139628791096e-12
Epoch 314, Training Loss: 8.827535924460506e-12, Validation Loss: 8.799560906325166e-12
Epoch 315, Training Loss: 8.706361152854836e-12, Validation Loss: 8.977783794161809e-12
Epoch 316, Training Loss: 8.851446485491632e-12, Validation Loss: 9.232424720562182e-12
Epoch 317, Training Loss: 9.16154825614246e-12, Validation Loss: 9.214940442647812e-12
Epoch 318, Training Loss: 9.210969660611301e-12, Validation Loss: 9.325308754359884e-12
Epoch 319, Training Loss: 9.286306966449498e-12, Validation Loss: 9.185635758968136e-12
Epoch 320, Training Loss: 9.144911390646104e-12, Validation Loss: 8.81349073583726e-12
Epoch 321, Training Loss: 9.011887590337775e-12, Validation Loss: 8.473523098462277e-12
Epoch 322, Training Loss: 8.533047532455207e-12, Validation Loss: 8.042781718398118e-12
Epoch 323, Training Loss: 7.980972653587326e-12, Validation Loss: 7.407384601532119e-12
Epoch 324, Training Loss: 7.415337441307734e-12, Validation Loss: 6.8645315126625306e-12
Epoch 325, Training Loss: 6.727353483310106e-12, Validation Loss: 6.156565708625994e-12
Epoch 326, Training Loss: 6.191506942559988e-12, Validation Loss: 5.597850308292074e-12
Epoch 327, Training Loss: 5.540070572435107e-12, Validation Loss: 5.02522242568082e-12
Epoch 328, Training Loss: 4.9964485673847925e-12, Validation Loss: 4.6300263970011635e-12
Epoch 329, Training Loss: 4.4845490168587965e-12, Validation Loss: 3.973457413791737e-12
Epoch 330, Training Loss: 4.089488730291135e-12, Validation Loss: 3.673725820080298e-12
Epoch 331, Training Loss: 3.716014475296792e-12, Validation Loss: 3.3164337161911694e-12
Epoch 332, Training Loss: 3.207690623535653e-12, Validation Loss: 2.8557200007495176e-12
Epoch 333, Training Loss: 2.834295732140335e-12, Validation Loss: 2.4308660553223893e-12
Epoch 334, Training Loss: 2.4173423679441086e-12, Validation Loss: 2.0301102379022273e-12
Epoch 335, Training Loss: 2.064626898265476e-12, Validation Loss: 1.741979390595949e-12
Epoch 336, Training Loss: 1.6687540021695368e-12, Validation Loss: 1.4528387173862178e-12
Epoch 337, Training Loss: 1.3934257393766192e-12, Validation Loss: 1.1370565947133038e-12
Epoch 338, Training Loss: 1.1567094938130795e-12, Validation Loss: 9.474379831023172e-13
Epoch 339, Training Loss: 9.33337825428926e-13, Validation Loss: 7.547943390098788e-13
Epoch 340, Training Loss: 7.246589396256442e-13, Validation Loss: 5.974918368227555e-13
Epoch 341, Training Loss: 6.185643902471838e-13, Validation Loss: 4.678395800102042e-13
Epoch 342, Training Loss: 4.986836681444839e-13, Validation Loss: 4.05026543987691e-13
Epoch 343, Training Loss: 4.211802347858784e-13, Validation Loss: 3.569834857407306e-13
Epoch 344, Training Loss: 3.694047021399194e-13, Validation Loss: 3.325008996434009e-13
Epoch 345, Training Loss: 3.2923165062259674e-13, Validation Loss: 3.0469989595674485e-13
Epoch 346, Training Loss: 3.014811165470699e-13, Validation Loss: 2.889230196236048e-13
Epoch 347, Training Loss: 2.942115409805546e-13, Validation Loss: 2.913317373801072e-13
Epoch 348, Training Loss: 2.9039932351176967e-13, Validation Loss: 2.943754723490344e-13
Epoch 349, Training Loss: 2.7903189741412815e-13, Validation Loss: 2.9989709717306856e-13
Epoch 350, Training Loss: 2.7288693765607774e-13, Validation Loss: 2.735427444451599e-13
Epoch 351, Training Loss: 2.84357850851083e-13, Validation Loss: 2.7988269796393184e-13
Epoch 352, Training Loss: 2.8028401539807735e-13, Validation Loss: 2.7615203960357215e-13
Epoch 353, Training Loss: 2.7292469499673455e-13, Validation Loss: 2.6211045595254945e-13
Epoch 354, Training Loss: 2.6603117495374584e-13, Validation Loss: 2.52246357482222e-13
Epoch 355, Training Loss: 2.4139709870786563e-13, Validation Loss: 2.431826983707863e-13
Epoch 356, Training Loss: 2.2976556096100664e-13, Validation Loss: 2.1531249548047138e-13
Epoch 357, Training Loss: 2.2268252237826747e-13, Validation Loss: 2.0930796700881216e-13
Epoch 358, Training Loss: 2.0090413978702398e-13, Validation Loss: 1.8470362500751236e-13
Epoch 359, Training Loss: 1.938470136362072e-13, Validation Loss: 1.7128517300259855e-13
Epoch 360, Training Loss: 1.7556109018802835e-13, Validation Loss: 1.550143612647284e-13
Epoch 361, Training Loss: 1.551197999260026e-13, Validation Loss: 1.4286629605037016e-13
Epoch 362, Training Loss: 1.4520817274293885e-13, Validation Loss: 1.277044333995725e-13
Epoch 363, Training Loss: 1.259537857041873e-13, Validation Loss: 1.1012954328863678e-13
Epoch 364, Training Loss: 1.1042684507685946e-13, Validation Loss: 8.664247840234687e-14
Epoch 365, Training Loss: 9.627652272420004e-14, Validation Loss: 9.043946283060836e-14
Epoch 366, Training Loss: 8.097579410389771e-14, Validation Loss: 7.194148976628206e-14
Epoch 367, Training Loss: 6.776092138565878e-14, Validation Loss: 6.172379230992564e-14
Epoch 368, Training Loss: 6.759812842946009e-14, Validation Loss: 5.756093030603177e-14
Epoch 369, Training Loss: 5.491877026926606e-14, Validation Loss: 5.185125061517998e-14
Epoch 370, Training Loss: 4.410969134979563e-14, Validation Loss: 3.886412133953521e-14
Epoch 371, Training Loss: 4.1159255365942615e-14, Validation Loss: 3.2703494860092386e-14
Epoch 372, Training Loss: 3.3549599459236495e-14, Validation Loss: 2.752197239910565e-14
Epoch 373, Training Loss: 2.749630221860616e-14, Validation Loss: 2.771906341340457e-14
Epoch 374, Training Loss: 2.6732485176221912e-14, Validation Loss: 2.365820958734853e-14
Epoch 375, Training Loss: 2.243390308318948e-14, Validation Loss: 2.152819446961298e-14
Epoch 376, Training Loss: 1.741597995376723e-14, Validation Loss: 2.4490289014952003e-14
Epoch 377, Training Loss: 1.926642845912971e-14, Validation Loss: 2.2945172170152177e-14
Epoch 378, Training Loss: 1.6088689489815108e-14, Validation Loss: 2.1801487955978686e-14
Epoch 379, Training Loss: 1.7104737697298637e-14, Validation Loss: 1.6980945526123316e-14
Epoch 380, Training Loss: 2.0229799687623493e-14, Validation Loss: 1.314865422352143e-14
Epoch 381, Training Loss: 1.786884950714853e-14, Validation Loss: 1.0886987315892986e-14
Epoch 382, Training Loss: 1.711257614019253e-14, Validation Loss: 1.1236033499830485e-14
Epoch 383, Training Loss: 1.3502542047785435e-14, Validation Loss: 1.2465798284301641e-14
Epoch 384, Training Loss: 1.4046577757279716e-14, Validation Loss: 1.03885795772014e-14
Epoch 385, Training Loss: 1.2269754202725528e-14, Validation Loss: 9.162684886266249e-15
Epoch 386, Training Loss: 9.929144671445931e-15, Validation Loss: 6.849722510385032e-15
Epoch 387, Training Loss: 8.633772950045193e-15, Validation Loss: 6.5462085825271875e-15
Epoch 388, Training Loss: 6.8731624531344e-15, Validation Loss: 5.275862026036604e-15
Epoch 389, Training Loss: 5.807374776922204e-15, Validation Loss: 5.035356761542639e-15
Epoch 390, Training Loss: 5.852144279832857e-15, Validation Loss: 8.826244246649788e-15
Epoch 391, Training Loss: 4.383901180710515e-15, Validation Loss: 8.025953118523822e-15
Epoch 392, Training Loss: 4.3577469208816704e-15, Validation Loss: 6.6240750508188544e-15
Epoch 393, Training Loss: 3.3985115425110924e-15, Validation Loss: 6.87853348905294e-15
Epoch 394, Training Loss: 2.8921056952150572e-15, Validation Loss: 4.902821516285759e-15
Epoch 395, Training Loss: 2.6888762331473857e-15, Validation Loss: 3.981716384827017e-15
Epoch 396, Training Loss: 2.2387152793731675e-15, Validation Loss: 5.462957204524976e-15
Epoch 397, Training Loss: 2.1533133942244894e-15, Validation Loss: 5.311936312227218e-15
Epoch 398, Training Loss: 2.3614802113417063e-15, Validation Loss: 4.4438994889798526e-15
Epoch 399, Training Loss: 1.881228623874516e-15, Validation Loss: 4.320296206151769e-15
Epoch 400, Training Loss: 1.9129874889571054e-15, Validation Loss: 4.21823508875473e-15
Epoch 401, Training Loss: 1.7611324809645385e-15, Validation Loss: 4.9404141090343256e-15
Epoch 402, Training Loss: 3.417793612280626e-15, Validation Loss: 4.985249680514864e-15
Epoch 403, Training Loss: 1.1237551171113728e-15, Validation Loss: 4.369289438853905e-15
Epoch 404, Training Loss: 1.0450254163673353e-15, Validation Loss: 4.029296343056659e-15
Epoch 405, Training Loss: 1.857809856948829e-15, Validation Loss: 4.001549237770503e-15
Epoch 406, Training Loss: 1.095207248052706e-15, Validation Loss: 5.363706965963401e-15
Epoch 407, Training Loss: 1.4059227559072248e-15, Validation Loss: 5.4589833494529325e-15
Epoch 408, Training Loss: 1.5324241619643392e-15, Validation Loss: 4.792161743924668e-15
Epoch 409, Training Loss: 1.1302353426743419e-15, Validation Loss: 4.782821088098821e-15
Epoch 410, Training Loss: 1.3290612922074751e-15, Validation Loss: 3.4441899117741486e-15
Epoch 411, Training Loss: 5.244498725340383e-16, Validation Loss: 3.5321354368634313e-15
Epoch 412, Training Loss: 1.062080742397656e-15, Validation Loss: 3.3396143770731855e-15
Epoch 413, Training Loss: 1.6101533050394325e-15, Validation Loss: 3.416476052531172e-15
Epoch 414, Training Loss: 1.7142365018398041e-15, Validation Loss: 3.3163499819021357e-15
Epoch 415, Training Loss: 9.684390266172065e-16, Validation Loss: 5.820405955299238e-15
Epoch 416, Training Loss: 1.0758583685594575e-15, Validation Loss: 5.604670898798304e-15
Epoch 417, Training Loss: 1.9462225207085224e-15, Validation Loss: 6.133682361390662e-15
Epoch 418, Training Loss: 2.0422995620914463e-15, Validation Loss: 5.619136527471513e-15
Epoch 419, Training Loss: 1.8033081572324614e-15, Validation Loss: 5.409635209945897e-15
Epoch 420, Training Loss: 8.806352736674705e-16, Validation Loss: 5.43899210134831e-15
Epoch 421, Training Loss: 7.728155498389641e-16, Validation Loss: 5.4710179935675216e-15
Epoch 422, Training Loss: 1.0853659957550318e-15, Validation Loss: 6.787272465249867e-15
Epoch 423, Training Loss: 5.959071072116279e-16, Validation Loss: 6.77846544018079e-15
Epoch 424, Training Loss: 6.12053408070867e-16, Validation Loss: 7.453673095403346e-15
Epoch 425, Training Loss: 6.338041553651734e-16, Validation Loss: 6.982308154102274e-15
Epoch 426, Training Loss: 6.872469580183546e-16, Validation Loss: 7.349814997608707e-15
Epoch 427, Training Loss: 1.3677590511939719e-15, Validation Loss: 6.611890481872601e-15
Epoch 428, Training Loss: 1.3231899774544635e-15, Validation Loss: 8.696227230345095e-15
Epoch 429, Training Loss: 7.840912524328134e-16, Validation Loss: 8.75921090623703e-15
Epoch 430, Training Loss: 7.50731177442558e-16, Validation Loss: 8.63324355445316e-15
Epoch 431, Training Loss: 7.41256955108841e-16, Validation Loss: 8.687954259549262e-15
Epoch 432, Training Loss: 7.359193240521588e-16, Validation Loss: 9.232557481118203e-15
Epoch 433, Training Loss: 7.899626201253842e-16, Validation Loss: 9.211207168649711e-15
Epoch 434, Training Loss: 8.272258229365874e-16, Validation Loss: 9.376672513796997e-15
Epoch 435, Training Loss: 8.126141340195363e-16, Validation Loss: 9.376672513796997e-15
Epoch 436, Training Loss: 8.202202251880839e-16, Validation Loss: 9.402293566385545e-15
Epoch 437, Training Loss: 8.046077139042926e-16, Validation Loss: 9.273122735995159e-15
Epoch 438, Training Loss: 6.338041553651734e-16, Validation Loss: 9.318493208781888e-15
Epoch 439, Training Loss: 6.338041553651734e-16, Validation Loss: 9.075498090939469e-15
Epoch 440, Training Loss: 5.998435869548739e-16, Validation Loss: 9.033864727516026e-15
Epoch 441, Training Loss: 5.371266735017645e-16, Validation Loss: 9.033864727516026e-15
Epoch 442, Training Loss: 5.444658963523678e-16, Validation Loss: 8.996501257179691e-15
Epoch 443, Training Loss: 5.338907429454571e-16, Validation Loss: 9.189368118170654e-15
Epoch 444, Training Loss: 1.1377079732141377e-15, Validation Loss: 9.189368118170654e-15
Epoch 445, Training Loss: 1.1495174124438756e-15, Validation Loss: 9.281083998666402e-15
Epoch 446, Training Loss: 1.6980903597992427e-15, Validation Loss: 9.74011825783782e-15
Epoch 447, Training Loss: 1.7528009590162268e-15, Validation Loss: 7.576250621332305e-15
Epoch 448, Training Loss: 1.7682132528871108e-15, Validation Loss: 6.540766819357552e-15
Epoch 449, Training Loss: 1.7228436271333287e-15, Validation Loss: 6.528757162714907e-15
Epoch 450, Training Loss: 1.2314497447614816e-15, Validation Loss: 5.6720705809607495e-15
Epoch 451, Training Loss: 1.0971755408638881e-15, Validation Loss: 5.8918472551695075e-15
Epoch 452, Training Loss: 4.463873161150819e-16, Validation Loss: 5.542787942221326e-15
Epoch 453, Training Loss: 9.444864171765125e-16, Validation Loss: 3.3526330617142473e-15
Epoch 454, Training Loss: 1.6068839696212677e-15, Validation Loss: 3.907877981716018e-15
Epoch 455, Training Loss: 1.6028807860334255e-15, Validation Loss: 3.859839778661911e-15
Epoch 456, Training Loss: 2.088603253427813e-15, Validation Loss: 3.603067246415927e-15
Epoch 457, Training Loss: 1.1732698044716623e-15, Validation Loss: 3.576378932313839e-15
Epoch 458, Training Loss: 1.1140222850309473e-15, Validation Loss: 3.576378932313839e-15
Epoch 459, Training Loss: 1.0424983994483206e-15, Validation Loss: 3.576378932313839e-15
Epoch 460, Training Loss: 1.0023995420879468e-15, Validation Loss: 3.634025453605125e-15
Epoch 461, Training Loss: 1.018412382318434e-15, Validation Loss: 3.632098877166595e-15
Epoch 462, Training Loss: 6.028793530378333e-16, Validation Loss: 3.619326043838474e-15
Epoch 463, Training Loss: 4.407494383483777e-16, Validation Loss: 3.3935451765831036e-15
Epoch 464, Training Loss: 4.620998831657676e-16, Validation Loss: 4.001232023931756e-15
Epoch 465, Training Loss: 4.548941209439161e-16, Validation Loss: 3.827926541824685e-15
Epoch 466, Training Loss: 4.294070054401526e-16, Validation Loss: 3.835933120758606e-15
Epoch 467, Training Loss: 1.0791944078222186e-15, Validation Loss: 5.3699618807624e-15
Epoch 468, Training Loss: 1.5916050834395763e-15, Validation Loss: 5.324592255008618e-15
Epoch 469, Training Loss: 1.6916853084103425e-15, Validation Loss: 3.784691862614457e-15
Epoch 470, Training Loss: 2.6945558008169626e-15, Validation Loss: 3.731315657926754e-15
Epoch 471, Training Loss: 2.0361611143226944e-15, Validation Loss: 5.622430638603385e-15
Epoch 472, Training Loss: 1.245461046137607e-15, Validation Loss: 5.898214401834018e-15
Epoch 473, Training Loss: 1.2422584145640385e-15, Validation Loss: 5.395144593800744e-15
Epoch 474, Training Loss: 1.2694802535437788e-15, Validation Loss: 5.331626863635565e-15
Epoch 475, Training Loss: 5.008642930573015e-16, Validation Loss: 5.897146716804004e-15
Epoch 476, Training Loss: 1.1920848414499036e-15, Validation Loss: 5.881133982452635e-15
Epoch 477, Training Loss: 1.374898056631668e-15, Validation Loss: 5.881133982452635e-15
Epoch 478, Training Loss: 9.247039626933884e-16, Validation Loss: 5.495224501134155e-15
Epoch 479, Training Loss: 9.287071462812306e-16, Validation Loss: 5.90782187303825e-15
Epoch 480, Training Loss: 9.240367124891888e-16, Validation Loss: 5.86912432580999e-15
Epoch 481, Training Loss: 6.515517190716375e-16, Validation Loss: 6.3868727913027074e-15
Epoch 482, Training Loss: 1.0903033508045772e-15, Validation Loss: 6.405820918332786e-15
Epoch 483, Training Loss: 9.671379840102239e-16, Validation Loss: 6.39514576209854e-15
Epoch 484, Training Loss: 1.0467350464922497e-15, Validation Loss: 6.339100980110512e-15
Epoch 485, Training Loss: 1.0253846281446394e-15, Validation Loss: 6.391142684389816e-15
Epoch 486, Training Loss: 1.096775211917192e-15, Validation Loss: 6.661225915885428e-15
Epoch 487, Training Loss: 3.622132263992727e-15, Validation Loss: 7.235323248194238e-15
Epoch 488, Training Loss: 3.669503852117345e-15, Validation Loss: 7.118684270258479e-15
Epoch 489, Training Loss: 8.058754045889771e-16, Validation Loss: 7.655672665631604e-15
Epoch 490, Training Loss: 8.125473772353808e-16, Validation Loss: 7.001861486173166e-15
Epoch 491, Training Loss: 5.948729329225896e-16, Validation Loss: 7.083426523829019e-15
Epoch 492, Training Loss: 1.3570170852360113e-15, Validation Loss: 7.015934938591796e-15
Epoch 493, Training Loss: 1.4760457548742114e-15, Validation Loss: 7.022340201738933e-15
Epoch 494, Training Loss: 1.1647964045046855e-15, Validation Loss: 7.009605061376965e-15
Epoch 495, Training Loss: 1.1694667324176088e-15, Validation Loss: 7.0082705609685655e-15
Epoch 496, Training Loss: 1.1517859784348594e-15, Validation Loss: 6.833463712962486e-15
Epoch 497, Training Loss: 1.1424451108507758e-15, Validation Loss: 6.718571740480439e-15
Epoch 498, Training Loss: 1.567719283722597e-15, Validation Loss: 6.6838772709609025e-15
Epoch 499, Training Loss: 9.005178897966075e-16, Validation Loss: 6.614621739611023e-15
Epoch 500, Training Loss: 2.1917186621463875e-16, Validation Loss: 6.63276984402242e-15
