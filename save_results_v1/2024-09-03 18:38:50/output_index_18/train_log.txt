Epoch 1, Training Loss: 0.5268069505691528, Validation Loss: 0.5252344608306885
Epoch 2, Training Loss: 0.5252344608306885, Validation Loss: 0.5236765146255493
Epoch 3, Training Loss: 0.5236765146255493, Validation Loss: 0.5222102403640747
Epoch 4, Training Loss: 0.5222102999687195, Validation Loss: 0.520801842212677
Epoch 5, Training Loss: 0.520801842212677, Validation Loss: 0.5194048881530762
Epoch 6, Training Loss: 0.5194048881530762, Validation Loss: 0.5180103778839111
Epoch 7, Training Loss: 0.5180103778839111, Validation Loss: 0.5166059732437134
Epoch 8, Training Loss: 0.5166059732437134, Validation Loss: 0.5152068138122559
Epoch 9, Training Loss: 0.5152068138122559, Validation Loss: 0.513816773891449
Epoch 10, Training Loss: 0.513816773891449, Validation Loss: 0.5124231576919556
Epoch 11, Training Loss: 0.5124231576919556, Validation Loss: 0.511080265045166
Epoch 12, Training Loss: 0.511080265045166, Validation Loss: 0.5097414255142212
Epoch 13, Training Loss: 0.5097414255142212, Validation Loss: 0.5084177255630493
Epoch 14, Training Loss: 0.5084177255630493, Validation Loss: 0.5070730447769165
Epoch 15, Training Loss: 0.5070730447769165, Validation Loss: 0.5057506561279297
Epoch 16, Training Loss: 0.5057506561279297, Validation Loss: 0.5043901801109314
Epoch 17, Training Loss: 0.5043901205062866, Validation Loss: 0.5030030012130737
Epoch 18, Training Loss: 0.5030030012130737, Validation Loss: 0.501583456993103
Epoch 19, Training Loss: 0.501583456993103, Validation Loss: 0.5001311898231506
Epoch 20, Training Loss: 0.5001311898231506, Validation Loss: 0.4986344575881958
Epoch 21, Training Loss: 0.4986344575881958, Validation Loss: 0.49709656834602356
Epoch 22, Training Loss: 0.49709656834602356, Validation Loss: 0.49554774165153503
Epoch 23, Training Loss: 0.49554774165153503, Validation Loss: 0.4939557909965515
Epoch 24, Training Loss: 0.49395573139190674, Validation Loss: 0.4923171103000641
Epoch 25, Training Loss: 0.4923171103000641, Validation Loss: 0.49057745933532715
Epoch 26, Training Loss: 0.49057748913764954, Validation Loss: 0.4887464642524719
Epoch 27, Training Loss: 0.48874643445014954, Validation Loss: 0.4868367314338684
Epoch 28, Training Loss: 0.4868367314338684, Validation Loss: 0.48481371998786926
Epoch 29, Training Loss: 0.48481371998786926, Validation Loss: 0.48267197608947754
Epoch 30, Training Loss: 0.4826720058917999, Validation Loss: 0.4804171919822693
Epoch 31, Training Loss: 0.4804171919822693, Validation Loss: 0.4780181050300598
Epoch 32, Training Loss: 0.4780181050300598, Validation Loss: 0.47549182176589966
Epoch 33, Training Loss: 0.47549182176589966, Validation Loss: 0.4728345572948456
Epoch 34, Training Loss: 0.4728345274925232, Validation Loss: 0.4700048267841339
Epoch 35, Training Loss: 0.4700048267841339, Validation Loss: 0.4670073986053467
Epoch 36, Training Loss: 0.46700742840766907, Validation Loss: 0.4638440012931824
Epoch 37, Training Loss: 0.4638440012931824, Validation Loss: 0.4604793190956116
Epoch 38, Training Loss: 0.46047934889793396, Validation Loss: 0.4568663537502289
Epoch 39, Training Loss: 0.4568663537502289, Validation Loss: 0.45301780104637146
Epoch 40, Training Loss: 0.45301780104637146, Validation Loss: 0.4489169418811798
Epoch 41, Training Loss: 0.4489169418811798, Validation Loss: 0.4445313811302185
Epoch 42, Training Loss: 0.4445314109325409, Validation Loss: 0.4398486912250519
Epoch 43, Training Loss: 0.4398486614227295, Validation Loss: 0.43482261896133423
Epoch 44, Training Loss: 0.43482261896133423, Validation Loss: 0.42945387959480286
Epoch 45, Training Loss: 0.42945387959480286, Validation Loss: 0.4237136244773865
Epoch 46, Training Loss: 0.4237136244773865, Validation Loss: 0.4175634980201721
Epoch 47, Training Loss: 0.41756346821784973, Validation Loss: 0.41099536418914795
Epoch 48, Training Loss: 0.4109953045845032, Validation Loss: 0.40402355790138245
Epoch 49, Training Loss: 0.40402352809906006, Validation Loss: 0.39658793807029724
Epoch 50, Training Loss: 0.39658793807029724, Validation Loss: 0.38868939876556396
Epoch 51, Training Loss: 0.38868942856788635, Validation Loss: 0.38023996353149414
Epoch 52, Training Loss: 0.38023993372917175, Validation Loss: 0.3713182508945465
Epoch 53, Training Loss: 0.3713182508945465, Validation Loss: 0.36194610595703125
Epoch 54, Training Loss: 0.36194610595703125, Validation Loss: 0.35208967328071594
Epoch 55, Training Loss: 0.35208967328071594, Validation Loss: 0.34180018305778503
Epoch 56, Training Loss: 0.34180018305778503, Validation Loss: 0.33109554648399353
Epoch 57, Training Loss: 0.33109554648399353, Validation Loss: 0.32004666328430176
Epoch 58, Training Loss: 0.32004666328430176, Validation Loss: 0.30865517258644104
Epoch 59, Training Loss: 0.30865517258644104, Validation Loss: 0.2970794141292572
Epoch 60, Training Loss: 0.2970794141292572, Validation Loss: 0.28545135259628296
Epoch 61, Training Loss: 0.28545138239860535, Validation Loss: 0.2738519310951233
Epoch 62, Training Loss: 0.2738519310951233, Validation Loss: 0.2623463571071625
Epoch 63, Training Loss: 0.2623463571071625, Validation Loss: 0.25124064087867737
Epoch 64, Training Loss: 0.25124067068099976, Validation Loss: 0.2406989336013794
Epoch 65, Training Loss: 0.2406989485025406, Validation Loss: 0.23072963953018188
Epoch 66, Training Loss: 0.23072963953018188, Validation Loss: 0.2214621901512146
Epoch 67, Training Loss: 0.2214621603488922, Validation Loss: 0.21325482428073883
Epoch 68, Training Loss: 0.21325482428073883, Validation Loss: 0.20574913918972015
Epoch 69, Training Loss: 0.20574913918972015, Validation Loss: 0.19891944527626038
Epoch 70, Training Loss: 0.19891943037509918, Validation Loss: 0.1924939900636673
Epoch 71, Training Loss: 0.19249401986598969, Validation Loss: 0.18621878325939178
Epoch 72, Training Loss: 0.18621878325939178, Validation Loss: 0.17992334067821503
Epoch 73, Training Loss: 0.17992332577705383, Validation Loss: 0.1734175682067871
Epoch 74, Training Loss: 0.1734175682067871, Validation Loss: 0.16650253534317017
Epoch 75, Training Loss: 0.16650252044200897, Validation Loss: 0.15921995043754578
Epoch 76, Training Loss: 0.15921996533870697, Validation Loss: 0.15176597237586975
Epoch 77, Training Loss: 0.15176597237586975, Validation Loss: 0.14410221576690674
Epoch 78, Training Loss: 0.14410223066806793, Validation Loss: 0.13626284897327423
Epoch 79, Training Loss: 0.13626284897327423, Validation Loss: 0.128525972366333
Epoch 80, Training Loss: 0.12852595746517181, Validation Loss: 0.12076570838689804
Epoch 81, Training Loss: 0.12076569348573685, Validation Loss: 0.11327893286943436
Epoch 82, Training Loss: 0.11327893286943436, Validation Loss: 0.10595618933439255
Epoch 83, Training Loss: 0.10595617443323135, Validation Loss: 0.09894968569278717
Epoch 84, Training Loss: 0.09894968569278717, Validation Loss: 0.09219169616699219
Epoch 85, Training Loss: 0.09219169616699219, Validation Loss: 0.08567586541175842
Epoch 86, Training Loss: 0.08567586541175842, Validation Loss: 0.07932406663894653
Epoch 87, Training Loss: 0.07932406663894653, Validation Loss: 0.07314088940620422
Epoch 88, Training Loss: 0.07314088940620422, Validation Loss: 0.0671255961060524
Epoch 89, Training Loss: 0.0671255886554718, Validation Loss: 0.06123742833733559
Epoch 90, Training Loss: 0.06123742833733559, Validation Loss: 0.05547431856393814
Epoch 91, Training Loss: 0.05547431856393814, Validation Loss: 0.04989746958017349
Epoch 92, Training Loss: 0.04989746958017349, Validation Loss: 0.04455921798944473
Epoch 93, Training Loss: 0.04455921798944473, Validation Loss: 0.03970437869429588
Epoch 94, Training Loss: 0.03970437869429588, Validation Loss: 0.035198863595724106
Epoch 95, Training Loss: 0.035198867321014404, Validation Loss: 0.03105379268527031
Epoch 96, Training Loss: 0.03105379268527031, Validation Loss: 0.027230525389313698
Epoch 97, Training Loss: 0.02723052352666855, Validation Loss: 0.023765617981553078
Epoch 98, Training Loss: 0.023765621706843376, Validation Loss: 0.020618557929992676
Epoch 99, Training Loss: 0.020618557929992676, Validation Loss: 0.017847437411546707
Epoch 100, Training Loss: 0.017847442999482155, Validation Loss: 0.015444702468812466
Epoch 101, Training Loss: 0.015444696880877018, Validation Loss: 0.013379382900893688
Epoch 102, Training Loss: 0.013379381969571114, Validation Loss: 0.011630315333604813
Epoch 103, Training Loss: 0.011630313470959663, Validation Loss: 0.010134054347872734
Epoch 104, Training Loss: 0.010134055279195309, Validation Loss: 0.008886309340596199
Epoch 105, Training Loss: 0.00888630747795105, Validation Loss: 0.007872485555708408
Epoch 106, Training Loss: 0.007872484624385834, Validation Loss: 0.007057478651404381
Epoch 107, Training Loss: 0.007057476788759232, Validation Loss: 0.006400819402188063
Epoch 108, Training Loss: 0.006400819402188063, Validation Loss: 0.005875451490283012
Epoch 109, Training Loss: 0.0058754500932991505, Validation Loss: 0.005405469797551632
Epoch 110, Training Loss: 0.0054054707288742065, Validation Loss: 0.004945025779306889
Epoch 111, Training Loss: 0.004945024382323027, Validation Loss: 0.004471299704164267
Epoch 112, Training Loss: 0.004471298307180405, Validation Loss: 0.003998711239546537
Epoch 113, Training Loss: 0.003998711705207825, Validation Loss: 0.003562011057510972
Epoch 114, Training Loss: 0.003562013618648052, Validation Loss: 0.0031429503578692675
Epoch 115, Training Loss: 0.003142949426546693, Validation Loss: 0.002741490490734577
Epoch 116, Training Loss: 0.0027414916548877954, Validation Loss: 0.0023623639717698097
Epoch 117, Training Loss: 0.0023623635061085224, Validation Loss: 0.002014094265177846
Epoch 118, Training Loss: 0.0020140944980084896, Validation Loss: 0.001706998678855598
Epoch 119, Training Loss: 0.0017070004250854254, Validation Loss: 0.0014562648721039295
Epoch 120, Training Loss: 0.0014562658034265041, Validation Loss: 0.0012600366026163101
Epoch 121, Training Loss: 0.001260037417523563, Validation Loss: 0.0011076944647356868
Epoch 122, Training Loss: 0.0011076937662437558, Validation Loss: 0.0009874626994132996
Epoch 123, Training Loss: 0.0009874642128124833, Validation Loss: 0.0008872029720805585
Epoch 124, Training Loss: 0.0008872034377418458, Validation Loss: 0.0007988265715539455
Epoch 125, Training Loss: 0.0007988266879692674, Validation Loss: 0.0007186679868027568
Epoch 126, Training Loss: 0.000718667870387435, Validation Loss: 0.0006446968181990087
Epoch 127, Training Loss: 0.0006446961197070777, Validation Loss: 0.000575347279664129
Epoch 128, Training Loss: 0.0005753484438173473, Validation Loss: 0.0005091800703667104
Epoch 129, Training Loss: 0.0005091805942356586, Validation Loss: 0.00044400329352356493
Epoch 130, Training Loss: 0.0004440035845618695, Validation Loss: 0.00037961589987389743
Epoch 131, Training Loss: 0.0003796155797317624, Validation Loss: 0.00031849811784923077
Epoch 132, Training Loss: 0.000318497623084113, Validation Loss: 0.00026416656328365207
Epoch 133, Training Loss: 0.00026416603941470385, Validation Loss: 0.00021917959384154528
Epoch 134, Training Loss: 0.0002191798121202737, Validation Loss: 0.00018416567763779312
Epoch 135, Training Loss: 0.00018416553211864084, Validation Loss: 0.0001581217657076195
Epoch 136, Training Loss: 0.0001581214601173997, Validation Loss: 0.00013951060827821493
Epoch 137, Training Loss: 0.00013951060827821493, Validation Loss: 0.00012696522753685713
Epoch 138, Training Loss: 0.00012696516932919621, Validation Loss: 0.00011948758037760854
Epoch 139, Training Loss: 0.00011948719475185499, Validation Loss: 0.0001159894309239462
Epoch 140, Training Loss: 0.00011598915443755686, Validation Loss: 0.00011485425056889653
Epoch 141, Training Loss: 0.00011485441063996404, Validation Loss: 0.00011408753925934434
Epoch 142, Training Loss: 0.00011408752470742911, Validation Loss: 0.00011191758676432073
Epoch 143, Training Loss: 0.00011191765224793926, Validation Loss: 0.00010740751167759299
Epoch 144, Training Loss: 0.00010740757716121152, Validation Loss: 0.00010058003681479022
Epoch 145, Training Loss: 0.00010057992039946839, Validation Loss: 9.205303649650887e-05
Epoch 146, Training Loss: 9.205345122609288e-05, Validation Loss: 8.256861474364996e-05
Epoch 147, Training Loss: 8.256855653598905e-05, Validation Loss: 7.263449515448883e-05
Epoch 148, Training Loss: 7.263400038937107e-05, Validation Loss: 6.263321847654879e-05
Epoch 149, Training Loss: 6.263309478526935e-05, Validation Loss: 5.303081343299709e-05
Epoch 150, Training Loss: 5.303086436470039e-05, Validation Loss: 4.4431653805077076e-05
Epoch 151, Training Loss: 4.443145735422149e-05, Validation Loss: 3.7389858334790915e-05
Epoch 152, Training Loss: 3.738988016266376e-05, Validation Loss: 3.2152580388356e-05
Epoch 153, Training Loss: 3.215260949218646e-05, Validation Loss: 2.8556974939419888e-05
Epoch 154, Training Loss: 2.855696584447287e-05, Validation Loss: 2.6163756047026254e-05
Epoch 155, Training Loss: 2.6163705115322955e-05, Validation Loss: 2.4503295207978226e-05
Epoch 156, Training Loss: 2.450331703585107e-05, Validation Loss: 2.32453785429243e-05
Epoch 157, Training Loss: 2.3245400370797142e-05, Validation Loss: 2.220516762463376e-05
Epoch 158, Training Loss: 2.220512214989867e-05, Validation Loss: 2.1246540200081654e-05
Epoch 159, Training Loss: 2.124660932167899e-05, Validation Loss: 2.0214456526446156e-05
Epoch 160, Training Loss: 2.021455111389514e-05, Validation Loss: 1.896029971248936e-05
Epoch 161, Training Loss: 1.8960092347697355e-05, Validation Loss: 1.7422906239517033e-05
Epoch 162, Training Loss: 1.742292079143226e-05, Validation Loss: 1.5673143934691325e-05
Epoch 163, Training Loss: 1.5673333109589294e-05, Validation Loss: 1.3871311239199713e-05
Epoch 164, Training Loss: 1.3871273040422238e-05, Validation Loss: 1.2170636182418093e-05
Epoch 165, Training Loss: 1.2170557056379039e-05, Validation Loss: 1.0655012374627404e-05
Epoch 166, Training Loss: 1.0655010555638e-05, Validation Loss: 9.314034286944661e-06
Epoch 167, Training Loss: 9.314045200881083e-06, Validation Loss: 8.125997737806756e-06
Epoch 168, Training Loss: 8.12595862953458e-06, Validation Loss: 7.1007425503921695e-06
Epoch 169, Training Loss: 7.1007384576660115e-06, Validation Loss: 6.250458682188764e-06
Epoch 170, Training Loss: 6.250460501178168e-06, Validation Loss: 5.580005563388113e-06
Epoch 171, Training Loss: 5.5799191613914445e-06, Validation Loss: 5.056241661804961e-06
Epoch 172, Training Loss: 5.056264399172505e-06, Validation Loss: 4.618456841853913e-06
Epoch 173, Training Loss: 4.618435923475772e-06, Validation Loss: 4.211408850096632e-06
Epoch 174, Training Loss: 4.211459781799931e-06, Validation Loss: 3.8118714655865915e-06
Epoch 175, Training Loss: 3.811897386185592e-06, Validation Loss: 3.4260001484653912e-06
Epoch 176, Training Loss: 3.4258898722328013e-06, Validation Loss: 3.06647802972293e-06
Epoch 177, Training Loss: 3.0664348287245957e-06, Validation Loss: 2.7350624804967083e-06
Epoch 178, Training Loss: 2.7351109110895777e-06, Validation Loss: 2.423331125100958e-06
Epoch 179, Training Loss: 2.423338173684897e-06, Validation Loss: 2.1274227037793025e-06
Epoch 180, Training Loss: 2.127407469743048e-06, Validation Loss: 1.8578803064883687e-06
Epoch 181, Training Loss: 1.8578234630695079e-06, Validation Loss: 1.6335263808286982e-06
Epoch 182, Training Loss: 1.6335045529558556e-06, Validation Loss: 1.466745516154333e-06
Epoch 183, Training Loss: 1.4667517689304077e-06, Validation Loss: 1.3537106724470505e-06
Epoch 184, Training Loss: 1.353711240881239e-06, Validation Loss: 1.277668161492329e-06
Epoch 185, Training Loss: 1.2776243920598063e-06, Validation Loss: 1.219998239321285e-06
Epoch 186, Training Loss: 1.219988803313754e-06, Validation Loss: 1.1689248822221998e-06
Epoch 187, Training Loss: 1.1689434131767484e-06, Validation Loss: 1.1189496262886678e-06
Epoch 188, Training Loss: 1.1189106317033293e-06, Validation Loss: 1.065187348103791e-06
Epoch 189, Training Loss: 1.0651785942172864e-06, Validation Loss: 1.0008869821831468e-06
Epoch 190, Training Loss: 1.0008969866248663e-06, Validation Loss: 9.198569728141592e-07
Epoch 191, Training Loss: 9.198543580168916e-07, Validation Loss: 8.218344191845972e-07
Epoch 192, Training Loss: 8.218543712246174e-07, Validation Loss: 7.139406079659238e-07
Epoch 193, Training Loss: 7.139111062315351e-07, Validation Loss: 6.066504170121334e-07
Epoch 194, Training Loss: 6.066973696761124e-07, Validation Loss: 5.086053533887025e-07
Epoch 195, Training Loss: 5.085991574560467e-07, Validation Loss: 4.2326297489125864e-07
Epoch 196, Training Loss: 4.2324793980696995e-07, Validation Loss: 3.507720975903794e-07
Epoch 197, Training Loss: 3.50771870216704e-07, Validation Loss: 2.910310570314323e-07
Epoch 198, Training Loss: 2.910250032073236e-07, Validation Loss: 2.447890778967121e-07
Epoch 199, Training Loss: 2.4480004867655225e-07, Validation Loss: 2.123607174553399e-07
Epoch 200, Training Loss: 2.123535125519993e-07, Validation Loss: 1.9195664435756044e-07
Epoch 201, Training Loss: 1.919541858796947e-07, Validation Loss: 1.7970579335724324e-07
Epoch 202, Training Loss: 1.7968086751807277e-07, Validation Loss: 1.7152629538941255e-07
Epoch 203, Training Loss: 1.715427799808822e-07, Validation Loss: 1.6499210175879853e-07
Epoch 204, Training Loss: 1.6497162391715392e-07, Validation Loss: 1.5933885322283459e-07
Epoch 205, Training Loss: 1.593470813077147e-07, Validation Loss: 1.5433229805239534e-07
Epoch 206, Training Loss: 1.5434268618719216e-07, Validation Loss: 1.4917718260676338e-07
Epoch 207, Training Loss: 1.4917232249445078e-07, Validation Loss: 1.4251008906285278e-07
Epoch 208, Training Loss: 1.425226230367116e-07, Validation Loss: 1.3360745754198433e-07
Epoch 209, Training Loss: 1.3359806416701758e-07, Validation Loss: 1.2280877115244948e-07
Epoch 210, Training Loss: 1.2280470684800093e-07, Validation Loss: 1.1128946653116145e-07
Epoch 211, Training Loss: 1.112750283027708e-07, Validation Loss: 1.0008385942228415e-07
Epoch 212, Training Loss: 1.0008662343352626e-07, Validation Loss: 8.951550967140065e-08
Epoch 213, Training Loss: 8.95163054792647e-08, Validation Loss: 7.94781769286601e-08
Epoch 214, Training Loss: 7.94963099792767e-08, Validation Loss: 6.998382673373271e-08
Epoch 215, Training Loss: 6.99858233588202e-08, Validation Loss: 6.129751284333906e-08
Epoch 216, Training Loss: 6.129950946842655e-08, Validation Loss: 5.370288747030827e-08
Epoch 217, Training Loss: 5.369760813778157e-08, Validation Loss: 4.714039292252892e-08
Epoch 218, Training Loss: 4.713769641284671e-08, Validation Loss: 4.120078500591262e-08
Epoch 219, Training Loss: 4.1198607192427517e-08, Validation Loss: 3.5478574744729485e-08
Epoch 220, Training Loss: 3.5473927795237614e-08, Validation Loss: 2.9886820129831904e-08
Epoch 221, Training Loss: 2.989611047610197e-08, Validation Loss: 2.4704435830358307e-08
Epoch 222, Training Loss: 2.4705721912710032e-08, Validation Loss: 2.0197123973275666e-08
Epoch 223, Training Loss: 2.0199191652636728e-08, Validation Loss: 1.647693714801335e-08
Epoch 224, Training Loss: 1.6473030939323507e-08, Validation Loss: 1.3464906523097397e-08
Epoch 225, Training Loss: 1.3461888492827256e-08, Validation Loss: 1.110245495539175e-08
Epoch 226, Training Loss: 1.1105548480827565e-08, Validation Loss: 9.412452151025263e-09
Epoch 227, Training Loss: 9.412794987895268e-09, Validation Loss: 8.444379417937853e-09
Epoch 228, Training Loss: 8.445547372559759e-09, Validation Loss: 8.106814775032944e-09
Epoch 229, Training Loss: 8.110327520682858e-09, Validation Loss: 8.177654997609807e-09
Epoch 230, Training Loss: 8.178365540345567e-09, Validation Loss: 8.4020017609987e-09
Epoch 231, Training Loss: 8.401582540784602e-09, Validation Loss: 8.60705284821961e-09
Epoch 232, Training Loss: 8.609664980951948e-09, Validation Loss: 8.75457839555338e-09
Epoch 233, Training Loss: 8.757384151181213e-09, Validation Loss: 8.810002505299508e-09
Epoch 234, Training Loss: 8.812794050072625e-09, Validation Loss: 8.736568801737121e-09
Epoch 235, Training Loss: 8.73509176102516e-09, Validation Loss: 8.448578725506195e-09
Epoch 236, Training Loss: 8.449052124603895e-09, Validation Loss: 7.937134505198173e-09
Epoch 237, Training Loss: 7.939695123582169e-09, Validation Loss: 7.258354806083389e-09
Epoch 238, Training Loss: 7.259725709474196e-09, Validation Loss: 6.502122840146285e-09
Epoch 239, Training Loss: 6.501818194948328e-09, Validation Loss: 5.747392339827684e-09
Epoch 240, Training Loss: 5.745885101049453e-09, Validation Loss: 5.023677029925011e-09
Epoch 241, Training Loss: 5.022254612185861e-09, Validation Loss: 4.339035353240206e-09
Epoch 242, Training Loss: 4.340989345763546e-09, Validation Loss: 3.725871611237608e-09
Epoch 243, Training Loss: 3.726170927365047e-09, Validation Loss: 3.2140556882609417e-09
Epoch 244, Training Loss: 3.2152671636254126e-09, Validation Loss: 2.816807675998234e-09
Epoch 245, Training Loss: 2.817904354301959e-09, Validation Loss: 2.512071217708467e-09
Epoch 246, Training Loss: 2.5140654003052987e-09, Validation Loss: 2.2648538600122947e-09
Epoch 247, Training Loss: 2.266345777712786e-09, Validation Loss: 2.0400094946637637e-09
Epoch 248, Training Loss: 2.0402945999364874e-09, Validation Loss: 1.829828066846062e-09
Epoch 249, Training Loss: 1.8293000447755503e-09, Validation Loss: 1.6366897837016836e-09
Epoch 250, Training Loss: 1.6361371146800252e-09, Validation Loss: 1.4608585452435818e-09
Epoch 251, Training Loss: 1.4601539977121547e-09, Validation Loss: 1.2938868865219888e-09
Epoch 252, Training Loss: 1.2945696736821333e-09, Validation Loss: 1.1321777959594215e-09
Epoch 253, Training Loss: 1.1316805270666919e-09, Validation Loss: 9.791566446537558e-10
Epoch 254, Training Loss: 9.793289512671777e-10, Validation Loss: 8.490454450615914e-10
Epoch 255, Training Loss: 8.489892677765454e-10, Validation Loss: 7.478396235605089e-10
Epoch 256, Training Loss: 7.477105601338963e-10, Validation Loss: 6.70039523864574e-10
Epoch 257, Training Loss: 6.699145682631524e-10, Validation Loss: 6.075659975124381e-10
Epoch 258, Training Loss: 6.08221750741933e-10, Validation Loss: 5.542467040875465e-10
Epoch 259, Training Loss: 5.548012049771955e-10, Validation Loss: 5.094801247551572e-10
Epoch 260, Training Loss: 5.089546006864509e-10, Validation Loss: 4.714734713751056e-10
Epoch 261, Training Loss: 4.716208534816246e-10, Validation Loss: 4.3695988494185656e-10
Epoch 262, Training Loss: 4.3749368017209633e-10, Validation Loss: 3.9962327891274185e-10
Epoch 263, Training Loss: 4.006375509124638e-10, Validation Loss: 3.5908984119537024e-10
Epoch 264, Training Loss: 3.588484231986655e-10, Validation Loss: 3.151104099874402e-10
Epoch 265, Training Loss: 3.149824845394278e-10, Validation Loss: 2.717823743836334e-10
Epoch 266, Training Loss: 2.7142818548320236e-10, Validation Loss: 2.3374527313713145e-10
Epoch 267, Training Loss: 2.3330115617170577e-10, Validation Loss: 2.0044715887124198e-10
Epoch 268, Training Loss: 2.0017200397237644e-10, Validation Loss: 1.7259096929400641e-10
Epoch 269, Training Loss: 1.7238821481413424e-10, Validation Loss: 1.496484741680959e-10
Epoch 270, Training Loss: 1.4941217707509225e-10, Validation Loss: 1.3343606775073624e-10
Epoch 271, Training Loss: 1.3297311862725536e-10, Validation Loss: 1.2283973838123075e-10
Epoch 272, Training Loss: 1.2299394835935118e-10, Validation Loss: 1.1678620570609866e-10
Epoch 273, Training Loss: 1.166579055578154e-10, Validation Loss: 1.1107678665744913e-10
Epoch 274, Training Loss: 1.1092125828948696e-10, Validation Loss: 1.0486731621961454e-10
Epoch 275, Training Loss: 1.0461660010507856e-10, Validation Loss: 9.830768837870707e-11
Epoch 276, Training Loss: 9.812912288298392e-11, Validation Loss: 9.092817471190173e-11
Epoch 277, Training Loss: 9.060458633358692e-11, Validation Loss: 8.353760738710747e-11
Epoch 278, Training Loss: 8.330525158584123e-11, Validation Loss: 7.5034943536334e-11
Epoch 279, Training Loss: 7.513743099929471e-11, Validation Loss: 6.620030218451589e-11
Epoch 280, Training Loss: 6.620205772467358e-11, Validation Loss: 5.8142393677407256e-11
Epoch 281, Training Loss: 5.8149283999053836e-11, Validation Loss: 5.130850952439481e-11
Epoch 282, Training Loss: 5.1358192004746783e-11, Validation Loss: 4.672045736398012e-11
Epoch 283, Training Loss: 4.6556078436843507e-11, Validation Loss: 4.323628260971546e-11
Epoch 284, Training Loss: 4.311933796130596e-11, Validation Loss: 4.031703443319046e-11
Epoch 285, Training Loss: 4.033410064274712e-11, Validation Loss: 3.810741652787719e-11
Epoch 286, Training Loss: 3.814973684179712e-11, Validation Loss: 3.621622446381423e-11
Epoch 287, Training Loss: 3.636830420150616e-11, Validation Loss: 3.4861360326265967e-11
Epoch 288, Training Loss: 3.484662558506102e-11, Validation Loss: 3.3160706819357344e-11
Epoch 289, Training Loss: 3.3224641787787945e-11, Validation Loss: 3.131570350256574e-11
Epoch 290, Training Loss: 3.1064921468537676e-11, Validation Loss: 2.881154689826637e-11
Epoch 291, Training Loss: 2.8817465774766404e-11, Validation Loss: 2.615541290496015e-11
Epoch 292, Training Loss: 2.6038445705145463e-11, Validation Loss: 2.3124533538032566e-11
Epoch 293, Training Loss: 2.3197048448775348e-11, Validation Loss: 2.0501985525944733e-11
Epoch 294, Training Loss: 2.032928166084691e-11, Validation Loss: 1.781530305222656e-11
Epoch 295, Training Loss: 1.762229771828938e-11, Validation Loss: 1.5383007367919532e-11
Epoch 296, Training Loss: 1.516430904457966e-11, Validation Loss: 1.3017521088842798e-11
Epoch 297, Training Loss: 1.286422270790899e-11, Validation Loss: 1.0973617847742645e-11
Epoch 298, Training Loss: 1.0923222396042043e-11, Validation Loss: 9.382142632241575e-12
Epoch 299, Training Loss: 9.375543744138959e-12, Validation Loss: 7.983399531730218e-12
Epoch 300, Training Loss: 8.011927926654394e-12, Validation Loss: 6.816228571154825e-12
Epoch 301, Training Loss: 6.7815189228048744e-12, Validation Loss: 5.836068173864506e-12
Epoch 302, Training Loss: 5.7789615107162184e-12, Validation Loss: 4.892241559778521e-12
Epoch 303, Training Loss: 4.877572304384792e-12, Validation Loss: 4.019667411425676e-12
Epoch 304, Training Loss: 4.018580173487107e-12, Validation Loss: 3.299302671344595e-12
Epoch 305, Training Loss: 3.3007973524595835e-12, Validation Loss: 2.6491805710932015e-12
Epoch 306, Training Loss: 2.7772187761315736e-12, Validation Loss: 2.289604053226646e-12
Epoch 307, Training Loss: 2.3098430720208674e-12, Validation Loss: 1.942086465603343e-12
Epoch 308, Training Loss: 1.992733452207962e-12, Validation Loss: 1.6728050151668117e-12
Epoch 309, Training Loss: 1.6973850710394478e-12, Validation Loss: 1.5466599355418165e-12
Epoch 310, Training Loss: 1.5252249333311263e-12, Validation Loss: 1.4323608488533979e-12
Epoch 311, Training Loss: 1.4770446150891292e-12, Validation Loss: 1.3795335316799107e-12
Epoch 312, Training Loss: 1.4070206588376322e-12, Validation Loss: 1.4572350487754293e-12
Epoch 313, Training Loss: 1.4177551277069766e-12, Validation Loss: 1.4728252254944674e-12
Epoch 314, Training Loss: 1.4443910477390798e-12, Validation Loss: 1.4310332432931894e-12
Epoch 315, Training Loss: 1.389785530582499e-12, Validation Loss: 1.4095778580816565e-12
Epoch 316, Training Loss: 1.4027422886447871e-12, Validation Loss: 1.4225360256067687e-12
Epoch 317, Training Loss: 1.4017801676369235e-12, Validation Loss: 1.3133317133470768e-12
Epoch 318, Training Loss: 1.3396144003113841e-12, Validation Loss: 1.2797893170560237e-12
Epoch 319, Training Loss: 1.3176274307746816e-12, Validation Loss: 1.2305632858186644e-12
Epoch 320, Training Loss: 1.2376060462906957e-12, Validation Loss: 1.1619432629603188e-12
Epoch 321, Training Loss: 1.136266753430648e-12, Validation Loss: 1.055197921227824e-12
Epoch 322, Training Loss: 1.0676737272063974e-12, Validation Loss: 9.464327108479886e-13
Epoch 323, Training Loss: 9.467658861755934e-13, Validation Loss: 8.524199141685118e-13
Epoch 324, Training Loss: 8.260058219008992e-13, Validation Loss: 7.728313974018908e-13
Epoch 325, Training Loss: 7.634942482924456e-13, Validation Loss: 6.748094379289971e-13
Epoch 326, Training Loss: 6.463226221581353e-13, Validation Loss: 5.749291559324632e-13
Epoch 327, Training Loss: 5.584776890076026e-13, Validation Loss: 5.231599116591046e-13
Epoch 328, Training Loss: 5.079115296749426e-13, Validation Loss: 4.3730161635932574e-13
Epoch 329, Training Loss: 4.2058435727188037e-13, Validation Loss: 3.8833237840651957e-13
Epoch 330, Training Loss: 3.6436489676133776e-13, Validation Loss: 3.6727706379663383e-13
Epoch 331, Training Loss: 3.3242264735160176e-13, Validation Loss: 3.1684081898929184e-13
Epoch 332, Training Loss: 2.935548126196258e-13, Validation Loss: 2.8528270240926745e-13
Epoch 333, Training Loss: 2.691563335058267e-13, Validation Loss: 2.6080073972818696e-13
Epoch 334, Training Loss: 2.4520153702606295e-13, Validation Loss: 2.238509670595551e-13
Epoch 335, Training Loss: 2.306420028921896e-13, Validation Loss: 2.020030193464195e-13
Epoch 336, Training Loss: 2.0662409229346007e-13, Validation Loss: 1.8968514096679573e-13
Epoch 337, Training Loss: 1.9141363028028074e-13, Validation Loss: 1.7358224504038927e-13
Epoch 338, Training Loss: 1.7581006366441249e-13, Validation Loss: 1.5165646516379638e-13
Epoch 339, Training Loss: 1.4324115895150702e-13, Validation Loss: 1.3734533530016663e-13
Epoch 340, Training Loss: 1.2676701864871437e-13, Validation Loss: 1.1248020879506618e-13
Epoch 341, Training Loss: 1.1839831957731473e-13, Validation Loss: 1.0374554405660763e-13
Epoch 342, Training Loss: 1.0085893031126433e-13, Validation Loss: 9.027297681075963e-14
Epoch 343, Training Loss: 9.063740426598632e-14, Validation Loss: 8.322186120573657e-14
Epoch 344, Training Loss: 7.803517353783748e-14, Validation Loss: 6.773408060562619e-14
Epoch 345, Training Loss: 6.598231482675063e-14, Validation Loss: 5.756809959289733e-14
Epoch 346, Training Loss: 5.181562440941846e-14, Validation Loss: 5.87175571836393e-14
Epoch 347, Training Loss: 4.7056610452851644e-14, Validation Loss: 4.315918824583653e-14
Epoch 348, Training Loss: 3.572032467448298e-14, Validation Loss: 3.52771367076888e-14
Epoch 349, Training Loss: 2.99535719036452e-14, Validation Loss: 3.348183343532436e-14
Epoch 350, Training Loss: 2.3485054030073123e-14, Validation Loss: 2.7580770038172255e-14
Epoch 351, Training Loss: 2.1632103389384455e-14, Validation Loss: 2.373605530333299e-14
Epoch 352, Training Loss: 1.9446617777999116e-14, Validation Loss: 2.129613285305372e-14
Epoch 353, Training Loss: 1.686881869269758e-14, Validation Loss: 2.084293634495478e-14
Epoch 354, Training Loss: 1.3391231754120853e-14, Validation Loss: 1.3449544890341628e-14
Epoch 355, Training Loss: 1.5079385358657618e-14, Validation Loss: 1.3592860323918213e-14
Epoch 356, Training Loss: 1.1210417529439621e-14, Validation Loss: 1.1946840679276718e-14
Epoch 357, Training Loss: 1.3323176891973706e-14, Validation Loss: 1.2451412276725474e-14
Epoch 358, Training Loss: 1.2885626776476446e-14, Validation Loss: 1.1506487731756995e-14
Epoch 359, Training Loss: 1.1214954237905115e-14, Validation Loss: 1.0266027462260859e-14
Epoch 360, Training Loss: 1.1704013273957856e-14, Validation Loss: 1.1393931452627001e-14
Epoch 361, Training Loss: 1.1777672106084037e-14, Validation Loss: 7.644926358629789e-15
Epoch 362, Training Loss: 1.1205480174390076e-14, Validation Loss: 8.577007343019052e-15
Epoch 363, Training Loss: 1.0236837012832581e-14, Validation Loss: 1.109499150268433e-14
Epoch 364, Training Loss: 8.854396233684732e-15, Validation Loss: 9.414445101046855e-15
Epoch 365, Training Loss: 6.648494587171722e-15, Validation Loss: 7.586880037787399e-15
Epoch 366, Training Loss: 6.238699623773618e-15, Validation Loss: 1.0244076603432763e-14
Epoch 367, Training Loss: 7.688662057828317e-15, Validation Loss: 1.0968389723222966e-14
Epoch 368, Training Loss: 6.612065394176209e-15, Validation Loss: 8.978761846165344e-15
Epoch 369, Training Loss: 6.083241972898142e-15, Validation Loss: 9.36663940853677e-15
Epoch 370, Training Loss: 5.005177824664916e-15, Validation Loss: 9.202007543809582e-15
Epoch 371, Training Loss: 6.275529039836709e-15, Validation Loss: 8.323737715526438e-15
Epoch 372, Training Loss: 5.555218574238756e-15, Validation Loss: 9.608500349262816e-15
Epoch 373, Training Loss: 6.3697381618127e-15, Validation Loss: 7.81089314728185e-15
Epoch 374, Training Loss: 5.439659139794273e-15, Validation Loss: 7.79437939294218e-15
Epoch 375, Training Loss: 4.469948716723238e-15, Validation Loss: 9.127715131038855e-15
Epoch 376, Training Loss: 3.754709013864023e-15, Validation Loss: 7.12744513203193e-15
Epoch 377, Training Loss: 2.7592445540317208e-15, Validation Loss: 7.218251299142327e-15
Epoch 378, Training Loss: 2.7928715502794797e-15, Validation Loss: 8.203874930193429e-15
Epoch 379, Training Loss: 4.056017267927217e-15, Validation Loss: 8.519327787442823e-15
Epoch 380, Training Loss: 3.94873122779504e-15, Validation Loss: 8.015723501619831e-15
Epoch 381, Training Loss: 3.364529639458434e-15, Validation Loss: 7.873209361211348e-15
Epoch 382, Training Loss: 3.583505020499089e-15, Validation Loss: 8.422683022227002e-15
Epoch 383, Training Loss: 3.7548424215532155e-15, Validation Loss: 8.444467015564488e-15
Epoch 384, Training Loss: 2.771521026052751e-15, Validation Loss: 8.185326602714454e-15
Epoch 385, Training Loss: 2.508510307908476e-15, Validation Loss: 8.395094312101982e-15
Epoch 386, Training Loss: 2.616329978797423e-15, Validation Loss: 8.345454793261091e-15
Epoch 387, Training Loss: 2.6990630748875396e-15, Validation Loss: 7.331175190571429e-15
Epoch 388, Training Loss: 2.9547346760603298e-15, Validation Loss: 1.048143302294531e-14
Epoch 389, Training Loss: 3.1536940332826556e-15, Validation Loss: 1.047729611403092e-14
Epoch 390, Training Loss: 3.319693644461422e-15, Validation Loss: 1.0317167923484284e-14
Epoch 391, Training Loss: 2.2815283479338993e-15, Validation Loss: 9.993575926644724e-15
Epoch 392, Training Loss: 3.413769146989984e-15, Validation Loss: 9.321036848722493e-15
Epoch 393, Training Loss: 3.311553869596545e-15, Validation Loss: 8.780202923768833e-15
Epoch 394, Training Loss: 3.2935393846325774e-15, Validation Loss: 9.210548177016747e-15
Epoch 395, Training Loss: 2.8836110135452807e-15, Validation Loss: 8.869474267178806e-15
Epoch 396, Training Loss: 3.3353061557452133e-15, Validation Loss: 7.838381907519093e-15
Epoch 397, Training Loss: 3.4094990421446383e-15, Validation Loss: 8.41657845577614e-15
Epoch 398, Training Loss: 3.1735766494117926e-15, Validation Loss: 8.295280796630482e-15
Epoch 399, Training Loss: 1.757508450499711e-15, Validation Loss: 9.341452883850163e-15
Epoch 400, Training Loss: 2.4780859432342855e-15, Validation Loss: 4.932586254052275e-15
Epoch 401, Training Loss: 2.578433089462555e-15, Validation Loss: 5.097518391959264e-15
Epoch 402, Training Loss: 2.542937962049627e-15, Validation Loss: 6.888287073440573e-15
Epoch 403, Training Loss: 2.6210005184685832e-15, Validation Loss: 6.417509549488422e-15
Epoch 404, Training Loss: 1.9061608269187093e-15, Validation Loss: 9.054289232973169e-15
Epoch 405, Training Loss: 2.5392014879610514e-15, Validation Loss: 6.18732538145675e-15
Epoch 406, Training Loss: 1.7134732192752096e-15, Validation Loss: 5.340246270906825e-15
Epoch 407, Training Loss: 1.6129926653577474e-15, Validation Loss: 5.212143549062926e-15
Epoch 408, Training Loss: 1.6129926653577474e-15, Validation Loss: 5.178116541505826e-15
Epoch 409, Training Loss: 2.2237488424698944e-15, Validation Loss: 4.402027685781757e-15
Epoch 410, Training Loss: 2.242964208394832e-15, Validation Loss: 4.453535759304291e-15
Epoch 411, Training Loss: 2.218277644905342e-15, Validation Loss: 4.437523024952922e-15
Epoch 412, Training Loss: 2.218277644905342e-15, Validation Loss: 4.917207523861926e-15
Epoch 413, Training Loss: 2.977419488937221e-15, Validation Loss: 4.896390842150204e-15
Epoch 414, Training Loss: 2.939522387844116e-15, Validation Loss: 5.093215041070739e-15
Epoch 415, Training Loss: 2.960339069555838e-15, Validation Loss: 4.75394319382808e-15
Epoch 416, Training Loss: 3.0078438536114112e-15, Validation Loss: 1.8189242684062785e-15
Epoch 417, Training Loss: 2.607656361417539e-15, Validation Loss: 2.3911162001002398e-15
Epoch 418, Training Loss: 1.8785388707505098e-15, Validation Loss: 2.2363255876707263e-15
Epoch 419, Training Loss: 1.7053333385312142e-15, Validation Loss: 2.231121417242796e-15
Epoch 420, Training Loss: 2.4772852853408934e-15, Validation Loss: 2.231121417242796e-15
Epoch 421, Training Loss: 1.9892941460764035e-15, Validation Loss: 2.0514773758331835e-15
Epoch 422, Training Loss: 1.924175311882677e-15, Validation Loss: 2.1582295734503534e-15
Epoch 423, Training Loss: 3.0221218644868033e-15, Validation Loss: 2.261912758941384e-15
Epoch 424, Training Loss: 2.935652717824585e-15, Validation Loss: 2.4819556132538168e-15
Epoch 425, Training Loss: 1.816889483508737e-15, Validation Loss: 2.4147018325165357e-15
Epoch 426, Training Loss: 1.4950314689913245e-15, Validation Loss: 1.9686110838121112e-15
Epoch 427, Training Loss: 7.66581016770258e-16, Validation Loss: 3.1909238841715606e-15
Epoch 428, Training Loss: 1.0804325582328676e-15, Validation Loss: 3.192525199958345e-15
Epoch 429, Training Loss: 7.974057103911445e-16, Validation Loss: 2.402558768184698e-15
Epoch 430, Training Loss: 2.3086168851035654e-15, Validation Loss: 2.1733084539773745e-15
Epoch 431, Training Loss: 2.2242824732266646e-15, Validation Loss: 2.2186780797311565e-15
Epoch 432, Training Loss: 1.9856912914352574e-15, Validation Loss: 2.066689664049397e-15
Epoch 433, Training Loss: 1.478618299814141e-15, Validation Loss: 2.060551428038882e-15
Epoch 434, Training Loss: 1.444324159241301e-15, Validation Loss: 2.060551428038882e-15
Epoch 435, Training Loss: 1.5943110360686985e-15, Validation Loss: 1.933382771777568e-15
Epoch 436, Training Loss: 9.505951129129921e-16, Validation Loss: 2.2584433119894306e-15
Epoch 437, Training Loss: 9.399199566787462e-16, Validation Loss: 2.181047794016437e-15
Epoch 438, Training Loss: 8.002079600784578e-16, Validation Loss: 1.8063475232054467e-15
Epoch 439, Training Loss: 8.749345301742122e-16, Validation Loss: 1.7934372587816334e-15
Epoch 440, Training Loss: 8.749345301742122e-16, Validation Loss: 1.4475600368580492e-15
Epoch 441, Training Loss: 8.749345301742122e-16, Validation Loss: 3.4491641127568995e-15
Epoch 442, Training Loss: 8.749345301742122e-16, Validation Loss: 3.4491641127568995e-15
Epoch 443, Training Loss: 9.122977887523098e-16, Validation Loss: 3.4491641127568995e-15
Epoch 444, Training Loss: 9.006884610563608e-16, Validation Loss: 3.49186494945212e-15
Epoch 445, Training Loss: 9.472591795293495e-16, Validation Loss: 3.432217312822946e-15
Epoch 446, Training Loss: 9.627381772448298e-16, Validation Loss: 3.720448225213481e-15
Epoch 447, Training Loss: 9.39119298785354e-16, Validation Loss: 3.720448225213481e-15
Epoch 448, Training Loss: 9.551321390158414e-16, Validation Loss: 3.714143335470594e-15
Epoch 449, Training Loss: 9.551321390158414e-16, Validation Loss: 4.3988250542081886e-15
Epoch 450, Training Loss: 8.990871452695766e-16, Validation Loss: 4.3988250542081886e-15
Epoch 451, Training Loss: 1.6303399001175154e-15, Validation Loss: 4.400960424268217e-15
Epoch 452, Training Loss: 1.7984745637189548e-15, Validation Loss: 3.683051720592204e-15
Epoch 453, Training Loss: 9.519295074422729e-16, Validation Loss: 5.233627692737084e-15
Epoch 454, Training Loss: 8.284972723299753e-16, Validation Loss: 4.685988705085183e-15
Epoch 455, Training Loss: 9.517960997530803e-16, Validation Loss: 4.685988705085183e-15
Epoch 456, Training Loss: 1.9212397074457304e-15, Validation Loss: 5.776062086444581e-15
Epoch 457, Training Loss: 1.0351962342891596e-15, Validation Loss: 1.738159676885581e-15
Epoch 458, Training Loss: 1.726416835621321e-15, Validation Loss: 3.992232722383653e-15
Epoch 459, Training Loss: 1.7310872694133628e-15, Validation Loss: 3.992232722383653e-15
Epoch 460, Training Loss: 1.6506228451933485e-15, Validation Loss: 3.992232722383653e-15
Epoch 461, Training Loss: 1.6005826797684062e-15, Validation Loss: 6.606995054953945e-15
Epoch 462, Training Loss: 8.084812485116457e-16, Validation Loss: 3.2209480257781734e-15
Epoch 463, Training Loss: 1.4009560723418808e-15, Validation Loss: 3.086306633097945e-15
Epoch 464, Training Loss: 1.2627119308996249e-15, Validation Loss: 3.1111266042766275e-15
Epoch 465, Training Loss: 1.2835286126113466e-15, Validation Loss: 3.0022392483576663e-15
Epoch 466, Training Loss: 8.6546025490093605e-16, Validation Loss: 4.2459025729438445e-15
Epoch 467, Training Loss: 9.320468913131359e-16, Validation Loss: 4.2459025729438445e-15
Epoch 468, Training Loss: 7.612433857135759e-16, Validation Loss: 4.2459025729438445e-15
Epoch 469, Training Loss: 1.5158481507030462e-15, Validation Loss: 4.2459025729438445e-15
Epoch 470, Training Loss: 1.314353306232233e-15, Validation Loss: 4.2459025729438445e-15
Epoch 471, Training Loss: 1.314353306232233e-15, Validation Loss: 4.1898577909558164e-15
Epoch 472, Training Loss: 1.385210153368897e-15, Validation Loss: 4.247503888730629e-15
Epoch 473, Training Loss: 1.85972372789315e-15, Validation Loss: 4.247503888730629e-15
Epoch 474, Training Loss: 9.50328297534607e-16, Validation Loss: 4.247503888730629e-15
Epoch 475, Training Loss: 9.50328297534607e-16, Validation Loss: 4.492366714221744e-15
Epoch 476, Training Loss: 2.1470205747011004e-15, Validation Loss: 1.8188910223630988e-15
Epoch 477, Training Loss: 2.1498227714488545e-15, Validation Loss: 1.8188910223630988e-15
Epoch 478, Training Loss: 2.1999963445629893e-15, Validation Loss: 1.5339960433562064e-15
Epoch 479, Training Loss: 2.0512105604547984e-15, Validation Loss: 1.495565205627213e-15
Epoch 480, Training Loss: 1.9144342212310157e-15, Validation Loss: 1.5051728885896818e-15
Epoch 481, Training Loss: 1.8784052513030804e-15, Validation Loss: 1.6839829201836039e-15
Epoch 482, Training Loss: 1.763646686510226e-15, Validation Loss: 3.4763525998143417e-15
Epoch 483, Training Loss: 1.6811806175567314e-15, Validation Loss: 4.159566622212582e-15
Epoch 484, Training Loss: 9.312463392988622e-16, Validation Loss: 4.902162101136321e-15
Epoch 485, Training Loss: 8.760020034459894e-16, Validation Loss: 4.2082727107455985e-15
Epoch 486, Training Loss: 8.413075339264533e-16, Validation Loss: 4.494502084281772e-15
Epoch 487, Training Loss: 1.4109640842510456e-15, Validation Loss: 4.654630274828408e-15
Epoch 488, Training Loss: 7.007949323723319e-16, Validation Loss: 3.930950312166278e-15
Epoch 489, Training Loss: 1.491828837417756e-15, Validation Loss: 6.533035526131489e-15
Epoch 490, Training Loss: 1.3218259367720289e-15, Validation Loss: 3.213041608490265e-15
Epoch 491, Training Loss: 8.474458228765276e-16, Validation Loss: 2.721981457099636e-15
Epoch 492, Training Loss: 8.474458228765276e-16, Validation Loss: 2.721981457099636e-15
Epoch 493, Training Loss: 2.3780058241426377e-15, Validation Loss: 2.721981457099636e-15
Epoch 494, Training Loss: 1.7635132788210335e-15, Validation Loss: 4.026093287966617e-15
Epoch 495, Training Loss: 1.7014635626325645e-15, Validation Loss: 5.104023604994177e-15
Epoch 496, Training Loss: 1.7648476733503143e-15, Validation Loss: 5.52169173963701e-15
Epoch 497, Training Loss: 1.0157139471067187e-15, Validation Loss: 4.5661259197521745e-15
Epoch 498, Training Loss: 2.1040529226274947e-15, Validation Loss: 4.570929867112527e-15
Epoch 499, Training Loss: 2.204533476544957e-15, Validation Loss: 4.6179008086530936e-15
Epoch 500, Training Loss: 8.359699558093303e-16, Validation Loss: 4.647524515433892e-15
