Epoch 1, Training Loss: 0.5316208004951477, Validation Loss: 0.5296847224235535
Epoch 2, Training Loss: 0.5296847224235535, Validation Loss: 0.5278366804122925
Epoch 3, Training Loss: 0.5278366804122925, Validation Loss: 0.5260059237480164
Epoch 4, Training Loss: 0.5260059237480164, Validation Loss: 0.5242254137992859
Epoch 5, Training Loss: 0.5242254137992859, Validation Loss: 0.5224717855453491
Epoch 6, Training Loss: 0.5224717855453491, Validation Loss: 0.5207176208496094
Epoch 7, Training Loss: 0.5207176208496094, Validation Loss: 0.5189775228500366
Epoch 8, Training Loss: 0.5189775824546814, Validation Loss: 0.5173309445381165
Epoch 9, Training Loss: 0.5173309445381165, Validation Loss: 0.5156594514846802
Epoch 10, Training Loss: 0.5156594514846802, Validation Loss: 0.5139678716659546
Epoch 11, Training Loss: 0.5139678716659546, Validation Loss: 0.5122478008270264
Epoch 12, Training Loss: 0.5122478604316711, Validation Loss: 0.5105111002922058
Epoch 13, Training Loss: 0.5105111002922058, Validation Loss: 0.5088033676147461
Epoch 14, Training Loss: 0.5088033676147461, Validation Loss: 0.5070866346359253
Epoch 15, Training Loss: 0.5070866346359253, Validation Loss: 0.5053436160087585
Epoch 16, Training Loss: 0.5053436160087585, Validation Loss: 0.5035759806632996
Epoch 17, Training Loss: 0.5035759806632996, Validation Loss: 0.5017728805541992
Epoch 18, Training Loss: 0.5017728805541992, Validation Loss: 0.49991315603256226
Epoch 19, Training Loss: 0.49991315603256226, Validation Loss: 0.49798351526260376
Epoch 20, Training Loss: 0.49798351526260376, Validation Loss: 0.4960267245769501
Epoch 21, Training Loss: 0.4960267245769501, Validation Loss: 0.49405547976493835
Epoch 22, Training Loss: 0.4940553903579712, Validation Loss: 0.4920271933078766
Epoch 23, Training Loss: 0.4920271933078766, Validation Loss: 0.48998013138771057
Epoch 24, Training Loss: 0.48998013138771057, Validation Loss: 0.4879065752029419
Epoch 25, Training Loss: 0.48790663480758667, Validation Loss: 0.48574021458625793
Epoch 26, Training Loss: 0.4857402443885803, Validation Loss: 0.48347681760787964
Epoch 27, Training Loss: 0.48347681760787964, Validation Loss: 0.48109570145606995
Epoch 28, Training Loss: 0.48109573125839233, Validation Loss: 0.47861963510513306
Epoch 29, Training Loss: 0.47861960530281067, Validation Loss: 0.476072758436203
Epoch 30, Training Loss: 0.4760727286338806, Validation Loss: 0.47339558601379395
Epoch 31, Training Loss: 0.47339558601379395, Validation Loss: 0.47055310010910034
Epoch 32, Training Loss: 0.47055312991142273, Validation Loss: 0.46754005551338196
Epoch 33, Training Loss: 0.46754002571105957, Validation Loss: 0.4643051028251648
Epoch 34, Training Loss: 0.4643051028251648, Validation Loss: 0.46095365285873413
Epoch 35, Training Loss: 0.4609536826610565, Validation Loss: 0.45736613869667053
Epoch 36, Training Loss: 0.45736610889434814, Validation Loss: 0.4535326659679413
Epoch 37, Training Loss: 0.4535326659679413, Validation Loss: 0.449458509683609
Epoch 38, Training Loss: 0.4494585394859314, Validation Loss: 0.44510847330093384
Epoch 39, Training Loss: 0.4451085031032562, Validation Loss: 0.440456360578537
Epoch 40, Training Loss: 0.44045642018318176, Validation Loss: 0.43550214171409607
Epoch 41, Training Loss: 0.43550214171409607, Validation Loss: 0.43021613359451294
Epoch 42, Training Loss: 0.4302161931991577, Validation Loss: 0.4246748089790344
Epoch 43, Training Loss: 0.4246748685836792, Validation Loss: 0.4187198579311371
Epoch 44, Training Loss: 0.4187198281288147, Validation Loss: 0.41234421730041504
Epoch 45, Training Loss: 0.4123442471027374, Validation Loss: 0.40553218126296997
Epoch 46, Training Loss: 0.40553218126296997, Validation Loss: 0.39824971556663513
Epoch 47, Training Loss: 0.39824971556663513, Validation Loss: 0.3904794752597809
Epoch 48, Training Loss: 0.3904794752597809, Validation Loss: 0.38214248418807983
Epoch 49, Training Loss: 0.38214245438575745, Validation Loss: 0.3732152581214905
Epoch 50, Training Loss: 0.3732152581214905, Validation Loss: 0.3637223243713379
Epoch 51, Training Loss: 0.3637223243713379, Validation Loss: 0.3537074625492096
Epoch 52, Training Loss: 0.3537074625492096, Validation Loss: 0.34312692284584045
Epoch 53, Training Loss: 0.34312692284584045, Validation Loss: 0.3320104777812958
Epoch 54, Training Loss: 0.3320104777812958, Validation Loss: 0.3203470706939697
Epoch 55, Training Loss: 0.3203471004962921, Validation Loss: 0.3081694543361664
Epoch 56, Training Loss: 0.30816948413848877, Validation Loss: 0.2956424653530121
Epoch 57, Training Loss: 0.2956424653530121, Validation Loss: 0.2827090919017792
Epoch 58, Training Loss: 0.2827090919017792, Validation Loss: 0.26950377225875854
Epoch 59, Training Loss: 0.26950374245643616, Validation Loss: 0.25621503591537476
Epoch 60, Training Loss: 0.25621503591537476, Validation Loss: 0.24300113320350647
Epoch 61, Training Loss: 0.24300113320350647, Validation Loss: 0.23005658388137817
Epoch 62, Training Loss: 0.23005656898021698, Validation Loss: 0.21757975220680237
Epoch 63, Training Loss: 0.21757973730564117, Validation Loss: 0.2057199627161026
Epoch 64, Training Loss: 0.2057199627161026, Validation Loss: 0.19472503662109375
Epoch 65, Training Loss: 0.19472503662109375, Validation Loss: 0.18474525213241577
Epoch 66, Training Loss: 0.18474522233009338, Validation Loss: 0.17605705559253693
Epoch 67, Training Loss: 0.17605705559253693, Validation Loss: 0.1685783863067627
Epoch 68, Training Loss: 0.1685783863067627, Validation Loss: 0.16215364634990692
Epoch 69, Training Loss: 0.16215364634990692, Validation Loss: 0.15674038231372833
Epoch 70, Training Loss: 0.15674038231372833, Validation Loss: 0.15194196999073029
Epoch 71, Training Loss: 0.15194198489189148, Validation Loss: 0.14744015038013458
Epoch 72, Training Loss: 0.14744016528129578, Validation Loss: 0.1428607702255249
Epoch 73, Training Loss: 0.1428607702255249, Validation Loss: 0.13794566690921783
Epoch 74, Training Loss: 0.13794568181037903, Validation Loss: 0.13254249095916748
Epoch 75, Training Loss: 0.13254250586032867, Validation Loss: 0.12661314010620117
Epoch 76, Training Loss: 0.12661314010620117, Validation Loss: 0.12029831856489182
Epoch 77, Training Loss: 0.12029831856489182, Validation Loss: 0.11381212621927261
Epoch 78, Training Loss: 0.11381211876869202, Validation Loss: 0.10734023153781891
Epoch 79, Training Loss: 0.1073402389883995, Validation Loss: 0.10106838494539261
Epoch 80, Training Loss: 0.10106836259365082, Validation Loss: 0.09516897797584534
Epoch 81, Training Loss: 0.09516897797584534, Validation Loss: 0.08962900191545486
Epoch 82, Training Loss: 0.08962899446487427, Validation Loss: 0.08457275480031967
Epoch 83, Training Loss: 0.08457275480031967, Validation Loss: 0.07998961210250854
Epoch 84, Training Loss: 0.07998961955308914, Validation Loss: 0.07569842785596848
Epoch 85, Training Loss: 0.07569841295480728, Validation Loss: 0.07154150307178497
Epoch 86, Training Loss: 0.07154151052236557, Validation Loss: 0.06745332479476929
Epoch 87, Training Loss: 0.0674533098936081, Validation Loss: 0.06342104077339172
Epoch 88, Training Loss: 0.06342103332281113, Validation Loss: 0.0594744011759758
Epoch 89, Training Loss: 0.0594743974506855, Validation Loss: 0.05551429092884064
Epoch 90, Training Loss: 0.05551429092884064, Validation Loss: 0.05154546722769737
Epoch 91, Training Loss: 0.05154545605182648, Validation Loss: 0.047595199197530746
Epoch 92, Training Loss: 0.047595199197530746, Validation Loss: 0.043696869164705276
Epoch 93, Training Loss: 0.043696872889995575, Validation Loss: 0.039880573749542236
Epoch 94, Training Loss: 0.03988058120012283, Validation Loss: 0.03616046532988548
Epoch 95, Training Loss: 0.03616046905517578, Validation Loss: 0.03256300464272499
Epoch 96, Training Loss: 0.03256300836801529, Validation Loss: 0.02914505824446678
Epoch 97, Training Loss: 0.02914505824446678, Validation Loss: 0.025941716507077217
Epoch 98, Training Loss: 0.02594171278178692, Validation Loss: 0.022944370284676552
Epoch 99, Training Loss: 0.022944368422031403, Validation Loss: 0.02017279341816902
Epoch 100, Training Loss: 0.020172789692878723, Validation Loss: 0.0176539309322834
Epoch 101, Training Loss: 0.0176539309322834, Validation Loss: 0.015405479818582535
Epoch 102, Training Loss: 0.01540547888725996, Validation Loss: 0.013428010046482086
Epoch 103, Training Loss: 0.01342801097780466, Validation Loss: 0.011730240657925606
Epoch 104, Training Loss: 0.011730240657925606, Validation Loss: 0.010315601713955402
Epoch 105, Training Loss: 0.010315604507923126, Validation Loss: 0.009173824451863766
Epoch 106, Training Loss: 0.009173822589218616, Validation Loss: 0.00827416218817234
Epoch 107, Training Loss: 0.008274160325527191, Validation Loss: 0.0075761862099170685
Epoch 108, Training Loss: 0.007576187141239643, Validation Loss: 0.0070158950984478
Epoch 109, Training Loss: 0.007015895564109087, Validation Loss: 0.006541099864989519
Epoch 110, Training Loss: 0.006541101261973381, Validation Loss: 0.006100303027778864
Epoch 111, Training Loss: 0.006100300699472427, Validation Loss: 0.005652459803968668
Epoch 112, Training Loss: 0.005652463063597679, Validation Loss: 0.005184934940189123
Epoch 113, Training Loss: 0.005184933077543974, Validation Loss: 0.004689379129558802
Epoch 114, Training Loss: 0.004689380526542664, Validation Loss: 0.004171486012637615
Epoch 115, Training Loss: 0.004171487409621477, Validation Loss: 0.0036494466476142406
Epoch 116, Training Loss: 0.0036494468804448843, Validation Loss: 0.00313750933855772
Epoch 117, Training Loss: 0.003137509571388364, Validation Loss: 0.0026482397224754095
Epoch 118, Training Loss: 0.002648238791152835, Validation Loss: 0.0021930490620434284
Epoch 119, Training Loss: 0.0021930509246885777, Validation Loss: 0.0017847419949248433
Epoch 120, Training Loss: 0.0017847424605861306, Validation Loss: 0.0014285659417510033
Epoch 121, Training Loss: 0.0014285665238276124, Validation Loss: 0.0011277073062956333
Epoch 122, Training Loss: 0.0011277074227109551, Validation Loss: 0.0008812083979137242
Epoch 123, Training Loss: 0.0008812093292362988, Validation Loss: 0.0006828461191616952
Epoch 124, Training Loss: 0.0006828466430306435, Validation Loss: 0.0005308693507686257
Epoch 125, Training Loss: 0.0005308692925609648, Validation Loss: 0.0004206169687677175
Epoch 126, Training Loss: 0.00042061691056005657, Validation Loss: 0.0003448162751737982
Epoch 127, Training Loss: 0.0003448155475780368, Validation Loss: 0.0002964383165817708
Epoch 128, Training Loss: 0.00029643793823197484, Validation Loss: 0.0002666730433702469
Epoch 129, Training Loss: 0.00026667313068173826, Validation Loss: 0.00024800957180559635
Epoch 130, Training Loss: 0.0002480097464285791, Validation Loss: 0.0002351587318116799
Epoch 131, Training Loss: 0.000235158993746154, Validation Loss: 0.00022433570120483637
Epoch 132, Training Loss: 0.00022433580306824297, Validation Loss: 0.00021336271311156452
Epoch 133, Training Loss: 0.0002133628586307168, Validation Loss: 0.00020136279636062682
Epoch 134, Training Loss: 0.00020136308739893138, Validation Loss: 0.00018970714882016182
Epoch 135, Training Loss: 0.00018970783276017755, Validation Loss: 0.0001766611821949482
Epoch 136, Training Loss: 0.0001766605128068477, Validation Loss: 0.00016235744988080114
Epoch 137, Training Loss: 0.00016235790099017322, Validation Loss: 0.00014743575593456626
Epoch 138, Training Loss: 0.00014743614883627743, Validation Loss: 0.00013290150673128664
Epoch 139, Training Loss: 0.0001329011720372364, Validation Loss: 0.00011995084787486121
Epoch 140, Training Loss: 0.00011995110980933532, Validation Loss: 0.0001094746621674858
Epoch 141, Training Loss: 0.0001094746112357825, Validation Loss: 0.00010204802674707025
Epoch 142, Training Loss: 0.00010204829595750198, Validation Loss: 9.739462257130072e-05
Epoch 143, Training Loss: 9.739476081449538e-05, Validation Loss: 9.458355634706095e-05
Epoch 144, Training Loss: 9.458362183067948e-05, Validation Loss: 9.271306043956429e-05
Epoch 145, Training Loss: 9.271323506254703e-05, Validation Loss: 9.083985787583515e-05
Epoch 146, Training Loss: 9.084011253435165e-05, Validation Loss: 8.822970994515345e-05
Epoch 147, Training Loss: 8.822964446153492e-05, Validation Loss: 8.448532753391191e-05
Epoch 148, Training Loss: 8.448582957498729e-05, Validation Loss: 7.955813634907827e-05
Epoch 149, Training Loss: 7.955807086545974e-05, Validation Loss: 7.363360055023804e-05
Epoch 150, Training Loss: 7.363352051470429e-05, Validation Loss: 6.700646918034181e-05
Epoch 151, Training Loss: 6.700604717480019e-05, Validation Loss: 5.9978301578667015e-05
Epoch 152, Training Loss: 5.9978250646963716e-05, Validation Loss: 5.2814328228123486e-05
Epoch 153, Training Loss: 5.28138734807726e-05, Validation Loss: 4.5744687668047845e-05
Epoch 154, Training Loss: 4.5744713133899495e-05, Validation Loss: 3.8987422158243135e-05
Epoch 155, Training Loss: 3.8987473089946434e-05, Validation Loss: 3.2758322049630806e-05
Epoch 156, Training Loss: 3.275827839388512e-05, Validation Loss: 2.7253156076767482e-05
Epoch 157, Training Loss: 2.7253179723629728e-05, Validation Loss: 2.26167085202178e-05
Epoch 158, Training Loss: 2.2616794012719765e-05, Validation Loss: 1.890837484097574e-05
Epoch 159, Training Loss: 1.8908225683844648e-05, Validation Loss: 1.60881409101421e-05
Epoch 160, Training Loss: 1.6088137272163294e-05, Validation Loss: 1.402932139171753e-05
Epoch 161, Training Loss: 1.402927955496125e-05, Validation Loss: 1.2551605323096737e-05
Epoch 162, Training Loss: 1.2551587133202702e-05, Validation Loss: 1.146213344327407e-05
Epoch 163, Training Loss: 1.1462089787528384e-05, Validation Loss: 1.0593045772111509e-05
Epoch 164, Training Loss: 1.0593104889267124e-05, Validation Loss: 9.820085324463435e-06
Epoch 165, Training Loss: 9.82004712568596e-06, Validation Loss: 9.065995982382447e-06
Epoch 166, Training Loss: 9.065934136742726e-06, Validation Loss: 8.292442544188816e-06
Epoch 167, Training Loss: 8.292486199934501e-06, Validation Loss: 7.489197287213756e-06
Epoch 168, Training Loss: 7.489236395485932e-06, Validation Loss: 6.666400167887332e-06
Epoch 169, Training Loss: 6.666323770332383e-06, Validation Loss: 5.849330591445323e-06
Epoch 170, Training Loss: 5.849336048413534e-06, Validation Loss: 5.0743396968755405e-06
Epoch 171, Training Loss: 5.074372893432155e-06, Validation Loss: 4.381114194984548e-06
Epoch 172, Training Loss: 4.381132384878583e-06, Validation Loss: 3.801902266786783e-06
Epoch 173, Training Loss: 3.8018531540728873e-06, Validation Loss: 3.3524252103234176e-06
Epoch 174, Training Loss: 3.3523626825626707e-06, Validation Loss: 3.025947762580472e-06
Epoch 175, Training Loss: 3.025946625712095e-06, Validation Loss: 2.796368789859116e-06
Epoch 176, Training Loss: 2.7963694719801424e-06, Validation Loss: 2.626421292006853e-06
Epoch 177, Training Loss: 2.6264069674653e-06, Validation Loss: 2.4795206172711914e-06
Epoch 178, Training Loss: 2.4795770059427014e-06, Validation Loss: 2.3295681330637308e-06
Epoch 179, Training Loss: 2.3295592654903885e-06, Validation Loss: 2.1642824776790803e-06
Epoch 180, Training Loss: 2.1642722458636854e-06, Validation Loss: 1.9840149434458e-06
Epoch 181, Training Loss: 1.984041773539502e-06, Validation Loss: 1.795891535039118e-06
Epoch 182, Training Loss: 1.795850721464376e-06, Validation Loss: 1.6075997564257705e-06
Epoch 183, Training Loss: 1.6076114661700558e-06, Validation Loss: 1.4245855481931358e-06
Epoch 184, Training Loss: 1.4245836155168945e-06, Validation Loss: 1.2491404959291685e-06
Epoch 185, Training Loss: 1.2491303778006113e-06, Validation Loss: 1.0829749044205528e-06
Epoch 186, Training Loss: 1.0829667189682368e-06, Validation Loss: 9.290431535191601e-07
Epoch 187, Training Loss: 9.290371281167609e-07, Validation Loss: 7.924039095996704e-07
Epoch 188, Training Loss: 7.924031706352253e-07, Validation Loss: 6.787579991396342e-07
Epoch 189, Training Loss: 6.787333290958486e-07, Validation Loss: 5.921572778788686e-07
Epoch 190, Training Loss: 5.921481829318509e-07, Validation Loss: 5.328902830115112e-07
Epoch 191, Training Loss: 5.328903398549301e-07, Validation Loss: 4.970092959410977e-07
Epoch 192, Training Loss: 4.969652991348994e-07, Validation Loss: 4.773151545123255e-07
Epoch 193, Training Loss: 4.773078217112925e-07, Validation Loss: 4.6584767687818385e-07
Epoch 194, Training Loss: 4.6581561718994635e-07, Validation Loss: 4.557387853765249e-07
Epoch 195, Training Loss: 4.557478519018332e-07, Validation Loss: 4.427075737112318e-07
Epoch 196, Training Loss: 4.4273321009313804e-07, Validation Loss: 4.2501676489337115e-07
Epoch 197, Training Loss: 4.2499442542975885e-07, Validation Loss: 4.026574629278912e-07
Epoch 198, Training Loss: 4.026808539947524e-07, Validation Loss: 3.7668633012799546e-07
Epoch 199, Training Loss: 3.7668564800696913e-07, Validation Loss: 3.4816619631783396e-07
Epoch 200, Training Loss: 3.481728754195501e-07, Validation Loss: 3.182134946655424e-07
Epoch 201, Training Loss: 3.182213674790546e-07, Validation Loss: 2.8787073347302794e-07
Epoch 202, Training Loss: 2.878399527617148e-07, Validation Loss: 2.5826466298894957e-07
Epoch 203, Training Loss: 2.5826429350672697e-07, Validation Loss: 2.3053135578265938e-07
Epoch 204, Training Loss: 2.3053176789744612e-07, Validation Loss: 2.054955245966994e-07
Epoch 205, Training Loss: 2.0547727785924508e-07, Validation Loss: 1.8343585850288946e-07
Epoch 206, Training Loss: 1.8345417629461735e-07, Validation Loss: 1.6416257153650804e-07
Epoch 207, Training Loss: 1.6415147285897547e-07, Validation Loss: 1.470127557468004e-07
Epoch 208, Training Loss: 1.4702231965202373e-07, Validation Loss: 1.3129208298323647e-07
Epoch 209, Training Loss: 1.312972415234981e-07, Validation Loss: 1.1648589293145051e-07
Epoch 210, Training Loss: 1.1649997588847327e-07, Validation Loss: 1.0229517499737995e-07
Epoch 211, Training Loss: 1.0231950398065237e-07, Validation Loss: 8.87356961243313e-08
Epoch 212, Training Loss: 8.873337264958536e-08, Validation Loss: 7.578046279377304e-08
Epoch 213, Training Loss: 7.578620397907798e-08, Validation Loss: 6.351969972229199e-08
Epoch 214, Training Loss: 6.352370007789432e-08, Validation Loss: 5.2002278039253724e-08
Epoch 215, Training Loss: 5.1997599115338744e-08, Validation Loss: 4.133015352181246e-08
Epoch 216, Training Loss: 4.133649511572912e-08, Validation Loss: 3.18085824346781e-08
Epoch 217, Training Loss: 3.1797725341675687e-08, Validation Loss: 2.3770642343379222e-08
Epoch 218, Training Loss: 2.3776786761686708e-08, Validation Loss: 1.7596926582541528e-08
Epoch 219, Training Loss: 1.7596494927829553e-08, Validation Loss: 1.3468137716188266e-08
Epoch 220, Training Loss: 1.3468419268747311e-08, Validation Loss: 1.1289675860837178e-08
Epoch 221, Training Loss: 1.1291735546592463e-08, Validation Loss: 1.0686556528582969e-08
Epoch 222, Training Loss: 1.0684661155835329e-08, Validation Loss: 1.1092120999478539e-08
Epoch 223, Training Loss: 1.1092492258057973e-08, Validation Loss: 1.1942313804524929e-08
Epoch 224, Training Loss: 1.1948289468932671e-08, Validation Loss: 1.2798293980154085e-08
Epoch 225, Training Loss: 1.2793433867841486e-08, Validation Loss: 1.338484079127511e-08
Epoch 226, Training Loss: 1.338643862425215e-08, Validation Loss: 1.3633149720249094e-08
Epoch 227, Training Loss: 1.3631694883997625e-08, Validation Loss: 1.3559870559731735e-08
Epoch 228, Training Loss: 1.355692180737833e-08, Validation Loss: 1.3232341444791018e-08
Epoch 229, Training Loss: 1.322985010432376e-08, Validation Loss: 1.270074445614e-08
Epoch 230, Training Loss: 1.2700025031620044e-08, Validation Loss: 1.2019595097001456e-08
Epoch 231, Training Loss: 1.2025193285580826e-08, Validation Loss: 1.1252552667428972e-08
Epoch 232, Training Loss: 1.1252820009133302e-08, Validation Loss: 1.0456990828799917e-08
Epoch 233, Training Loss: 1.0455583954183112e-08, Validation Loss: 9.70710534176078e-09
Epoch 234, Training Loss: 9.711111026433628e-09, Validation Loss: 9.059435868152832e-09
Epoch 235, Training Loss: 9.058429562003312e-09, Validation Loss: 8.517937466478998e-09
Epoch 236, Training Loss: 8.519051242217301e-09, Validation Loss: 8.063063106078516e-09
Epoch 237, Training Loss: 8.062583489731878e-09, Validation Loss: 7.638093713069338e-09
Epoch 238, Training Loss: 7.636051790882448e-09, Validation Loss: 7.184294936735114e-09
Epoch 239, Training Loss: 7.185921191421585e-09, Validation Loss: 6.664081286800183e-09
Epoch 240, Training Loss: 6.666318164150198e-09, Validation Loss: 6.05821925958594e-09
Epoch 241, Training Loss: 6.060000057317438e-09, Validation Loss: 5.378764100782973e-09
Epoch 242, Training Loss: 5.379716228048892e-09, Validation Loss: 4.651214524642455e-09
Epoch 243, Training Loss: 4.651668383814922e-09, Validation Loss: 3.903418921424873e-09
Epoch 244, Training Loss: 3.901456047117335e-09, Validation Loss: 3.1710096770609653e-09
Epoch 245, Training Loss: 3.171238383004038e-09, Validation Loss: 2.4875448367822628e-09
Epoch 246, Training Loss: 2.4872637283124277e-09, Validation Loss: 1.8875616625280145e-09
Epoch 247, Training Loss: 1.8878925089893528e-09, Validation Loss: 1.392482906759085e-09
Epoch 248, Training Loss: 1.3927758946152835e-09, Validation Loss: 1.0131763206189248e-09
Epoch 249, Training Loss: 1.013973793817513e-09, Validation Loss: 7.478841990149476e-10
Epoch 250, Training Loss: 7.478846431041575e-10, Validation Loss: 5.777887057689668e-10
Epoch 251, Training Loss: 5.779161038610425e-10, Validation Loss: 4.81446993383372e-10
Epoch 252, Training Loss: 4.805934539220402e-10, Validation Loss: 4.324546831746545e-10
Epoch 253, Training Loss: 4.3297257446006654e-10, Validation Loss: 4.1524778060519907e-10
Epoch 254, Training Loss: 4.1599756972487967e-10, Validation Loss: 4.1589257038232574e-10
Epoch 255, Training Loss: 4.161947175784775e-10, Validation Loss: 4.266338948788473e-10
Epoch 256, Training Loss: 4.2622663731783916e-10, Validation Loss: 4.396628894287602e-10
Epoch 257, Training Loss: 4.3957559814344904e-10, Validation Loss: 4.5026735118192107e-10
Epoch 258, Training Loss: 4.503558637125593e-10, Validation Loss: 4.5240267088075825e-10
Epoch 259, Training Loss: 4.5241282942143357e-10, Validation Loss: 4.420188104425904e-10
Epoch 260, Training Loss: 4.4258346987291475e-10, Validation Loss: 4.212713788920297e-10
Epoch 261, Training Loss: 4.2129599808760076e-10, Validation Loss: 3.932819625518391e-10
Epoch 262, Training Loss: 3.934567116559151e-10, Validation Loss: 3.653626567956536e-10
Epoch 263, Training Loss: 3.6480529708171616e-10, Validation Loss: 3.400758008531568e-10
Epoch 264, Training Loss: 3.400327797109526e-10, Validation Loss: 3.212189680912303e-10
Epoch 265, Training Loss: 3.208059373704941e-10, Validation Loss: 3.075842358590819e-10
Epoch 266, Training Loss: 3.0765182068570596e-10, Validation Loss: 2.967850687429774e-10
Epoch 267, Training Loss: 2.967980861079411e-10, Validation Loss: 2.866281101354673e-10
Epoch 268, Training Loss: 2.8632896054148205e-10, Validation Loss: 2.7335730901079103e-10
Epoch 269, Training Loss: 2.7240951161466853e-10, Validation Loss: 2.578454116886064e-10
Epoch 270, Training Loss: 2.5727059371760674e-10, Validation Loss: 2.3933813264598314e-10
Epoch 271, Training Loss: 2.392057940614478e-10, Validation Loss: 2.1851115361570805e-10
Epoch 272, Training Loss: 2.1923096671372377e-10, Validation Loss: 1.9690528374471938e-10
Epoch 273, Training Loss: 1.9632864778351689e-10, Validation Loss: 1.733219262556318e-10
Epoch 274, Training Loss: 1.7302652366435467e-10, Validation Loss: 1.4999412822902514e-10
Epoch 275, Training Loss: 1.5010170884011131e-10, Validation Loss: 1.2649348235527214e-10
Epoch 276, Training Loss: 1.2664407023077473e-10, Validation Loss: 1.0529958155425234e-10
Epoch 277, Training Loss: 1.0467437333572249e-10, Validation Loss: 8.598698142403549e-11
Epoch 278, Training Loss: 8.614142038565475e-11, Validation Loss: 7.033103266440577e-11
Epoch 279, Training Loss: 7.036102950275236e-11, Validation Loss: 5.726247601089973e-11
Epoch 280, Training Loss: 5.727348803552523e-11, Validation Loss: 4.726380051223167e-11
Epoch 281, Training Loss: 4.7458363627850275e-11, Validation Loss: 3.99742704215722e-11
Epoch 282, Training Loss: 3.9995059347708306e-11, Validation Loss: 3.430395550951815e-11
Epoch 283, Training Loss: 3.4394220110867124e-11, Validation Loss: 2.9975962684281043e-11
Epoch 284, Training Loss: 3.0411225621085336e-11, Validation Loss: 2.696308801231062e-11
Epoch 285, Training Loss: 2.7006247932392924e-11, Validation Loss: 2.4468286771717196e-11
Epoch 286, Training Loss: 2.426900173879698e-11, Validation Loss: 2.2226482807030656e-11
Epoch 287, Training Loss: 2.2249100131710442e-11, Validation Loss: 2.043674084128977e-11
Epoch 288, Training Loss: 2.066355073160331e-11, Validation Loss: 1.8923055830621927e-11
Epoch 289, Training Loss: 1.8901312806574033e-11, Validation Loss: 1.7149656694748217e-11
Epoch 290, Training Loss: 1.7256581580360475e-11, Validation Loss: 1.6154001747370472e-11
Epoch 291, Training Loss: 1.597449776624682e-11, Validation Loss: 1.5026547714458438e-11
Epoch 292, Training Loss: 1.50516075297924e-11, Validation Loss: 1.4319962750308779e-11
Epoch 293, Training Loss: 1.4243064193342203e-11, Validation Loss: 1.3730010184342945e-11
Epoch 294, Training Loss: 1.3664130590895773e-11, Validation Loss: 1.2979665953150032e-11
Epoch 295, Training Loss: 1.3026426291806725e-11, Validation Loss: 1.2286456574361893e-11
Epoch 296, Training Loss: 1.2198730740820007e-11, Validation Loss: 1.145780172129296e-11
Epoch 297, Training Loss: 1.1504803186512813e-11, Validation Loss: 1.050206796526787e-11
Epoch 298, Training Loss: 1.0448037400523358e-11, Validation Loss: 9.489265276330094e-12
Epoch 299, Training Loss: 9.389614086252607e-12, Validation Loss: 8.47728571368167e-12
Epoch 300, Training Loss: 8.395204670330614e-12, Validation Loss: 7.496841689103029e-12
Epoch 301, Training Loss: 7.499269434607658e-12, Validation Loss: 6.7972229407520235e-12
Epoch 302, Training Loss: 6.636695533412951e-12, Validation Loss: 6.050034605242782e-12
Epoch 303, Training Loss: 6.0024507066158694e-12, Validation Loss: 5.428115422423385e-12
Epoch 304, Training Loss: 5.411009314226778e-12, Validation Loss: 4.800047078562519e-12
Epoch 305, Training Loss: 4.814630898825056e-12, Validation Loss: 4.316057927722383e-12
Epoch 306, Training Loss: 4.407247570364925e-12, Validation Loss: 3.898235033383823e-12
Epoch 307, Training Loss: 3.919814993424975e-12, Validation Loss: 3.5480921586200642e-12
Epoch 308, Training Loss: 3.577031899848482e-12, Validation Loss: 3.2424438568129377e-12
Epoch 309, Training Loss: 3.2391869134867912e-12, Validation Loss: 3.042155936883173e-12
Epoch 310, Training Loss: 2.9632091051723375e-12, Validation Loss: 2.7457970792899022e-12
Epoch 311, Training Loss: 2.8216357202126563e-12, Validation Loss: 2.6261219761292143e-12
Epoch 312, Training Loss: 2.6129222483600723e-12, Validation Loss: 2.419698122424485e-12
Epoch 313, Training Loss: 2.3266763949508773e-12, Validation Loss: 2.2311325963836337e-12
Epoch 314, Training Loss: 2.1239932555816576e-12, Validation Loss: 1.916213064959149e-12
Epoch 315, Training Loss: 1.9314155309813064e-12, Validation Loss: 1.6603546879392916e-12
Epoch 316, Training Loss: 1.658285921773972e-12, Validation Loss: 1.4350312388042297e-12
Epoch 317, Training Loss: 1.4766771789728739e-12, Validation Loss: 1.2516775810267333e-12
Epoch 318, Training Loss: 1.2880668753822988e-12, Validation Loss: 1.0728585988356576e-12
Epoch 319, Training Loss: 1.0648928570541893e-12, Validation Loss: 9.112011275722032e-13
Epoch 320, Training Loss: 8.979740236982059e-13, Validation Loss: 7.604100183723761e-13
Epoch 321, Training Loss: 7.966539754267199e-13, Validation Loss: 6.934577152957477e-13
Epoch 322, Training Loss: 7.055261865181184e-13, Validation Loss: 5.983921040966789e-13
Epoch 323, Training Loss: 5.940880383123459e-13, Validation Loss: 5.756876095622254e-13
Epoch 324, Training Loss: 5.38030069715395e-13, Validation Loss: 5.003868413372414e-13
Epoch 325, Training Loss: 4.769563108179831e-13, Validation Loss: 4.454493414754457e-13
Epoch 326, Training Loss: 4.528636580319878e-13, Validation Loss: 4.2572144269038825e-13
Epoch 327, Training Loss: 4.175604632027097e-13, Validation Loss: 3.859578943336134e-13
Epoch 328, Training Loss: 3.723830597178457e-13, Validation Loss: 3.4898982575332083e-13
Epoch 329, Training Loss: 3.329732052147899e-13, Validation Loss: 3.0424461235946387e-13
Epoch 330, Training Loss: 3.013654863853743e-13, Validation Loss: 2.548727559299052e-13
Epoch 331, Training Loss: 2.605207445171426e-13, Validation Loss: 2.142160689284911e-13
Epoch 332, Training Loss: 2.2830692956825327e-13, Validation Loss: 1.7355328328985675e-13
Epoch 333, Training Loss: 1.7244136619933709e-13, Validation Loss: 1.4788531185229437e-13
Epoch 334, Training Loss: 1.6172530166187055e-13, Validation Loss: 1.3134052222543713e-13
Epoch 335, Training Loss: 1.39061003922962e-13, Validation Loss: 9.402158549333753e-14
Epoch 336, Training Loss: 1.1159579797791544e-13, Validation Loss: 9.059523557774021e-14
Epoch 337, Training Loss: 1.0436921102753918e-13, Validation Loss: 7.816207262586333e-14
Epoch 338, Training Loss: 8.54886094640156e-14, Validation Loss: 7.841707697683192e-14
Epoch 339, Training Loss: 7.867408032555603e-14, Validation Loss: 9.017706557607613e-14
Epoch 340, Training Loss: 6.885807977410549e-14, Validation Loss: 6.253394883078828e-14
Epoch 341, Training Loss: 7.999647493907303e-14, Validation Loss: 5.4493539400953667e-14
Epoch 342, Training Loss: 6.610534466827342e-14, Validation Loss: 6.03018611607109e-14
Epoch 343, Training Loss: 5.730535674892262e-14, Validation Loss: 5.552923369061581e-14
Epoch 344, Training Loss: 6.047256201650517e-14, Validation Loss: 5.0970715820795875e-14
Epoch 345, Training Loss: 5.326758795881105e-14, Validation Loss: 4.742957600018666e-14
Epoch 346, Training Loss: 5.75366102960502e-14, Validation Loss: 5.366727570156604e-14
Epoch 347, Training Loss: 4.7843107649431574e-14, Validation Loss: 4.609414046741374e-14
Epoch 348, Training Loss: 4.771393851310708e-14, Validation Loss: 4.0655348689357454e-14
Epoch 349, Training Loss: 4.5720341439658627e-14, Validation Loss: 4.291445671045224e-14
Epoch 350, Training Loss: 5.0201531977657823e-14, Validation Loss: 4.35766230229024e-14
Epoch 351, Training Loss: 4.5881135398101805e-14, Validation Loss: 4.2229274818759294e-14
Epoch 352, Training Loss: 4.362319289434244e-14, Validation Loss: 4.3292626428215186e-14
Epoch 353, Training Loss: 3.5598894031164605e-14, Validation Loss: 4.621273524442471e-14
Epoch 354, Training Loss: 3.6354701529999617e-14, Validation Loss: 4.284070046953713e-14
Epoch 355, Training Loss: 3.738686199820582e-14, Validation Loss: 2.7812955321541814e-14
Epoch 356, Training Loss: 3.490767448862363e-14, Validation Loss: 2.7443693002252197e-14
Epoch 357, Training Loss: 2.8016685380081313e-14, Validation Loss: 2.670660323748561e-14
Epoch 358, Training Loss: 2.5113159774913137e-14, Validation Loss: 2.392407290070092e-14
Epoch 359, Training Loss: 2.3802642257382545e-14, Validation Loss: 2.1704560281758482e-14
Epoch 360, Training Loss: 2.3165598942147952e-14, Validation Loss: 2.4275320523268334e-14
Epoch 361, Training Loss: 2.1202157935687645e-14, Validation Loss: 2.0056706810786182e-14
Epoch 362, Training Loss: 1.8476639692516748e-14, Validation Loss: 1.6828352540675454e-14
Epoch 363, Training Loss: 1.7791959244328574e-14, Validation Loss: 1.973538316817937e-14
Epoch 364, Training Loss: 1.588256232803488e-14, Validation Loss: 1.716949336611623e-14
Epoch 365, Training Loss: 1.661061255718837e-14, Validation Loss: 1.7273676724562613e-14
Epoch 366, Training Loss: 1.499064679897147e-14, Validation Loss: 1.2952112933605278e-14
Epoch 367, Training Loss: 1.5412452266045165e-14, Validation Loss: 1.4313571012583744e-14
Epoch 368, Training Loss: 1.1923655693444474e-14, Validation Loss: 1.1940202482069086e-14
Epoch 369, Training Loss: 1.2026004378527105e-14, Validation Loss: 1.4048024489553626e-14
Epoch 370, Training Loss: 1.4815305896692145e-14, Validation Loss: 1.6058069248771865e-14
Epoch 371, Training Loss: 1.2272468096288531e-14, Validation Loss: 1.5024174057089688e-14
Epoch 372, Training Loss: 9.949006747026097e-15, Validation Loss: 1.5897773345701673e-14
Epoch 373, Training Loss: 9.100326320689387e-15, Validation Loss: 1.2410178712853135e-14
Epoch 374, Training Loss: 9.146496392578325e-15, Validation Loss: 1.3078147200991982e-14
Epoch 375, Training Loss: 1.0919383785026621e-14, Validation Loss: 1.2253019372786625e-14
Epoch 376, Training Loss: 6.9455329481478076e-15, Validation Loss: 1.1879253379316456e-14
Epoch 377, Training Loss: 8.92672014188604e-15, Validation Loss: 1.0932827891965442e-14
Epoch 378, Training Loss: 6.487699358179123e-15, Validation Loss: 1.1239507181947175e-14
Epoch 379, Training Loss: 5.639419578426464e-15, Validation Loss: 8.966886444244839e-15
Epoch 380, Training Loss: 5.748039695450567e-15, Validation Loss: 1.286094000122872e-14
Epoch 381, Training Loss: 6.663173244631166e-15, Validation Loss: 1.1218991196931729e-14
Epoch 382, Training Loss: 5.575368217504515e-15, Validation Loss: 1.1213853095073684e-14
Epoch 383, Training Loss: 6.604459461826339e-15, Validation Loss: 9.109299787732599e-15
Epoch 384, Training Loss: 4.594715399304375e-15, Validation Loss: 9.265491816173345e-15
Epoch 385, Training Loss: 4.88895135177447e-15, Validation Loss: 9.276700603164361e-15
Epoch 386, Training Loss: 6.250442465037878e-15, Validation Loss: 9.230163766009263e-15
Epoch 387, Training Loss: 4.078968896182493e-15, Validation Loss: 8.921749752551552e-15
Epoch 388, Training Loss: 4.181851212021895e-15, Validation Loss: 6.665541972268162e-15
Epoch 389, Training Loss: 5.280198411210073e-15, Validation Loss: 6.552050992280874e-15
Epoch 390, Training Loss: 4.1750457258071805e-15, Validation Loss: 6.434623426671221e-15
Epoch 391, Training Loss: 4.065091108374679e-15, Validation Loss: 6.730727510306485e-15
Epoch 392, Training Loss: 3.386413794441933e-15, Validation Loss: 6.612098851977626e-15
Epoch 393, Training Loss: 2.6630341049596043e-15, Validation Loss: 6.640355024065082e-15
Epoch 394, Training Loss: 4.691459690891499e-15, Validation Loss: 6.64649304831736e-15
Epoch 395, Training Loss: 3.602720386424027e-15, Validation Loss: 5.146357464665e-15
Epoch 396, Training Loss: 2.9767522387330212e-15, Validation Loss: 5.524527182427944e-15
Epoch 397, Training Loss: 2.7976752858815956e-15, Validation Loss: 4.343213953089155e-15
Epoch 398, Training Loss: 3.427513527108606e-15, Validation Loss: 3.7776271843178826e-15
Epoch 399, Training Loss: 2.73535886019386e-15, Validation Loss: 2.7801613973894553e-15
Epoch 400, Training Loss: 3.999305023976753e-15, Validation Loss: 3.4475627969701153e-15
Epoch 401, Training Loss: 3.572563048886458e-15, Validation Loss: 4.29824455040295e-15
Epoch 402, Training Loss: 3.7785949194601206e-15, Validation Loss: 4.431517984873363e-15
Epoch 403, Training Loss: 2.861059608357582e-15, Validation Loss: 4.68772342856116e-15
Epoch 404, Training Loss: 2.209337212147073e-15, Validation Loss: 4.477955295657159e-15
Epoch 405, Training Loss: 2.099248975267142e-15, Validation Loss: 4.003441509374669e-15
Epoch 406, Training Loss: 2.4594042080661183e-15, Validation Loss: 3.176245438470354e-15
Epoch 407, Training Loss: 2.756308949594774e-15, Validation Loss: 3.1148628666069662e-15
Epoch 408, Training Loss: 3.310753211703153e-15, Validation Loss: 3.2578108996426805e-15
Epoch 409, Training Loss: 3.2318899973908044e-15, Validation Loss: 3.850819301290127e-15
Epoch 410, Training Loss: 4.073364502686985e-15, Validation Loss: 3.79157188772853e-15
Epoch 411, Training Loss: 4.067226054918233e-15, Validation Loss: 3.1660039631051023e-15
Epoch 412, Training Loss: 4.0127825887169895e-15, Validation Loss: 3.259945846186235e-15
Epoch 413, Training Loss: 4.293274161068462e-15, Validation Loss: 3.3295683545605127e-15
Epoch 414, Training Loss: 3.752307251942083e-15, Validation Loss: 4.6103279105881665e-15
Epoch 415, Training Loss: 3.79927819348265e-15, Validation Loss: 4.326067041621412e-15
Epoch 416, Training Loss: 2.998903420853142e-15, Validation Loss: 4.069861597933615e-15
Epoch 417, Training Loss: 4.106190841041352e-15, Validation Loss: 3.931884165990626e-15
Epoch 418, Training Loss: 3.4352530789059053e-15, Validation Loss: 3.861427965438013e-15
Epoch 419, Training Loss: 1.5425361471677794e-15, Validation Loss: 5.571865312751145e-15
Epoch 420, Training Loss: 2.6949263777313864e-15, Validation Loss: 6.048914268644767e-15
Epoch 421, Training Loss: 2.2310879594413793e-15, Validation Loss: 3.471248591032424e-15
Epoch 422, Training Loss: 2.39868888640693e-15, Validation Loss: 3.4968690083462617e-15
Epoch 423, Training Loss: 2.230554328684609e-15, Validation Loss: 3.472616337484003e-15
Epoch 424, Training Loss: 2.3051474381516118e-15, Validation Loss: 3.5099795960621006e-15
Epoch 425, Training Loss: 3.010779458048358e-15, Validation Loss: 4.284433678197969e-15
Epoch 426, Training Loss: 1.8234279425868296e-15, Validation Loss: 4.118967486017736e-15
Epoch 427, Training Loss: 3.024390430477787e-15, Validation Loss: 4.118967486017736e-15
Epoch 428, Training Loss: 2.150757048789676e-15, Validation Loss: 4.006644140948238e-15
Epoch 429, Training Loss: 2.9772860812480283e-15, Validation Loss: 3.009578577087388e-15
Epoch 430, Training Loss: 2.6834505636037483e-15, Validation Loss: 4.381344411759228e-15
Epoch 431, Training Loss: 2.3830763751231387e-15, Validation Loss: 5.262984584139497e-15
Epoch 432, Training Loss: 2.8687991601548815e-15, Validation Loss: 4.465011785190166e-15
Epoch 433, Training Loss: 3.762849000487137e-15, Validation Loss: 3.768553343870421e-15
Epoch 434, Training Loss: 2.3679977063543545e-15, Validation Loss: 5.425781351986458e-15
Epoch 435, Training Loss: 3.0530800716760008e-15, Validation Loss: 4.293774334023816e-15
Epoch 436, Training Loss: 2.830635031925155e-15, Validation Loss: 4.102154305531212e-15
Epoch 437, Training Loss: 2.839842491820046e-15, Validation Loss: 4.078935438381077e-15
Epoch 438, Training Loss: 3.1669045708862704e-15, Validation Loss: 4.13177801231201e-15
Epoch 439, Training Loss: 2.1396814577296155e-15, Validation Loss: 4.532098488678601e-15
Epoch 440, Training Loss: 9.468588505826534e-16, Validation Loss: 4.11950154029098e-15
Epoch 441, Training Loss: 1.7651145946078178e-15, Validation Loss: 4.3007466857291395e-15
Epoch 442, Training Loss: 1.1436832612614248e-15, Validation Loss: 4.652495328284854e-15
Epoch 443, Training Loss: 2.4319156595871113e-15, Validation Loss: 3.8813772854117464e-15
Epoch 444, Training Loss: 1.4549994213546654e-15, Validation Loss: 4.0376358059388516e-15
Epoch 445, Training Loss: 1.573761169735362e-15, Validation Loss: 3.933018766623473e-15
Epoch 446, Training Loss: 1.568823920564935e-15, Validation Loss: 4.404663228797139e-15
Epoch 447, Training Loss: 9.4659192932515e-16, Validation Loss: 3.4598060229479657e-15
Epoch 448, Training Loss: 1.7085358642256643e-15, Validation Loss: 4.019754940422313e-15
Epoch 449, Training Loss: 2.401491294912921e-15, Validation Loss: 3.672776787425535e-15
Epoch 450, Training Loss: 1.9026913799667557e-15, Validation Loss: 4.377341334050504e-15
Epoch 451, Training Loss: 1.1773101516300653e-15, Validation Loss: 3.771255802488636e-15
Epoch 452, Training Loss: 1.769518107142356e-15, Validation Loss: 3.771255802488636e-15
Epoch 453, Training Loss: 2.137813326564446e-15, Validation Loss: 2.6212340878037886e-15
Epoch 454, Training Loss: 2.271253414767231e-15, Validation Loss: 3.4649767355744796e-15
Epoch 455, Training Loss: 1.5728271041527773e-15, Validation Loss: 4.268821166914178e-15
Epoch 456, Training Loss: 1.466742156739807e-15, Validation Loss: 4.844215306665234e-15
Epoch 457, Training Loss: 1.7477673598480497e-15, Validation Loss: 4.845816622452018e-15
Epoch 458, Training Loss: 2.416569963681705e-15, Validation Loss: 4.037168667268441e-15
Epoch 459, Training Loss: 2.5805680360061097e-15, Validation Loss: 4.063856981370529e-15
Epoch 460, Training Loss: 1.684249735561989e-15, Validation Loss: 3.3674654556536173e-15
Epoch 461, Training Loss: 1.684249735561989e-15, Validation Loss: 4.1360813632005354e-15
Epoch 462, Training Loss: 1.4787517075033336e-15, Validation Loss: 4.200132724122485e-15
Epoch 463, Training Loss: 1.529592530821668e-15, Validation Loss: 5.6750479017703484e-15
Epoch 464, Training Loss: 2.0424035353857218e-15, Validation Loss: 5.7987473228379455e-15
Epoch 465, Training Loss: 2.245766405142586e-15, Validation Loss: 5.7987473228379455e-15
Epoch 466, Training Loss: 2.269785718427876e-15, Validation Loss: 4.384280227954411e-15
Epoch 467, Training Loss: 2.2492358520945395e-15, Validation Loss: 3.4060295951926847e-15
Epoch 468, Training Loss: 2.5815021015886943e-15, Validation Loss: 4.2242854450969675e-15
Epoch 469, Training Loss: 3.093912777206052e-15, Validation Loss: 5.070296870616879e-15
Epoch 470, Training Loss: 2.738961714835006e-15, Validation Loss: 5.001441562334577e-15
Epoch 471, Training Loss: 2.533730502154736e-15, Validation Loss: 3.478587708003909e-15
Epoch 472, Training Loss: 2.65382685682295e-15, Validation Loss: 2.5614860777703648e-15
Epoch 473, Training Loss: 1.35038217028105e-15, Validation Loss: 3.815290927834019e-15
Epoch 474, Training Loss: 1.370665115356883e-15, Validation Loss: 4.618701254788249e-15
Epoch 475, Training Loss: 9.110968019122217e-16, Validation Loss: 3.88010970060618e-15
Epoch 476, Training Loss: 1.068556309279415e-15, Validation Loss: 3.3890493374573146e-15
Epoch 477, Training Loss: 1.0869711231900787e-15, Validation Loss: 3.3890493374573146e-15
Epoch 478, Training Loss: 9.268427208852055e-16, Validation Loss: 3.4664446436720713e-15
Epoch 479, Training Loss: 1.3325011988853932e-15, Validation Loss: 3.509145480367292e-15
Epoch 480, Training Loss: 1.5726936964635847e-15, Validation Loss: 3.2315897242110028e-15
Epoch 481, Training Loss: 1.438185923230786e-15, Validation Loss: 3.702100221026532e-15
Epoch 482, Training Loss: 1.1713053233087427e-15, Validation Loss: 2.4485621863412632e-15
Epoch 483, Training Loss: 1.5726936964635847e-15, Validation Loss: 2.4485621863412632e-15
Epoch 484, Training Loss: 1.5278578073456913e-15, Validation Loss: 2.4512311871580615e-15
Epoch 485, Training Loss: 3.587908744791864e-15, Validation Loss: 2.508877284932874e-15
Epoch 486, Training Loss: 3.884146236116321e-15, Validation Loss: 2.5184849678953425e-15
Epoch 487, Training Loss: 3.852120343897109e-15, Validation Loss: 2.487993899376556e-15
Epoch 488, Training Loss: 1.407494637299092e-15, Validation Loss: 2.4917301617068946e-15
Epoch 489, Training Loss: 1.7844633682219477e-15, Validation Loss: 3.0975490896486147e-15
Epoch 490, Training Loss: 1.1316736046187797e-15, Validation Loss: 3.4591722305451827e-15
Epoch 491, Training Loss: 9.95030778963308e-16, Validation Loss: 4.019888348111506e-15
Epoch 492, Training Loss: 1.178644546159346e-15, Validation Loss: 3.8752388376429945e-15
Epoch 493, Training Loss: 1.2457650250865529e-15, Validation Loss: 4.4137370692446005e-15
Epoch 494, Training Loss: 1.4445910804988045e-15, Validation Loss: 5.570530812342746e-15
Epoch 495, Training Loss: 2.1064546845494343e-15, Validation Loss: 5.202802893237079e-15
Epoch 496, Training Loss: 2.779661012675865e-15, Validation Loss: 4.58163848114819e-15
Epoch 497, Training Loss: 2.577899246947548e-15, Validation Loss: 3.711474334653795e-15
Epoch 498, Training Loss: 3.1702406101490315e-15, Validation Loss: 3.5505454862137667e-15
Epoch 499, Training Loss: 1.939921230855661e-15, Validation Loss: 3.855689740736839e-15
Epoch 500, Training Loss: 2.4966340589550233e-15, Validation Loss: 3.503707952362393e-15
