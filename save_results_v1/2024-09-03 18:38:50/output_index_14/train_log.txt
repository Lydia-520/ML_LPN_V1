Epoch 1, Training Loss: 0.5605948567390442, Validation Loss: 0.5588075518608093
Epoch 2, Training Loss: 0.5588075518608093, Validation Loss: 0.5570953488349915
Epoch 3, Training Loss: 0.5570953488349915, Validation Loss: 0.5554249286651611
Epoch 4, Training Loss: 0.5554248690605164, Validation Loss: 0.5538054704666138
Epoch 5, Training Loss: 0.5538054704666138, Validation Loss: 0.552176833152771
Epoch 6, Training Loss: 0.552176833152771, Validation Loss: 0.5505198836326599
Epoch 7, Training Loss: 0.5505198836326599, Validation Loss: 0.5488096475601196
Epoch 8, Training Loss: 0.5488096475601196, Validation Loss: 0.5470899343490601
Epoch 9, Training Loss: 0.5470899343490601, Validation Loss: 0.5453663468360901
Epoch 10, Training Loss: 0.5453663468360901, Validation Loss: 0.5436235070228577
Epoch 11, Training Loss: 0.5436235666275024, Validation Loss: 0.5418331623077393
Epoch 12, Training Loss: 0.5418331623077393, Validation Loss: 0.5399881601333618
Epoch 13, Training Loss: 0.5399881601333618, Validation Loss: 0.5381177663803101
Epoch 14, Training Loss: 0.5381177663803101, Validation Loss: 0.5362024903297424
Epoch 15, Training Loss: 0.5362024903297424, Validation Loss: 0.5342258810997009
Epoch 16, Training Loss: 0.5342258810997009, Validation Loss: 0.5321856737136841
Epoch 17, Training Loss: 0.5321856737136841, Validation Loss: 0.5300909876823425
Epoch 18, Training Loss: 0.5300909876823425, Validation Loss: 0.5279287695884705
Epoch 19, Training Loss: 0.5279288291931152, Validation Loss: 0.5257205963134766
Epoch 20, Training Loss: 0.5257205963134766, Validation Loss: 0.5234297513961792
Epoch 21, Training Loss: 0.5234297513961792, Validation Loss: 0.5210562944412231
Epoch 22, Training Loss: 0.5210562944412231, Validation Loss: 0.5185844302177429
Epoch 23, Training Loss: 0.5185844302177429, Validation Loss: 0.5159664154052734
Epoch 24, Training Loss: 0.5159664154052734, Validation Loss: 0.5131470561027527
Epoch 25, Training Loss: 0.5131470561027527, Validation Loss: 0.5102347135543823
Epoch 26, Training Loss: 0.5102347135543823, Validation Loss: 0.50711989402771
Epoch 27, Training Loss: 0.50711989402771, Validation Loss: 0.5039598345756531
Epoch 28, Training Loss: 0.5039598345756531, Validation Loss: 0.5007211565971375
Epoch 29, Training Loss: 0.5007211565971375, Validation Loss: 0.4972466826438904
Epoch 30, Training Loss: 0.4972466826438904, Validation Loss: 0.49357426166534424
Epoch 31, Training Loss: 0.49357423186302185, Validation Loss: 0.4896923005580902
Epoch 32, Training Loss: 0.4896923005580902, Validation Loss: 0.4855724275112152
Epoch 33, Training Loss: 0.4855724573135376, Validation Loss: 0.4811793565750122
Epoch 34, Training Loss: 0.4811793565750122, Validation Loss: 0.47647255659103394
Epoch 35, Training Loss: 0.4764725863933563, Validation Loss: 0.4714038670063019
Epoch 36, Training Loss: 0.4714038670063019, Validation Loss: 0.46593913435935974
Epoch 37, Training Loss: 0.46593910455703735, Validation Loss: 0.46005111932754517
Epoch 38, Training Loss: 0.46005111932754517, Validation Loss: 0.4537721276283264
Epoch 39, Training Loss: 0.4537721276283264, Validation Loss: 0.4471195936203003
Epoch 40, Training Loss: 0.4471195936203003, Validation Loss: 0.43998339772224426
Epoch 41, Training Loss: 0.43998339772224426, Validation Loss: 0.4323822259902954
Epoch 42, Training Loss: 0.4323822259902954, Validation Loss: 0.42430058121681213
Epoch 43, Training Loss: 0.4243006408214569, Validation Loss: 0.4157605767250061
Epoch 44, Training Loss: 0.4157605767250061, Validation Loss: 0.4066658318042755
Epoch 45, Training Loss: 0.4066658318042755, Validation Loss: 0.3970750570297241
Epoch 46, Training Loss: 0.3970750570297241, Validation Loss: 0.3869509696960449
Epoch 47, Training Loss: 0.3869510293006897, Validation Loss: 0.37635642290115356
Epoch 48, Training Loss: 0.37635642290115356, Validation Loss: 0.3653310537338257
Epoch 49, Training Loss: 0.3653310537338257, Validation Loss: 0.3538981080055237
Epoch 50, Training Loss: 0.35389813780784607, Validation Loss: 0.34214526414871216
Epoch 51, Training Loss: 0.34214526414871216, Validation Loss: 0.33017173409461975
Epoch 52, Training Loss: 0.33017173409461975, Validation Loss: 0.3180732727050781
Epoch 53, Training Loss: 0.3180732727050781, Validation Loss: 0.30602380633354187
Epoch 54, Training Loss: 0.30602383613586426, Validation Loss: 0.2942391633987427
Epoch 55, Training Loss: 0.2942391633987427, Validation Loss: 0.2829577624797821
Epoch 56, Training Loss: 0.2829577624797821, Validation Loss: 0.27243050932884216
Epoch 57, Training Loss: 0.27243050932884216, Validation Loss: 0.2628996968269348
Epoch 58, Training Loss: 0.2628997266292572, Validation Loss: 0.2545424699783325
Epoch 59, Training Loss: 0.2545424699783325, Validation Loss: 0.24747566878795624
Epoch 60, Training Loss: 0.24747566878795624, Validation Loss: 0.24178707599639893
Epoch 61, Training Loss: 0.24178704619407654, Validation Loss: 0.237267404794693
Epoch 62, Training Loss: 0.2372673898935318, Validation Loss: 0.23375748097896576
Epoch 63, Training Loss: 0.23375748097896576, Validation Loss: 0.2309439480304718
Epoch 64, Training Loss: 0.2309439778327942, Validation Loss: 0.2282773107290268
Epoch 65, Training Loss: 0.228277325630188, Validation Loss: 0.22532108426094055
Epoch 66, Training Loss: 0.22532108426094055, Validation Loss: 0.22186022996902466
Epoch 67, Training Loss: 0.22186022996902466, Validation Loss: 0.21772660315036774
Epoch 68, Training Loss: 0.21772660315036774, Validation Loss: 0.21295075118541718
Epoch 69, Training Loss: 0.21295073628425598, Validation Loss: 0.20770639181137085
Epoch 70, Training Loss: 0.20770639181137085, Validation Loss: 0.20216810703277588
Epoch 71, Training Loss: 0.20216809213161469, Validation Loss: 0.19662828743457794
Epoch 72, Training Loss: 0.19662828743457794, Validation Loss: 0.1912928968667984
Epoch 73, Training Loss: 0.1912929117679596, Validation Loss: 0.18630385398864746
Epoch 74, Training Loss: 0.18630385398864746, Validation Loss: 0.18178007006645203
Epoch 75, Training Loss: 0.18178005516529083, Validation Loss: 0.17764724791049957
Epoch 76, Training Loss: 0.17764726281166077, Validation Loss: 0.17386668920516968
Epoch 77, Training Loss: 0.17386668920516968, Validation Loss: 0.1704012155532837
Epoch 78, Training Loss: 0.1704012155532837, Validation Loss: 0.16707457602024078
Epoch 79, Training Loss: 0.1670745611190796, Validation Loss: 0.1638384908437729
Epoch 80, Training Loss: 0.1638384908437729, Validation Loss: 0.1606030911207199
Epoch 81, Training Loss: 0.1606030911207199, Validation Loss: 0.1573408991098404
Epoch 82, Training Loss: 0.1573408991098404, Validation Loss: 0.15405508875846863
Epoch 83, Training Loss: 0.15405510365962982, Validation Loss: 0.15071889758110046
Epoch 84, Training Loss: 0.15071891248226166, Validation Loss: 0.1473291665315628
Epoch 85, Training Loss: 0.1473291516304016, Validation Loss: 0.1439446061849594
Epoch 86, Training Loss: 0.1439446061849594, Validation Loss: 0.1405741572380066
Epoch 87, Training Loss: 0.1405741423368454, Validation Loss: 0.13722500205039978
Epoch 88, Training Loss: 0.1372249871492386, Validation Loss: 0.1339103877544403
Epoch 89, Training Loss: 0.1339103877544403, Validation Loss: 0.13064245879650116
Epoch 90, Training Loss: 0.13064245879650116, Validation Loss: 0.12745773792266846
Epoch 91, Training Loss: 0.12745770812034607, Validation Loss: 0.12432194501161575
Epoch 92, Training Loss: 0.12432193011045456, Validation Loss: 0.12118904292583466
Epoch 93, Training Loss: 0.12118902802467346, Validation Loss: 0.11804421246051788
Epoch 94, Training Loss: 0.11804421246051788, Validation Loss: 0.11490346491336823
Epoch 95, Training Loss: 0.11490346491336823, Validation Loss: 0.11174217611551285
Epoch 96, Training Loss: 0.11174216866493225, Validation Loss: 0.10847528278827667
Epoch 97, Training Loss: 0.10847529768943787, Validation Loss: 0.10508822649717331
Epoch 98, Training Loss: 0.10508822649717331, Validation Loss: 0.10162832587957382
Epoch 99, Training Loss: 0.10162832587957382, Validation Loss: 0.09811324626207352
Epoch 100, Training Loss: 0.09811324626207352, Validation Loss: 0.09465115517377853
Epoch 101, Training Loss: 0.09465116262435913, Validation Loss: 0.09127310663461685
Epoch 102, Training Loss: 0.09127310663461685, Validation Loss: 0.08785921335220337
Epoch 103, Training Loss: 0.08785920590162277, Validation Loss: 0.08442345261573792
Epoch 104, Training Loss: 0.08442345261573792, Validation Loss: 0.08085817098617554
Epoch 105, Training Loss: 0.08085817843675613, Validation Loss: 0.07726743072271347
Epoch 106, Training Loss: 0.07726743072271347, Validation Loss: 0.07371705770492554
Epoch 107, Training Loss: 0.07371705770492554, Validation Loss: 0.07016559690237045
Epoch 108, Training Loss: 0.07016559690237045, Validation Loss: 0.06656356900930405
Epoch 109, Training Loss: 0.06656356155872345, Validation Loss: 0.0628674179315567
Epoch 110, Training Loss: 0.06286740303039551, Validation Loss: 0.05916095897555351
Epoch 111, Training Loss: 0.059160955250263214, Validation Loss: 0.05540088564157486
Epoch 112, Training Loss: 0.05540089309215546, Validation Loss: 0.05163359269499779
Epoch 113, Training Loss: 0.051633600145578384, Validation Loss: 0.04803183674812317
Epoch 114, Training Loss: 0.04803183674812317, Validation Loss: 0.04446571320295334
Epoch 115, Training Loss: 0.04446570947766304, Validation Loss: 0.04095520079135895
Epoch 116, Training Loss: 0.04095520079135895, Validation Loss: 0.037631500512361526
Epoch 117, Training Loss: 0.037631504237651825, Validation Loss: 0.03451545536518097
Epoch 118, Training Loss: 0.03451545909047127, Validation Loss: 0.031534235924482346
Epoch 119, Training Loss: 0.031534235924482346, Validation Loss: 0.02871115878224373
Epoch 120, Training Loss: 0.02871115878224373, Validation Loss: 0.026073342189192772
Epoch 121, Training Loss: 0.026073342189192772, Validation Loss: 0.023642776533961296
Epoch 122, Training Loss: 0.023642774671316147, Validation Loss: 0.02142803557217121
Epoch 123, Training Loss: 0.02142803557217121, Validation Loss: 0.01946566253900528
Epoch 124, Training Loss: 0.01946566067636013, Validation Loss: 0.01772773265838623
Epoch 125, Training Loss: 0.01772773265838623, Validation Loss: 0.016177773475646973
Epoch 126, Training Loss: 0.016177773475646973, Validation Loss: 0.014789671637117863
Epoch 127, Training Loss: 0.014789669774472713, Validation Loss: 0.013532278127968311
Epoch 128, Training Loss: 0.013532274402678013, Validation Loss: 0.012379050254821777
Epoch 129, Training Loss: 0.012379050254821777, Validation Loss: 0.011293900199234486
Epoch 130, Training Loss: 0.011293902061879635, Validation Loss: 0.010240164585411549
Epoch 131, Training Loss: 0.010240169242024422, Validation Loss: 0.009203092195093632
Epoch 132, Training Loss: 0.00920309778302908, Validation Loss: 0.008200591430068016
Epoch 133, Training Loss: 0.00820059422403574, Validation Loss: 0.007249987684190273
Epoch 134, Training Loss: 0.007249987218528986, Validation Loss: 0.006343343295156956
Epoch 135, Training Loss: 0.00634334422647953, Validation Loss: 0.005493223201483488
Epoch 136, Training Loss: 0.005493225995451212, Validation Loss: 0.004708276595920324
Epoch 137, Training Loss: 0.004708276595920324, Validation Loss: 0.004001612775027752
Epoch 138, Training Loss: 0.004001614172011614, Validation Loss: 0.0033701893407851458
Epoch 139, Training Loss: 0.003370187245309353, Validation Loss: 0.0028308311011642218
Epoch 140, Training Loss: 0.0028308306355029345, Validation Loss: 0.0023819475900381804
Epoch 141, Training Loss: 0.0023819475900381804, Validation Loss: 0.0020193227101117373
Epoch 142, Training Loss: 0.002019322942942381, Validation Loss: 0.0017332349671050906
Epoch 143, Training Loss: 0.0017332346178591251, Validation Loss: 0.0015093670226633549
Epoch 144, Training Loss: 0.0015093664405867457, Validation Loss: 0.0013424434000626206
Epoch 145, Training Loss: 0.0013424409553408623, Validation Loss: 0.0012191495625302196
Epoch 146, Training Loss: 0.0012191496789455414, Validation Loss: 0.0011272156843915582
Epoch 147, Training Loss: 0.0011272166157141328, Validation Loss: 0.0010565858101472259
Epoch 148, Training Loss: 0.0010565860429778695, Validation Loss: 0.000997350667603314
Epoch 149, Training Loss: 0.000997350667603314, Validation Loss: 0.0009426308679394424
Epoch 150, Training Loss: 0.0009426309261471033, Validation Loss: 0.0008875258499756455
Epoch 151, Training Loss: 0.0008875245111994445, Validation Loss: 0.0008292514248751104
Epoch 152, Training Loss: 0.0008292512502521276, Validation Loss: 0.0007671553757973015
Epoch 153, Training Loss: 0.000767155725043267, Validation Loss: 0.0007019740878604352
Epoch 154, Training Loss: 0.0007019735057838261, Validation Loss: 0.000635286676697433
Epoch 155, Training Loss: 0.0006352867931127548, Validation Loss: 0.0005689046229235828
Epoch 156, Training Loss: 0.0005689040990546346, Validation Loss: 0.0005046629230491817
Epoch 157, Training Loss: 0.0005046630394645035, Validation Loss: 0.0004439932818058878
Epoch 158, Training Loss: 0.0004439933691173792, Validation Loss: 0.00038785941433161497
Epoch 159, Training Loss: 0.00038785894867032766, Validation Loss: 0.00033693117438815534
Epoch 160, Training Loss: 0.0003369313490111381, Validation Loss: 0.000290777679765597
Epoch 161, Training Loss: 0.0002907778543885797, Validation Loss: 0.00024841661797836423
Epoch 162, Training Loss: 0.0002484167634975165, Validation Loss: 0.0002101608697557822
Epoch 163, Training Loss: 0.00021016049140598625, Validation Loss: 0.000175691326148808
Epoch 164, Training Loss: 0.00017569120973348618, Validation Loss: 0.00014453633048105985
Epoch 165, Training Loss: 0.0001445367670385167, Validation Loss: 0.0001165402281912975
Epoch 166, Training Loss: 0.00011654014087980613, Validation Loss: 9.175811283057556e-05
Epoch 167, Training Loss: 9.175806917482987e-05, Validation Loss: 7.033640576992184e-05
Epoch 168, Training Loss: 7.033599831629544e-05, Validation Loss: 5.238478479441255e-05
Epoch 169, Training Loss: 5.2384759328560904e-05, Validation Loss: 3.7925095966784284e-05
Epoch 170, Training Loss: 3.792502320720814e-05, Validation Loss: 2.6898485884885304e-05
Epoch 171, Training Loss: 2.6898707801592536e-05, Validation Loss: 1.919475653267e-05
Epoch 172, Training Loss: 1.9194570995750837e-05, Validation Loss: 1.455776236980455e-05
Epoch 173, Training Loss: 1.4557756003341638e-05, Validation Loss: 1.2566330042318441e-05
Epoch 174, Training Loss: 1.2566302757477388e-05, Validation Loss: 1.2647365110751707e-05
Epoch 175, Training Loss: 1.2647390576603357e-05, Validation Loss: 1.421657816536026e-05
Epoch 176, Training Loss: 1.421660363121191e-05, Validation Loss: 1.6627685909043066e-05
Epoch 177, Training Loss: 1.662783688516356e-05, Validation Loss: 1.9220789909013547e-05
Epoch 178, Training Loss: 1.9220618924009614e-05, Validation Loss: 2.2028174498700537e-05
Epoch 179, Training Loss: 2.202813993790187e-05, Validation Loss: 2.4425673473160714e-05
Epoch 180, Training Loss: 2.44257171289064e-05, Validation Loss: 2.5821998860919848e-05
Epoch 181, Training Loss: 2.5821887902566232e-05, Validation Loss: 2.6183444788330235e-05
Epoch 182, Training Loss: 2.6183515728916973e-05, Validation Loss: 2.572841003711801e-05
Epoch 183, Training Loss: 2.5728191758389585e-05, Validation Loss: 2.471690640959423e-05
Epoch 184, Training Loss: 2.4716811822145246e-05, Validation Loss: 2.323097396583762e-05
Epoch 185, Training Loss: 2.323074295418337e-05, Validation Loss: 2.1400423065642826e-05
Epoch 186, Training Loss: 2.1400401237769984e-05, Validation Loss: 1.9390388843021356e-05
Epoch 187, Training Loss: 1.9390625311643817e-05, Validation Loss: 1.7349460904370062e-05
Epoch 188, Training Loss: 1.734952638798859e-05, Validation Loss: 1.539303411846049e-05
Epoch 189, Training Loss: 1.5393010471598245e-05, Validation Loss: 1.3592960385722108e-05
Epoch 190, Training Loss: 1.3592933100881055e-05, Validation Loss: 1.1980847375525627e-05
Epoch 191, Training Loss: 1.1980865565419663e-05, Validation Loss: 1.0561851922830101e-05
Epoch 192, Training Loss: 1.0561838280409575e-05, Validation Loss: 9.327446605311707e-06
Epoch 193, Training Loss: 9.327484804089181e-06, Validation Loss: 8.261000402853824e-06
Epoch 194, Training Loss: 8.260933100245893e-06, Validation Loss: 7.339093826885801e-06
Epoch 195, Training Loss: 7.339079729717923e-06, Validation Loss: 6.534702151839156e-06
Epoch 196, Training Loss: 6.534712611028226e-06, Validation Loss: 5.823165338370018e-06
Epoch 197, Training Loss: 5.823196261189878e-06, Validation Loss: 5.187311217014212e-06
Epoch 198, Training Loss: 5.187410806684056e-06, Validation Loss: 4.617438662535278e-06
Epoch 199, Training Loss: 4.617442300514085e-06, Validation Loss: 4.106472260900773e-06
Epoch 200, Training Loss: 4.106407232029596e-06, Validation Loss: 3.646908453447395e-06
Epoch 201, Training Loss: 3.64690322385286e-06, Validation Loss: 3.2315092539647594e-06
Epoch 202, Training Loss: 3.2314981126546627e-06, Validation Loss: 2.8547374313347973e-06
Epoch 203, Training Loss: 2.8547356123453937e-06, Validation Loss: 2.513055505914963e-06
Epoch 204, Training Loss: 2.5130502763204277e-06, Validation Loss: 2.20364404412976e-06
Epoch 205, Training Loss: 2.203685653512366e-06, Validation Loss: 1.9229432837164495e-06
Epoch 206, Training Loss: 1.9229591998737305e-06, Validation Loss: 1.6671478988428134e-06
Epoch 207, Training Loss: 1.6671198181938962e-06, Validation Loss: 1.4339310610012035e-06
Epoch 208, Training Loss: 1.4339208291858085e-06, Validation Loss: 1.2232333119754912e-06
Epoch 209, Training Loss: 1.2232209201101796e-06, Validation Loss: 1.0360312217017054e-06
Epoch 210, Training Loss: 1.0360519127061707e-06, Validation Loss: 8.729907108318002e-07
Epoch 211, Training Loss: 8.730053764338663e-07, Validation Loss: 7.33803801722388e-07
Epoch 212, Training Loss: 7.338195473494125e-07, Validation Loss: 6.178015610203147e-07
Epoch 213, Training Loss: 6.177807563290116e-07, Validation Loss: 5.242520160209097e-07
Epoch 214, Training Loss: 5.242563929641619e-07, Validation Loss: 4.5195355369287427e-07
Epoch 215, Training Loss: 4.5192410880190437e-07, Validation Loss: 3.9847000721238146e-07
Epoch 216, Training Loss: 3.9847122934588697e-07, Validation Loss: 3.602951608172589e-07
Epoch 217, Training Loss: 3.6028598060511285e-07, Validation Loss: 3.335451026487135e-07
Epoch 218, Training Loss: 3.3355578921145934e-07, Validation Loss: 3.148043106193654e-07
Epoch 219, Training Loss: 3.148141161091189e-07, Validation Loss: 3.0127270633784065e-07
Epoch 220, Training Loss: 3.012793001744285e-07, Validation Loss: 2.906345173414593e-07
Epoch 221, Training Loss: 2.906530198742985e-07, Validation Loss: 2.8102277838115697e-07
Epoch 222, Training Loss: 2.8103781346544565e-07, Validation Loss: 2.711619515594066e-07
Epoch 223, Training Loss: 2.711833815283171e-07, Validation Loss: 2.605588065307529e-07
Epoch 224, Training Loss: 2.605833913094102e-07, Validation Loss: 2.4931335929068155e-07
Epoch 225, Training Loss: 2.493123645308515e-07, Validation Loss: 2.3766079948472907e-07
Epoch 226, Training Loss: 2.3767928780671355e-07, Validation Loss: 2.2585246028938855e-07
Epoch 227, Training Loss: 2.2585462033930526e-07, Validation Loss: 2.1384060744367162e-07
Epoch 228, Training Loss: 2.138260981610074e-07, Validation Loss: 2.016044078345658e-07
Epoch 229, Training Loss: 2.0159971825250977e-07, Validation Loss: 1.8924595224234508e-07
Epoch 230, Training Loss: 1.8925169342765003e-07, Validation Loss: 1.7666330620613735e-07
Epoch 231, Training Loss: 1.7667180429725704e-07, Validation Loss: 1.6370583466596145e-07
Epoch 232, Training Loss: 1.636997097875792e-07, Validation Loss: 1.5017128873751062e-07
Epoch 233, Training Loss: 1.5017278087725572e-07, Validation Loss: 1.3613318117222661e-07
Epoch 234, Training Loss: 1.3612921634376107e-07, Validation Loss: 1.218387524204445e-07
Epoch 235, Training Loss: 1.218416372239517e-07, Validation Loss: 1.0767306690695477e-07
Epoch 236, Training Loss: 1.0767820413093432e-07, Validation Loss: 9.402637601851893e-08
Epoch 237, Training Loss: 9.4027370778349e-08, Validation Loss: 8.127801010004987e-08
Epoch 238, Training Loss: 8.127658901457835e-08, Validation Loss: 6.977269606522896e-08
Epoch 239, Training Loss: 6.97710120789452e-08, Validation Loss: 5.981870287996571e-08
Epoch 240, Training Loss: 5.981351591799466e-08, Validation Loss: 5.15647009535769e-08
Epoch 241, Training Loss: 5.1569607251167326e-08, Validation Loss: 4.498683381370938e-08
Epoch 242, Training Loss: 4.498367189853525e-08, Validation Loss: 3.984465024586825e-08
Epoch 243, Training Loss: 3.985827845554013e-08, Validation Loss: 3.5895720174039525e-08
Epoch 244, Training Loss: 3.589467212350428e-08, Validation Loss: 3.279416915802358e-08
Epoch 245, Training Loss: 3.279341598272367e-08, Validation Loss: 3.0226832592461506e-08
Epoch 246, Training Loss: 3.0221979585576264e-08, Validation Loss: 2.7886636999596703e-08
Epoch 247, Training Loss: 2.7884890840823573e-08, Validation Loss: 2.5530345837410096e-08
Epoch 248, Training Loss: 2.553380262781957e-08, Validation Loss: 2.3029643969607605e-08
Epoch 249, Training Loss: 2.303166901640452e-08, Validation Loss: 2.037366542140262e-08
Epoch 250, Training Loss: 2.0367577846513996e-08, Validation Loss: 1.7614834035839522e-08
Epoch 251, Training Loss: 1.7609318447853184e-08, Validation Loss: 1.4859364405594988e-08
Epoch 252, Training Loss: 1.4856063046408963e-08, Validation Loss: 1.2220109368854537e-08
Epoch 253, Training Loss: 1.221918122240595e-08, Validation Loss: 9.832100467122018e-09
Epoch 254, Training Loss: 9.830545266709123e-09, Validation Loss: 7.80759368268491e-09
Epoch 255, Training Loss: 7.800964318960268e-09, Validation Loss: 6.204456060032726e-09
Epoch 256, Training Loss: 6.2026743741228074e-09, Validation Loss: 5.040499573283341e-09
Epoch 257, Training Loss: 5.039873407497453e-09, Validation Loss: 4.26879820381032e-09
Epoch 258, Training Loss: 4.273658760212129e-09, Validation Loss: 3.8386738232532025e-09
Epoch 259, Training Loss: 3.838310558279545e-09, Validation Loss: 3.656492886250362e-09
Epoch 260, Training Loss: 3.6559162364113718e-09, Validation Loss: 3.640099111024142e-09
Epoch 261, Training Loss: 3.641360546424721e-09, Validation Loss: 3.7082676929145464e-09
Epoch 262, Training Loss: 3.705268980525034e-09, Validation Loss: 3.780328050595472e-09
Epoch 263, Training Loss: 3.776884582862294e-09, Validation Loss: 3.812628879273916e-09
Epoch 264, Training Loss: 3.8151686254650485e-09, Validation Loss: 3.7938434616080485e-09
Epoch 265, Training Loss: 3.79437103958935e-09, Validation Loss: 3.7097633853733214e-09
Epoch 266, Training Loss: 3.7069765035369073e-09, Validation Loss: 3.5636982254061422e-09
Epoch 267, Training Loss: 3.562401706957985e-09, Validation Loss: 3.3718867697984933e-09
Epoch 268, Training Loss: 3.3716731628885555e-09, Validation Loss: 3.1461715455094463e-09
Epoch 269, Training Loss: 3.148061811231173e-09, Validation Loss: 2.9077618091122304e-09
Epoch 270, Training Loss: 2.910390151100728e-09, Validation Loss: 2.6702404731793195e-09
Epoch 271, Training Loss: 2.669323428960979e-09, Validation Loss: 2.4348960625530935e-09
Epoch 272, Training Loss: 2.4348816296537734e-09, Validation Loss: 2.2102211172381203e-09
Epoch 273, Training Loss: 2.2116446452002947e-09, Validation Loss: 1.9996342359718255e-09
Epoch 274, Training Loss: 1.9990478161702185e-09, Validation Loss: 1.7998010859443525e-09
Epoch 275, Training Loss: 1.8022560110964037e-09, Validation Loss: 1.6180400352894253e-09
Epoch 276, Training Loss: 1.616512812496751e-09, Validation Loss: 1.4458262365124597e-09
Epoch 277, Training Loss: 1.4451346785904207e-09, Validation Loss: 1.2859837639211946e-09
Epoch 278, Training Loss: 1.2861698373001218e-09, Validation Loss: 1.1396248389416996e-09
Epoch 279, Training Loss: 1.1382459419451152e-09, Validation Loss: 1.005762473305083e-09
Epoch 280, Training Loss: 1.0062720656733859e-09, Validation Loss: 8.834072362517986e-10
Epoch 281, Training Loss: 8.841077869803371e-10, Validation Loss: 7.727308792837562e-10
Epoch 282, Training Loss: 7.7327116931869e-10, Validation Loss: 6.732692181543598e-10
Epoch 283, Training Loss: 6.733439361639171e-10, Validation Loss: 5.834061567178139e-10
Epoch 284, Training Loss: 5.828435512000851e-10, Validation Loss: 5.02024422033287e-10
Epoch 285, Training Loss: 5.029863747729735e-10, Validation Loss: 4.3259201776280065e-10
Epoch 286, Training Loss: 4.321316360300642e-10, Validation Loss: 3.705882822835349e-10
Epoch 287, Training Loss: 3.704039019947203e-10, Validation Loss: 3.1643102027523184e-10
Epoch 288, Training Loss: 3.1640920439279796e-10, Validation Loss: 2.7039179228971477e-10
Epoch 289, Training Loss: 2.7061303198294695e-10, Validation Loss: 2.317151193143019e-10
Epoch 290, Training Loss: 2.322344261340703e-10, Validation Loss: 2.0011824142240897e-10
Epoch 291, Training Loss: 2.005542953931183e-10, Validation Loss: 1.742986449615458e-10
Epoch 292, Training Loss: 1.7450169087496192e-10, Validation Loss: 1.5362944250085775e-10
Epoch 293, Training Loss: 1.5366972971886383e-10, Validation Loss: 1.3621934136232028e-10
Epoch 294, Training Loss: 1.3609624538446496e-10, Validation Loss: 1.218469075636719e-10
Epoch 295, Training Loss: 1.2190617959539907e-10, Validation Loss: 1.0974065406399447e-10
Epoch 296, Training Loss: 1.096098142805424e-10, Validation Loss: 9.879073253893367e-11
Epoch 297, Training Loss: 9.898492442372842e-11, Validation Loss: 8.952743407730779e-11
Epoch 298, Training Loss: 8.942886708940279e-11, Validation Loss: 8.138461432549704e-11
Epoch 299, Training Loss: 8.114470206876945e-11, Validation Loss: 7.441770810689974e-11
Epoch 300, Training Loss: 7.452220091019868e-11, Validation Loss: 6.859694062777422e-11
Epoch 301, Training Loss: 6.864780272008986e-11, Validation Loss: 6.400861091160337e-11
Epoch 302, Training Loss: 6.429078797109966e-11, Validation Loss: 6.022461696009174e-11
Epoch 303, Training Loss: 6.066360608292243e-11, Validation Loss: 5.8141203657102736e-11
Epoch 304, Training Loss: 5.7880554515943317e-11, Validation Loss: 5.669393426943614e-11
Epoch 305, Training Loss: 5.653234130820195e-11, Validation Loss: 5.519893223060457e-11
Epoch 306, Training Loss: 5.568618829943084e-11, Validation Loss: 5.461038218856906e-11
Epoch 307, Training Loss: 5.4525429310503526e-11, Validation Loss: 5.379470133237696e-11
Epoch 308, Training Loss: 5.356042345749934e-11, Validation Loss: 5.217544452040812e-11
Epoch 309, Training Loss: 5.204233918809642e-11, Validation Loss: 5.0004524826396946e-11
Epoch 310, Training Loss: 5.0057461647989854e-11, Validation Loss: 4.71530349488436e-11
Epoch 311, Training Loss: 4.723061525213623e-11, Validation Loss: 4.3878321115409236e-11
Epoch 312, Training Loss: 4.386176491455451e-11, Validation Loss: 3.9769531418043513e-11
Epoch 313, Training Loss: 3.975348522589073e-11, Validation Loss: 3.5323393515751533e-11
Epoch 314, Training Loss: 3.5429895128835653e-11, Validation Loss: 3.076373183974468e-11
Epoch 315, Training Loss: 3.094910439038756e-11, Validation Loss: 2.6514360151885796e-11
Epoch 316, Training Loss: 2.6477538911384713e-11, Validation Loss: 2.225964378099743e-11
Epoch 317, Training Loss: 2.22115537767964e-11, Validation Loss: 1.854443508475523e-11
Epoch 318, Training Loss: 1.8457398803795044e-11, Validation Loss: 1.5264142380622125e-11
Epoch 319, Training Loss: 1.5300835251585987e-11, Validation Loss: 1.2467909517310805e-11
Epoch 320, Training Loss: 1.2555205139430647e-11, Validation Loss: 1.0379657203185566e-11
Epoch 321, Training Loss: 1.0382724194291093e-11, Validation Loss: 8.4618883081089e-12
Epoch 322, Training Loss: 8.504029078149067e-12, Validation Loss: 7.124241734740577e-12
Epoch 323, Training Loss: 7.072552179326896e-12, Validation Loss: 6.037010735066017e-12
Epoch 324, Training Loss: 5.9147153320948664e-12, Validation Loss: 5.0936069598273015e-12
Epoch 325, Training Loss: 5.054243915753043e-12, Validation Loss: 4.39094680754204e-12
Epoch 326, Training Loss: 4.405058783019111e-12, Validation Loss: 3.8522336362478704e-12
Epoch 327, Training Loss: 3.775588782589656e-12, Validation Loss: 3.4202556151857744e-12
Epoch 328, Training Loss: 3.3413033624640764e-12, Validation Loss: 3.022421722620461e-12
Epoch 329, Training Loss: 3.0212295339115958e-12, Validation Loss: 2.7891686356362744e-12
Epoch 330, Training Loss: 2.714974729409181e-12, Validation Loss: 2.509341042247759e-12
Epoch 331, Training Loss: 2.5402418883657685e-12, Validation Loss: 2.3895080792507573e-12
Epoch 332, Training Loss: 2.38641745253787e-12, Validation Loss: 2.2670979676897574e-12
Epoch 333, Training Loss: 2.3007984406575588e-12, Validation Loss: 2.2013263607789657e-12
Epoch 334, Training Loss: 2.2581251105102673e-12, Validation Loss: 2.1656476525272472e-12
Epoch 335, Training Loss: 2.172894243007706e-12, Validation Loss: 2.141058814617014e-12
Epoch 336, Training Loss: 2.1412275164750527e-12, Validation Loss: 2.0968678182686773e-12
Epoch 337, Training Loss: 2.0589315842534095e-12, Validation Loss: 1.970869648038054e-12
Epoch 338, Training Loss: 2.003333696848353e-12, Validation Loss: 1.905387956788185e-12
Epoch 339, Training Loss: 1.894371161673125e-12, Validation Loss: 1.7587643581090662e-12
Epoch 340, Training Loss: 1.7686752670081907e-12, Validation Loss: 1.6638128591886514e-12
Epoch 341, Training Loss: 1.6301568385099219e-12, Validation Loss: 1.4941212329866449e-12
Epoch 342, Training Loss: 1.4829572032165617e-12, Validation Loss: 1.3972757412911152e-12
Epoch 343, Training Loss: 1.3273736493638055e-12, Validation Loss: 1.206736425195254e-12
Epoch 344, Training Loss: 1.2016204004039466e-12, Validation Loss: 1.061811337639551e-12
Epoch 345, Training Loss: 1.0821357915649643e-12, Validation Loss: 9.147049437330246e-13
Epoch 346, Training Loss: 9.575053423749313e-13, Validation Loss: 8.323727991588203e-13
Epoch 347, Training Loss: 8.454571678168099e-13, Validation Loss: 7.407865553615833e-13
Epoch 348, Training Loss: 7.430833834538852e-13, Validation Loss: 6.467132059907732e-13
Epoch 349, Training Loss: 6.558000670287001e-13, Validation Loss: 5.536015981570663e-13
Epoch 350, Training Loss: 5.938624700503603e-13, Validation Loss: 5.193627646005172e-13
Epoch 351, Training Loss: 5.407916952790415e-13, Validation Loss: 4.79367413819265e-13
Epoch 352, Training Loss: 4.777967843420938e-13, Validation Loss: 4.243822903770428e-13
Epoch 353, Training Loss: 4.364342004112287e-13, Validation Loss: 3.6785196199859427e-13
Epoch 354, Training Loss: 3.7990872383750207e-13, Validation Loss: 3.509500632811746e-13
Epoch 355, Training Loss: 3.631083335484814e-13, Validation Loss: 3.0634368197550443e-13
Epoch 356, Training Loss: 3.306471036638309e-13, Validation Loss: 2.970327705586334e-13
Epoch 357, Training Loss: 2.9052899409159894e-13, Validation Loss: 2.7160779593297935e-13
Epoch 358, Training Loss: 2.5734067112502534e-13, Validation Loss: 2.305173467474081e-13
Epoch 359, Training Loss: 2.346299695331344e-13, Validation Loss: 1.9991465622683224e-13
Epoch 360, Training Loss: 1.9965280784964984e-13, Validation Loss: 1.8167012219658801e-13
Epoch 361, Training Loss: 1.9065891714801358e-13, Validation Loss: 1.4909041611953916e-13
Epoch 362, Training Loss: 1.5611496199507274e-13, Validation Loss: 1.4285137471797132e-13
Epoch 363, Training Loss: 1.2749327147395378e-13, Validation Loss: 1.373165903900686e-13
Epoch 364, Training Loss: 1.0774625007307914e-13, Validation Loss: 1.1204656180738987e-13
Epoch 365, Training Loss: 1.0299761396418208e-13, Validation Loss: 8.791027666021564e-14
Epoch 366, Training Loss: 8.227488514696985e-14, Validation Loss: 6.624708377353516e-14
Epoch 367, Training Loss: 7.187575323331155e-14, Validation Loss: 5.811382598015433e-14
Epoch 368, Training Loss: 5.877138782150321e-14, Validation Loss: 4.9283236454485124e-14
Epoch 369, Training Loss: 5.69232296932301e-14, Validation Loss: 4.559718623725964e-14
Epoch 370, Training Loss: 4.546105449010872e-14, Validation Loss: 4.023187964957535e-14
Epoch 371, Training Loss: 4.014700694826047e-14, Validation Loss: 3.1666265746729816e-14
Epoch 372, Training Loss: 3.208817285775718e-14, Validation Loss: 2.7462221000940437e-14
Epoch 373, Training Loss: 2.6518831279672382e-14, Validation Loss: 2.3969365446456503e-14
Epoch 374, Training Loss: 2.1362436898098892e-14, Validation Loss: 1.80251118393239e-14
Epoch 375, Training Loss: 1.9437163196241863e-14, Validation Loss: 2.160600630427955e-14
Epoch 376, Training Loss: 2.0599934450848782e-14, Validation Loss: 1.8880110284414178e-14
Epoch 377, Training Loss: 2.0410321043408224e-14, Validation Loss: 1.9908072857333786e-14
Epoch 378, Training Loss: 1.9728384981969153e-14, Validation Loss: 1.744608858691033e-14
Epoch 379, Training Loss: 1.997132250157116e-14, Validation Loss: 1.3439213629483967e-14
Epoch 380, Training Loss: 1.6519498917118118e-14, Validation Loss: 1.5527196431277916e-14
Epoch 381, Training Loss: 1.7921866993383072e-14, Validation Loss: 1.3089083243373982e-14
Epoch 382, Training Loss: 1.4730490793617677e-14, Validation Loss: 1.4767970307467786e-14
Epoch 383, Training Loss: 1.333672179583325e-14, Validation Loss: 1.4098094301131722e-14
Epoch 384, Training Loss: 1.405276194482762e-14, Validation Loss: 1.4114015132408314e-14
Epoch 385, Training Loss: 1.5538585636286698e-14, Validation Loss: 1.5465913597544068e-14
Epoch 386, Training Loss: 1.3162948751539293e-14, Validation Loss: 1.3937571393231665e-14
Epoch 387, Training Loss: 1.345514970735361e-14, Validation Loss: 1.1543146470681213e-14
Epoch 388, Training Loss: 1.1465621780183764e-14, Validation Loss: 1.426433298735985e-14
Epoch 389, Training Loss: 1.115877562471142e-14, Validation Loss: 1.4950592304961707e-14
Epoch 390, Training Loss: 9.994976919139482e-15, Validation Loss: 1.4944403882249067e-14
Epoch 391, Training Loss: 7.835380022754024e-15, Validation Loss: 8.945529355512769e-15
Epoch 392, Training Loss: 6.980595453482926e-15, Validation Loss: 9.683147668838443e-15
Epoch 393, Training Loss: 9.283840243876768e-15, Validation Loss: 8.134213246545341e-15
Epoch 394, Training Loss: 8.962816450933282e-15, Validation Loss: 9.43588096384302e-15
Epoch 395, Training Loss: 8.88355280179512e-15, Validation Loss: 9.11041956528887e-15
Epoch 396, Training Loss: 9.98023176959368e-15, Validation Loss: 5.467443091013635e-15
Epoch 397, Training Loss: 6.549282888609247e-15, Validation Loss: 3.989324858275729e-15
Epoch 398, Training Loss: 5.7852371473292395e-15, Validation Loss: 5.753647477077864e-15
Epoch 399, Training Loss: 8.024597865808215e-15, Validation Loss: 3.5133431638956474e-15
Epoch 400, Training Loss: 6.9231492554836654e-15, Validation Loss: 5.493438955681343e-15
Epoch 401, Training Loss: 6.055253886738492e-15, Validation Loss: 6.574390639231759e-15
Epoch 402, Training Loss: 5.306753741139442e-15, Validation Loss: 4.6887123395270795e-15
Epoch 403, Training Loss: 4.269722409970056e-15, Validation Loss: 3.2921680382909727e-15
Epoch 404, Training Loss: 6.5070489788262e-15, Validation Loss: 4.3079947466587946e-15
Epoch 405, Training Loss: 2.9817234751004567e-15, Validation Loss: 4.140927238691777e-15
Epoch 406, Training Loss: 3.563523089756887e-15, Validation Loss: 4.343289762537934e-15
Epoch 407, Training Loss: 4.5012415019266006e-15, Validation Loss: 5.882256724624221e-15
Epoch 408, Training Loss: 3.733359124912005e-15, Validation Loss: 4.1553471275858345e-15
Epoch 409, Training Loss: 4.260715485125428e-15, Validation Loss: 3.314690220841991e-15
Epoch 410, Training Loss: 3.586074494944585e-15, Validation Loss: 3.2225997400253193e-15
Epoch 411, Training Loss: 3.49960513652413e-15, Validation Loss: 5.380930110396396e-15
Epoch 412, Training Loss: 4.09311434640164e-15, Validation Loss: 5.587762427105214e-15
Epoch 413, Training Loss: 3.835007313747257e-15, Validation Loss: 6.124580145339467e-15
Epoch 414, Training Loss: 3.2870348068723748e-15, Validation Loss: 6.326116812062051e-15
Epoch 415, Training Loss: 3.673544622792221e-15, Validation Loss: 6.717046657658907e-15
Epoch 416, Training Loss: 3.5963494281112535e-15, Validation Loss: 6.270194849851375e-15
Epoch 417, Training Loss: 3.512081720078949e-15, Validation Loss: 7.114604959584502e-15
Epoch 418, Training Loss: 3.4388231110203454e-15, Validation Loss: 5.949838095353852e-15
Epoch 419, Training Loss: 2.7058022807741316e-15, Validation Loss: 5.5655070599325805e-15
Epoch 420, Training Loss: 4.052881975472955e-15, Validation Loss: 4.482505980166283e-15
Epoch 421, Training Loss: 3.7222502878087645e-15, Validation Loss: 5.276483748219889e-15
Epoch 422, Training Loss: 3.0580513080434362e-15, Validation Loss: 4.969076856936464e-15
Epoch 423, Training Loss: 2.0664565182306653e-15, Validation Loss: 3.3323023651560127e-15
Epoch 424, Training Loss: 2.407496546750717e-15, Validation Loss: 4.089325568028572e-15
Epoch 425, Training Loss: 2.8676654065549817e-15, Validation Loss: 4.387610337986542e-15
Epoch 426, Training Loss: 4.234294409918198e-15, Validation Loss: 4.753771246139788e-15
Epoch 427, Training Loss: 3.649291528413489e-15, Validation Loss: 3.95913363942027e-15
Epoch 428, Training Loss: 3.574365111481742e-15, Validation Loss: 3.3603247561500267e-15
Epoch 429, Training Loss: 3.1827845328231573e-15, Validation Loss: 3.49961974784247e-15
Epoch 430, Training Loss: 3.6341461558001085e-15, Validation Loss: 3.8137984557809566e-15
Epoch 431, Training Loss: 3.0279939203936438e-15, Validation Loss: 5.4059167353074505e-15
Epoch 432, Training Loss: 1.874702870290632e-15, Validation Loss: 4.986505406859168e-15
Epoch 433, Training Loss: 2.307082696677851e-15, Validation Loss: 6.951505377458898e-15
Epoch 434, Training Loss: 2.5279264206419126e-15, Validation Loss: 7.112767745121908e-15
Epoch 435, Training Loss: 3.291805296431311e-15, Validation Loss: 4.98323628319924e-15
Epoch 436, Training Loss: 4.638751795199179e-15, Validation Loss: 4.019130253623713e-15
Epoch 437, Training Loss: 2.660232331728324e-15, Validation Loss: 3.867942072318872e-15
Epoch 438, Training Loss: 2.7236166542043104e-15, Validation Loss: 3.91018191133255e-15
Epoch 439, Training Loss: 3.798944886017905e-15, Validation Loss: 5.4234367647884585e-15
Epoch 440, Training Loss: 2.723216219378496e-15, Validation Loss: 4.632561678420645e-15
Epoch 441, Training Loss: 2.4188389531891626e-15, Validation Loss: 5.64492910423188e-15
Epoch 442, Training Loss: 2.561686824578864e-15, Validation Loss: 2.8009117987730543e-15
Epoch 443, Training Loss: 2.754107722723097e-15, Validation Loss: 3.889880225652759e-15
Epoch 444, Training Loss: 1.690355149045798e-15, Validation Loss: 3.251326862431449e-15
Epoch 445, Training Loss: 4.1580665268629944e-15, Validation Loss: 4.807241047968163e-15
Epoch 446, Training Loss: 3.5410383884137845e-15, Validation Loss: 4.836064308613806e-15
Epoch 447, Training Loss: 3.4059300688213823e-15, Validation Loss: 3.6130503767322665e-15
Epoch 448, Training Loss: 5.530132846472873e-15, Validation Loss: 5.1872873672257486e-15
Epoch 449, Training Loss: 2.346414248067131e-15, Validation Loss: 3.656685279010072e-15
Epoch 450, Training Loss: 1.804813546537969e-15, Validation Loss: 6.452467869771028e-15
Epoch 451, Training Loss: 2.9442265970749297e-15, Validation Loss: 7.674240474868366e-15
Epoch 452, Training Loss: 3.109692577496926e-15, Validation Loss: 7.417779227230498e-15
Epoch 453, Training Loss: 3.0734969538366184e-15, Validation Loss: 7.178654202924083e-15
Epoch 454, Training Loss: 3.15649686530512e-15, Validation Loss: 6.813294164422466e-15
Epoch 455, Training Loss: 2.511246436086344e-15, Validation Loss: 7.250277614878013e-15
Epoch 456, Training Loss: 2.1785130479217785e-15, Validation Loss: 7.056918627744695e-15
Epoch 457, Training Loss: 2.6779800013139064e-15, Validation Loss: 6.4106672173405016e-15
Epoch 458, Training Loss: 3.3477833745747428e-15, Validation Loss: 5.495000460919606e-15
Epoch 459, Training Loss: 2.4355856415893273e-15, Validation Loss: 6.293573806228541e-15
Epoch 460, Training Loss: 2.809618873954355e-15, Validation Loss: 9.099463194116135e-15
Epoch 461, Training Loss: 2.7728559499776238e-15, Validation Loss: 8.074909081776278e-15
Epoch 462, Training Loss: 2.1777123900283864e-15, Validation Loss: 8.25367792639314e-15
Epoch 463, Training Loss: 2.70079822187999e-15, Validation Loss: 5.9653358336732906e-15
Epoch 464, Training Loss: 2.0279256247347777e-15, Validation Loss: 5.3858047850078444e-15
Epoch 465, Training Loss: 2.395286778574283e-15, Validation Loss: 4.567731894220169e-15
Epoch 466, Training Loss: 3.740031203437527e-15, Validation Loss: 4.304053925871694e-15
Epoch 467, Training Loss: 3.360059846595773e-15, Validation Loss: 4.8088588808974184e-15
Epoch 468, Training Loss: 1.360891308057634e-15, Validation Loss: 9.036045837355206e-15
Epoch 469, Training Loss: 1.2603774022178736e-15, Validation Loss: 4.53498941212758e-15
Epoch 470, Training Loss: 3.082204029017919e-15, Validation Loss: 4.158787351901108e-15
Epoch 471, Training Loss: 3.436154321961784e-15, Validation Loss: 4.653088251347932e-15
Epoch 472, Training Loss: 2.494899970753757e-15, Validation Loss: 4.481392555357117e-15
Epoch 473, Training Loss: 2.4095647894496752e-15, Validation Loss: 4.972118975766528e-15
Epoch 474, Training Loss: 1.6850843806523897e-15, Validation Loss: 4.0359184466382935e-15
Epoch 475, Training Loss: 2.1826829911211114e-15, Validation Loss: 4.837319187925163e-15
Epoch 476, Training Loss: 1.6166963169196168e-15, Validation Loss: 6.376510613742472e-15
Epoch 477, Training Loss: 1.654960289158001e-15, Validation Loss: 6.413582704744951e-15
Epoch 478, Training Loss: 1.5056740144571011e-15, Validation Loss: 4.9232383984463765e-15
Epoch 479, Training Loss: 1.6010838056358255e-15, Validation Loss: 4.778989111045443e-15
Epoch 480, Training Loss: 1.070591941209904e-15, Validation Loss: 4.537061678233038e-15
Epoch 481, Training Loss: 1.2400611052197424e-15, Validation Loss: 7.149780543818079e-15
Epoch 482, Training Loss: 2.1233688737149186e-15, Validation Loss: 7.115795040875394e-15
Epoch 483, Training Loss: 2.7718886383518593e-15, Validation Loss: 6.378620996330556e-15
Epoch 484, Training Loss: 1.9464270791652843e-15, Validation Loss: 7.916186118889137e-15
Epoch 485, Training Loss: 5.778971221101926e-16, Validation Loss: 8.040994729601163e-15
Epoch 486, Training Loss: 1.6573288050367608e-15, Validation Loss: 6.273182335056341e-15
Epoch 487, Training Loss: 1.8902488894880637e-15, Validation Loss: 6.538661518967152e-15
Epoch 488, Training Loss: 2.716544140852974e-15, Validation Loss: 9.461795089831318e-15
Epoch 489, Training Loss: 2.5041406766918278e-15, Validation Loss: 6.496753293352324e-15
Epoch 490, Training Loss: 2.130474633109435e-15, Validation Loss: 6.364780477972421e-15
Epoch 491, Training Loss: 1.7527719481377833e-15, Validation Loss: 4.4350340186374154e-15
Epoch 492, Training Loss: 1.331167439630823e-15, Validation Loss: 5.810136527846727e-15
Epoch 493, Training Loss: 8.97052889767627e-16, Validation Loss: 4.6834996987696765e-15
Epoch 494, Training Loss: 1.791269489711373e-15, Validation Loss: 4.639865220008345e-15
Epoch 495, Training Loss: 1.9083631125815705e-15, Validation Loss: 4.906745819930388e-15
Epoch 496, Training Loss: 2.5141820405232907e-15, Validation Loss: 6.714427631785997e-15
Epoch 497, Training Loss: 2.476818781945193e-15, Validation Loss: 5.91209303667478e-15
Epoch 498, Training Loss: 2.160832293939029e-15, Validation Loss: 5.946787506194316e-15
Epoch 499, Training Loss: 3.121235307227397e-15, Validation Loss: 3.789958713480484e-15
Epoch 500, Training Loss: 2.3455136402859627e-15, Validation Loss: 7.26621199868176e-15
