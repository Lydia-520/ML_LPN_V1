Epoch 1, Training Loss: 0.5251807570457458, Validation Loss: 0.5237392783164978
Epoch 2, Training Loss: 0.5237392783164978, Validation Loss: 0.522314727306366
Epoch 3, Training Loss: 0.5223148465156555, Validation Loss: 0.5209096670150757
Epoch 4, Training Loss: 0.5209096670150757, Validation Loss: 0.5195247530937195
Epoch 5, Training Loss: 0.5195247530937195, Validation Loss: 0.5181418657302856
Epoch 6, Training Loss: 0.5181418657302856, Validation Loss: 0.5167771577835083
Epoch 7, Training Loss: 0.5167771577835083, Validation Loss: 0.5154059529304504
Epoch 8, Training Loss: 0.5154059529304504, Validation Loss: 0.5140354633331299
Epoch 9, Training Loss: 0.5140354633331299, Validation Loss: 0.5126470327377319
Epoch 10, Training Loss: 0.5126470923423767, Validation Loss: 0.5112595558166504
Epoch 11, Training Loss: 0.5112595558166504, Validation Loss: 0.5098506212234497
Epoch 12, Training Loss: 0.5098506212234497, Validation Loss: 0.5084177851676941
Epoch 13, Training Loss: 0.5084177851676941, Validation Loss: 0.5069593191146851
Epoch 14, Training Loss: 0.5069593191146851, Validation Loss: 0.5054818391799927
Epoch 15, Training Loss: 0.5054818391799927, Validation Loss: 0.5039658546447754
Epoch 16, Training Loss: 0.5039658546447754, Validation Loss: 0.5024120211601257
Epoch 17, Training Loss: 0.502411961555481, Validation Loss: 0.5008479356765747
Epoch 18, Training Loss: 0.5008479356765747, Validation Loss: 0.49921897053718567
Epoch 19, Training Loss: 0.49921897053718567, Validation Loss: 0.49751952290534973
Epoch 20, Training Loss: 0.49751952290534973, Validation Loss: 0.49577081203460693
Epoch 21, Training Loss: 0.49577081203460693, Validation Loss: 0.4939503073692322
Epoch 22, Training Loss: 0.4939502775669098, Validation Loss: 0.4920264184474945
Epoch 23, Training Loss: 0.4920264184474945, Validation Loss: 0.4900265336036682
Epoch 24, Training Loss: 0.4900265038013458, Validation Loss: 0.48800837993621826
Epoch 25, Training Loss: 0.48800840973854065, Validation Loss: 0.4858683943748474
Epoch 26, Training Loss: 0.4858683943748474, Validation Loss: 0.48357048630714417
Epoch 27, Training Loss: 0.48357048630714417, Validation Loss: 0.48114684224128723
Epoch 28, Training Loss: 0.48114678263664246, Validation Loss: 0.4785956144332886
Epoch 29, Training Loss: 0.4785956144332886, Validation Loss: 0.47591108083724976
Epoch 30, Training Loss: 0.47591111063957214, Validation Loss: 0.4731316864490509
Epoch 31, Training Loss: 0.4731316864490509, Validation Loss: 0.47022727131843567
Epoch 32, Training Loss: 0.47022727131843567, Validation Loss: 0.4670713245868683
Epoch 33, Training Loss: 0.4670713245868683, Validation Loss: 0.46360546350479126
Epoch 34, Training Loss: 0.46360546350479126, Validation Loss: 0.4598466455936432
Epoch 35, Training Loss: 0.4598466455936432, Validation Loss: 0.4558062255382538
Epoch 36, Training Loss: 0.4558062255382538, Validation Loss: 0.45150649547576904
Epoch 37, Training Loss: 0.4515064060688019, Validation Loss: 0.4468900263309479
Epoch 38, Training Loss: 0.4468900263309479, Validation Loss: 0.44194886088371277
Epoch 39, Training Loss: 0.44194886088371277, Validation Loss: 0.43662935495376587
Epoch 40, Training Loss: 0.43662938475608826, Validation Loss: 0.4308936297893524
Epoch 41, Training Loss: 0.4308936297893524, Validation Loss: 0.42476439476013184
Epoch 42, Training Loss: 0.42476436495780945, Validation Loss: 0.41817718744277954
Epoch 43, Training Loss: 0.41817718744277954, Validation Loss: 0.4110925793647766
Epoch 44, Training Loss: 0.4110925495624542, Validation Loss: 0.403495728969574
Epoch 45, Training Loss: 0.40349575877189636, Validation Loss: 0.3953246474266052
Epoch 46, Training Loss: 0.3953246474266052, Validation Loss: 0.386581152677536
Epoch 47, Training Loss: 0.38658109307289124, Validation Loss: 0.3772292733192444
Epoch 48, Training Loss: 0.3772292733192444, Validation Loss: 0.3672577142715454
Epoch 49, Training Loss: 0.367257684469223, Validation Loss: 0.3566919267177582
Epoch 50, Training Loss: 0.3566918969154358, Validation Loss: 0.34554362297058105
Epoch 51, Training Loss: 0.34554365277290344, Validation Loss: 0.3338167369365692
Epoch 52, Training Loss: 0.3338167667388916, Validation Loss: 0.321556955575943
Epoch 53, Training Loss: 0.3215568959712982, Validation Loss: 0.3088306486606598
Epoch 54, Training Loss: 0.3088306486606598, Validation Loss: 0.2957432270050049
Epoch 55, Training Loss: 0.29574325680732727, Validation Loss: 0.2823905944824219
Epoch 56, Training Loss: 0.2823905944824219, Validation Loss: 0.2689369320869446
Epoch 57, Training Loss: 0.2689369320869446, Validation Loss: 0.25549831986427307
Epoch 58, Training Loss: 0.25549834966659546, Validation Loss: 0.2422468513250351
Epoch 59, Training Loss: 0.2422468513250351, Validation Loss: 0.22949014604091644
Epoch 60, Training Loss: 0.22949014604091644, Validation Loss: 0.2175702452659607
Epoch 61, Training Loss: 0.2175702452659607, Validation Loss: 0.20663203299045563
Epoch 62, Training Loss: 0.20663201808929443, Validation Loss: 0.19688327610492706
Epoch 63, Training Loss: 0.19688330590724945, Validation Loss: 0.18844099342823029
Epoch 64, Training Loss: 0.18844102323055267, Validation Loss: 0.18138164281845093
Epoch 65, Training Loss: 0.18138161301612854, Validation Loss: 0.17553547024726868
Epoch 66, Training Loss: 0.17553547024726868, Validation Loss: 0.1706836074590683
Epoch 67, Training Loss: 0.17068365216255188, Validation Loss: 0.16636106371879578
Epoch 68, Training Loss: 0.16636104881763458, Validation Loss: 0.16208559274673462
Epoch 69, Training Loss: 0.16208559274673462, Validation Loss: 0.1575741469860077
Epoch 70, Training Loss: 0.1575741320848465, Validation Loss: 0.1525096446275711
Epoch 71, Training Loss: 0.1525096595287323, Validation Loss: 0.1468406319618225
Epoch 72, Training Loss: 0.1468406468629837, Validation Loss: 0.14075465500354767
Epoch 73, Training Loss: 0.14075465500354767, Validation Loss: 0.1344645768404007
Epoch 74, Training Loss: 0.1344645619392395, Validation Loss: 0.1281370371580124
Epoch 75, Training Loss: 0.1281370371580124, Validation Loss: 0.12220008671283722
Epoch 76, Training Loss: 0.12220010906457901, Validation Loss: 0.11662397533655167
Epoch 77, Training Loss: 0.11662397533655167, Validation Loss: 0.11150381714105606
Epoch 78, Training Loss: 0.11150382459163666, Validation Loss: 0.10677233338356018
Epoch 79, Training Loss: 0.10677233338356018, Validation Loss: 0.10236560553312302
Epoch 80, Training Loss: 0.10236560553312302, Validation Loss: 0.09824640303850174
Epoch 81, Training Loss: 0.09824640303850174, Validation Loss: 0.09436430037021637
Epoch 82, Training Loss: 0.09436430037021637, Validation Loss: 0.09063529968261719
Epoch 83, Training Loss: 0.09063529968261719, Validation Loss: 0.08693196624517441
Epoch 84, Training Loss: 0.086931973695755, Validation Loss: 0.0831340104341507
Epoch 85, Training Loss: 0.0831340104341507, Validation Loss: 0.07931975275278091
Epoch 86, Training Loss: 0.07931975275278091, Validation Loss: 0.07563330978155136
Epoch 87, Training Loss: 0.07563330233097076, Validation Loss: 0.07203836739063263
Epoch 88, Training Loss: 0.07203836739063263, Validation Loss: 0.06845327466726303
Epoch 89, Training Loss: 0.06845326721668243, Validation Loss: 0.0648273229598999
Epoch 90, Training Loss: 0.0648273155093193, Validation Loss: 0.0611966997385025
Epoch 91, Training Loss: 0.061196696013212204, Validation Loss: 0.05760980024933815
Epoch 92, Training Loss: 0.05760980024933815, Validation Loss: 0.054047778248786926
Epoch 93, Training Loss: 0.054047781974077225, Validation Loss: 0.050506189465522766
Epoch 94, Training Loss: 0.050506189465522766, Validation Loss: 0.04706064611673355
Epoch 95, Training Loss: 0.04706065356731415, Validation Loss: 0.043659936636686325
Epoch 96, Training Loss: 0.043659936636686325, Validation Loss: 0.04029623419046402
Epoch 97, Training Loss: 0.04029623419046402, Validation Loss: 0.036967236548662186
Epoch 98, Training Loss: 0.036967236548662186, Validation Loss: 0.03368566930294037
Epoch 99, Training Loss: 0.03368566930294037, Validation Loss: 0.03060849756002426
Epoch 100, Training Loss: 0.03060849942266941, Validation Loss: 0.027634378522634506
Epoch 101, Training Loss: 0.027634384110569954, Validation Loss: 0.024794207885861397
Epoch 102, Training Loss: 0.024794206023216248, Validation Loss: 0.022134410217404366
Epoch 103, Training Loss: 0.022134410217404366, Validation Loss: 0.019670400768518448
Epoch 104, Training Loss: 0.019670402631163597, Validation Loss: 0.017412889748811722
Epoch 105, Training Loss: 0.017412887886166573, Validation Loss: 0.01536819152534008
Epoch 106, Training Loss: 0.015368194319307804, Validation Loss: 0.013536169193685055
Epoch 107, Training Loss: 0.01353616826236248, Validation Loss: 0.01191037055104971
Epoch 108, Training Loss: 0.011910372413694859, Validation Loss: 0.010500249452888966
Epoch 109, Training Loss: 0.01050025224685669, Validation Loss: 0.00927694234997034
Epoch 110, Training Loss: 0.009276940487325191, Validation Loss: 0.008259238675236702
Epoch 111, Training Loss: 0.008259234949946404, Validation Loss: 0.007377204019576311
Epoch 112, Training Loss: 0.007377204019576311, Validation Loss: 0.006604655645787716
Epoch 113, Training Loss: 0.006604653317481279, Validation Loss: 0.005935213062912226
Epoch 114, Training Loss: 0.005935213062912226, Validation Loss: 0.005316032562404871
Epoch 115, Training Loss: 0.005316031165421009, Validation Loss: 0.004730502609163523
Epoch 116, Training Loss: 0.004730503540486097, Validation Loss: 0.004202815238386393
Epoch 117, Training Loss: 0.004202818963676691, Validation Loss: 0.0036949021741747856
Epoch 118, Training Loss: 0.003694902639836073, Validation Loss: 0.0031902489718049765
Epoch 119, Training Loss: 0.003190248738974333, Validation Loss: 0.0027030296623706818
Epoch 120, Training Loss: 0.00270302826538682, Validation Loss: 0.002253251615911722
Epoch 121, Training Loss: 0.0022532527800649405, Validation Loss: 0.0018548831576481462
Epoch 122, Training Loss: 0.0018548830412328243, Validation Loss: 0.0015140873147174716
Epoch 123, Training Loss: 0.001514085684902966, Validation Loss: 0.0012341758701950312
Epoch 124, Training Loss: 0.0012341768015176058, Validation Loss: 0.0010123664978891611
Epoch 125, Training Loss: 0.001012367312796414, Validation Loss: 0.0008427072898484766
Epoch 126, Training Loss: 0.0008427074062637985, Validation Loss: 0.0007188012241385877
Epoch 127, Training Loss: 0.0007188015151768923, Validation Loss: 0.0006324985297396779
Epoch 128, Training Loss: 0.0006324981222860515, Validation Loss: 0.000569260970223695
Epoch 129, Training Loss: 0.0005692599806934595, Validation Loss: 0.0005205123452469707
Epoch 130, Training Loss: 0.0005205118213780224, Validation Loss: 0.0004794221022166312
Epoch 131, Training Loss: 0.0004794231499545276, Validation Loss: 0.00044063033419661224
Epoch 132, Training Loss: 0.0004406306834425777, Validation Loss: 0.0004004514485131949
Epoch 133, Training Loss: 0.00040045089554041624, Validation Loss: 0.0003577195748221129
Epoch 134, Training Loss: 0.00035771995317190886, Validation Loss: 0.00031298017711378634
Epoch 135, Training Loss: 0.00031298049725592136, Validation Loss: 0.0002680534962564707
Epoch 136, Training Loss: 0.0002680532052181661, Validation Loss: 0.00022513513977173716
Epoch 137, Training Loss: 0.0002251349505968392, Validation Loss: 0.0001863584475358948
Epoch 138, Training Loss: 0.0001863585493993014, Validation Loss: 0.00015334272757172585
Epoch 139, Training Loss: 0.00015334284398704767, Validation Loss: 0.00012727065768558532
Epoch 140, Training Loss: 0.00012727004650514573, Validation Loss: 0.00010759677388705313
Epoch 141, Training Loss: 0.00010759683209471405, Validation Loss: 9.4304108642973e-05
Epoch 142, Training Loss: 9.430412319488823e-05, Validation Loss: 8.612532110419124e-05
Epoch 143, Training Loss: 8.612530655227602e-05, Validation Loss: 8.15356252132915e-05
Epoch 144, Training Loss: 8.153548697009683e-05, Validation Loss: 7.959038339322433e-05
Epoch 145, Training Loss: 7.959039066918194e-05, Validation Loss: 7.893314614193514e-05
Epoch 146, Training Loss: 7.893319707363844e-05, Validation Loss: 7.832852861611173e-05
Epoch 147, Training Loss: 7.832836854504421e-05, Validation Loss: 7.687089964747429e-05
Epoch 148, Training Loss: 7.687074685236439e-05, Validation Loss: 7.410384569084272e-05
Epoch 149, Training Loss: 7.410370017169043e-05, Validation Loss: 6.99460506439209e-05
Epoch 150, Training Loss: 6.994645809754729e-05, Validation Loss: 6.46205953671597e-05
Epoch 151, Training Loss: 6.462030432885513e-05, Validation Loss: 5.851635069120675e-05
Epoch 152, Training Loss: 5.851625246577896e-05, Validation Loss: 5.209425580687821e-05
Epoch 153, Training Loss: 5.209423034102656e-05, Validation Loss: 4.5796776248607785e-05
Epoch 154, Training Loss: 4.579681626637466e-05, Validation Loss: 3.997635212726891e-05
Epoch 155, Training Loss: 3.997612657258287e-05, Validation Loss: 3.4861539461417124e-05
Epoch 156, Training Loss: 3.486167770461179e-05, Validation Loss: 3.056910281884484e-05
Epoch 157, Training Loss: 3.0569022783311084e-05, Validation Loss: 2.710945045691915e-05
Epoch 158, Training Loss: 2.710952321649529e-05, Validation Loss: 2.440105345158372e-05
Epoch 159, Training Loss: 2.44008897425374e-05, Validation Loss: 2.2296735551208258e-05
Epoch 160, Training Loss: 2.229667552455794e-05, Validation Loss: 2.0613717424566858e-05
Epoch 161, Training Loss: 2.06136883207364e-05, Validation Loss: 1.9153489120071754e-05
Epoch 162, Training Loss: 1.9153621906298213e-05, Validation Loss: 1.777251236489974e-05
Epoch 163, Training Loss: 1.7772541468730196e-05, Validation Loss: 1.63848017109558e-05
Epoch 164, Training Loss: 1.6384892660425976e-05, Validation Loss: 1.4954039215808734e-05
Epoch 165, Training Loss: 1.4953962818253785e-05, Validation Loss: 1.3494119230017532e-05
Epoch 166, Training Loss: 1.3494404811353888e-05, Validation Loss: 1.2053752470819745e-05
Epoch 167, Training Loss: 1.2053752470819745e-05, Validation Loss: 1.0693524927773979e-05
Epoch 168, Training Loss: 1.0693425792851485e-05, Validation Loss: 9.468745702179149e-06
Epoch 169, Training Loss: 9.468712960369885e-06, Validation Loss: 8.416176569880918e-06
Epoch 170, Training Loss: 8.41612654767232e-06, Validation Loss: 7.54916800360661e-06
Epoch 171, Training Loss: 7.5490938797884155e-06, Validation Loss: 6.858050710434327e-06
Epoch 172, Training Loss: 6.858028882561484e-06, Validation Loss: 6.314389793260489e-06
Epoch 173, Training Loss: 6.314381153060822e-06, Validation Loss: 5.876887371414341e-06
Epoch 174, Training Loss: 5.876866907783551e-06, Validation Loss: 5.498829978023423e-06
Epoch 175, Training Loss: 5.498801783687668e-06, Validation Loss: 5.135772880748846e-06
Epoch 176, Training Loss: 5.135795163369039e-06, Validation Loss: 4.7524481487926096e-06
Epoch 177, Training Loss: 4.7524722504022066e-06, Validation Loss: 4.328291197452927e-06
Epoch 178, Training Loss: 4.328332579461858e-06, Validation Loss: 3.85935800295556e-06
Epoch 179, Training Loss: 3.859252956317505e-06, Validation Loss: 3.357096147738048e-06
Epoch 180, Training Loss: 3.3571227504580747e-06, Validation Loss: 2.8440438200050266e-06
Epoch 181, Training Loss: 2.844033133442281e-06, Validation Loss: 2.3471977783628972e-06
Epoch 182, Training Loss: 2.3471845906897215e-06, Validation Loss: 1.8930529677163577e-06
Epoch 183, Training Loss: 1.8930743408418493e-06, Validation Loss: 1.5024371577965212e-06
Epoch 184, Training Loss: 1.502420104770863e-06, Validation Loss: 1.188153419207083e-06
Epoch 185, Training Loss: 1.188167289001285e-06, Validation Loss: 9.53911580836575e-07
Epoch 186, Training Loss: 9.539209031572682e-07, Validation Loss: 7.950011990942585e-07
Epoch 187, Training Loss: 7.950135341161513e-07, Validation Loss: 6.996262982283952e-07
Epoch 188, Training Loss: 6.996106094447896e-07, Validation Loss: 6.513553785225668e-07
Epoch 189, Training Loss: 6.513245125461253e-07, Validation Loss: 6.31892248748045e-07
Epoch 190, Training Loss: 6.318955456663389e-07, Validation Loss: 6.241543246687797e-07
Epoch 191, Training Loss: 6.24123174475244e-07, Validation Loss: 6.146400437501143e-07
Epoch 192, Training Loss: 6.146124746919668e-07, Validation Loss: 5.95202436670661e-07
Epoch 193, Training Loss: 5.951866910436365e-07, Validation Loss: 5.631142130368971e-07
Epoch 194, Training Loss: 5.631316639664874e-07, Validation Loss: 5.20271782988857e-07
Epoch 195, Training Loss: 5.202770125833922e-07, Validation Loss: 4.712223642400204e-07
Epoch 196, Training Loss: 4.7125644186962745e-07, Validation Loss: 4.2142889356000524e-07
Epoch 197, Training Loss: 4.214397222312982e-07, Validation Loss: 3.756756541406503e-07
Epoch 198, Training Loss: 3.756718456315866e-07, Validation Loss: 3.372093431153189e-07
Epoch 199, Training Loss: 3.3719589964675833e-07, Validation Loss: 3.0742901913072274e-07
Epoch 200, Training Loss: 3.074421499604796e-07, Validation Loss: 2.860702750240307e-07
Epoch 201, Training Loss: 2.8606740443137824e-07, Validation Loss: 2.7147461878485046e-07
Epoch 202, Training Loss: 2.7145458147970203e-07, Validation Loss: 2.6112215323337296e-07
Epoch 203, Training Loss: 2.6111820261576213e-07, Validation Loss: 2.5232426992261026e-07
Epoch 204, Training Loss: 2.52326628924493e-07, Validation Loss: 2.426081664452795e-07
Epoch 205, Training Loss: 2.4258690700662555e-07, Validation Loss: 2.301983954566822e-07
Epoch 206, Training Loss: 2.3017778971734515e-07, Validation Loss: 2.1436311214984016e-07
Epoch 207, Training Loss: 2.1435428720906202e-07, Validation Loss: 1.9525295158473455e-07
Epoch 208, Training Loss: 1.9522875049915456e-07, Validation Loss: 1.7375896277371794e-07
Epoch 209, Training Loss: 1.7375739957969927e-07, Validation Loss: 1.5129374730804557e-07
Epoch 210, Training Loss: 1.5128934194308385e-07, Validation Loss: 1.29255468550582e-07
Epoch 211, Training Loss: 1.2926024339776632e-07, Validation Loss: 1.0896160773654628e-07
Epoch 212, Training Loss: 1.0895885083073154e-07, Validation Loss: 9.134792833265237e-08
Epoch 213, Training Loss: 9.134265610555303e-08, Validation Loss: 7.700879223193624e-08
Epoch 214, Training Loss: 7.700364790252934e-08, Validation Loss: 6.610786584815287e-08
Epoch 215, Training Loss: 6.610736846823784e-08, Validation Loss: 5.842392170052335e-08
Epoch 216, Training Loss: 5.8426607552064524e-08, Validation Loss: 5.341902564737211e-08
Epoch 217, Training Loss: 5.34190611745089e-08, Validation Loss: 5.033155403566525e-08
Epoch 218, Training Loss: 5.0332864987012726e-08, Validation Loss: 4.834114974983095e-08
Epoch 219, Training Loss: 4.8341306069232814e-08, Validation Loss: 4.669880127039505e-08
Epoch 220, Training Loss: 4.6694886179921014e-08, Validation Loss: 4.482089011048629e-08
Epoch 221, Training Loss: 4.4821764078051274e-08, Validation Loss: 4.236236605947852e-08
Epoch 222, Training Loss: 4.2356184337677405e-08, Validation Loss: 3.916410662441194e-08
Epoch 223, Training Loss: 3.9171123233927574e-08, Validation Loss: 3.53033122735269e-08
Epoch 224, Training Loss: 3.5298558742624664e-08, Validation Loss: 3.094186595831161e-08
Epoch 225, Training Loss: 3.0938466011321e-08, Validation Loss: 2.635839990716704e-08
Epoch 226, Training Loss: 2.6360604366004736e-08, Validation Loss: 2.1869084321224364e-08
Epoch 227, Training Loss: 2.186230751988205e-08, Validation Loss: 1.7758951642576903e-08
Epoch 228, Training Loss: 1.7755681369635568e-08, Validation Loss: 1.4281690496886768e-08
Epoch 229, Training Loss: 1.428224472022066e-08, Validation Loss: 1.1551398948483893e-08
Epoch 230, Training Loss: 1.1550274514604553e-08, Validation Loss: 9.58854151633659e-09
Epoch 231, Training Loss: 9.587318494652664e-09, Validation Loss: 8.286336061757993e-09
Epoch 232, Training Loss: 8.295003794955846e-09, Validation Loss: 7.496116616323434e-09
Epoch 233, Training Loss: 7.49707584901671e-09, Validation Loss: 7.0059198442606885e-09
Epoch 234, Training Loss: 7.0029817500483205e-09, Validation Loss: 6.637228544548179e-09
Epoch 235, Training Loss: 6.63636789965949e-09, Validation Loss: 6.263448870669208e-09
Epoch 236, Training Loss: 6.2650324927915335e-09, Validation Loss: 5.814775327905863e-09
Epoch 237, Training Loss: 5.815658621344255e-09, Validation Loss: 5.274929382181881e-09
Epoch 238, Training Loss: 5.274156666956742e-09, Validation Loss: 4.682718213189219e-09
Epoch 239, Training Loss: 4.68215066717903e-09, Validation Loss: 4.092740368832892e-09
Epoch 240, Training Loss: 4.0944221346705945e-09, Validation Loss: 3.5748342064323424e-09
Epoch 241, Training Loss: 3.577694140943777e-09, Validation Loss: 3.177618390637349e-09
Epoch 242, Training Loss: 3.1767066754895268e-09, Validation Loss: 2.922065922561501e-09
Epoch 243, Training Loss: 2.921725528182151e-09, Validation Loss: 2.797046594338326e-09
Epoch 244, Training Loss: 2.797354348160752e-09, Validation Loss: 2.769540152769423e-09
Epoch 245, Training Loss: 2.7699911253620257e-09, Validation Loss: 2.7870936669671664e-09
Epoch 246, Training Loss: 2.7855331374837533e-09, Validation Loss: 2.799759313276695e-09
Epoch 247, Training Loss: 2.7991802209470507e-09, Validation Loss: 2.769019014081664e-09
Epoch 248, Training Loss: 2.769207974040455e-09, Validation Loss: 2.6755422322111144e-09
Epoch 249, Training Loss: 2.6764186422667535e-09, Validation Loss: 2.517790420597521e-09
Epoch 250, Training Loss: 2.5189319519114406e-09, Validation Loss: 2.3052220132768753e-09
Epoch 251, Training Loss: 2.3057784570568174e-09, Validation Loss: 2.0587489490964117e-09
Epoch 252, Training Loss: 2.057805925659295e-09, Validation Loss: 1.80081582978886e-09
Epoch 253, Training Loss: 1.8012824565261099e-09, Validation Loss: 1.556813677972002e-09
Epoch 254, Training Loss: 1.5582239942801834e-09, Validation Loss: 1.3402857712563332e-09
Epoch 255, Training Loss: 1.3398465670277915e-09, Validation Loss: 1.159436879838438e-09
Epoch 256, Training Loss: 1.1581789971515377e-09, Validation Loss: 1.0147296336526779e-09
Epoch 257, Training Loss: 1.0141606443525575e-09, Validation Loss: 8.982410371061178e-10
Epoch 258, Training Loss: 8.989524680202976e-10, Validation Loss: 8.046605604050683e-10
Epoch 259, Training Loss: 8.042577714917343e-10, Validation Loss: 7.214859265580742e-10
Epoch 260, Training Loss: 7.217691999628073e-10, Validation Loss: 6.452288703329145e-10
Epoch 261, Training Loss: 6.446393974179898e-10, Validation Loss: 5.70598346349982e-10
Epoch 262, Training Loss: 5.702324723522167e-10, Validation Loss: 4.996827951408989e-10
Epoch 263, Training Loss: 4.999377023473528e-10, Validation Loss: 4.3163819740676956e-10
Epoch 264, Training Loss: 4.3220252377018653e-10, Validation Loss: 3.706774054368367e-10
Epoch 265, Training Loss: 3.701221273910704e-10, Validation Loss: 3.1718774828881635e-10
Epoch 266, Training Loss: 3.1667912736565995e-10, Validation Loss: 2.71848765720506e-10
Epoch 267, Training Loss: 2.7146815351208886e-10, Validation Loss: 2.352229244717563e-10
Epoch 268, Training Loss: 2.3478063937432125e-10, Validation Loss: 2.0680125667471572e-10
Epoch 269, Training Loss: 2.0687219992598926e-10, Validation Loss: 1.8503505672118337e-10
Epoch 270, Training Loss: 1.8510612487254718e-10, Validation Loss: 1.6819393100497848e-10
Epoch 271, Training Loss: 1.681890043903067e-10, Validation Loss: 1.5457959912090757e-10
Epoch 272, Training Loss: 1.5469342473650727e-10, Validation Loss: 1.424151907514215e-10
Epoch 273, Training Loss: 1.424800138982718e-10, Validation Loss: 1.3134056342511968e-10
Epoch 274, Training Loss: 1.3124383524409922e-10, Validation Loss: 1.1958431467284925e-10
Epoch 275, Training Loss: 1.1970396895932822e-10, Validation Loss: 1.0758047230829959e-10
Epoch 276, Training Loss: 1.0775970393783751e-10, Validation Loss: 9.58411822127303e-11
Epoch 277, Training Loss: 9.592877187047932e-11, Validation Loss: 8.377238486234617e-11
Epoch 278, Training Loss: 8.407063240012391e-11, Validation Loss: 7.224653514326107e-11
Epoch 279, Training Loss: 7.223084630414434e-11, Validation Loss: 6.150872866594881e-11
Epoch 280, Training Loss: 6.14953851729716e-11, Validation Loss: 5.28025713431024e-11
Epoch 281, Training Loss: 5.2488281082618826e-11, Validation Loss: 4.5965693057370416e-11
Epoch 282, Training Loss: 4.596970026859992e-11, Validation Loss: 4.151796267892749e-11
Epoch 283, Training Loss: 4.1600001221553384e-11, Validation Loss: 3.957172436952483e-11
Epoch 284, Training Loss: 3.954796559679785e-11, Validation Loss: 3.902050210724539e-11
Epoch 285, Training Loss: 3.912606350020553e-11, Validation Loss: 3.9688304726004375e-11
Epoch 286, Training Loss: 3.9630070058915834e-11, Validation Loss: 4.0564718251090426e-11
Epoch 287, Training Loss: 4.026193267669953e-11, Validation Loss: 4.060022110174977e-11
Epoch 288, Training Loss: 4.047187585065615e-11, Validation Loss: 4.0006477297627185e-11
Epoch 289, Training Loss: 3.995137554113626e-11, Validation Loss: 3.8363739268687524e-11
Epoch 290, Training Loss: 3.8131626328707924e-11, Validation Loss: 3.594611067136988e-11
Epoch 291, Training Loss: 3.5855107077820136e-11, Validation Loss: 3.248171176473136e-11
Epoch 292, Training Loss: 3.258487923929465e-11, Validation Loss: 2.872550114441097e-11
Epoch 293, Training Loss: 2.8807303764644132e-11, Validation Loss: 2.489605917255222e-11
Epoch 294, Training Loss: 2.4875450657657616e-11, Validation Loss: 2.1446140002767677e-11
Epoch 295, Training Loss: 2.149356387315393e-11, Validation Loss: 1.8367191448320774e-11
Epoch 296, Training Loss: 1.861911493039603e-11, Validation Loss: 1.6186352605473964e-11
Epoch 297, Training Loss: 1.6175704872778418e-11, Validation Loss: 1.4347813735715587e-11
Epoch 298, Training Loss: 1.4314962409889276e-11, Validation Loss: 1.2877562731439252e-11
Epoch 299, Training Loss: 1.2963585933889465e-11, Validation Loss: 1.1904310003030272e-11
Epoch 300, Training Loss: 1.1758675630413329e-11, Validation Loss: 1.0667276957587735e-11
Epoch 301, Training Loss: 1.0606765465936974e-11, Validation Loss: 9.589022284539617e-12
Epoch 302, Training Loss: 9.609577023006466e-12, Validation Loss: 8.529841763471602e-12
Epoch 303, Training Loss: 8.423774698618214e-12, Validation Loss: 7.053761654635116e-12
Epoch 304, Training Loss: 7.138613485058176e-12, Validation Loss: 5.981536880389493e-12
Epoch 305, Training Loss: 5.926800283190259e-12, Validation Loss: 4.873954104894773e-12
Epoch 306, Training Loss: 4.776015086888075e-12, Validation Loss: 3.772686590214347e-12
Epoch 307, Training Loss: 3.778530439924044e-12, Validation Loss: 2.8671294938914516e-12
Epoch 308, Training Loss: 2.8665951990608507e-12, Validation Loss: 2.2243476591882194e-12
Epoch 309, Training Loss: 2.220849155618043e-12, Validation Loss: 1.7257352231264678e-12
Epoch 310, Training Loss: 1.7043464079283255e-12, Validation Loss: 1.3319764128466582e-12
Epoch 311, Training Loss: 1.366531128706161e-12, Validation Loss: 1.166796151884364e-12
Epoch 312, Training Loss: 1.1794529112055252e-12, Validation Loss: 1.0324104852271754e-12
Epoch 313, Training Loss: 1.0683466914948592e-12, Validation Loss: 1.0060912606496553e-12
Epoch 314, Training Loss: 1.0186027368797035e-12, Validation Loss: 1.0365751226121267e-12
Epoch 315, Training Loss: 1.002666916508077e-12, Validation Loss: 1.0591838820947497e-12
Epoch 316, Training Loss: 1.0307564263928315e-12, Validation Loss: 1.1003874677770198e-12
Epoch 317, Training Loss: 1.0830807821785027e-12, Validation Loss: 1.083639688398419e-12
Epoch 318, Training Loss: 1.076772893938982e-12, Validation Loss: 1.0822248045633254e-12
Epoch 319, Training Loss: 1.0182834393399065e-12, Validation Loss: 1.0669160867282645e-12
Epoch 320, Training Loss: 1.044710542033589e-12, Validation Loss: 1.028934641482404e-12
Epoch 321, Training Loss: 1.0569469561724776e-12, Validation Loss: 1.0259830094880296e-12
Epoch 322, Training Loss: 1.0312660014138997e-12, Validation Loss: 9.490731768188598e-13
Epoch 323, Training Loss: 9.513478329767344e-13, Validation Loss: 9.196058628133108e-13
Epoch 324, Training Loss: 8.955030727370028e-13, Validation Loss: 8.401233268090502e-13
Epoch 325, Training Loss: 8.678345585558245e-13, Validation Loss: 7.944142305787993e-13
Epoch 326, Training Loss: 8.046009605106041e-13, Validation Loss: 7.547464714839636e-13
Epoch 327, Training Loss: 7.39214516421588e-13, Validation Loss: 7.096062019235072e-13
Epoch 328, Training Loss: 7.106073542095803e-13, Validation Loss: 6.408462627748024e-13
Epoch 329, Training Loss: 6.53276315421697e-13, Validation Loss: 5.971755208389329e-13
Epoch 330, Training Loss: 5.862984793839066e-13, Validation Loss: 5.588342288920245e-13
Epoch 331, Training Loss: 5.664831667986925e-13, Validation Loss: 5.236060066429737e-13
Epoch 332, Training Loss: 5.089153382563383e-13, Validation Loss: 4.855037270649898e-13
Epoch 333, Training Loss: 4.738831939701815e-13, Validation Loss: 4.357499333151188e-13
Epoch 334, Training Loss: 4.173972907757506e-13, Validation Loss: 3.6746541681904887e-13
Epoch 335, Training Loss: 3.7651273158273435e-13, Validation Loss: 3.104079222392836e-13
Epoch 336, Training Loss: 3.199950883697039e-13, Validation Loss: 2.7556253177733747e-13
Epoch 337, Training Loss: 2.7042514820323216e-13, Validation Loss: 2.4330781530149115e-13
Epoch 338, Training Loss: 2.430379302757052e-13, Validation Loss: 2.203426108021364e-13
Epoch 339, Training Loss: 2.0841028826757563e-13, Validation Loss: 1.6277929525132517e-13
Epoch 340, Training Loss: 1.7916451742344686e-13, Validation Loss: 1.3330229118885956e-13
Epoch 341, Training Loss: 1.4282489307990837e-13, Validation Loss: 1.0287867698586042e-13
Epoch 342, Training Loss: 1.0628190629012949e-13, Validation Loss: 8.169997339248225e-14
Epoch 343, Training Loss: 8.362094924916491e-14, Validation Loss: 7.651386848325087e-14
Epoch 344, Training Loss: 6.667350048797371e-14, Validation Loss: 5.614501986700611e-14
Epoch 345, Training Loss: 6.111268853166776e-14, Validation Loss: 4.6726789375717975e-14
Epoch 346, Training Loss: 4.483485658473077e-14, Validation Loss: 3.653494675304354e-14
Epoch 347, Training Loss: 4.171135144096297e-14, Validation Loss: 3.1444051735215334e-14
Epoch 348, Training Loss: 2.7598925342363703e-14, Validation Loss: 2.6790628905853237e-14
Epoch 349, Training Loss: 2.7565265947105712e-14, Validation Loss: 2.7166479447406598e-14
Epoch 350, Training Loss: 2.1037684466121594e-14, Validation Loss: 2.7274808185096845e-14
Epoch 351, Training Loss: 1.9272728690191386e-14, Validation Loss: 2.4965862439451508e-14
Epoch 352, Training Loss: 2.0897822385870964e-14, Validation Loss: 2.0610137809731408e-14
Epoch 353, Training Loss: 1.675100826819577e-14, Validation Loss: 1.6854420826660152e-14
Epoch 354, Training Loss: 1.648743024973507e-14, Validation Loss: 1.8380316799820884e-14
Epoch 355, Training Loss: 1.64286834326453e-14, Validation Loss: 1.680596884801131e-14
Epoch 356, Training Loss: 1.3304346502523295e-14, Validation Loss: 1.3381270646661142e-14
Epoch 357, Training Loss: 1.2624351840599332e-14, Validation Loss: 1.0627425927668167e-14
Epoch 358, Training Loss: 1.2440220430393403e-14, Validation Loss: 1.546160897610612e-14
Epoch 359, Training Loss: 1.0503117913427968e-14, Validation Loss: 1.3615602311519044e-14
Epoch 360, Training Loss: 9.845841522182312e-15, Validation Loss: 1.2960243602865972e-14
Epoch 361, Training Loss: 8.038468030319504e-15, Validation Loss: 9.629382252511476e-15
Epoch 362, Training Loss: 7.198286732575544e-15, Validation Loss: 8.106537292026754e-15
Epoch 363, Training Loss: 6.329615058134211e-15, Validation Loss: 6.386358642303724e-15
Epoch 364, Training Loss: 5.72907547479449e-15, Validation Loss: 4.86949754607488e-15
Epoch 365, Training Loss: 4.815569075905567e-15, Validation Loss: 7.242309575943191e-15
Epoch 366, Training Loss: 5.650354350259044e-15, Validation Loss: 5.064758545691257e-15
Epoch 367, Training Loss: 6.646085625469731e-15, Validation Loss: 6.361530412553806e-15
Epoch 368, Training Loss: 5.201636952385184e-15, Validation Loss: 7.851908176653797e-15
Epoch 369, Training Loss: 5.109429792780028e-15, Validation Loss: 3.128954953750436e-15
Epoch 370, Training Loss: 5.897535504926794e-15, Validation Loss: 3.7307705922251955e-15
Epoch 371, Training Loss: 6.592642928695668e-15, Validation Loss: 3.76704350764194e-15
Epoch 372, Training Loss: 6.593434904501351e-15, Validation Loss: 3.734902842458376e-15
Epoch 373, Training Loss: 6.424791491735967e-15, Validation Loss: 5.086341792220244e-15
Epoch 374, Training Loss: 5.581715882411239e-15, Validation Loss: 3.890350328938485e-15
Epoch 375, Training Loss: 4.4480579972343975e-15, Validation Loss: 4.910668429509123e-15
Epoch 376, Training Loss: 3.8043421799578096e-15, Validation Loss: 6.812952810144723e-15
Epoch 377, Training Loss: 3.212717830146177e-15, Validation Loss: 4.144614796627649e-15
Epoch 378, Training Loss: 3.3181607265851286e-15, Validation Loss: 3.646932541655386e-15
Epoch 379, Training Loss: 4.168684084856827e-15, Validation Loss: 4.79151164613765e-15
Epoch 380, Training Loss: 2.359208892493644e-15, Validation Loss: 4.893236914971103e-15
Epoch 381, Training Loss: 3.347509359416306e-15, Validation Loss: 4.294757739275578e-15
Epoch 382, Training Loss: 3.1094350794809607e-15, Validation Loss: 4.275842646530442e-15
Epoch 383, Training Loss: 2.7400473993151493e-15, Validation Loss: 3.63734794034073e-15
Epoch 384, Training Loss: 3.6871729593970694e-15, Validation Loss: 3.671508355587022e-15
Epoch 385, Training Loss: 3.861729509167236e-15, Validation Loss: 4.103988555378491e-15
Epoch 386, Training Loss: 3.714778610181034e-15, Validation Loss: 4.650359534708352e-15
Epoch 387, Training Loss: 2.79300644027633e-15, Validation Loss: 3.786379575761861e-15
Epoch 388, Training Loss: 2.319560550782091e-15, Validation Loss: 7.671030219998272e-15
Epoch 389, Training Loss: 3.523466901681231e-15, Validation Loss: 8.1874103037647e-15
Epoch 390, Training Loss: 2.4754520942847982e-15, Validation Loss: 6.47960849946695e-15
Epoch 391, Training Loss: 2.816808913127123e-15, Validation Loss: 5.202689390822147e-15
Epoch 392, Training Loss: 3.0204555389213173e-15, Validation Loss: 6.5599936202272776e-15
Epoch 393, Training Loss: 2.4875284547720396e-15, Validation Loss: 7.042476292477536e-15
Epoch 394, Training Loss: 2.626264616477532e-15, Validation Loss: 6.852824345037877e-15
Epoch 395, Training Loss: 1.728811927158801e-15, Validation Loss: 4.8916355991843186e-15
Epoch 396, Training Loss: 2.1226275081278343e-15, Validation Loss: 3.6457776122318045e-15
Epoch 397, Training Loss: 2.1815666016966303e-15, Validation Loss: 3.5169242074384018e-15
Epoch 398, Training Loss: 1.8519689295028e-15, Validation Loss: 3.518575498169074e-15
Epoch 399, Training Loss: 2.567492388399345e-15, Validation Loss: 4.15441835595917e-15
Epoch 400, Training Loss: 2.3833448845674184e-15, Validation Loss: 4.192953272861557e-15
Epoch 401, Training Loss: 2.312079555791941e-15, Validation Loss: 2.7871602188743808e-15
Epoch 402, Training Loss: 2.8450648734563424e-15, Validation Loss: 2.297334406246138e-15
Epoch 403, Training Loss: 3.2448436722531645e-15, Validation Loss: 3.4617340816941533e-15
Epoch 404, Training Loss: 1.5386678535767874e-15, Validation Loss: 3.499835529485783e-15
Epoch 405, Training Loss: 2.3906090391230712e-15, Validation Loss: 3.1520651889250855e-15
Epoch 406, Training Loss: 1.836031157567263e-15, Validation Loss: 2.9545567991414064e-15
Epoch 407, Training Loss: 2.5784930170435734e-15, Validation Loss: 6.001781543811275e-15
Epoch 408, Training Loss: 3.1216198601854506e-15, Validation Loss: 4.903051062214465e-15
Epoch 409, Training Loss: 3.114147335524773e-15, Validation Loss: 4.810210321964763e-15
Epoch 410, Training Loss: 2.6716926875046745e-15, Validation Loss: 2.3819978904230472e-15
Epoch 411, Training Loss: 2.855840191336601e-15, Validation Loss: 2.168334888269334e-15
Epoch 412, Training Loss: 1.3378568823317638e-15, Validation Loss: 1.8322428027106683e-15
Epoch 413, Training Loss: 1.9631663560271606e-15, Validation Loss: 3.059059277250669e-15
Epoch 414, Training Loss: 1.5975066796204522e-15, Validation Loss: 3.6940347733027765e-15
Epoch 415, Training Loss: 3.317318352319084e-15, Validation Loss: 1.96334783283611e-15
Epoch 416, Training Loss: 2.5785929669313494e-15, Validation Loss: 2.3934925510337617e-15
Epoch 417, Training Loss: 2.111551917067774e-15, Validation Loss: 2.3120939553520443e-15
Epoch 418, Training Loss: 1.692799686131574e-15, Validation Loss: 3.5636471800836594e-15
Epoch 419, Training Loss: 1.8611929065401626e-15, Validation Loss: 3.15683779606639e-15
Epoch 420, Training Loss: 2.345848218300128e-15, Validation Loss: 2.9650172325235234e-15
Epoch 421, Training Loss: 2.227069635139605e-15, Validation Loss: 4.158707307287592e-15
Epoch 422, Training Loss: 2.241981650176017e-15, Validation Loss: 3.893444540294805e-15
Epoch 423, Training Loss: 2.604939079722747e-15, Validation Loss: 6.995596830495273e-15
Epoch 424, Training Loss: 2.066907775033315e-15, Validation Loss: 7.36022249143162e-15
Epoch 425, Training Loss: 2.3076593143566944e-15, Validation Loss: 7.866378040491742e-15
Epoch 426, Training Loss: 1.6548359870729914e-15, Validation Loss: 8.534638754997392e-15
Epoch 427, Training Loss: 8.889221146278145e-16, Validation Loss: 7.0753856400607336e-15
Epoch 428, Training Loss: 1.5723865411410866e-15, Validation Loss: 6.971302231502125e-15
Epoch 429, Training Loss: 1.2745478399089644e-15, Validation Loss: 6.47557196395681e-15
Epoch 430, Training Loss: 1.2745478399089644e-15, Validation Loss: 6.81918061988941e-15
Epoch 431, Training Loss: 5.112695104791693e-16, Validation Loss: 7.052968066078701e-15
Epoch 432, Training Loss: 1.4987274972566686e-15, Validation Loss: 7.018673819626743e-15
Epoch 433, Training Loss: 1.3973128777566217e-15, Validation Loss: 6.012751043994692e-15
Epoch 434, Training Loss: 5.326199288267796e-16, Validation Loss: 6.012751043994692e-15
Epoch 435, Training Loss: 8.598154685217558e-16, Validation Loss: 5.769889757357939e-15
Epoch 436, Training Loss: 2.533156637332971e-15, Validation Loss: 5.748539021372973e-15
Epoch 437, Training Loss: 2.5184614627310562e-15, Validation Loss: 4.8925614061956675e-15
Epoch 438, Training Loss: 2.2088800261137924e-15, Validation Loss: 3.942667318925647e-15
Epoch 439, Training Loss: 9.633067481106742e-16, Validation Loss: 3.4620407076210594e-15
Epoch 440, Training Loss: 2.5058764589589886e-15, Validation Loss: 3.119165793979018e-15
Epoch 441, Training Loss: 2.6686736503224234e-15, Validation Loss: 2.9913300992717414e-15
Epoch 442, Training Loss: 2.046900221544458e-15, Validation Loss: 2.963541065854696e-15
Epoch 443, Training Loss: 1.9881864387396317e-15, Validation Loss: 2.9507642091200752e-15
Epoch 444, Training Loss: 1.583061803254451e-15, Validation Loss: 2.6697390060118325e-15
Epoch 445, Training Loss: 2.9441526934502818e-15, Validation Loss: 2.575138131297736e-15
Epoch 446, Training Loss: 2.5515880742652246e-15, Validation Loss: 2.3538941842660968e-15
Epoch 447, Training Loss: 1.5024722299164799e-15, Validation Loss: 2.369479590495576e-15
Epoch 448, Training Loss: 1.0386338116264728e-15, Validation Loss: 2.1880008757222107e-15
Epoch 449, Training Loss: 2.2315900382208643e-15, Validation Loss: 3.2964891768713905e-15
Epoch 450, Training Loss: 2.673406711613003e-16, Validation Loss: 3.9457924469845414e-15
Epoch 451, Training Loss: 2.497928325298428e-15, Validation Loss: 4.516134882238173e-15
Epoch 452, Training Loss: 9.876345931470018e-16, Validation Loss: 4.257260861250051e-15
Epoch 453, Training Loss: 8.189660870305555e-16, Validation Loss: 3.489979665869769e-15
Epoch 454, Training Loss: 1.4842658919899591e-15, Validation Loss: 3.3085009510964037e-15
Epoch 455, Training Loss: 1.3188000174470813e-15, Validation Loss: 3.568509149200899e-15
Epoch 456, Training Loss: 1.1006251884206997e-15, Validation Loss: 3.5386270973711883e-15
Epoch 457, Training Loss: 1.319967546485753e-15, Validation Loss: 4.034590722493472e-15
Epoch 458, Training Loss: 1.306757008882138e-15, Validation Loss: 3.9253031435069335e-15
Epoch 459, Training Loss: 1.472756725940023e-15, Validation Loss: 3.2164019999502596e-15
Epoch 460, Training Loss: 1.826923859318385e-15, Validation Loss: 3.0706185241236115e-15
Epoch 461, Training Loss: 1.8184253660003457e-15, Validation Loss: 3.4118921219788685e-15
Epoch 462, Training Loss: 6.826151701045313e-16, Validation Loss: 2.5950374763275812e-15
Epoch 463, Training Loss: 2.577967644858039e-15, Validation Loss: 4.8161501405073835e-15
Epoch 464, Training Loss: 9.353593195324922e-16, Validation Loss: 3.925837197780177e-15
Epoch 465, Training Loss: 1.9356276208460288e-15, Validation Loss: 5.06661778301048e-15
Epoch 466, Training Loss: 2.4691387342124383e-15, Validation Loss: 4.84377230843382e-15
Epoch 467, Training Loss: 2.5510794309803984e-15, Validation Loss: 4.840569676860251e-15
Epoch 468, Training Loss: 2.745902091046571e-15, Validation Loss: 4.090635927997974e-15
Epoch 469, Training Loss: 2.543606694561484e-15, Validation Loss: 3.62626366719296e-15
Epoch 470, Training Loss: 1.9519323698059636e-15, Validation Loss: 3.817984069089814e-15
Epoch 471, Training Loss: 1.7544408148021111e-15, Validation Loss: 3.545340680511126e-15
Epoch 472, Training Loss: 2.1942267796427667e-15, Validation Loss: 3.5373343133354414e-15
Epoch 473, Training Loss: 2.3906507554957235e-15, Validation Loss: 3.955635816864584e-15
Epoch 474, Training Loss: 3.1128295640170823e-15, Validation Loss: 2.4002230748326444e-15
Epoch 475, Training Loss: 2.2411560048106807e-15, Validation Loss: 2.3141539394797668e-15
Epoch 476, Training Loss: 2.216828159774353e-15, Validation Loss: 3.826966006462498e-15
Epoch 477, Training Loss: 1.110608106978802e-15, Validation Loss: 3.9777120365688725e-15
Epoch 478, Training Loss: 4.327315568185665e-16, Validation Loss: 4.5443156683933235e-15
Epoch 479, Training Loss: 1.9711060193582488e-15, Validation Loss: 4.961450172279386e-15
Epoch 480, Training Loss: 1.4320073472761578e-15, Validation Loss: 4.5851485856816115e-15
Epoch 481, Training Loss: 2.1323018949348993e-15, Validation Loss: 5.0805455457621825e-15
Epoch 482, Training Loss: 2.1856780996226026e-15, Validation Loss: 3.192533035013107e-15
Epoch 483, Training Loss: 2.20435983479077e-15, Validation Loss: 3.199872151984592e-15
Epoch 484, Training Loss: 1.3983804569075173e-15, Validation Loss: 3.2137499397924063e-15
Epoch 485, Training Loss: 2.381034813962019e-15, Validation Loss: 3.5470504165151587e-15
Epoch 486, Training Loss: 1.4442839251763064e-15, Validation Loss: 2.898939345275268e-15
Epoch 487, Training Loss: 1.0436794810141483e-15, Validation Loss: 3.137855787718421e-15
Epoch 488, Training Loss: 9.812294358789832e-16, Validation Loss: 2.749694681067902e-15
Epoch 489, Training Loss: 1.8219198004242433e-15, Validation Loss: 1.7939619956924575e-15
Epoch 490, Training Loss: 1.7098300246899505e-15, Validation Loss: 1.6965339367586629e-15
Epoch 491, Training Loss: 2.8917774699479962e-15, Validation Loss: 1.7334635144677663e-15
Epoch 492, Training Loss: 1.6160882531426066e-15, Validation Loss: 1.899580016193254e-15
Epoch 493, Training Loss: 3.5194803411149785e-15, Validation Loss: 2.4743740331011803e-15
Epoch 494, Training Loss: 1.8843116120442847e-15, Validation Loss: 2.6772200010019825e-15
Epoch 495, Training Loss: 7.04449297204583e-16, Validation Loss: 2.7719792708772156e-15
Epoch 496, Training Loss: 3.330020246637873e-15, Validation Loss: 2.9324411924050702e-15
Epoch 497, Training Loss: 1.3509507411468944e-15, Validation Loss: 2.363318484595485e-15
Epoch 498, Training Loss: 6.957590038635499e-16, Validation Loss: 2.4511388605668108e-15
Epoch 499, Training Loss: 9.829224429823077e-16, Validation Loss: 2.2846721107176336e-15
Epoch 500, Training Loss: 1.0196352861360325e-15, Validation Loss: 2.2461077594203294e-15
