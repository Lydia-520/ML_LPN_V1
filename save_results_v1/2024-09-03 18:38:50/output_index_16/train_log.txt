Epoch 1, Training Loss: 0.5219747424125671, Validation Loss: 0.5202643275260925
Epoch 2, Training Loss: 0.5202643275260925, Validation Loss: 0.5185457468032837
Epoch 3, Training Loss: 0.5185457468032837, Validation Loss: 0.5168417096138
Epoch 4, Training Loss: 0.5168417096138, Validation Loss: 0.515204131603241
Epoch 5, Training Loss: 0.515204131603241, Validation Loss: 0.5136163830757141
Epoch 6, Training Loss: 0.5136163830757141, Validation Loss: 0.5120709538459778
Epoch 7, Training Loss: 0.5120709538459778, Validation Loss: 0.51057368516922
Epoch 8, Training Loss: 0.5105736255645752, Validation Loss: 0.5091133713722229
Epoch 9, Training Loss: 0.5091134309768677, Validation Loss: 0.5076848268508911
Epoch 10, Training Loss: 0.5076848268508911, Validation Loss: 0.5062592625617981
Epoch 11, Training Loss: 0.5062592625617981, Validation Loss: 0.5048801302909851
Epoch 12, Training Loss: 0.5048801302909851, Validation Loss: 0.5035062432289124
Epoch 13, Training Loss: 0.5035062432289124, Validation Loss: 0.5021184682846069
Epoch 14, Training Loss: 0.5021184682846069, Validation Loss: 0.5006990432739258
Epoch 15, Training Loss: 0.5006990432739258, Validation Loss: 0.49926644563674927
Epoch 16, Training Loss: 0.49926650524139404, Validation Loss: 0.4978185296058655
Epoch 17, Training Loss: 0.4978185296058655, Validation Loss: 0.4963565766811371
Epoch 18, Training Loss: 0.4963565766811371, Validation Loss: 0.49489739537239075
Epoch 19, Training Loss: 0.49489733576774597, Validation Loss: 0.49343520402908325
Epoch 20, Training Loss: 0.49343520402908325, Validation Loss: 0.4919300377368927
Epoch 21, Training Loss: 0.4919300973415375, Validation Loss: 0.4904046356678009
Epoch 22, Training Loss: 0.4904046356678009, Validation Loss: 0.4888627231121063
Epoch 23, Training Loss: 0.4888627231121063, Validation Loss: 0.487324595451355
Epoch 24, Training Loss: 0.487324595451355, Validation Loss: 0.4857243299484253
Epoch 25, Training Loss: 0.4857243299484253, Validation Loss: 0.48414361476898193
Epoch 26, Training Loss: 0.48414361476898193, Validation Loss: 0.4825032949447632
Epoch 27, Training Loss: 0.4825032353401184, Validation Loss: 0.48080945014953613
Epoch 28, Training Loss: 0.48080942034721375, Validation Loss: 0.4790462255477905
Epoch 29, Training Loss: 0.4790462553501129, Validation Loss: 0.4771968722343445
Epoch 30, Training Loss: 0.4771968722343445, Validation Loss: 0.4753000736236572
Epoch 31, Training Loss: 0.4753000736236572, Validation Loss: 0.4733242690563202
Epoch 32, Training Loss: 0.4733242690563202, Validation Loss: 0.4712628424167633
Epoch 33, Training Loss: 0.4712628126144409, Validation Loss: 0.4691089689731598
Epoch 34, Training Loss: 0.4691089689731598, Validation Loss: 0.46683523058891296
Epoch 35, Training Loss: 0.46683526039123535, Validation Loss: 0.4644126296043396
Epoch 36, Training Loss: 0.4644125998020172, Validation Loss: 0.4618228077888489
Epoch 37, Training Loss: 0.4618228077888489, Validation Loss: 0.45905423164367676
Epoch 38, Training Loss: 0.45905423164367676, Validation Loss: 0.4560908377170563
Epoch 39, Training Loss: 0.4560908079147339, Validation Loss: 0.4529515206813812
Epoch 40, Training Loss: 0.45295149087905884, Validation Loss: 0.4496168792247772
Epoch 41, Training Loss: 0.4496168792247772, Validation Loss: 0.4460031986236572
Epoch 42, Training Loss: 0.4460031986236572, Validation Loss: 0.4420957863330841
Epoch 43, Training Loss: 0.4420957863330841, Validation Loss: 0.4378427267074585
Epoch 44, Training Loss: 0.4378426671028137, Validation Loss: 0.4330952763557434
Epoch 45, Training Loss: 0.4330952763557434, Validation Loss: 0.42789918184280396
Epoch 46, Training Loss: 0.42789915204048157, Validation Loss: 0.42229166626930237
Epoch 47, Training Loss: 0.42229166626930237, Validation Loss: 0.41632264852523804
Epoch 48, Training Loss: 0.41632264852523804, Validation Loss: 0.40992283821105957
Epoch 49, Training Loss: 0.4099228084087372, Validation Loss: 0.4029516279697418
Epoch 50, Training Loss: 0.4029516279697418, Validation Loss: 0.39550504088401794
Epoch 51, Training Loss: 0.39550504088401794, Validation Loss: 0.3875485062599182
Epoch 52, Training Loss: 0.38754844665527344, Validation Loss: 0.37906700372695923
Epoch 53, Training Loss: 0.37906700372695923, Validation Loss: 0.37003880739212036
Epoch 54, Training Loss: 0.370038777589798, Validation Loss: 0.3605005443096161
Epoch 55, Training Loss: 0.3605004847049713, Validation Loss: 0.35050511360168457
Epoch 56, Training Loss: 0.3505050837993622, Validation Loss: 0.34005048871040344
Epoch 57, Training Loss: 0.34005048871040344, Validation Loss: 0.32919350266456604
Epoch 58, Training Loss: 0.32919350266456604, Validation Loss: 0.318075567483902
Epoch 59, Training Loss: 0.3180755078792572, Validation Loss: 0.30671635270118713
Epoch 60, Training Loss: 0.30671629309654236, Validation Loss: 0.29515764117240906
Epoch 61, Training Loss: 0.29515767097473145, Validation Loss: 0.28360995650291443
Epoch 62, Training Loss: 0.28360995650291443, Validation Loss: 0.2722669243812561
Epoch 63, Training Loss: 0.2722669243812561, Validation Loss: 0.2613039016723633
Epoch 64, Training Loss: 0.2613039016723633, Validation Loss: 0.2509562075138092
Epoch 65, Training Loss: 0.2509562075138092, Validation Loss: 0.2413681149482727
Epoch 66, Training Loss: 0.24136808514595032, Validation Loss: 0.23258602619171143
Epoch 67, Training Loss: 0.23258602619171143, Validation Loss: 0.22466720640659332
Epoch 68, Training Loss: 0.22466719150543213, Validation Loss: 0.21752116084098816
Epoch 69, Training Loss: 0.21752113103866577, Validation Loss: 0.2109796106815338
Epoch 70, Training Loss: 0.2109796106815338, Validation Loss: 0.20481210947036743
Epoch 71, Training Loss: 0.20481210947036743, Validation Loss: 0.19871914386749268
Epoch 72, Training Loss: 0.19871917366981506, Validation Loss: 0.19236333668231964
Epoch 73, Training Loss: 0.19236338138580322, Validation Loss: 0.1855926215648651
Epoch 74, Training Loss: 0.1855926215648651, Validation Loss: 0.17844516038894653
Epoch 75, Training Loss: 0.17844514548778534, Validation Loss: 0.17094829678535461
Epoch 76, Training Loss: 0.17094829678535461, Validation Loss: 0.1631302386522293
Epoch 77, Training Loss: 0.1631302386522293, Validation Loss: 0.15515708923339844
Epoch 78, Training Loss: 0.15515708923339844, Validation Loss: 0.1472099870443344
Epoch 79, Training Loss: 0.14720995724201202, Validation Loss: 0.13951750099658966
Epoch 80, Training Loss: 0.13951748609542847, Validation Loss: 0.13224166631698608
Epoch 81, Training Loss: 0.13224168121814728, Validation Loss: 0.12531022727489471
Epoch 82, Training Loss: 0.12531021237373352, Validation Loss: 0.11865998059511185
Epoch 83, Training Loss: 0.11865998059511185, Validation Loss: 0.1123829185962677
Epoch 84, Training Loss: 0.1123829260468483, Validation Loss: 0.10651537775993347
Epoch 85, Training Loss: 0.10651538521051407, Validation Loss: 0.10092336684465408
Epoch 86, Training Loss: 0.10092337429523468, Validation Loss: 0.09559875726699829
Epoch 87, Training Loss: 0.09559875726699829, Validation Loss: 0.09048157930374146
Epoch 88, Training Loss: 0.09048157930374146, Validation Loss: 0.08554628491401672
Epoch 89, Training Loss: 0.08554629236459732, Validation Loss: 0.08070683479309082
Epoch 90, Training Loss: 0.08070684969425201, Validation Loss: 0.07605835795402527
Epoch 91, Training Loss: 0.07605836540460587, Validation Loss: 0.07157479971647263
Epoch 92, Training Loss: 0.07157479971647263, Validation Loss: 0.06733404099941254
Epoch 93, Training Loss: 0.06733405590057373, Validation Loss: 0.06327120214700699
Epoch 94, Training Loss: 0.06327120214700699, Validation Loss: 0.05938416346907616
Epoch 95, Training Loss: 0.05938415601849556, Validation Loss: 0.055724505335092545
Epoch 96, Training Loss: 0.05572449788451195, Validation Loss: 0.052149828523397446
Epoch 97, Training Loss: 0.052149828523397446, Validation Loss: 0.04861418902873993
Epoch 98, Training Loss: 0.04861418157815933, Validation Loss: 0.04511241614818573
Epoch 99, Training Loss: 0.04511241614818573, Validation Loss: 0.041582025587558746
Epoch 100, Training Loss: 0.041582025587558746, Validation Loss: 0.038002997636795044
Epoch 101, Training Loss: 0.038002997636795044, Validation Loss: 0.03441804647445679
Epoch 102, Training Loss: 0.03441804647445679, Validation Loss: 0.030966462567448616
Epoch 103, Training Loss: 0.030966462567448616, Validation Loss: 0.027753647416830063
Epoch 104, Training Loss: 0.02775365300476551, Validation Loss: 0.024728182703256607
Epoch 105, Training Loss: 0.024728182703256607, Validation Loss: 0.02188933454453945
Epoch 106, Training Loss: 0.02188933454453945, Validation Loss: 0.01925407163798809
Epoch 107, Training Loss: 0.01925407163798809, Validation Loss: 0.016851473599672318
Epoch 108, Training Loss: 0.016851479187607765, Validation Loss: 0.014669911004602909
Epoch 109, Training Loss: 0.014669913798570633, Validation Loss: 0.012763628736138344
Epoch 110, Training Loss: 0.012763631530106068, Validation Loss: 0.01110937912017107
Epoch 111, Training Loss: 0.01110937912017107, Validation Loss: 0.009723483584821224
Epoch 112, Training Loss: 0.009723484516143799, Validation Loss: 0.008608493022620678
Epoch 113, Training Loss: 0.008608492091298103, Validation Loss: 0.007712268270552158
Epoch 114, Training Loss: 0.007712269201874733, Validation Loss: 0.006982374470680952
Epoch 115, Training Loss: 0.006982370279729366, Validation Loss: 0.006369708105921745
Epoch 116, Training Loss: 0.006369707174599171, Validation Loss: 0.0058212969452142715
Epoch 117, Training Loss: 0.005821296479552984, Validation Loss: 0.0053199660032987595
Epoch 118, Training Loss: 0.005319965071976185, Validation Loss: 0.004816967528313398
Epoch 119, Training Loss: 0.00481696892529726, Validation Loss: 0.0042989603243768215
Epoch 120, Training Loss: 0.004298957996070385, Validation Loss: 0.003769499249756336
Epoch 121, Training Loss: 0.0037694976199418306, Validation Loss: 0.0032412067521363497
Epoch 122, Training Loss: 0.0032412041909992695, Validation Loss: 0.0027248882688581944
Epoch 123, Training Loss: 0.0027248894330114126, Validation Loss: 0.0022601415403187275
Epoch 124, Training Loss: 0.002260141307488084, Validation Loss: 0.0018317510839551687
Epoch 125, Training Loss: 0.0018317491048946977, Validation Loss: 0.0014554326189681888
Epoch 126, Training Loss: 0.0014554309891536832, Validation Loss: 0.0011380608193576336
Epoch 127, Training Loss: 0.0011380597716197371, Validation Loss: 0.0008848299621604383
Epoch 128, Training Loss: 0.0008848299039527774, Validation Loss: 0.0006944715278223157
Epoch 129, Training Loss: 0.0006944711785763502, Validation Loss: 0.000555659644305706
Epoch 130, Training Loss: 0.0005556601099669933, Validation Loss: 0.0004589029704220593
Epoch 131, Training Loss: 0.00045890233013778925, Validation Loss: 0.00039405786083079875
Epoch 132, Training Loss: 0.0003940569586120546, Validation Loss: 0.0003512040129862726
Epoch 133, Training Loss: 0.00035120404209010303, Validation Loss: 0.00032194037339650095
Epoch 134, Training Loss: 0.0003219402569811791, Validation Loss: 0.00030004908330738544
Epoch 135, Training Loss: 0.00030004786094650626, Validation Loss: 0.00028094876324757934
Epoch 136, Training Loss: 0.00028094969457015395, Validation Loss: 0.00026162690483033657
Epoch 137, Training Loss: 0.0002616273704916239, Validation Loss: 0.00024089118232950568
Epoch 138, Training Loss: 0.00024089074577204883, Validation Loss: 0.00021880872373003513
Epoch 139, Training Loss: 0.00021880918939132243, Validation Loss: 0.00019635766511783004
Epoch 140, Training Loss: 0.00019635813077911735, Validation Loss: 0.00017495668726041913
Epoch 141, Training Loss: 0.0001749564689816907, Validation Loss: 0.0001561837998451665
Epoch 142, Training Loss: 0.00015618365432601422, Validation Loss: 0.00014138744154479355
Epoch 143, Training Loss: 0.00014138732512947172, Validation Loss: 0.00013136507186573
Epoch 144, Training Loss: 0.0001313648681389168, Validation Loss: 0.0001261941361008212
Epoch 145, Training Loss: 0.00012619428161997348, Validation Loss: 0.0001252285874215886
Epoch 146, Training Loss: 0.00012522886390797794, Validation Loss: 0.00012724798580165952
Epoch 147, Training Loss: 0.00012724789849016815, Validation Loss: 0.00013071266585029662
Epoch 148, Training Loss: 0.00013071278226561844, Validation Loss: 0.00013406903599388897
Epoch 149, Training Loss: 0.0001340685848845169, Validation Loss: 0.00013598734221886843
Epoch 150, Training Loss: 0.00013598745863419026, Validation Loss: 0.0001354983978671953
Epoch 151, Training Loss: 0.00013549817958846688, Validation Loss: 0.00013076706090942025
Epoch 152, Training Loss: 0.0001307674392592162, Validation Loss: 0.00012270640581846237
Epoch 153, Training Loss: 0.00012270653678569943, Validation Loss: 0.00011217359860893339
Epoch 154, Training Loss: 0.00011217327846679837, Validation Loss: 0.00010020275658462197
Epoch 155, Training Loss: 0.00010020279296441004, Validation Loss: 8.78327336977236e-05
Epoch 156, Training Loss: 8.783244265941903e-05, Validation Loss: 7.59530666982755e-05
Epoch 157, Training Loss: 7.595321221742779e-05, Validation Loss: 6.519329326692969e-05
Epoch 158, Training Loss: 6.519321323139593e-05, Validation Loss: 5.585902908933349e-05
Epoch 159, Training Loss: 5.585921826423146e-05, Validation Loss: 4.794231062987819e-05
Epoch 160, Training Loss: 4.7942532546585426e-05, Validation Loss: 4.121827078051865e-05
Epoch 161, Training Loss: 4.121817619306967e-05, Validation Loss: 3.538699456839822e-05
Epoch 162, Training Loss: 3.538704913808033e-05, Validation Loss: 3.0192812118912116e-05
Epoch 163, Training Loss: 3.0192843041731976e-05, Validation Loss: 2.5475610527792014e-05
Epoch 164, Training Loss: 2.5475692382315174e-05, Validation Loss: 2.116421819664538e-05
Epoch 165, Training Loss: 2.116426549036987e-05, Validation Loss: 1.7263371773879044e-05
Epoch 166, Training Loss: 1.726338086882606e-05, Validation Loss: 1.3827620932715945e-05
Epoch 167, Training Loss: 1.3827578186464962e-05, Validation Loss: 1.0926193681370933e-05
Epoch 168, Training Loss: 1.0926191862381529e-05, Validation Loss: 8.611321391072124e-06
Epoch 169, Training Loss: 8.611375051259529e-06, Validation Loss: 6.891347311466234e-06
Epoch 170, Training Loss: 6.89136595610762e-06, Validation Loss: 5.719323780795094e-06
Epoch 171, Training Loss: 5.719317414332181e-06, Validation Loss: 4.997518317395588e-06
Epoch 172, Training Loss: 4.997532869310817e-06, Validation Loss: 4.597349743562518e-06
Epoch 173, Training Loss: 4.597391125571448e-06, Validation Loss: 4.385752163216239e-06
Epoch 174, Training Loss: 4.385866304801311e-06, Validation Loss: 4.2499614210100845e-06
Epoch 175, Training Loss: 4.249920493748505e-06, Validation Loss: 4.1111247810476925e-06
Epoch 176, Training Loss: 4.1110806705546565e-06, Validation Loss: 3.929536887881113e-06
Epoch 177, Training Loss: 3.929578724637395e-06, Validation Loss: 3.6986509712733096e-06
Epoch 178, Training Loss: 3.6986741633882048e-06, Validation Loss: 3.435496410020278e-06
Epoch 179, Training Loss: 3.435437520238338e-06, Validation Loss: 3.1688912258687196e-06
Epoch 180, Training Loss: 3.168839157297043e-06, Validation Loss: 2.930173423010274e-06
Epoch 181, Training Loss: 2.930090431618737e-06, Validation Loss: 2.7440373742138036e-06
Epoch 182, Training Loss: 2.7440100893727504e-06, Validation Loss: 2.62325193034485e-06
Epoch 183, Training Loss: 2.623256705192034e-06, Validation Loss: 2.5658519007265568e-06
Epoch 184, Training Loss: 2.5658239337644773e-06, Validation Loss: 2.5559213554515736e-06
Epoch 185, Training Loss: 2.555848141128081e-06, Validation Loss: 2.5674687549326336e-06
Epoch 186, Training Loss: 2.5674439712020103e-06, Validation Loss: 2.5710212412377587e-06
Epoch 187, Training Loss: 2.5710530735523207e-06, Validation Loss: 2.540720061006141e-06
Epoch 188, Training Loss: 2.5407382509001764e-06, Validation Loss: 2.4599873995612143e-06
Epoch 189, Training Loss: 2.4600008146080654e-06, Validation Loss: 2.324419938304345e-06
Epoch 190, Training Loss: 2.3243590021593263e-06, Validation Loss: 2.141312734238454e-06
Epoch 191, Training Loss: 2.1413138711068314e-06, Validation Loss: 1.926638560689753e-06
Epoch 192, Training Loss: 1.9267060906713596e-06, Validation Loss: 1.6999200624923105e-06
Epoch 193, Training Loss: 1.6999240415316308e-06, Validation Loss: 1.4792559568377328e-06
Epoch 194, Training Loss: 1.4792296951782191e-06, Validation Loss: 1.2779738653989625e-06
Epoch 195, Training Loss: 1.2779904636772699e-06, Validation Loss: 1.1032651627829182e-06
Epoch 196, Training Loss: 1.1032703923774534e-06, Validation Loss: 9.562312470734469e-07
Epoch 197, Training Loss: 9.562485274727806e-07, Validation Loss: 8.337179338013812e-07
Epoch 198, Training Loss: 8.337187296092452e-07, Validation Loss: 7.302513722606818e-07
Epoch 199, Training Loss: 7.302517701646138e-07, Validation Loss: 6.401123755495064e-07
Epoch 200, Training Loss: 6.401124892363441e-07, Validation Loss: 5.584817586168356e-07
Epoch 201, Training Loss: 5.584969926530903e-07, Validation Loss: 4.823757535632467e-07
Epoch 202, Training Loss: 4.823573362955358e-07, Validation Loss: 4.1054556731978664e-07
Epoch 203, Training Loss: 4.1054110511140607e-07, Validation Loss: 3.433671338370914e-07
Epoch 204, Training Loss: 3.433716244671814e-07, Validation Loss: 2.8217732506163884e-07
Epoch 205, Training Loss: 2.821862494784e-07, Validation Loss: 2.285960505332696e-07
Epoch 206, Training Loss: 2.28589044581895e-07, Validation Loss: 1.8396045220470114e-07
Epoch 207, Training Loss: 1.8395982692709367e-07, Validation Loss: 1.487506580133413e-07
Epoch 208, Training Loss: 1.4875797660351964e-07, Validation Loss: 1.2244895231106057e-07
Epoch 209, Training Loss: 1.2243569358361128e-07, Validation Loss: 1.0363383040612462e-07
Epoch 210, Training Loss: 1.0363257985090968e-07, Validation Loss: 9.038795667493105e-08
Epoch 211, Training Loss: 9.039573711788762e-08, Validation Loss: 8.080155566858593e-08
Epoch 212, Training Loss: 8.081358515710235e-08, Validation Loss: 7.329045104143006e-08
Epoch 213, Training Loss: 7.328418405450066e-08, Validation Loss: 6.695879051221709e-08
Epoch 214, Training Loss: 6.694520493510936e-08, Validation Loss: 6.151537945697783e-08
Epoch 215, Training Loss: 6.151157094791415e-08, Validation Loss: 5.711785533435432e-08
Epoch 216, Training Loss: 5.7126836594534325e-08, Validation Loss: 5.412342929389524e-08
Epoch 217, Training Loss: 5.412600856402605e-08, Validation Loss: 5.280532633378243e-08
Epoch 218, Training Loss: 5.280136505803057e-08, Validation Loss: 5.315649431736347e-08
Epoch 219, Training Loss: 5.315195750199564e-08, Validation Loss: 5.4894474743605315e-08
Epoch 220, Training Loss: 5.4893913414844064e-08, Validation Loss: 5.7497835825870425e-08
Epoch 221, Training Loss: 5.749509313091039e-08, Validation Loss: 6.02361254209427e-08
Epoch 222, Training Loss: 6.02292544726879e-08, Validation Loss: 6.236994209984914e-08
Epoch 223, Training Loss: 6.237727490088218e-08, Validation Loss: 6.329454294018433e-08
Epoch 224, Training Loss: 6.329266000193456e-08, Validation Loss: 6.254669671079682e-08
Epoch 225, Training Loss: 6.255604745319943e-08, Validation Loss: 6.000793462135334e-08
Epoch 226, Training Loss: 6.001212682349433e-08, Validation Loss: 5.585112816675064e-08
Epoch 227, Training Loss: 5.584890772070139e-08, Validation Loss: 5.0478799806796815e-08
Epoch 228, Training Loss: 5.047621343123865e-08, Validation Loss: 4.445033141564636e-08
Epoch 229, Training Loss: 4.444547840876112e-08, Validation Loss: 3.834282935599731e-08
Epoch 230, Training Loss: 3.8347376829506175e-08, Validation Loss: 3.26398534866712e-08
Epoch 231, Training Loss: 3.2637586855344125e-08, Validation Loss: 2.761857231803333e-08
Epoch 232, Training Loss: 2.7620309595022263e-08, Validation Loss: 2.3366309775951777e-08
Epoch 233, Training Loss: 2.336935267521767e-08, Validation Loss: 1.9807732343224416e-08
Epoch 234, Training Loss: 1.980928487910205e-08, Validation Loss: 1.6767744526191564e-08
Epoch 235, Training Loss: 1.67708975595815e-08, Validation Loss: 1.408010241732427e-08
Epoch 236, Training Loss: 1.4084111654710796e-08, Validation Loss: 1.161905771596139e-08
Epoch 237, Training Loss: 1.1617074413550199e-08, Validation Loss: 9.327983718776522e-09
Epoch 238, Training Loss: 9.326282857102797e-09, Validation Loss: 7.222606068779669e-09
Epoch 239, Training Loss: 7.219951747572395e-09, Validation Loss: 5.359169108487549e-09
Epoch 240, Training Loss: 5.3631281637933625e-09, Validation Loss: 3.8186014350571895e-09
Epoch 241, Training Loss: 3.817349547574622e-09, Validation Loss: 2.643407714941759e-09
Epoch 242, Training Loss: 2.6410249542863085e-09, Validation Loss: 1.8520380784536883e-09
Epoch 243, Training Loss: 1.851851005874039e-09, Validation Loss: 1.423069329042903e-09
Epoch 244, Training Loss: 1.4238000778377113e-09, Validation Loss: 1.2972041218972663e-09
Epoch 245, Training Loss: 1.2960836848208146e-09, Validation Loss: 1.3823036049132043e-09
Epoch 246, Training Loss: 1.3830038225748353e-09, Validation Loss: 1.587181608364574e-09
Epoch 247, Training Loss: 1.5868791836126661e-09, Validation Loss: 1.8269278312388337e-09
Epoch 248, Training Loss: 1.826466311527497e-09, Validation Loss: 2.0382560084186707e-09
Epoch 249, Training Loss: 2.0374688602942115e-09, Validation Loss: 2.1922863524537206e-09
Epoch 250, Training Loss: 2.1913624248526276e-09, Validation Loss: 2.2798714027771894e-09
Epoch 251, Training Loss: 2.281696831474278e-09, Validation Loss: 2.3218909017685974e-09
Epoch 252, Training Loss: 2.3214814515171156e-09, Validation Loss: 2.3269879356746515e-09
Epoch 253, Training Loss: 2.326743686609234e-09, Validation Loss: 2.3146895511416687e-09
Epoch 254, Training Loss: 2.31456742660896e-09, Validation Loss: 2.2908674957022868e-09
Epoch 255, Training Loss: 2.289513023612244e-09, Validation Loss: 2.249161523693033e-09
Epoch 256, Training Loss: 2.2497306240154558e-09, Validation Loss: 2.182265257388849e-09
Epoch 257, Training Loss: 2.1826629392762698e-09, Validation Loss: 2.082854555496283e-09
Epoch 258, Training Loss: 2.0832107150425827e-09, Validation Loss: 1.9417845109614973e-09
Epoch 259, Training Loss: 1.9432708775468654e-09, Validation Loss: 1.76434078458243e-09
Epoch 260, Training Loss: 1.7639544269698604e-09, Validation Loss: 1.5571522959945128e-09
Epoch 261, Training Loss: 1.557487916414857e-09, Validation Loss: 1.3341724391935372e-09
Epoch 262, Training Loss: 1.3343588456393718e-09, Validation Loss: 1.1124796639450096e-09
Epoch 263, Training Loss: 1.1122408549724128e-09, Validation Loss: 9.053597316288631e-10
Epoch 264, Training Loss: 9.060187045051293e-10, Validation Loss: 7.253529443751461e-10
Epoch 265, Training Loss: 7.261382051204635e-10, Validation Loss: 5.806166103461408e-10
Epoch 266, Training Loss: 5.808402092633003e-10, Validation Loss: 4.695658306630435e-10
Epoch 267, Training Loss: 4.692006783102443e-10, Validation Loss: 3.8857794759650233e-10
Epoch 268, Training Loss: 3.881908960945424e-10, Validation Loss: 3.2918878734022883e-10
Epoch 269, Training Loss: 3.2912381153771264e-10, Validation Loss: 2.8222341130756945e-10
Epoch 270, Training Loss: 2.833395185142251e-10, Validation Loss: 2.423604927859202e-10
Epoch 271, Training Loss: 2.42275949302595e-10, Validation Loss: 2.0505290521111164e-10
Epoch 272, Training Loss: 2.056801118310858e-10, Validation Loss: 1.7019390063932605e-10
Epoch 273, Training Loss: 1.700652396685598e-10, Validation Loss: 1.3874833226790173e-10
Epoch 274, Training Loss: 1.388992393325239e-10, Validation Loss: 1.1383006343068658e-10
Epoch 275, Training Loss: 1.1381668524323985e-10, Validation Loss: 9.702649100828964e-11
Epoch 276, Training Loss: 9.715461074533138e-11, Validation Loss: 8.851532701248388e-11
Epoch 277, Training Loss: 8.875898627191958e-11, Validation Loss: 8.686242003452804e-11
Epoch 278, Training Loss: 8.712306570624051e-11, Validation Loss: 8.975400284105817e-11
Epoch 279, Training Loss: 8.950982316457967e-11, Validation Loss: 9.348695428901266e-11
Epoch 280, Training Loss: 9.327873889963811e-11, Validation Loss: 9.684283930333493e-11
Epoch 281, Training Loss: 9.713744392181312e-11, Validation Loss: 9.774871190249002e-11
Epoch 282, Training Loss: 9.784309473737096e-11, Validation Loss: 9.554036728420812e-11
Epoch 283, Training Loss: 9.549037255363046e-11, Validation Loss: 9.029788028414032e-11
Epoch 284, Training Loss: 9.069524298244147e-11, Validation Loss: 8.391785877304159e-11
Epoch 285, Training Loss: 8.400803663821677e-11, Validation Loss: 7.669067464410873e-11
Epoch 286, Training Loss: 7.679924751702316e-11, Validation Loss: 7.06436506514585e-11
Epoch 287, Training Loss: 7.043093885883422e-11, Validation Loss: 6.509225103368266e-11
Epoch 288, Training Loss: 6.548556141794393e-11, Validation Loss: 6.120758760941314e-11
Epoch 289, Training Loss: 6.108680228322783e-11, Validation Loss: 5.773635736172622e-11
Epoch 290, Training Loss: 5.7984124446353036e-11, Validation Loss: 5.4943403993146234e-11
Epoch 291, Training Loss: 5.483604542666498e-11, Validation Loss: 5.141879283465656e-11
Epoch 292, Training Loss: 5.164575711535946e-11, Validation Loss: 4.767618244638783e-11
Epoch 293, Training Loss: 4.743155521125253e-11, Validation Loss: 4.268238887328302e-11
Epoch 294, Training Loss: 4.265300265759997e-11, Validation Loss: 3.72100648904361e-11
Epoch 295, Training Loss: 3.712766205588025e-11, Validation Loss: 3.17319122367099e-11
Epoch 296, Training Loss: 3.1629070890160094e-11, Validation Loss: 2.665882965768862e-11
Epoch 297, Training Loss: 2.6662958299561446e-11, Validation Loss: 2.209326818713997e-11
Epoch 298, Training Loss: 2.215635834523777e-11, Validation Loss: 1.8581927663241515e-11
Epoch 299, Training Loss: 1.8567987425388566e-11, Validation Loss: 1.5636937925056493e-11
Epoch 300, Training Loss: 1.5717361440126254e-11, Validation Loss: 1.339662322047408e-11
Epoch 301, Training Loss: 1.3668118720167044e-11, Validation Loss: 1.1747049513677332e-11
Epoch 302, Training Loss: 1.1698477256349982e-11, Validation Loss: 1.0020069843297286e-11
Epoch 303, Training Loss: 1.0119841596656354e-11, Validation Loss: 8.644504383148455e-12
Epoch 304, Training Loss: 8.633722209383521e-12, Validation Loss: 7.25165023515717e-12
Epoch 305, Training Loss: 7.195118632841169e-12, Validation Loss: 5.838112111800076e-12
Epoch 306, Training Loss: 5.897844278929254e-12, Validation Loss: 4.653328503773091e-12
Epoch 307, Training Loss: 4.664709157137237e-12, Validation Loss: 3.748011016130315e-12
Epoch 308, Training Loss: 3.724319030257162e-12, Validation Loss: 3.069154305701538e-12
Epoch 309, Training Loss: 3.012275108169038e-12, Validation Loss: 2.6041066004955926e-12
Epoch 310, Training Loss: 2.6257587684014316e-12, Validation Loss: 2.4005665077292404e-12
Epoch 311, Training Loss: 2.39608029597993e-12, Validation Loss: 2.2631861662514297e-12
Epoch 312, Training Loss: 2.351762664817847e-12, Validation Loss: 2.3761775966996135e-12
Epoch 313, Training Loss: 2.3406237885381653e-12, Validation Loss: 2.5066314041782833e-12
Epoch 314, Training Loss: 2.5102960075212843e-12, Validation Loss: 2.5676732875318242e-12
Epoch 315, Training Loss: 2.6291876661921343e-12, Validation Loss: 2.6415848675132025e-12
Epoch 316, Training Loss: 2.6113189301874007e-12, Validation Loss: 2.6613674371928076e-12
Epoch 317, Training Loss: 2.6804333492363996e-12, Validation Loss: 2.6448105858167814e-12
Epoch 318, Training Loss: 2.577220555022297e-12, Validation Loss: 2.594219977725132e-12
Epoch 319, Training Loss: 2.5259015799111717e-12, Validation Loss: 2.5053214711134864e-12
Epoch 320, Training Loss: 2.503256282815336e-12, Validation Loss: 2.445624215294262e-12
Epoch 321, Training Loss: 2.430893810898005e-12, Validation Loss: 2.335860671554002e-12
Epoch 322, Training Loss: 2.359228914658451e-12, Validation Loss: 2.2765654379003353e-12
Epoch 323, Training Loss: 2.2644345166328295e-12, Validation Loss: 2.0804595025902817e-12
Epoch 324, Training Loss: 2.1405897887571967e-12, Validation Loss: 1.9139349393543226e-12
Epoch 325, Training Loss: 1.9348285994202907e-12, Validation Loss: 1.7308705467164454e-12
Epoch 326, Training Loss: 1.7501650085779974e-12, Validation Loss: 1.4977630680840237e-12
Epoch 327, Training Loss: 1.534518280672803e-12, Validation Loss: 1.2662624854914428e-12
Epoch 328, Training Loss: 1.2652369386564888e-12, Validation Loss: 1.0122250260202748e-12
Epoch 329, Training Loss: 1.0568692188767104e-12, Validation Loss: 8.283608716498636e-13
Epoch 330, Training Loss: 8.337555906096084e-13, Validation Loss: 6.479545632681605e-13
Epoch 331, Training Loss: 6.340755286278477e-13, Validation Loss: 4.917401663813437e-13
Epoch 332, Training Loss: 4.619526874742597e-13, Validation Loss: 3.65519761810415e-13
Epoch 333, Training Loss: 3.5790836440396934e-13, Validation Loss: 2.8463554213251085e-13
Epoch 334, Training Loss: 2.7418169189045993e-13, Validation Loss: 1.9977469927889152e-13
Epoch 335, Training Loss: 2.1863744538788699e-13, Validation Loss: 1.6377998675147498e-13
Epoch 336, Training Loss: 1.771460582389306e-13, Validation Loss: 1.326917362879515e-13
Epoch 337, Training Loss: 1.3977411079686003e-13, Validation Loss: 1.1126015609036824e-13
Epoch 338, Training Loss: 1.1541578782102435e-13, Validation Loss: 9.950329812489708e-14
Epoch 339, Training Loss: 1.0264221249204133e-13, Validation Loss: 8.510135955305809e-14
Epoch 340, Training Loss: 8.679898298594516e-14, Validation Loss: 8.520807892814855e-14
Epoch 341, Training Loss: 8.059948108235515e-14, Validation Loss: 7.876067419781974e-14
Epoch 342, Training Loss: 7.460187795207268e-14, Validation Loss: 7.001299903329136e-14
Epoch 343, Training Loss: 6.442144994539545e-14, Validation Loss: 7.01464101106157e-14
Epoch 344, Training Loss: 6.082563923023865e-14, Validation Loss: 7.717577390955327e-14
Epoch 345, Training Loss: 6.486461080713532e-14, Validation Loss: 7.501380701498139e-14
Epoch 346, Training Loss: 6.563028793387174e-14, Validation Loss: 7.123181168175452e-14
Epoch 347, Training Loss: 6.450205360065617e-14, Validation Loss: 7.172353802455816e-14
Epoch 348, Training Loss: 6.86105428655999e-14, Validation Loss: 7.32953669003826e-14
Epoch 349, Training Loss: 6.709505862142681e-14, Validation Loss: 7.229963562517192e-14
Epoch 350, Training Loss: 6.933018883385073e-14, Validation Loss: 7.576614167873266e-14
Epoch 351, Training Loss: 6.344613555234538e-14, Validation Loss: 7.43370005850709e-14
Epoch 352, Training Loss: 6.416044182489672e-14, Validation Loss: 6.716057831396283e-14
Epoch 353, Training Loss: 6.413535609713084e-14, Validation Loss: 6.07643547024389e-14
Epoch 354, Training Loss: 5.97880035410614e-14, Validation Loss: 6.179745029501887e-14
Epoch 355, Training Loss: 5.0150815032908025e-14, Validation Loss: 5.813718376070781e-14
Epoch 356, Training Loss: 4.730800305533314e-14, Validation Loss: 5.2450492544044505e-14
Epoch 357, Training Loss: 4.288712803944203e-14, Validation Loss: 4.31155457202622e-14
Epoch 358, Training Loss: 4.9816413201595605e-14, Validation Loss: 4.2378820179662935e-14
Epoch 359, Training Loss: 4.046972311303257e-14, Validation Loss: 3.772468923075693e-14
Epoch 360, Training Loss: 3.9016024840164004e-14, Validation Loss: 3.8683727038692564e-14
Epoch 361, Training Loss: 3.561997159902408e-14, Validation Loss: 3.7681456669129074e-14
Epoch 362, Training Loss: 3.656539589343144e-14, Validation Loss: 3.37958082200808e-14
Epoch 363, Training Loss: 3.349600260246603e-14, Validation Loss: 3.0720943096276127e-14
Epoch 364, Training Loss: 2.9063248796522625e-14, Validation Loss: 2.9829196973802166e-14
Epoch 365, Training Loss: 2.460807911066308e-14, Validation Loss: 2.9773553685431137e-14
Epoch 366, Training Loss: 2.4020007852306943e-14, Validation Loss: 2.247129958781076e-14
Epoch 367, Training Loss: 2.198597850815425e-14, Validation Loss: 2.3675731310895433e-14
Epoch 368, Training Loss: 2.131397306098879e-14, Validation Loss: 2.1401376696750067e-14
Epoch 369, Training Loss: 1.6866675699341027e-14, Validation Loss: 1.49746260178071e-14
Epoch 370, Training Loss: 1.759672662031593e-14, Validation Loss: 1.9358138410394826e-14
Epoch 371, Training Loss: 1.5139824547576e-14, Validation Loss: 1.8157843596224542e-14
Epoch 372, Training Loss: 1.1489165907985644e-14, Validation Loss: 1.9465123753830728e-14
Epoch 373, Training Loss: 1.3619673151863548e-14, Validation Loss: 1.419063095655336e-14
Epoch 374, Training Loss: 1.1454871238017212e-14, Validation Loss: 1.6984736845595226e-14
Epoch 375, Training Loss: 1.1247371882862432e-14, Validation Loss: 1.4562962923243827e-14
Epoch 376, Training Loss: 8.884544677376354e-15, Validation Loss: 1.1108860820162672e-14
Epoch 377, Training Loss: 8.263113873425553e-15, Validation Loss: 1.3823136395024662e-14
Epoch 378, Training Loss: 7.72815158086226e-15, Validation Loss: 1.4153267486217026e-14
Epoch 379, Training Loss: 7.548674616701494e-15, Validation Loss: 1.2537572468120182e-14
Epoch 380, Training Loss: 6.879338170352831e-15, Validation Loss: 8.563054169278932e-15
Epoch 381, Training Loss: 5.798071390546037e-15, Validation Loss: 1.0049345422924894e-14
Epoch 382, Training Loss: 6.1739727540762335e-15, Validation Loss: 1.101491893708154e-14
Epoch 383, Training Loss: 4.253633866169908e-15, Validation Loss: 1.0923512223611539e-14
Epoch 384, Training Loss: 4.7453610560065e-15, Validation Loss: 1.0074832644307776e-14
Epoch 385, Training Loss: 4.689449681707664e-15, Validation Loss: 1.0957640028089362e-14
Epoch 386, Training Loss: 3.606848825008944e-15, Validation Loss: 7.348214105338396e-15
Epoch 387, Training Loss: 5.009039447871448e-15, Validation Loss: 8.26895162449803e-15
Epoch 388, Training Loss: 3.1324686581738837e-15, Validation Loss: 6.8666614752642234e-15
Epoch 389, Training Loss: 2.9064209755401285e-15, Validation Loss: 8.55855049509838e-15
Epoch 390, Training Loss: 2.3758624072696107e-15, Validation Loss: 1.1082406287154026e-14
Epoch 391, Training Loss: 3.522247809511895e-15, Validation Loss: 6.1395120656501396e-15
Epoch 392, Training Loss: 2.9050864751317294e-15, Validation Loss: 9.727854067794525e-15
Epoch 393, Training Loss: 2.1670283399481943e-15, Validation Loss: 8.520086728963563e-15
Epoch 394, Training Loss: 2.0345221055697573e-15, Validation Loss: 9.025024244645533e-15
Epoch 395, Training Loss: 3.2373527246258842e-15, Validation Loss: 8.71747759292581e-15
Epoch 396, Training Loss: 2.7369517056511717e-15, Validation Loss: 9.010512876193172e-15
Epoch 397, Training Loss: 3.199856058358594e-15, Validation Loss: 7.959537265129612e-15
Epoch 398, Training Loss: 2.5742881337351663e-15, Validation Loss: 7.933916212541064e-15
Epoch 399, Training Loss: 2.4241676374603394e-15, Validation Loss: 6.070690215169254e-15
Epoch 400, Training Loss: 2.338765964069898e-15, Validation Loss: 6.159561335511649e-15
Epoch 401, Training Loss: 2.167962405530779e-15, Validation Loss: 3.812347064825836e-15
Epoch 402, Training Loss: 2.3868043788822417e-15, Validation Loss: 3.7140014574519285e-15
Epoch 403, Training Loss: 1.348639082354719e-15, Validation Loss: 3.586565774053993e-15
Epoch 404, Training Loss: 5.684138471118518e-16, Validation Loss: 3.3755969719472586e-15
Epoch 405, Training Loss: 1.499293209386316e-15, Validation Loss: 3.785525343034555e-15
Epoch 406, Training Loss: 7.402849318623075e-16, Validation Loss: 6.874667630681671e-15
Epoch 407, Training Loss: 4.353739025673059e-16, Validation Loss: 6.955799410985003e-15
Epoch 408, Training Loss: 4.0014566994210155e-16, Validation Loss: 6.827296466073527e-15
Epoch 409, Training Loss: 4.3430637635596947e-16, Validation Loss: 3.5893681825599835e-15
Epoch 410, Training Loss: 4.1949452296557034e-16, Validation Loss: 3.992891714016617e-15
Epoch 411, Training Loss: 3.978771833604565e-16, Validation Loss: 4.139675747512209e-15
Epoch 412, Training Loss: 4.058836034757002e-16, Validation Loss: 4.822889981668686e-15
Epoch 413, Training Loss: 4.1829356259526175e-16, Validation Loss: 3.5226480325794727e-15
Epoch 414, Training Loss: 4.1829356259526175e-16, Validation Loss: 3.530654399755157e-15
Epoch 415, Training Loss: 1.1447423700828479e-15, Validation Loss: 4.043065287130752e-15
Epoch 416, Training Loss: 1.1099144928741192e-15, Validation Loss: 5.179976202341523e-15
Epoch 417, Training Loss: 1.0870961664289172e-15, Validation Loss: 6.441787631339098e-15
Epoch 418, Training Loss: 1.1159193211954417e-15, Validation Loss: 6.574160246270106e-15
Epoch 419, Training Loss: 1.1035093356061005e-15, Validation Loss: 6.603517137672519e-15
Epoch 420, Training Loss: 1.2209367953366348e-15, Validation Loss: 6.881739932274771e-15
Epoch 421, Training Loss: 5.377226141197171e-16, Validation Loss: 6.113124024727853e-15
Epoch 422, Training Loss: 5.494653495048587e-16, Validation Loss: 4.266310561258516e-15
Epoch 423, Training Loss: 5.494653495048587e-16, Validation Loss: 4.477146379192531e-15
Epoch 424, Training Loss: 4.424462306301853e-16, Validation Loss: 4.005668358993001e-15
Epoch 425, Training Loss: 4.840795940536287e-16, Validation Loss: 4.184611692396997e-15
Epoch 426, Training Loss: 5.267804836884085e-16, Validation Loss: 4.805109066039924e-15
Epoch 427, Training Loss: 4.686005433985892e-16, Validation Loss: 4.7745515054347775e-15
Epoch 428, Training Loss: 5.326518513809793e-16, Validation Loss: 4.743326482867195e-15
Epoch 429, Training Loss: 6.762336238799174e-16, Validation Loss: 4.369026435123782e-15
Epoch 430, Training Loss: 6.650246251306644e-16, Validation Loss: 4.36702489626942e-15
Epoch 431, Training Loss: 6.458092062661678e-16, Validation Loss: 3.560378479940205e-15
Epoch 432, Training Loss: 1.938578471876026e-15, Validation Loss: 3.560378479940205e-15
Epoch 433, Training Loss: 1.938578471876026e-15, Validation Loss: 3.560378479940205e-15
Epoch 434, Training Loss: 1.9257683690982255e-15, Validation Loss: 3.830995342192587e-15
Epoch 435, Training Loss: 1.916160686135757e-15, Validation Loss: 3.81751777745235e-15
Epoch 436, Training Loss: 1.977543046240908e-15, Validation Loss: 3.83219601139532e-15
Epoch 437, Training Loss: 1.8666543632258215e-15, Validation Loss: 4.375831921338497e-15
Epoch 438, Training Loss: 1.8666543632258215e-15, Validation Loss: 4.232383503589192e-15
Epoch 439, Training Loss: 4.922194747976241e-16, Validation Loss: 4.200358034886454e-15
Epoch 440, Training Loss: 5.525344675101163e-16, Validation Loss: 4.200358034886454e-15
Epoch 441, Training Loss: 3.7532577817275803e-16, Validation Loss: 3.713967999650512e-15
Epoch 442, Training Loss: 3.7532577817275803e-16, Validation Loss: 3.713967999650512e-15
Epoch 443, Training Loss: 7.441547077609572e-16, Validation Loss: 3.713967999650512e-15
Epoch 444, Training Loss: 7.441547077609572e-16, Validation Loss: 3.681942530947774e-15
Epoch 445, Training Loss: 7.441547077609572e-16, Validation Loss: 4.439883282260446e-15
Epoch 446, Training Loss: 1.5234459303607988e-15, Validation Loss: 4.439883282260446e-15
Epoch 447, Training Loss: 1.1332665559552098e-15, Validation Loss: 4.439883282260446e-15
Epoch 448, Training Loss: 1.1781024450731033e-15, Validation Loss: 4.385439392542729e-15
Epoch 449, Training Loss: 1.0179741486473484e-15, Validation Loss: 2.8588827336831386e-15
Epoch 450, Training Loss: 9.53922787725399e-16, Validation Loss: 2.8588827336831386e-15
Epoch 451, Training Loss: 7.88456860242962e-16, Validation Loss: 3.712900314620498e-15
Epoch 452, Training Loss: 8.044697004734494e-16, Validation Loss: 3.8063085669448604e-15
Epoch 453, Training Loss: 3.677172041388838e-15, Validation Loss: 4.5155436532409894e-15
Epoch 454, Training Loss: 3.677172041388838e-15, Validation Loss: 4.7083647744528e-15
Epoch 455, Training Loss: 8.503731687422385e-16, Validation Loss: 4.096274626327846e-15
Epoch 456, Training Loss: 8.226175931266096e-16, Validation Loss: 3.7331833655754494e-15
Epoch 457, Training Loss: 2.7551247445949535e-16, Validation Loss: 3.7331833655754494e-15
Epoch 458, Training Loss: 1.0737771821382741e-16, Validation Loss: 4.78936314706694e-15
Epoch 459, Training Loss: 1.2072174291597365e-16, Validation Loss: 6.540099357395116e-15
Epoch 460, Training Loss: 1.2072174291597365e-16, Validation Loss: 6.540099357395116e-15
Epoch 461, Training Loss: 1.2072174291597365e-16, Validation Loss: 4.773083597337186e-15
Epoch 462, Training Loss: 1.1829062865543376e-15, Validation Loss: 4.111219675649201e-15
Epoch 463, Training Loss: 1.2122631779567508e-15, Validation Loss: 4.111219675649201e-15
Epoch 464, Training Loss: 1.2122631779567508e-15, Validation Loss: 4.164595880336904e-15
Epoch 465, Training Loss: 1.1866426547637947e-15, Validation Loss: 4.17580466732792e-15
Epoch 466, Training Loss: 1.1572857633613816e-15, Validation Loss: 3.801505043100981e-15
Epoch 467, Training Loss: 5.274476809530488e-16, Validation Loss: 3.801505043100981e-15
Epoch 468, Training Loss: 5.594733614140235e-16, Validation Loss: 3.801505043100981e-15
Epoch 469, Training Loss: 5.594733614140235e-16, Validation Loss: 3.966970811764741e-15
Epoch 470, Training Loss: 1.4348415195176707e-15, Validation Loss: 3.966970811764741e-15
Epoch 471, Training Loss: 6.288623004530958e-16, Validation Loss: 4.3877081702919495e-15
Epoch 472, Training Loss: 1.1786361817089919e-15, Validation Loss: 4.372362474386543e-15
Epoch 473, Training Loss: 1.1183211889964997e-15, Validation Loss: 4.274550497769406e-15
Epoch 474, Training Loss: 1.2384174377855954e-15, Validation Loss: 3.7087638292225816e-15
Epoch 475, Training Loss: 9.92887362090281e-16, Validation Loss: 4.95242715380876e-15
Epoch 476, Training Loss: 1.0142377804378913e-15, Validation Loss: 3.5392947710918615e-15
Epoch 477, Training Loss: 1.0142377804378913e-15, Validation Loss: 3.4832497773455966e-15
Epoch 478, Training Loss: 3.592303998755167e-15, Validation Loss: 3.4832497773455966e-15
Epoch 479, Training Loss: 3.1439444723015218e-15, Validation Loss: 5.041832328424398e-15
Epoch 480, Training Loss: 3.2293463574501998e-15, Validation Loss: 4.980716360181159e-15
Epoch 481, Training Loss: 7.126628168754303e-16, Validation Loss: 5.695956486556847e-15
Epoch 482, Training Loss: 7.313444461644792e-16, Validation Loss: 5.695956486556847e-15
Epoch 483, Training Loss: 5.952353571448961e-16, Validation Loss: 5.695956486556847e-15
Epoch 484, Training Loss: 5.952353571448961e-16, Validation Loss: 5.695956486556847e-15
Epoch 485, Training Loss: 1.2998000096489833e-15, Validation Loss: 5.695956486556847e-15
Epoch 486, Training Loss: 2.9632915617121703e-16, Validation Loss: 5.695956486556847e-15
Epoch 487, Training Loss: 2.557632924893305e-16, Validation Loss: 6.122965277025527e-15
Epoch 488, Training Loss: 2.557632924893305e-16, Validation Loss: 6.122965277025527e-15
Epoch 489, Training Loss: 2.4508808331552535e-16, Validation Loss: 6.122965277025527e-15
Epoch 490, Training Loss: 1.1524819218801472e-15, Validation Loss: 6.126301316288288e-15
Epoch 491, Training Loss: 9.896848363958309e-16, Validation Loss: 5.724645915996824e-15
Epoch 492, Training Loss: 9.896848363958309e-16, Validation Loss: 5.814051090612463e-15
Epoch 493, Training Loss: 4.799429498370347e-16, Validation Loss: 4.475645013293523e-15
Epoch 494, Training Loss: 1.176501129286319e-15, Validation Loss: 3.792430779137046e-15
Epoch 495, Training Loss: 1.165825973052073e-15, Validation Loss: 4.219439993122199e-15
Epoch 496, Training Loss: 9.411125790684803e-16, Validation Loss: 4.6718021737680946e-15
Epoch 497, Training Loss: 9.70469364591775e-16, Validation Loss: 4.4692401736628595e-15
Epoch 498, Training Loss: 1.0265143583380399e-15, Validation Loss: 4.501265642365597e-15
Epoch 499, Training Loss: 3.2461849489251416e-16, Validation Loss: 4.5920048938731615e-15
Epoch 500, Training Loss: 2.3921671562295455e-16, Validation Loss: 4.72010761571706e-15
