Epoch 1, Training Loss: 0.5412190556526184, Validation Loss: 0.5397584438323975
Epoch 2, Training Loss: 0.5397584438323975, Validation Loss: 0.538345992565155
Epoch 3, Training Loss: 0.538345992565155, Validation Loss: 0.5369764566421509
Epoch 4, Training Loss: 0.5369764566421509, Validation Loss: 0.5356413722038269
Epoch 5, Training Loss: 0.5356413722038269, Validation Loss: 0.5343577861785889
Epoch 6, Training Loss: 0.5343577265739441, Validation Loss: 0.5330866575241089
Epoch 7, Training Loss: 0.5330866575241089, Validation Loss: 0.5318218469619751
Epoch 8, Training Loss: 0.5318218469619751, Validation Loss: 0.5305715799331665
Epoch 9, Training Loss: 0.5305715799331665, Validation Loss: 0.5293295979499817
Epoch 10, Training Loss: 0.5293295979499817, Validation Loss: 0.5281218886375427
Epoch 11, Training Loss: 0.5281218886375427, Validation Loss: 0.5269494652748108
Epoch 12, Training Loss: 0.5269494652748108, Validation Loss: 0.5257614850997925
Epoch 13, Training Loss: 0.5257614850997925, Validation Loss: 0.5245906710624695
Epoch 14, Training Loss: 0.5245906710624695, Validation Loss: 0.5234469175338745
Epoch 15, Training Loss: 0.5234469175338745, Validation Loss: 0.5222957730293274
Epoch 16, Training Loss: 0.5222957730293274, Validation Loss: 0.5211160778999329
Epoch 17, Training Loss: 0.5211160778999329, Validation Loss: 0.5199078321456909
Epoch 18, Training Loss: 0.5199078321456909, Validation Loss: 0.518709123134613
Epoch 19, Training Loss: 0.5187091827392578, Validation Loss: 0.51751309633255
Epoch 20, Training Loss: 0.51751309633255, Validation Loss: 0.5162621736526489
Epoch 21, Training Loss: 0.5162621736526489, Validation Loss: 0.5149649381637573
Epoch 22, Training Loss: 0.5149649381637573, Validation Loss: 0.5136678814888
Epoch 23, Training Loss: 0.5136678814888, Validation Loss: 0.5123376846313477
Epoch 24, Training Loss: 0.5123376846313477, Validation Loss: 0.5109499096870422
Epoch 25, Training Loss: 0.510949969291687, Validation Loss: 0.5094895362854004
Epoch 26, Training Loss: 0.5094895362854004, Validation Loss: 0.5079460144042969
Epoch 27, Training Loss: 0.5079460144042969, Validation Loss: 0.5063218474388123
Epoch 28, Training Loss: 0.5063218474388123, Validation Loss: 0.504607081413269
Epoch 29, Training Loss: 0.5046070218086243, Validation Loss: 0.502809464931488
Epoch 30, Training Loss: 0.5028095245361328, Validation Loss: 0.5008966326713562
Epoch 31, Training Loss: 0.5008966326713562, Validation Loss: 0.4988503158092499
Epoch 32, Training Loss: 0.4988503158092499, Validation Loss: 0.4967416822910309
Epoch 33, Training Loss: 0.4967416822910309, Validation Loss: 0.49462488293647766
Epoch 34, Training Loss: 0.49462488293647766, Validation Loss: 0.4923945367336273
Epoch 35, Training Loss: 0.4923945665359497, Validation Loss: 0.4900081157684326
Epoch 36, Training Loss: 0.4900081157684326, Validation Loss: 0.4874688386917114
Epoch 37, Training Loss: 0.4874688386917114, Validation Loss: 0.4847355782985687
Epoch 38, Training Loss: 0.48473554849624634, Validation Loss: 0.4817518889904022
Epoch 39, Training Loss: 0.4817518889904022, Validation Loss: 0.4785422384738922
Epoch 40, Training Loss: 0.4785422384738922, Validation Loss: 0.4750893712043762
Epoch 41, Training Loss: 0.4750893712043762, Validation Loss: 0.4713580906391144
Epoch 42, Training Loss: 0.4713580906391144, Validation Loss: 0.4673241972923279
Epoch 43, Training Loss: 0.4673241972923279, Validation Loss: 0.46294930577278137
Epoch 44, Training Loss: 0.46294933557510376, Validation Loss: 0.45822635293006897
Epoch 45, Training Loss: 0.45822635293006897, Validation Loss: 0.453141450881958
Epoch 46, Training Loss: 0.453141450881958, Validation Loss: 0.44765153527259827
Epoch 47, Training Loss: 0.44765159487724304, Validation Loss: 0.4417820870876312
Epoch 48, Training Loss: 0.4417820870876312, Validation Loss: 0.4353986978530884
Epoch 49, Training Loss: 0.4353986978530884, Validation Loss: 0.42849600315093994
Epoch 50, Training Loss: 0.42849600315093994, Validation Loss: 0.42106181383132935
Epoch 51, Training Loss: 0.42106181383132935, Validation Loss: 0.41310039162635803
Epoch 52, Training Loss: 0.41310039162635803, Validation Loss: 0.4045565724372864
Epoch 53, Training Loss: 0.4045565724372864, Validation Loss: 0.39538073539733887
Epoch 54, Training Loss: 0.39538073539733887, Validation Loss: 0.38556644320487976
Epoch 55, Training Loss: 0.38556650280952454, Validation Loss: 0.3751104176044464
Epoch 56, Training Loss: 0.3751104176044464, Validation Loss: 0.36402884125709534
Epoch 57, Training Loss: 0.3640288710594177, Validation Loss: 0.35227203369140625
Epoch 58, Training Loss: 0.35227203369140625, Validation Loss: 0.33990123867988586
Epoch 59, Training Loss: 0.33990123867988586, Validation Loss: 0.3269461691379547
Epoch 60, Training Loss: 0.3269461691379547, Validation Loss: 0.3134452998638153
Epoch 61, Training Loss: 0.3134452998638153, Validation Loss: 0.2995857894420624
Epoch 62, Training Loss: 0.29958575963974, Validation Loss: 0.2854781448841095
Epoch 63, Training Loss: 0.2854781746864319, Validation Loss: 0.27114927768707275
Epoch 64, Training Loss: 0.27114927768707275, Validation Loss: 0.256801575422287
Epoch 65, Training Loss: 0.256801575422287, Validation Loss: 0.24272938072681427
Epoch 66, Training Loss: 0.2427293360233307, Validation Loss: 0.22904811799526215
Epoch 67, Training Loss: 0.22904813289642334, Validation Loss: 0.2160930335521698
Epoch 68, Training Loss: 0.2160930335521698, Validation Loss: 0.20402541756629944
Epoch 69, Training Loss: 0.20402544736862183, Validation Loss: 0.19319967925548553
Epoch 70, Training Loss: 0.19319967925548553, Validation Loss: 0.183852881193161
Epoch 71, Training Loss: 0.18385286629199982, Validation Loss: 0.17562435567378998
Epoch 72, Training Loss: 0.17562435567378998, Validation Loss: 0.16849936544895172
Epoch 73, Training Loss: 0.16849936544895172, Validation Loss: 0.1624678522348404
Epoch 74, Training Loss: 0.1624678522348404, Validation Loss: 0.15696947276592255
Epoch 75, Training Loss: 0.15696947276592255, Validation Loss: 0.15169620513916016
Epoch 76, Training Loss: 0.15169620513916016, Validation Loss: 0.14605394005775452
Epoch 77, Training Loss: 0.14605394005775452, Validation Loss: 0.1397046595811844
Epoch 78, Training Loss: 0.139704629778862, Validation Loss: 0.13275505602359772
Epoch 79, Training Loss: 0.13275505602359772, Validation Loss: 0.1252557784318924
Epoch 80, Training Loss: 0.1252557784318924, Validation Loss: 0.11745187640190125
Epoch 81, Training Loss: 0.11745187640190125, Validation Loss: 0.10973566770553589
Epoch 82, Training Loss: 0.10973567515611649, Validation Loss: 0.102120541036129
Epoch 83, Training Loss: 0.102120541036129, Validation Loss: 0.0948934555053711
Epoch 84, Training Loss: 0.0948934555053711, Validation Loss: 0.08810331672430038
Epoch 85, Training Loss: 0.08810330927371979, Validation Loss: 0.08173757791519165
Epoch 86, Training Loss: 0.08173757046461105, Validation Loss: 0.07580237835645676
Epoch 87, Training Loss: 0.07580235600471497, Validation Loss: 0.07031392306089401
Epoch 88, Training Loss: 0.07031391561031342, Validation Loss: 0.06505190581083298
Epoch 89, Training Loss: 0.06505191326141357, Validation Loss: 0.05999026075005531
Epoch 90, Training Loss: 0.05999026075005531, Validation Loss: 0.055123478174209595
Epoch 91, Training Loss: 0.055123478174209595, Validation Loss: 0.050518617033958435
Epoch 92, Training Loss: 0.05051859840750694, Validation Loss: 0.04600454866886139
Epoch 93, Training Loss: 0.04600454121828079, Validation Loss: 0.04169193655252457
Epoch 94, Training Loss: 0.04169193282723427, Validation Loss: 0.03760021552443504
Epoch 95, Training Loss: 0.037600211799144745, Validation Loss: 0.03376815840601921
Epoch 96, Training Loss: 0.03376815840601921, Validation Loss: 0.030232058838009834
Epoch 97, Training Loss: 0.030232058838009834, Validation Loss: 0.026951299980282784
Epoch 98, Training Loss: 0.026951301842927933, Validation Loss: 0.02400275692343712
Epoch 99, Training Loss: 0.024002758786082268, Validation Loss: 0.021364519372582436
Epoch 100, Training Loss: 0.021364517509937286, Validation Loss: 0.019072948023676872
Epoch 101, Training Loss: 0.01907294988632202, Validation Loss: 0.01710958033800125
Epoch 102, Training Loss: 0.017109576612710953, Validation Loss: 0.015421250835061073
Epoch 103, Training Loss: 0.01542124804109335, Validation Loss: 0.013987048529088497
Epoch 104, Training Loss: 0.013987048529088497, Validation Loss: 0.012776895426213741
Epoch 105, Training Loss: 0.012776895426213741, Validation Loss: 0.011762780137360096
Epoch 106, Training Loss: 0.01176278293132782, Validation Loss: 0.010921919718384743
Epoch 107, Training Loss: 0.010921919718384743, Validation Loss: 0.010225423611700535
Epoch 108, Training Loss: 0.01022542454302311, Validation Loss: 0.009628832340240479
Epoch 109, Training Loss: 0.009628832340240479, Validation Loss: 0.00909445434808731
Epoch 110, Training Loss: 0.00909445621073246, Validation Loss: 0.008561146445572376
Epoch 111, Training Loss: 0.008561146445572376, Validation Loss: 0.008003642782568932
Epoch 112, Training Loss: 0.008003640919923782, Validation Loss: 0.007421462796628475
Epoch 113, Training Loss: 0.007421461865305901, Validation Loss: 0.006822117604315281
Epoch 114, Training Loss: 0.0068221185356378555, Validation Loss: 0.006217066664248705
Epoch 115, Training Loss: 0.006217067129909992, Validation Loss: 0.005603352095931768
Epoch 116, Training Loss: 0.005603351630270481, Validation Loss: 0.004999879747629166
Epoch 117, Training Loss: 0.004999879747629166, Validation Loss: 0.004415980074554682
Epoch 118, Training Loss: 0.004415984731167555, Validation Loss: 0.003866807324811816
Epoch 119, Training Loss: 0.0038668096531182528, Validation Loss: 0.003350192680954933
Epoch 120, Training Loss: 0.0033501938451081514, Validation Loss: 0.002876085229218006
Epoch 121, Training Loss: 0.0028760863933712244, Validation Loss: 0.0024530671071261168
Epoch 122, Training Loss: 0.0024530685041099787, Validation Loss: 0.00208505941554904
Epoch 123, Training Loss: 0.0020850582513958216, Validation Loss: 0.0017708184896036983
Epoch 124, Training Loss: 0.0017708202358335257, Validation Loss: 0.0015051423106342554
Epoch 125, Training Loss: 0.001505142543464899, Validation Loss: 0.0012810799526050687
Epoch 126, Training Loss: 0.001281081698834896, Validation Loss: 0.0010920383501797915
Epoch 127, Training Loss: 0.0010920377681031823, Validation Loss: 0.0009325026767328382
Epoch 128, Training Loss: 0.0009325016872026026, Validation Loss: 0.0007974355830810964
Epoch 129, Training Loss: 0.0007974345353432, Validation Loss: 0.0006829748162999749
Epoch 130, Training Loss: 0.0006829742342233658, Validation Loss: 0.0005849897861480713
Epoch 131, Training Loss: 0.0005849904264323413, Validation Loss: 0.000499390996992588
Epoch 132, Training Loss: 0.0004993909387849271, Validation Loss: 0.0004228492034599185
Epoch 133, Training Loss: 0.00042284911614842713, Validation Loss: 0.0003535308933351189
Epoch 134, Training Loss: 0.00035353045677766204, Validation Loss: 0.00029124884167686105
Epoch 135, Training Loss: 0.00029124945285730064, Validation Loss: 0.00023687978682573885
Epoch 136, Training Loss: 0.00023688055807724595, Validation Loss: 0.00019147570128552616
Epoch 137, Training Loss: 0.00019147619605064392, Validation Loss: 0.00015534610429313034
Epoch 138, Training Loss: 0.00015534611884504557, Validation Loss: 0.00012778960808645934
Epoch 139, Training Loss: 0.00012778921518474817, Validation Loss: 0.00010740216384874657
Epoch 140, Training Loss: 0.00010740175639512017, Validation Loss: 9.263546962756664e-05
Epoch 141, Training Loss: 9.26357606658712e-05, Validation Loss: 8.225883357226849e-05
Epoch 142, Training Loss: 8.22590445750393e-05, Validation Loss: 7.54477150621824e-05
Epoch 143, Training Loss: 7.544759137090296e-05, Validation Loss: 7.157305662985891e-05
Epoch 144, Training Loss: 7.157334766816348e-05, Validation Loss: 6.990336260059848e-05
Epoch 145, Training Loss: 6.990331166889518e-05, Validation Loss: 6.95114940754138e-05
Epoch 146, Training Loss: 6.951126124477014e-05, Validation Loss: 6.941876927157864e-05
Epoch 147, Training Loss: 6.941889296285808e-05, Validation Loss: 6.883068999741226e-05
Epoch 148, Training Loss: 6.883036257931963e-05, Validation Loss: 6.730332097504288e-05
Epoch 149, Training Loss: 6.730336463078856e-05, Validation Loss: 6.478141585830599e-05
Epoch 150, Training Loss: 6.478168506873772e-05, Validation Loss: 6.149034015834332e-05
Epoch 151, Training Loss: 6.149004184408113e-05, Validation Loss: 5.77266764594242e-05
Epoch 152, Training Loss: 5.772663644165732e-05, Validation Loss: 5.37375126441475e-05
Epoch 153, Training Loss: 5.373762905946933e-05, Validation Loss: 4.9681610107654706e-05
Epoch 154, Training Loss: 4.9681511882226914e-05, Validation Loss: 4.5671760744880885e-05
Epoch 155, Training Loss: 4.567172072711401e-05, Validation Loss: 4.18616364186164e-05
Epoch 156, Training Loss: 4.1861741920001805e-05, Validation Loss: 3.844807724817656e-05
Epoch 157, Training Loss: 3.8448059058282524e-05, Validation Loss: 3.559526157914661e-05
Epoch 158, Training Loss: 3.559508331818506e-05, Validation Loss: 3.3344709663651884e-05
Epoch 159, Training Loss: 3.3344644180033356e-05, Validation Loss: 3.157548053422943e-05
Epoch 160, Training Loss: 3.157548053422943e-05, Validation Loss: 3.0046710890019313e-05
Epoch 161, Training Loss: 3.0046743631828576e-05, Validation Loss: 2.8500378903117962e-05
Epoch 162, Training Loss: 2.8500549888121895e-05, Validation Loss: 2.675834002729971e-05
Epoch 163, Training Loss: 2.6758349122246727e-05, Validation Loss: 2.4765657144598663e-05
Epoch 164, Training Loss: 2.4765571652096696e-05, Validation Loss: 2.2572405214305036e-05
Epoch 165, Training Loss: 2.25722324103117e-05, Validation Loss: 2.0277444491512142e-05
Epoch 166, Training Loss: 2.027752088906709e-05, Validation Loss: 1.7980151824303903e-05
Epoch 167, Training Loss: 1.7980239135795273e-05, Validation Loss: 1.5761148461024277e-05
Epoch 168, Training Loss: 1.576109934831038e-05, Validation Loss: 1.3687063074030448e-05
Epoch 169, Training Loss: 1.3687012142327148e-05, Validation Loss: 1.1822798114735633e-05
Epoch 170, Training Loss: 1.1822814485640265e-05, Validation Loss: 1.0226066478935536e-05
Epoch 171, Training Loss: 1.0226045560557395e-05, Validation Loss: 8.929692739911843e-06
Epoch 172, Training Loss: 8.929585419537034e-06, Validation Loss: 7.923300472612027e-06
Epoch 173, Training Loss: 7.92325590737164e-06, Validation Loss: 7.151809313654667e-06
Epoch 174, Training Loss: 7.1518943514092825e-06, Validation Loss: 6.53406323181116e-06
Epoch 175, Training Loss: 6.53411461826181e-06, Validation Loss: 5.9919984778389335e-06
Epoch 176, Training Loss: 5.991963007545564e-06, Validation Loss: 5.473459168570116e-06
Epoch 177, Training Loss: 5.473495548358187e-06, Validation Loss: 4.958374574925983e-06
Epoch 178, Training Loss: 4.958375939168036e-06, Validation Loss: 4.44816305389395e-06
Epoch 179, Training Loss: 4.4481603254098445e-06, Validation Loss: 3.950738573621493e-06
Epoch 180, Training Loss: 3.950769951188704e-06, Validation Loss: 3.470895990176359e-06
Epoch 181, Training Loss: 3.470941464911448e-06, Validation Loss: 3.0097082799329655e-06
Epoch 182, Training Loss: 3.0096871341811493e-06, Validation Loss: 2.570272499724524e-06
Epoch 183, Training Loss: 2.5701906452013645e-06, Validation Loss: 2.1616185676975874e-06
Epoch 184, Training Loss: 2.1616494905174477e-06, Validation Loss: 1.7971217403101036e-06
Epoch 185, Training Loss: 1.7971132137972745e-06, Validation Loss: 1.488043039898912e-06
Epoch 186, Training Loss: 1.4880890830681892e-06, Validation Loss: 1.238336153619457e-06
Epoch 187, Training Loss: 1.238361051036918e-06, Validation Loss: 1.0431222108309157e-06
Epoch 188, Training Loss: 1.0431434702695697e-06, Validation Loss: 8.922016263568366e-07
Epoch 189, Training Loss: 8.92238631422515e-07, Validation Loss: 7.755421052024758e-07
Epoch 190, Training Loss: 7.755757565064414e-07, Validation Loss: 6.863052703920403e-07
Epoch 191, Training Loss: 6.862757686576515e-07, Validation Loss: 6.200988309501554e-07
Epoch 192, Training Loss: 6.200848474691156e-07, Validation Loss: 5.726386120841198e-07
Epoch 193, Training Loss: 5.726132599193079e-07, Validation Loss: 5.375606519919529e-07
Epoch 194, Training Loss: 5.375713953981176e-07, Validation Loss: 5.07246454617416e-07
Epoch 195, Training Loss: 5.072300268693652e-07, Validation Loss: 4.7499659672212147e-07
Epoch 196, Training Loss: 4.749969093609252e-07, Validation Loss: 4.3788151060653036e-07
Epoch 197, Training Loss: 4.3790046788672043e-07, Validation Loss: 3.970399973241001e-07
Epoch 198, Training Loss: 3.9704534060547303e-07, Validation Loss: 3.561378605354548e-07
Epoch 199, Training Loss: 3.561139294561144e-07, Validation Loss: 3.188640391726949e-07
Epoch 200, Training Loss: 3.1885343787507736e-07, Validation Loss: 2.8726640266540926e-07
Epoch 201, Training Loss: 2.8725216338898463e-07, Validation Loss: 2.615209666601004e-07
Epoch 202, Training Loss: 2.615371670344757e-07, Validation Loss: 2.407960550954158e-07
Epoch 203, Training Loss: 2.408264379027969e-07, Validation Loss: 2.2469910732070275e-07
Epoch 204, Training Loss: 2.246869001965024e-07, Validation Loss: 2.1322205157048302e-07
Epoch 205, Training Loss: 2.1324450472093304e-07, Validation Loss: 2.062776758293694e-07
Epoch 206, Training Loss: 2.062784147938146e-07, Validation Loss: 2.0271974676688842e-07
Epoch 207, Training Loss: 2.026965546519932e-07, Validation Loss: 2.0071740891580703e-07
Epoch 208, Training Loss: 2.0072104689461412e-07, Validation Loss: 1.9818568830487493e-07
Epoch 209, Training Loss: 1.981874362400049e-07, Validation Loss: 1.936954419079484e-07
Epoch 210, Training Loss: 1.9368005155229184e-07, Validation Loss: 1.866563792418674e-07
Epoch 211, Training Loss: 1.866421825980069e-07, Validation Loss: 1.7731869661474775e-07
Epoch 212, Training Loss: 1.772974229652391e-07, Validation Loss: 1.660700803540749e-07
Epoch 213, Training Loss: 1.6606817609954305e-07, Validation Loss: 1.5326432389883848e-07
Epoch 214, Training Loss: 1.5325710478464316e-07, Validation Loss: 1.3907674656365998e-07
Epoch 215, Training Loss: 1.3906851847877988e-07, Validation Loss: 1.238903450939688e-07
Epoch 216, Training Loss: 1.2387715742079308e-07, Validation Loss: 1.0834672536930157e-07
Epoch 217, Training Loss: 1.0834266817028038e-07, Validation Loss: 9.343106199821705e-08
Epoch 218, Training Loss: 9.34307848865501e-08, Validation Loss: 8.004534635119853e-08
Epoch 219, Training Loss: 8.005118701248648e-08, Validation Loss: 6.866746815603619e-08
Epoch 220, Training Loss: 6.866428492457999e-08, Validation Loss: 5.931266144898473e-08
Epoch 221, Training Loss: 5.931640600920218e-08, Validation Loss: 5.1639304388118035e-08
Epoch 222, Training Loss: 5.164580585415024e-08, Validation Loss: 4.51867592232702e-08
Epoch 223, Training Loss: 4.5187306341176736e-08, Validation Loss: 3.960164107752462e-08
Epoch 224, Training Loss: 3.960791872259506e-08, Validation Loss: 3.463227571387506e-08
Epoch 225, Training Loss: 3.4634481949069595e-08, Validation Loss: 3.009407834042577e-08
Epoch 226, Training Loss: 3.009172999668408e-08, Validation Loss: 2.5807002757005648e-08
Epoch 227, Training Loss: 2.58143089126861e-08, Validation Loss: 2.166185453233993e-08
Epoch 228, Training Loss: 2.1666075156190345e-08, Validation Loss: 1.7645513494812803e-08
Epoch 229, Training Loss: 1.764371759804817e-08, Validation Loss: 1.3888246108706426e-08
Epoch 230, Training Loss: 1.388870618512783e-08, Validation Loss: 1.059746335130285e-08
Epoch 231, Training Loss: 1.0597574373605312e-08, Validation Loss: 7.959233272458732e-09
Epoch 232, Training Loss: 7.95965338085125e-09, Validation Loss: 6.023015863831915e-09
Epoch 233, Training Loss: 6.02401017957277e-09, Validation Loss: 4.716570245477669e-09
Epoch 234, Training Loss: 4.714492796153991e-09, Validation Loss: 3.885143318171913e-09
Epoch 235, Training Loss: 3.884932819886444e-09, Validation Loss: 3.3881726313467198e-09
Epoch 236, Training Loss: 3.3871456750489415e-09, Validation Loss: 3.1217564089303096e-09
Epoch 237, Training Loss: 3.119590363809266e-09, Validation Loss: 3.0249767135615002e-09
Epoch 238, Training Loss: 3.0243421100806245e-09, Validation Loss: 3.047901708796985e-09
Epoch 239, Training Loss: 3.0491800195875385e-09, Validation Loss: 3.1335123384934604e-09
Epoch 240, Training Loss: 3.1334681516170804e-09, Validation Loss: 3.2276443739931437e-09
Epoch 241, Training Loss: 3.23061710716388e-09, Validation Loss: 3.3007219180092306e-09
Epoch 242, Training Loss: 3.2991462894926826e-09, Validation Loss: 3.352117694532808e-09
Epoch 243, Training Loss: 3.3535907384418806e-09, Validation Loss: 3.4009894900322024e-09
Epoch 244, Training Loss: 3.400795645092103e-09, Validation Loss: 3.454019070758818e-09
Epoch 245, Training Loss: 3.4563456541292226e-09, Validation Loss: 3.503573209329147e-09
Epoch 246, Training Loss: 3.504212919835936e-09, Validation Loss: 3.5327578640220736e-09
Epoch 247, Training Loss: 3.53248674755946e-09, Validation Loss: 3.5142238008489812e-09
Epoch 248, Training Loss: 3.513184632097932e-09, Validation Loss: 3.442572227285723e-09
Epoch 249, Training Loss: 3.442458984537211e-09, Validation Loss: 3.3322717918338185e-09
Epoch 250, Training Loss: 3.3321061465585444e-09, Validation Loss: 3.193647568622282e-09
Epoch 251, Training Loss: 3.1946005840666203e-09, Validation Loss: 3.0322238053770434e-09
Epoch 252, Training Loss: 3.0319455834870723e-09, Validation Loss: 2.842768243027649e-09
Epoch 253, Training Loss: 2.8425983789048814e-09, Validation Loss: 2.6224895588455865e-09
Epoch 254, Training Loss: 2.621143302405926e-09, Validation Loss: 2.373351293272208e-09
Epoch 255, Training Loss: 2.3739381571630247e-09, Validation Loss: 2.109629582136563e-09
Epoch 256, Training Loss: 2.1087267487729378e-09, Validation Loss: 1.8437961157857785e-09
Epoch 257, Training Loss: 1.844234542858203e-09, Validation Loss: 1.590439890897244e-09
Epoch 258, Training Loss: 1.5921910456739852e-09, Validation Loss: 1.3518779429233518e-09
Epoch 259, Training Loss: 1.3519207975321024e-09, Validation Loss: 1.1315333114936266e-09
Epoch 260, Training Loss: 1.1315804959721731e-09, Validation Loss: 9.295697545042003e-10
Epoch 261, Training Loss: 9.288119162675912e-10, Validation Loss: 7.5035405666668e-10
Epoch 262, Training Loss: 7.508966226588143e-10, Validation Loss: 5.997635166288262e-10
Epoch 263, Training Loss: 6.000365759817328e-10, Validation Loss: 4.750038695711112e-10
Epoch 264, Training Loss: 4.755632554420686e-10, Validation Loss: 3.7453279366772563e-10
Epoch 265, Training Loss: 3.7467381974742864e-10, Validation Loss: 2.942286414508999e-10
Epoch 266, Training Loss: 2.9312677285453503e-10, Validation Loss: 2.266836440778519e-10
Epoch 267, Training Loss: 2.2705601288031119e-10, Validation Loss: 1.7420476172702593e-10
Epoch 268, Training Loss: 1.7401649565762511e-10, Validation Loss: 1.3581068214474357e-10
Epoch 269, Training Loss: 1.351104783609003e-10, Validation Loss: 1.0920519349921776e-10
Epoch 270, Training Loss: 1.090873572029416e-10, Validation Loss: 9.20449827468417e-11
Epoch 271, Training Loss: 9.230836928164621e-11, Validation Loss: 8.164622450346215e-11
Epoch 272, Training Loss: 8.2098633447103e-11, Validation Loss: 7.544045943497224e-11
Epoch 273, Training Loss: 7.505832760879017e-11, Validation Loss: 7.104192928375497e-11
Epoch 274, Training Loss: 7.101905175055379e-11, Validation Loss: 6.919466388755069e-11
Epoch 275, Training Loss: 6.908928984472595e-11, Validation Loss: 7.018251257928654e-11
Epoch 276, Training Loss: 7.013430114444219e-11, Validation Loss: 7.281777264500633e-11
Epoch 277, Training Loss: 7.27770552155782e-11, Validation Loss: 7.692525783031812e-11
Epoch 278, Training Loss: 7.696752957198072e-11, Validation Loss: 8.089712927317194e-11
Epoch 279, Training Loss: 8.063348599929299e-11, Validation Loss: 8.390876188313356e-11
Epoch 280, Training Loss: 8.44030678681662e-11, Validation Loss: 8.637884851836475e-11
Epoch 281, Training Loss: 8.665837492038975e-11, Validation Loss: 8.769576731459949e-11
Epoch 282, Training Loss: 8.775653120851601e-11, Validation Loss: 8.694171077516799e-11
Epoch 283, Training Loss: 8.70168381794656e-11, Validation Loss: 8.471745527316443e-11
Epoch 284, Training Loss: 8.448505783853477e-11, Validation Loss: 8.028460535269843e-11
Epoch 285, Training Loss: 7.988441158568449e-11, Validation Loss: 7.398364559874082e-11
Epoch 286, Training Loss: 7.38463387661703e-11, Validation Loss: 6.730859619663576e-11
Epoch 287, Training Loss: 6.722256085112122e-11, Validation Loss: 6.037499666877721e-11
Epoch 288, Training Loss: 6.078704900547294e-11, Validation Loss: 5.470464359280669e-11
Epoch 289, Training Loss: 5.4696202428372587e-11, Validation Loss: 4.9596257656325804e-11
Epoch 290, Training Loss: 4.94753994717545e-11, Validation Loss: 4.516876456195362e-11
Epoch 291, Training Loss: 4.4956777883742305e-11, Validation Loss: 4.096041908430159e-11
Epoch 292, Training Loss: 4.080621951452201e-11, Validation Loss: 3.663463282732593e-11
Epoch 293, Training Loss: 3.6587399776522034e-11, Validation Loss: 3.267674325568848e-11
Epoch 294, Training Loss: 3.2873884170392387e-11, Validation Loss: 2.9052441008481367e-11
Epoch 295, Training Loss: 2.9154977043699404e-11, Validation Loss: 2.5324999042286578e-11
Epoch 296, Training Loss: 2.554148038902415e-11, Validation Loss: 2.180560072784221e-11
Epoch 297, Training Loss: 2.184139327732204e-11, Validation Loss: 1.807847448132005e-11
Epoch 298, Training Loss: 1.8354488068306196e-11, Validation Loss: 1.4993362454363002e-11
Epoch 299, Training Loss: 1.4907311496337172e-11, Validation Loss: 1.2236302249224451e-11
Epoch 300, Training Loss: 1.220552044850498e-11, Validation Loss: 9.748824143784862e-12
Epoch 301, Training Loss: 9.809275787475702e-12, Validation Loss: 8.020585931522994e-12
Epoch 302, Training Loss: 7.966357608302221e-12, Validation Loss: 6.542408975684921e-12
Epoch 303, Training Loss: 6.4765684135159596e-12, Validation Loss: 5.312096248988318e-12
Epoch 304, Training Loss: 5.20773701939703e-12, Validation Loss: 4.27501523764251e-12
Epoch 305, Training Loss: 4.190342517418344e-12, Validation Loss: 3.5916599555596562e-12
Epoch 306, Training Loss: 3.53150646746625e-12, Validation Loss: 3.130775153015186e-12
Epoch 307, Training Loss: 3.100745138082117e-12, Validation Loss: 2.7555592356509617e-12
Epoch 308, Training Loss: 2.750685530045205e-12, Validation Loss: 2.6394194989343145e-12
Epoch 309, Training Loss: 2.6044843365324866e-12, Validation Loss: 2.5284444676865192e-12
Epoch 310, Training Loss: 2.514729960725881e-12, Validation Loss: 2.4252054357798425e-12
Epoch 311, Training Loss: 2.408662895872493e-12, Validation Loss: 2.3526057404271716e-12
Epoch 312, Training Loss: 2.3269927651448086e-12, Validation Loss: 2.2578267380723993e-12
Epoch 313, Training Loss: 2.296167379498004e-12, Validation Loss: 2.2355038827026608e-12
Epoch 314, Training Loss: 2.2085742523020313e-12, Validation Loss: 2.145968732575332e-12
Epoch 315, Training Loss: 2.1122817037144692e-12, Validation Loss: 2.0608595125565232e-12
Epoch 316, Training Loss: 2.0636767034815096e-12, Validation Loss: 1.895158509290784e-12
Epoch 317, Training Loss: 1.918106081952309e-12, Validation Loss: 1.7671465419449861e-12
Epoch 318, Training Loss: 1.7608705292493365e-12, Validation Loss: 1.6087095848146826e-12
Epoch 319, Training Loss: 1.6570308493391028e-12, Validation Loss: 1.4787501735266662e-12
Epoch 320, Training Loss: 1.5230914402961093e-12, Validation Loss: 1.395197542566895e-12
Epoch 321, Training Loss: 1.3917471775731771e-12, Validation Loss: 1.2753975393159367e-12
Epoch 322, Training Loss: 1.30057705056974e-12, Validation Loss: 1.2001538001252254e-12
Epoch 323, Training Loss: 1.1933576956474345e-12, Validation Loss: 1.1064380748410096e-12
Epoch 324, Training Loss: 1.0924586972896333e-12, Validation Loss: 1.0304823400836272e-12
Epoch 325, Training Loss: 1.0112172601009495e-12, Validation Loss: 9.26531637870931e-13
Epoch 326, Training Loss: 9.704581973093984e-13, Validation Loss: 8.897918751631095e-13
Epoch 327, Training Loss: 8.63393937507867e-13, Validation Loss: 7.911269838019319e-13
Epoch 328, Training Loss: 7.943214770829432e-13, Validation Loss: 7.321364651688422e-13
Epoch 329, Training Loss: 7.463403809901403e-13, Validation Loss: 6.65527962601109e-13
Epoch 330, Training Loss: 6.483064952933493e-13, Validation Loss: 5.99995910160328e-13
Epoch 331, Training Loss: 5.601658460002712e-13, Validation Loss: 5.341781162369885e-13
Epoch 332, Training Loss: 5.331077918523108e-13, Validation Loss: 4.879424772216701e-13
Epoch 333, Training Loss: 4.911634792457986e-13, Validation Loss: 4.407720390932346e-13
Epoch 334, Training Loss: 4.13763722719937e-13, Validation Loss: 3.7943842404013217e-13
Epoch 335, Training Loss: 3.7412640260109375e-13, Validation Loss: 3.3603987105966515e-13
Epoch 336, Training Loss: 3.329472656778132e-13, Validation Loss: 2.8107361273524423e-13
Epoch 337, Training Loss: 2.9650736618584694e-13, Validation Loss: 2.618289970685722e-13
Epoch 338, Training Loss: 2.5441814995898204e-13, Validation Loss: 2.2051895628549117e-13
Epoch 339, Training Loss: 2.2582367291239247e-13, Validation Loss: 1.9478217866755743e-13
Epoch 340, Training Loss: 1.926986809052192e-13, Validation Loss: 1.7446291536004493e-13
Epoch 341, Training Loss: 1.643718256123805e-13, Validation Loss: 1.4423752719549404e-13
Epoch 342, Training Loss: 1.4368856853051032e-13, Validation Loss: 1.30130959176758e-13
Epoch 343, Training Loss: 1.3072293356293507e-13, Validation Loss: 1.0676165897519074e-13
Epoch 344, Training Loss: 1.1510107103540612e-13, Validation Loss: 1.0166185655888921e-13
Epoch 345, Training Loss: 1.0891188260498189e-13, Validation Loss: 8.739102513475802e-14
Epoch 346, Training Loss: 9.307614087013943e-14, Validation Loss: 8.246357020630021e-14
Epoch 347, Training Loss: 9.309468750355251e-14, Validation Loss: 7.871404672813928e-14
Epoch 348, Training Loss: 7.4230721667113e-14, Validation Loss: 7.055969442624002e-14
Epoch 349, Training Loss: 6.49065423261562e-14, Validation Loss: 6.976416785844236e-14
Epoch 350, Training Loss: 6.601452240753702e-14, Validation Loss: 6.014026082690194e-14
Epoch 351, Training Loss: 6.340093787427989e-14, Validation Loss: 5.4480244371813563e-14
Epoch 352, Training Loss: 5.686363923132487e-14, Validation Loss: 5.1705435587376045e-14
Epoch 353, Training Loss: 5.1658306674190815e-14, Validation Loss: 4.771429765507672e-14
Epoch 354, Training Loss: 4.381917598954635e-14, Validation Loss: 4.561589888913038e-14
Epoch 355, Training Loss: 4.303457953490006e-14, Validation Loss: 4.1700394222757287e-14
Epoch 356, Training Loss: 3.652833989605496e-14, Validation Loss: 3.412427065636707e-14
Epoch 357, Training Loss: 3.117985538270314e-14, Validation Loss: 3.19882771800898e-14
Epoch 358, Training Loss: 2.5155660500074568e-14, Validation Loss: 2.995874896901882e-14
Epoch 359, Training Loss: 2.6796466656925713e-14, Validation Loss: 3.12906167990179e-14
Epoch 360, Training Loss: 2.3284120874325458e-14, Validation Loss: 2.5702689624004446e-14
Epoch 361, Training Loss: 2.022909665027727e-14, Validation Loss: 2.4898211612020202e-14
Epoch 362, Training Loss: 1.6682696755065604e-14, Validation Loss: 2.4419920905825905e-14
Epoch 363, Training Loss: 1.3952992475069377e-14, Validation Loss: 2.0217863299330785e-14
Epoch 364, Training Loss: 1.4400066629025564e-14, Validation Loss: 1.7297247957418806e-14
Epoch 365, Training Loss: 1.3354521346186851e-14, Validation Loss: 1.9781621002704086e-14
Epoch 366, Training Loss: 9.454679166041435e-15, Validation Loss: 1.7818664499089608e-14
Epoch 367, Training Loss: 1.2589382932404886e-14, Validation Loss: 1.54233620504058e-14
Epoch 368, Training Loss: 1.0055351733553874e-14, Validation Loss: 1.282282860079996e-14
Epoch 369, Training Loss: 7.485358903894235e-15, Validation Loss: 1.196332309339734e-14
Epoch 370, Training Loss: 7.346680975703866e-15, Validation Loss: 1.471991474023826e-14
Epoch 371, Training Loss: 8.47514316078225e-15, Validation Loss: 1.0089663344181252e-14
Epoch 372, Training Loss: 5.053968616492658e-15, Validation Loss: 9.164221404032568e-15
Epoch 373, Training Loss: 6.550634753193065e-15, Validation Loss: 1.0644991696928327e-14
Epoch 374, Training Loss: 4.519448475127832e-15, Validation Loss: 1.1356378246910482e-14
Epoch 375, Training Loss: 6.050692190801054e-15, Validation Loss: 8.426570903454899e-15
Epoch 376, Training Loss: 2.989472344260176e-15, Validation Loss: 1.0583633477262173e-14
Epoch 377, Training Loss: 4.886092192061013e-15, Validation Loss: 7.599350056836877e-15
Epoch 378, Training Loss: 2.9820997694872745e-15, Validation Loss: 1.0191828223114329e-14
Epoch 379, Training Loss: 3.620010869976329e-15, Validation Loss: 8.915071744795399e-15
Epoch 380, Training Loss: 4.318812627944653e-15, Validation Loss: 9.30771979672576e-15
Epoch 381, Training Loss: 5.491636046053112e-15, Validation Loss: 1.0594784666012776e-14
Epoch 382, Training Loss: 3.9244467931972594e-15, Validation Loss: 7.01111193299013e-15
Epoch 383, Training Loss: 3.9148973437499145e-15, Validation Loss: 6.843769562831729e-15
Epoch 384, Training Loss: 2.7579534640618684e-15, Validation Loss: 9.179141889398452e-15
Epoch 385, Training Loss: 4.343090286278856e-15, Validation Loss: 9.51813802741678e-15
Epoch 386, Training Loss: 5.3035184987974045e-15, Validation Loss: 7.582853243156152e-15
Epoch 387, Training Loss: 3.594081920911454e-15, Validation Loss: 8.358191627688954e-15
Epoch 388, Training Loss: 2.8395104549047223e-15, Validation Loss: 8.28395681315864e-15
Epoch 389, Training Loss: 3.961209293657517e-15, Validation Loss: 7.255599522885611e-15
Epoch 390, Training Loss: 4.726856350724309e-15, Validation Loss: 1.0672538055405984e-14
Epoch 391, Training Loss: 4.76128400486546e-15, Validation Loss: 9.684446170346583e-15
Epoch 392, Training Loss: 4.270223853474831e-15, Validation Loss: 7.306690856198096e-15
Epoch 393, Training Loss: 4.367401402414475e-15, Validation Loss: 6.84271881846066e-15
Epoch 394, Training Loss: 3.8141664915965386e-15, Validation Loss: 6.784005035655833e-15
Epoch 395, Training Loss: 3.0417558764459212e-15, Validation Loss: 7.731030645849978e-15
Epoch 396, Training Loss: 2.3051571790305052e-15, Validation Loss: 7.853027954210067e-15
Epoch 397, Training Loss: 1.9045694637690553e-15, Validation Loss: 7.337415282293851e-15
Epoch 398, Training Loss: 1.6923995689431147e-15, Validation Loss: 7.710380829628865e-15
Epoch 399, Training Loss: 1.7444412732224189e-15, Validation Loss: 7.381516899725594e-15
Epoch 400, Training Loss: 2.2145845812553133e-15, Validation Loss: 7.368707220464267e-15
Epoch 401, Training Loss: 1.7674263592791116e-15, Validation Loss: 9.930760810309292e-15
Epoch 402, Training Loss: 1.8528280326695528e-15, Validation Loss: 7.555522878080045e-15
Epoch 403, Training Loss: 1.8826853087855564e-15, Validation Loss: 8.87952685419682e-15
Epoch 404, Training Loss: 2.6699829515006417e-15, Validation Loss: 8.236344244160528e-15
Epoch 405, Training Loss: 2.3122629384250215e-15, Validation Loss: 1.135204143822054e-14
Epoch 406, Training Loss: 2.3568736226580638e-15, Validation Loss: 1.1324318896889854e-14
Epoch 407, Training Loss: 2.8759563768009436e-15, Validation Loss: 1.1297630582787765e-14
Epoch 408, Training Loss: 2.756960953205923e-15, Validation Loss: 7.374085879679332e-15
Epoch 409, Training Loss: 2.821512698841463e-15, Validation Loss: 1.0180068864707598e-14
Epoch 410, Training Loss: 3.002991413614828e-15, Validation Loss: 1.0172462508841254e-14
Epoch 411, Training Loss: 2.9502492130881446e-15, Validation Loss: 7.826982538114945e-15
Epoch 412, Training Loss: 2.9502492130881446e-15, Validation Loss: 6.2890498032572555e-15
Epoch 413, Training Loss: 2.2868508912162085e-15, Validation Loss: 6.531152148373269e-15
Epoch 414, Training Loss: 4.603440685694042e-15, Validation Loss: 6.34967364535814e-15
Epoch 415, Training Loss: 3.1465732390533255e-15, Validation Loss: 6.705917491764933e-15
Epoch 416, Training Loss: 3.604682114729868e-15, Validation Loss: 7.124920126816165e-15
Epoch 417, Training Loss: 4.3942481116777e-15, Validation Loss: 6.484773282862833e-15
Epoch 418, Training Loss: 2.3898418390310957e-15, Validation Loss: 6.334286021321845e-15
Epoch 419, Training Loss: 1.8425031245589965e-15, Validation Loss: 9.761033195371423e-15
Epoch 420, Training Loss: 2.0239818393323616e-15, Validation Loss: 5.986482434717968e-15
Epoch 421, Training Loss: 2.082695622137188e-15, Validation Loss: 6.061534212525909e-15
Epoch 422, Training Loss: 1.9668026684697233e-15, Validation Loss: 8.778378414800447e-15
Epoch 423, Training Loss: 1.5464658506474474e-15, Validation Loss: 7.851769263250447e-15
Epoch 424, Training Loss: 2.42660455124959e-15, Validation Loss: 8.40678082567525e-15
Epoch 425, Training Loss: 2.2105313168444647e-15, Validation Loss: 8.444143448978637e-15
Epoch 426, Training Loss: 2.0223807353038142e-15, Validation Loss: 7.207118745116564e-15
Epoch 427, Training Loss: 2.1025115344217287e-15, Validation Loss: 7.199513236283168e-15
Epoch 428, Training Loss: 2.0812944178841926e-15, Validation Loss: 8.651342954470089e-15
Epoch 429, Training Loss: 2.3550806656669632e-15, Validation Loss: 8.679765992048154e-15
Epoch 430, Training Loss: 1.694059224124141e-15, Validation Loss: 8.938239789968699e-15
Epoch 431, Training Loss: 2.1344120657647465e-15, Validation Loss: 9.090512596962499e-15
Epoch 432, Training Loss: 2.0263253677391775e-15, Validation Loss: 7.013780933806928e-15
Epoch 433, Training Loss: 2.2064697938623803e-15, Validation Loss: 7.143351563748419e-15
Epoch 434, Training Loss: 2.191657940471981e-15, Validation Loss: 8.103587076271467e-15
Epoch 435, Training Loss: 1.902092527673047e-15, Validation Loss: 8.126272312664832e-15
Epoch 436, Training Loss: 2.184885912058683e-15, Validation Loss: 7.922776035218775e-15
Epoch 437, Training Loss: 1.4859924627738186e-15, Validation Loss: 8.066891067897569e-15
Epoch 438, Training Loss: 6.061792981091295e-15, Validation Loss: 1.0501509397861132e-14
Epoch 439, Training Loss: 6.0804742927429885e-15, Validation Loss: 9.592381312276566e-15
Epoch 440, Training Loss: 4.174647196805497e-15, Validation Loss: 1.003340087472578e-14
Epoch 441, Training Loss: 2.0257582791809907e-15, Validation Loss: 1.0038738876359376e-14
Epoch 442, Training Loss: 2.830870295326255e-15, Validation Loss: 9.978023554700188e-15
Epoch 443, Training Loss: 3.555350915881777e-15, Validation Loss: 1.0191527526418054e-14
Epoch 444, Training Loss: 3.010914559803445e-15, Validation Loss: 1.0156299426141747e-14
Epoch 445, Training Loss: 4.560389389116895e-15, Validation Loss: 1.0156299426141747e-14
Epoch 446, Training Loss: 3.1107611095598873e-15, Validation Loss: 1.018161978203402e-14
Epoch 447, Training Loss: 2.7818308993284935e-15, Validation Loss: 7.383960589778422e-15
Epoch 448, Training Loss: 1.5006709084750252e-15, Validation Loss: 1.0162654714344996e-14
Epoch 449, Training Loss: 1.4200396187644018e-15, Validation Loss: 7.429797777719089e-15
Epoch 450, Training Loss: 1.5948130089690651e-15, Validation Loss: 7.429797777719089e-15
Epoch 451, Training Loss: 1.7055683901740773e-15, Validation Loss: 6.0633688858896615e-15
Epoch 452, Training Loss: 1.7055683901740773e-15, Validation Loss: 6.0633688858896615e-15
Epoch 453, Training Loss: 1.5611860127213062e-15, Validation Loss: 8.940342125743784e-15
Epoch 454, Training Loss: 1.557182829133464e-15, Validation Loss: 8.940342125743784e-15
Epoch 455, Training Loss: 1.5411699889029767e-15, Validation Loss: 6.341758969498996e-15
Epoch 456, Training Loss: 2.240397063289941e-15, Validation Loss: 7.190438972319232e-15
Epoch 457, Training Loss: 2.3738373632509625e-15, Validation Loss: 6.2943873813743785e-15
Epoch 458, Training Loss: 2.195027225777922e-15, Validation Loss: 3.963853307002371e-15
Epoch 459, Training Loss: 2.416538199946183e-15, Validation Loss: 5.399670714354397e-15
Epoch 460, Training Loss: 2.961007802067695e-15, Validation Loss: 6.9079793189148146e-15
Epoch 461, Training Loss: 2.666104811151638e-15, Validation Loss: 6.40624401128994e-15
Epoch 462, Training Loss: 1.7133412938936748e-15, Validation Loss: 5.1679182648208845e-15
Epoch 463, Training Loss: 1.7235161712934486e-15, Validation Loss: 7.006224552884473e-15
Epoch 464, Training Loss: 2.5094793136001348e-15, Validation Loss: 8.628858464885224e-15
Epoch 465, Training Loss: 3.375506762938376e-15, Validation Loss: 8.24188129853673e-15
Epoch 466, Training Loss: 2.0290276145991555e-15, Validation Loss: 8.23707777469285e-15
Epoch 467, Training Loss: 2.0925451330060978e-15, Validation Loss: 8.176729218299823e-15
Epoch 468, Training Loss: 2.0578506634865617e-15, Validation Loss: 7.854270551543689e-15
Epoch 469, Training Loss: 2.5689602964969367e-15, Validation Loss: 7.157379276387897e-15
Epoch 470, Training Loss: 2.633011657418886e-15, Validation Loss: 7.531545916442117e-15
Epoch 471, Training Loss: 3.031797945359763e-15, Validation Loss: 7.141766765104106e-15
Epoch 472, Training Loss: 3.242366736157156e-15, Validation Loss: 6.3952351240744755e-15
Epoch 473, Training Loss: 2.2215486743894014e-15, Validation Loss: 7.652775812951994e-15
Epoch 474, Training Loss: 2.1884887666998292e-15, Validation Loss: 8.393369753021372e-15
Epoch 475, Training Loss: 1.5255574776191854e-15, Validation Loss: 7.337782047560013e-15
Epoch 476, Training Loss: 1.763981899799102e-15, Validation Loss: 6.14937152915618e-15
Epoch 477, Training Loss: 2.2710549972993366e-15, Validation Loss: 9.54449261053765e-15
Epoch 478, Training Loss: 1.2577761640368557e-15, Validation Loss: 5.797155747930055e-15
Epoch 479, Training Loss: 2.496735702908694e-15, Validation Loss: 5.833851756303953e-15
Epoch 480, Training Loss: 1.7654830539398734e-15, Validation Loss: 7.090859237941175e-15
Epoch 481, Training Loss: 2.033697942512079e-15, Validation Loss: 7.885496421144219e-15
Epoch 482, Training Loss: 2.2617473757584328e-15, Validation Loss: 8.435603662804419e-15
Epoch 483, Training Loss: 2.252406719932586e-15, Validation Loss: 6.937194332298563e-15
Epoch 484, Training Loss: 4.586010018188969e-15, Validation Loss: 6.956543105912693e-15
Epoch 485, Training Loss: 3.26335007160125e-15, Validation Loss: 4.356910052329783e-15
Epoch 486, Training Loss: 4.011616647865094e-15, Validation Loss: 5.718934796349962e-15
Epoch 487, Training Loss: 2.625171943975574e-15, Validation Loss: 7.0476745336748355e-15
Epoch 488, Training Loss: 2.761614763976375e-15, Validation Loss: 8.698230463265351e-15
Epoch 489, Training Loss: 2.3265993945737742e-15, Validation Loss: 7.53666623060827e-15
Epoch 490, Training Loss: 3.251340414958605e-15, Validation Loss: 6.495732195134409e-15
Epoch 491, Training Loss: 2.2216153782339976e-15, Validation Loss: 6.319424404745795e-15
Epoch 492, Training Loss: 3.956939400570408e-15, Validation Loss: 5.590173082873099e-15
Epoch 493, Training Loss: 2.0541478589576395e-15, Validation Loss: 7.185351692438023e-15
Epoch 494, Training Loss: 2.6280743023693407e-15, Validation Loss: 7.14064868161373e-15
Epoch 495, Training Loss: 1.6721416113392256e-15, Validation Loss: 6.410780719755434e-15
Epoch 496, Training Loss: 1.5613862301342134e-15, Validation Loss: 9.847535588076821e-15
Epoch 497, Training Loss: 1.4252437891923322e-15, Validation Loss: 8.988847467468301e-15
Epoch 498, Training Loss: 1.9488301116366447e-15, Validation Loss: 8.821713467414925e-15
Epoch 499, Training Loss: 2.6413850016189684e-15, Validation Loss: 9.180667395736457e-15
Epoch 500, Training Loss: 2.107624013533119e-15, Validation Loss: 6.142232311960247e-15
