Epoch 1, Training Loss: 0.5157918334007263, Validation Loss: 0.5143028497695923
Epoch 2, Training Loss: 0.5143029093742371, Validation Loss: 0.5128202438354492
Epoch 3, Training Loss: 0.5128201842308044, Validation Loss: 0.5113426446914673
Epoch 4, Training Loss: 0.5113426446914673, Validation Loss: 0.509909987449646
Epoch 5, Training Loss: 0.509909987449646, Validation Loss: 0.5085077285766602
Epoch 6, Training Loss: 0.5085077285766602, Validation Loss: 0.5070910453796387
Epoch 7, Training Loss: 0.5070910453796387, Validation Loss: 0.5056495666503906
Epoch 8, Training Loss: 0.5056495666503906, Validation Loss: 0.5041855573654175
Epoch 9, Training Loss: 0.5041855573654175, Validation Loss: 0.5026947259902954
Epoch 10, Training Loss: 0.5026947259902954, Validation Loss: 0.5012038946151733
Epoch 11, Training Loss: 0.5012038946151733, Validation Loss: 0.49970075488090515
Epoch 12, Training Loss: 0.49970072507858276, Validation Loss: 0.4981631636619568
Epoch 13, Training Loss: 0.4981631636619568, Validation Loss: 0.49661409854888916
Epoch 14, Training Loss: 0.49661409854888916, Validation Loss: 0.49502477049827576
Epoch 15, Training Loss: 0.49502477049827576, Validation Loss: 0.49340569972991943
Epoch 16, Training Loss: 0.49340569972991943, Validation Loss: 0.49180442094802856
Epoch 17, Training Loss: 0.49180442094802856, Validation Loss: 0.490196168422699
Epoch 18, Training Loss: 0.490196168422699, Validation Loss: 0.48853442072868347
Epoch 19, Training Loss: 0.48853442072868347, Validation Loss: 0.48680680990219116
Epoch 20, Training Loss: 0.4868067800998688, Validation Loss: 0.48501288890838623
Epoch 21, Training Loss: 0.48501288890838623, Validation Loss: 0.4831247627735138
Epoch 22, Training Loss: 0.4831247627735138, Validation Loss: 0.48111769556999207
Epoch 23, Training Loss: 0.48111769556999207, Validation Loss: 0.47906428575515747
Epoch 24, Training Loss: 0.47906434535980225, Validation Loss: 0.4769154489040375
Epoch 25, Training Loss: 0.4769154489040375, Validation Loss: 0.474662184715271
Epoch 26, Training Loss: 0.474662184715271, Validation Loss: 0.47232815623283386
Epoch 27, Training Loss: 0.4723281264305115, Validation Loss: 0.46984320878982544
Epoch 28, Training Loss: 0.46984320878982544, Validation Loss: 0.46724948287010193
Epoch 29, Training Loss: 0.46724948287010193, Validation Loss: 0.4645358920097351
Epoch 30, Training Loss: 0.4645358920097351, Validation Loss: 0.4616515338420868
Epoch 31, Training Loss: 0.4616515636444092, Validation Loss: 0.45860427618026733
Epoch 32, Training Loss: 0.45860427618026733, Validation Loss: 0.45542284846305847
Epoch 33, Training Loss: 0.45542284846305847, Validation Loss: 0.4520164132118225
Epoch 34, Training Loss: 0.4520164132118225, Validation Loss: 0.44837090373039246
Epoch 35, Training Loss: 0.44837090373039246, Validation Loss: 0.4444294273853302
Epoch 36, Training Loss: 0.4444294571876526, Validation Loss: 0.4402581751346588
Epoch 37, Training Loss: 0.4402581751346588, Validation Loss: 0.4357817471027374
Epoch 38, Training Loss: 0.43578171730041504, Validation Loss: 0.4309834837913513
Epoch 39, Training Loss: 0.4309835135936737, Validation Loss: 0.4258551299571991
Epoch 40, Training Loss: 0.4258551299571991, Validation Loss: 0.42033305764198303
Epoch 41, Training Loss: 0.42033305764198303, Validation Loss: 0.41439148783683777
Epoch 42, Training Loss: 0.4143914580345154, Validation Loss: 0.40803882479667664
Epoch 43, Training Loss: 0.40803882479667664, Validation Loss: 0.4012935161590576
Epoch 44, Training Loss: 0.40129354596138, Validation Loss: 0.3940737843513489
Epoch 45, Training Loss: 0.3940737843513489, Validation Loss: 0.38633108139038086
Epoch 46, Training Loss: 0.38633114099502563, Validation Loss: 0.3780374526977539
Epoch 47, Training Loss: 0.3780374526977539, Validation Loss: 0.3692079186439514
Epoch 48, Training Loss: 0.3692079186439514, Validation Loss: 0.3598329722881317
Epoch 49, Training Loss: 0.3598329722881317, Validation Loss: 0.34989452362060547
Epoch 50, Training Loss: 0.34989452362060547, Validation Loss: 0.33942076563835144
Epoch 51, Training Loss: 0.33942079544067383, Validation Loss: 0.32842931151390076
Epoch 52, Training Loss: 0.32842931151390076, Validation Loss: 0.31698542833328247
Epoch 53, Training Loss: 0.31698542833328247, Validation Loss: 0.30507150292396545
Epoch 54, Training Loss: 0.30507150292396545, Validation Loss: 0.2927836775779724
Epoch 55, Training Loss: 0.2927836775779724, Validation Loss: 0.28020498156547546
Epoch 56, Training Loss: 0.28020498156547546, Validation Loss: 0.26745063066482544
Epoch 57, Training Loss: 0.26745063066482544, Validation Loss: 0.25472527742385864
Epoch 58, Training Loss: 0.25472527742385864, Validation Loss: 0.242177352309227
Epoch 59, Training Loss: 0.24217736721038818, Validation Loss: 0.23007073998451233
Epoch 60, Training Loss: 0.23007073998451233, Validation Loss: 0.218603253364563
Epoch 61, Training Loss: 0.2186032086610794, Validation Loss: 0.20812609791755676
Epoch 62, Training Loss: 0.20812611281871796, Validation Loss: 0.19894307851791382
Epoch 63, Training Loss: 0.19894307851791382, Validation Loss: 0.19131845235824585
Epoch 64, Training Loss: 0.19131845235824585, Validation Loss: 0.18541014194488525
Epoch 65, Training Loss: 0.18541015684604645, Validation Loss: 0.1813203990459442
Epoch 66, Training Loss: 0.18132038414478302, Validation Loss: 0.17891836166381836
Epoch 67, Training Loss: 0.17891836166381836, Validation Loss: 0.17782114446163177
Epoch 68, Training Loss: 0.17782114446163177, Validation Loss: 0.17751330137252808
Epoch 69, Training Loss: 0.17751330137252808, Validation Loss: 0.17741437256336212
Epoch 70, Training Loss: 0.17741435766220093, Validation Loss: 0.17684125900268555
Epoch 71, Training Loss: 0.17684125900268555, Validation Loss: 0.17541730403900146
Epoch 72, Training Loss: 0.17541731894016266, Validation Loss: 0.1729937046766281
Epoch 73, Training Loss: 0.17299368977546692, Validation Loss: 0.16967004537582397
Epoch 74, Training Loss: 0.16967004537582397, Validation Loss: 0.16573920845985413
Epoch 75, Training Loss: 0.16573920845985413, Validation Loss: 0.1615232229232788
Epoch 76, Training Loss: 0.16152320802211761, Validation Loss: 0.1573459655046463
Epoch 77, Training Loss: 0.1573459655046463, Validation Loss: 0.15347075462341309
Epoch 78, Training Loss: 0.1534707397222519, Validation Loss: 0.1500110924243927
Epoch 79, Training Loss: 0.1500110924243927, Validation Loss: 0.14703701436519623
Epoch 80, Training Loss: 0.14703701436519623, Validation Loss: 0.14454998075962067
Epoch 81, Training Loss: 0.14454998075962067, Validation Loss: 0.1424713432788849
Epoch 82, Training Loss: 0.14247135818004608, Validation Loss: 0.14069418609142303
Epoch 83, Training Loss: 0.14069418609142303, Validation Loss: 0.13907559216022491
Epoch 84, Training Loss: 0.13907557725906372, Validation Loss: 0.1375274509191513
Epoch 85, Training Loss: 0.1375274360179901, Validation Loss: 0.13595877587795258
Epoch 86, Training Loss: 0.13595876097679138, Validation Loss: 0.13433513045310974
Epoch 87, Training Loss: 0.13433513045310974, Validation Loss: 0.13271234929561615
Epoch 88, Training Loss: 0.13271233439445496, Validation Loss: 0.13103429973125458
Epoch 89, Training Loss: 0.13103429973125458, Validation Loss: 0.12928158044815063
Epoch 90, Training Loss: 0.12928156554698944, Validation Loss: 0.12746910750865936
Epoch 91, Training Loss: 0.12746909260749817, Validation Loss: 0.12560732662677765
Epoch 92, Training Loss: 0.12560732662677765, Validation Loss: 0.12374146282672882
Epoch 93, Training Loss: 0.12374146282672882, Validation Loss: 0.1219089925289154
Epoch 94, Training Loss: 0.121908999979496, Validation Loss: 0.1201338842511177
Epoch 95, Training Loss: 0.1201338842511177, Validation Loss: 0.11844675987958908
Epoch 96, Training Loss: 0.11844675242900848, Validation Loss: 0.11683536320924759
Epoch 97, Training Loss: 0.11683537065982819, Validation Loss: 0.11529427766799927
Epoch 98, Training Loss: 0.11529428511857986, Validation Loss: 0.11390441656112671
Epoch 99, Training Loss: 0.1139044240117073, Validation Loss: 0.11250326782464981
Epoch 100, Training Loss: 0.11250326782464981, Validation Loss: 0.11117666214704514
Epoch 101, Training Loss: 0.11117666214704514, Validation Loss: 0.109813392162323
Epoch 102, Training Loss: 0.109813392162323, Validation Loss: 0.10839981585741043
Epoch 103, Training Loss: 0.10839982330799103, Validation Loss: 0.10692708939313889
Epoch 104, Training Loss: 0.10692707449197769, Validation Loss: 0.10538128018379211
Epoch 105, Training Loss: 0.10538128018379211, Validation Loss: 0.10380793362855911
Epoch 106, Training Loss: 0.10380793362855911, Validation Loss: 0.1022157222032547
Epoch 107, Training Loss: 0.1022157147526741, Validation Loss: 0.10054600983858109
Epoch 108, Training Loss: 0.10054600983858109, Validation Loss: 0.09880152344703674
Epoch 109, Training Loss: 0.09880152344703674, Validation Loss: 0.09699922055006027
Epoch 110, Training Loss: 0.09699922800064087, Validation Loss: 0.09512393921613693
Epoch 111, Training Loss: 0.09512393921613693, Validation Loss: 0.0931726023554802
Epoch 112, Training Loss: 0.09317260980606079, Validation Loss: 0.09113147854804993
Epoch 113, Training Loss: 0.09113147854804993, Validation Loss: 0.08905564993619919
Epoch 114, Training Loss: 0.08905564248561859, Validation Loss: 0.08685914427042007
Epoch 115, Training Loss: 0.08685913681983948, Validation Loss: 0.08459840714931488
Epoch 116, Training Loss: 0.08459841459989548, Validation Loss: 0.08222426474094391
Epoch 117, Training Loss: 0.08222426474094391, Validation Loss: 0.07975213974714279
Epoch 118, Training Loss: 0.07975213974714279, Validation Loss: 0.077200748026371
Epoch 119, Training Loss: 0.077200748026371, Validation Loss: 0.07457750290632248
Epoch 120, Training Loss: 0.07457750290632248, Validation Loss: 0.07190157473087311
Epoch 121, Training Loss: 0.07190156728029251, Validation Loss: 0.06916113197803497
Epoch 122, Training Loss: 0.06916112452745438, Validation Loss: 0.06636644154787064
Epoch 123, Training Loss: 0.06636644899845123, Validation Loss: 0.06353584676980972
Epoch 124, Training Loss: 0.06353584676980972, Validation Loss: 0.06066880375146866
Epoch 125, Training Loss: 0.06066880375146866, Validation Loss: 0.05779879912734032
Epoch 126, Training Loss: 0.05779879540205002, Validation Loss: 0.05490162968635559
Epoch 127, Training Loss: 0.05490163341164589, Validation Loss: 0.05199148878455162
Epoch 128, Training Loss: 0.05199149250984192, Validation Loss: 0.049083370715379715
Epoch 129, Training Loss: 0.04908337816596031, Validation Loss: 0.04619396850466728
Epoch 130, Training Loss: 0.046193964779376984, Validation Loss: 0.0433499701321125
Epoch 131, Training Loss: 0.0433499738574028, Validation Loss: 0.040613193064928055
Epoch 132, Training Loss: 0.04061318561434746, Validation Loss: 0.03798569738864899
Epoch 133, Training Loss: 0.03798569366335869, Validation Loss: 0.03547140955924988
Epoch 134, Training Loss: 0.03547140583395958, Validation Loss: 0.033090341836214066
Epoch 135, Training Loss: 0.033090341836214066, Validation Loss: 0.030866699293255806
Epoch 136, Training Loss: 0.030866697430610657, Validation Loss: 0.02880527451634407
Epoch 137, Training Loss: 0.028805270791053772, Validation Loss: 0.026930393651127815
Epoch 138, Training Loss: 0.026930393651127815, Validation Loss: 0.025190019980072975
Epoch 139, Training Loss: 0.025190019980072975, Validation Loss: 0.02358446829020977
Epoch 140, Training Loss: 0.02358447201550007, Validation Loss: 0.022085756063461304
Epoch 141, Training Loss: 0.022085754200816154, Validation Loss: 0.020678196102380753
Epoch 142, Training Loss: 0.020678196102380753, Validation Loss: 0.019340354949235916
Epoch 143, Training Loss: 0.019340354949235916, Validation Loss: 0.018046170473098755
Epoch 144, Training Loss: 0.018046170473098755, Validation Loss: 0.016776997596025467
Epoch 145, Training Loss: 0.01677699014544487, Validation Loss: 0.015560171566903591
Epoch 146, Training Loss: 0.015560170635581017, Validation Loss: 0.014367586933076382
Epoch 147, Training Loss: 0.014367588795721531, Validation Loss: 0.013183929957449436
Epoch 148, Training Loss: 0.013183929957449436, Validation Loss: 0.012030122801661491
Epoch 149, Training Loss: 0.012030121870338917, Validation Loss: 0.010914125479757786
Epoch 150, Training Loss: 0.010914125479757786, Validation Loss: 0.009847436100244522
Epoch 151, Training Loss: 0.009847432374954224, Validation Loss: 0.00884478073567152
Epoch 152, Training Loss: 0.00884478259831667, Validation Loss: 0.007906951010227203
Epoch 153, Training Loss: 0.007906952872872353, Validation Loss: 0.007032015826553106
Epoch 154, Training Loss: 0.007032018154859543, Validation Loss: 0.006222082301974297
Epoch 155, Training Loss: 0.006222080904990435, Validation Loss: 0.005475230049341917
Epoch 156, Training Loss: 0.005475230049341917, Validation Loss: 0.004789761267602444
Epoch 157, Training Loss: 0.004789759870618582, Validation Loss: 0.004164030309766531
Epoch 158, Training Loss: 0.004164029378443956, Validation Loss: 0.00359372072853148
Epoch 159, Training Loss: 0.0035937223583459854, Validation Loss: 0.0030755349434912205
Epoch 160, Training Loss: 0.0030755368061363697, Validation Loss: 0.0026197705883532763
Epoch 161, Training Loss: 0.002619771286845207, Validation Loss: 0.0022131865844130516
Epoch 162, Training Loss: 0.0022131872829049826, Validation Loss: 0.0018520023440942168
Epoch 163, Training Loss: 0.001852001529186964, Validation Loss: 0.0015264579560607672
Epoch 164, Training Loss: 0.001526458072476089, Validation Loss: 0.0012360771652311087
Epoch 165, Training Loss: 0.0012360765831544995, Validation Loss: 0.0009804434375837445
Epoch 166, Training Loss: 0.0009804436704143882, Validation Loss: 0.0007594975177198648
Epoch 167, Training Loss: 0.0007594979833811522, Validation Loss: 0.0005732639692723751
Epoch 168, Training Loss: 0.0005732644349336624, Validation Loss: 0.00042022127308882773
Epoch 169, Training Loss: 0.00042022200068458915, Validation Loss: 0.00029805334634147584
Epoch 170, Training Loss: 0.0002980526187457144, Validation Loss: 0.0002040317194769159
Epoch 171, Training Loss: 0.0002040312538156286, Validation Loss: 0.00013486015086527914
Epoch 172, Training Loss: 0.00013485988893080503, Validation Loss: 8.692528354004025e-05
Epoch 173, Training Loss: 8.692475967109203e-05, Validation Loss: 5.6586195569252595e-05
Epoch 174, Training Loss: 5.6586231949040666e-05, Validation Loss: 4.017284300061874e-05
Epoch 175, Training Loss: 4.017304308945313e-05, Validation Loss: 3.4343738661846146e-05
Epoch 176, Training Loss: 3.434376048971899e-05, Validation Loss: 3.612552973208949e-05
Epoch 177, Training Loss: 3.612551518017426e-05, Validation Loss: 4.307134804548696e-05
Epoch 178, Training Loss: 4.3071224354207516e-05, Validation Loss: 5.314371446729638e-05
Epoch 179, Training Loss: 5.3143830882618204e-05, Validation Loss: 6.484663026640192e-05
Epoch 180, Training Loss: 6.484673940576613e-05, Validation Loss: 7.701823051320389e-05
Epoch 181, Training Loss: 7.70182377891615e-05, Validation Loss: 8.879432425601408e-05
Epoch 182, Training Loss: 8.879401866579428e-05, Validation Loss: 9.95347072603181e-05
Epoch 183, Training Loss: 9.953461994882673e-05, Validation Loss: 0.00010876793385250494
Epoch 184, Training Loss: 0.00010876772284973413, Validation Loss: 0.00011615078255999833
Epoch 185, Training Loss: 0.000116150920803193, Validation Loss: 0.00012144629727117717
Epoch 186, Training Loss: 0.00012144650827394798, Validation Loss: 0.00012450749636627734
Epoch 187, Training Loss: 0.0001245079329237342, Validation Loss: 0.0001252313086297363
Epoch 188, Training Loss: 0.00012523184705059975, Validation Loss: 0.00012362375855445862
Epoch 189, Training Loss: 0.00012362428242340684, Validation Loss: 0.00011994990927632898
Epoch 190, Training Loss: 0.00011994993110420182, Validation Loss: 0.00011443482071626931
Epoch 191, Training Loss: 0.00011443472612882033, Validation Loss: 0.00010736746480688453
Epoch 192, Training Loss: 0.0001073672974598594, Validation Loss: 9.908629726851359e-05
Epoch 193, Training Loss: 9.908656647894531e-05, Validation Loss: 8.996506221592426e-05
Epoch 194, Training Loss: 8.996472752187401e-05, Validation Loss: 8.038205123739317e-05
Epoch 195, Training Loss: 8.038223313633353e-05, Validation Loss: 7.070235733408481e-05
Epoch 196, Training Loss: 7.070228457450867e-05, Validation Loss: 6.124914216343313e-05
Epoch 197, Training Loss: 6.12492804066278e-05, Validation Loss: 5.228769441600889e-05
Epoch 198, Training Loss: 5.228762165643275e-05, Validation Loss: 4.40131698269397e-05
Epoch 199, Training Loss: 4.401317346491851e-05, Validation Loss: 3.65481355402153e-05
Epoch 200, Training Loss: 3.654812462627888e-05, Validation Loss: 2.9950135285616852e-05
Epoch 201, Training Loss: 2.9950278985779732e-05, Validation Loss: 2.4220817067543976e-05
Epoch 202, Training Loss: 2.422068064333871e-05, Validation Loss: 1.932335908350069e-05
Epoch 203, Training Loss: 1.932342092914041e-05, Validation Loss: 1.5196370441117324e-05
Epoch 204, Training Loss: 1.5196207641565707e-05, Validation Loss: 1.1766503121179994e-05
Epoch 205, Training Loss: 1.1766396710299887e-05, Validation Loss: 8.958550097304396e-06
Epoch 206, Training Loss: 8.95859284355538e-06, Validation Loss: 6.6999023147218395e-06
Epoch 207, Training Loss: 6.699896857753629e-06, Validation Loss: 4.923197593598161e-06
Epoch 208, Training Loss: 4.923185315419687e-06, Validation Loss: 3.5666830626723822e-06
Epoch 209, Training Loss: 3.566807663446525e-06, Validation Loss: 2.5737770101841306e-06
Epoch 210, Training Loss: 2.573732672317419e-06, Validation Loss: 1.8906275727204047e-06
Epoch 211, Training Loss: 1.890573116725136e-06, Validation Loss: 1.4668302128484356e-06
Epoch 212, Training Loss: 1.4668164567410713e-06, Validation Loss: 1.2545234540084493e-06
Epoch 213, Training Loss: 1.2545757499538013e-06, Validation Loss: 1.2080392934876727e-06
Epoch 214, Training Loss: 1.208030198540655e-06, Validation Loss: 1.2834702829422895e-06
Epoch 215, Training Loss: 1.2834627796109999e-06, Validation Loss: 1.4418235423363512e-06
Epoch 216, Training Loss: 1.4418492355616763e-06, Validation Loss: 1.6486117146996548e-06
Epoch 217, Training Loss: 1.6485481637573685e-06, Validation Loss: 1.8739236793408054e-06
Epoch 218, Training Loss: 1.8739435745374067e-06, Validation Loss: 2.09356153391127e-06
Epoch 219, Training Loss: 2.0935221982654184e-06, Validation Loss: 2.288570158270886e-06
Epoch 220, Training Loss: 2.2885585622134386e-06, Validation Loss: 2.4453518108202843e-06
Epoch 221, Training Loss: 2.4454504909954267e-06, Validation Loss: 2.555883156674099e-06
Epoch 222, Training Loss: 2.5558788365742657e-06, Validation Loss: 2.616556457724073e-06
Epoch 223, Training Loss: 2.61655759459245e-06, Validation Loss: 2.6279785743099637e-06
Epoch 224, Training Loss: 2.627905814733822e-06, Validation Loss: 2.59348576037155e-06
Epoch 225, Training Loss: 2.593455974420067e-06, Validation Loss: 2.518694373065955e-06
Epoch 226, Training Loss: 2.5186802758980775e-06, Validation Loss: 2.410216438875068e-06
Epoch 227, Training Loss: 2.410172783129383e-06, Validation Loss: 2.274824510095641e-06
Epoch 228, Training Loss: 2.274843382110703e-06, Validation Loss: 2.119244300047285e-06
Epoch 229, Training Loss: 2.1192729491303908e-06, Validation Loss: 1.949579427673598e-06
Epoch 230, Training Loss: 1.9495828382787295e-06, Validation Loss: 1.7712919770929147e-06
Epoch 231, Training Loss: 1.7712977751216386e-06, Validation Loss: 1.5891463363004732e-06
Epoch 232, Training Loss: 1.5891763496256317e-06, Validation Loss: 1.4073502825340256e-06
Epoch 233, Training Loss: 1.4073775673750788e-06, Validation Loss: 1.2296371778575121e-06
Epoch 234, Training Loss: 1.2296623026486486e-06, Validation Loss: 1.0592442549750558e-06
Epoch 235, Training Loss: 1.059214810084086e-06, Validation Loss: 8.989195521280635e-07
Epoch 236, Training Loss: 8.989279649540549e-07, Validation Loss: 7.510213890782325e-07
Epoch 237, Training Loss: 7.510242312491755e-07, Validation Loss: 6.171192694637284e-07
Epoch 238, Training Loss: 6.171281370370707e-07, Validation Loss: 4.983483563592017e-07
Epoch 239, Training Loss: 4.983450025974889e-07, Validation Loss: 3.951053031414631e-07
Epoch 240, Training Loss: 3.951052178763348e-07, Validation Loss: 3.0730879529983213e-07
Epoch 241, Training Loss: 3.0732491040907917e-07, Validation Loss: 2.3433233309333446e-07
Epoch 242, Training Loss: 2.3433740636846778e-07, Validation Loss: 1.7519072059712926e-07
Epoch 243, Training Loss: 1.7518834738439182e-07, Validation Loss: 1.2860057552188664e-07
Epoch 244, Training Loss: 1.2859196374392923e-07, Validation Loss: 9.313888682527249e-08
Epoch 245, Training Loss: 9.313900051211021e-08, Validation Loss: 6.728189561044928e-08
Epoch 246, Training Loss: 6.727253065719196e-08, Validation Loss: 4.9499671916919397e-08
Epoch 247, Training Loss: 4.9497689502686626e-08, Validation Loss: 3.83377027901588e-08
Epoch 248, Training Loss: 3.833464745639503e-08, Validation Loss: 3.2441725750231853e-08
Epoch 249, Training Loss: 3.2435170993494467e-08, Validation Loss: 3.05741529871284e-08
Epoch 250, Training Loss: 3.057074593471043e-08, Validation Loss: 3.1646560927356404e-08
Epoch 251, Training Loss: 3.164656803278376e-08, Validation Loss: 3.4709032092905545e-08
Epoch 252, Training Loss: 3.4714123131607266e-08, Validation Loss: 3.900314737848021e-08
Epoch 253, Training Loss: 3.900303013892881e-08, Validation Loss: 4.385603702417029e-08
Epoch 254, Training Loss: 4.3859166964921315e-08, Validation Loss: 4.874211256833405e-08
Epoch 255, Training Loss: 4.8748848513469056e-08, Validation Loss: 5.326589658238845e-08
Epoch 256, Training Loss: 5.3260546195588176e-08, Validation Loss: 5.708388073344395e-08
Epoch 257, Training Loss: 5.707835626367341e-08, Validation Loss: 5.997108587507682e-08
Epoch 258, Training Loss: 5.996719210088486e-08, Validation Loss: 6.181566902796476e-08
Epoch 259, Training Loss: 6.180912492936841e-08, Validation Loss: 6.25244780394496e-08
Epoch 260, Training Loss: 6.252933104633485e-08, Validation Loss: 6.211789838062032e-08
Epoch 261, Training Loss: 6.212406589156672e-08, Validation Loss: 6.067780589091853e-08
Epoch 262, Training Loss: 6.068087543553702e-08, Validation Loss: 5.829350868680194e-08
Epoch 263, Training Loss: 5.8291632853979536e-08, Validation Loss: 5.511978784511484e-08
Epoch 264, Training Loss: 5.5122001185736735e-08, Validation Loss: 5.1320732552539994e-08
Epoch 265, Training Loss: 5.132557845399788e-08, Validation Loss: 4.7050868090536824e-08
Epoch 266, Training Loss: 4.705448475306184e-08, Validation Loss: 4.2462900751161214e-08
Epoch 267, Training Loss: 4.247214846486713e-08, Validation Loss: 3.7721687107250546e-08
Epoch 268, Training Loss: 3.7720681689279445e-08, Validation Loss: 3.293914829782807e-08
Epoch 269, Training Loss: 3.2930955740084755e-08, Validation Loss: 2.823611744418031e-08
Epoch 270, Training Loss: 2.8237705507194732e-08, Validation Loss: 2.3727389830696666e-08
Epoch 271, Training Loss: 2.373089813545448e-08, Validation Loss: 1.951751649187372e-08
Epoch 272, Training Loss: 1.95194136409782e-08, Validation Loss: 1.5675274411819373e-08
Epoch 273, Training Loss: 1.567454432915838e-08, Validation Loss: 1.2271555327458827e-08
Epoch 274, Training Loss: 1.22706298455455e-08, Validation Loss: 9.340082485209678e-09
Epoch 275, Training Loss: 9.337152384603087e-09, Validation Loss: 6.895036541720856e-09
Epoch 276, Training Loss: 6.895342075097233e-09, Validation Loss: 4.925237551134387e-09
Epoch 277, Training Loss: 4.923579322024807e-09, Validation Loss: 3.400570713907314e-09
Epoch 278, Training Loss: 3.401713133399653e-09, Validation Loss: 2.275972077470101e-09
Epoch 279, Training Loss: 2.2745991756778494e-09, Validation Loss: 1.4905500167472496e-09
Epoch 280, Training Loss: 1.4904746326038776e-09, Validation Loss: 9.865257499797053e-10
Epoch 281, Training Loss: 9.87101289595671e-10, Validation Loss: 7.061736195801416e-10
Epoch 282, Training Loss: 7.066097706953656e-10, Validation Loss: 5.975899775023663e-10
Epoch 283, Training Loss: 5.967810134954732e-10, Validation Loss: 6.152250375812685e-10
Epoch 284, Training Loss: 6.143706654526682e-10, Validation Loss: 7.182727745913553e-10
Epoch 285, Training Loss: 7.192147988277497e-10, Validation Loss: 8.797893524814526e-10
Epoch 286, Training Loss: 8.800867812297497e-10, Validation Loss: 1.0732827959714086e-09
Epoch 287, Training Loss: 1.0744747314106462e-09, Validation Loss: 1.2808838434352765e-09
Epoch 288, Training Loss: 1.2800545068358815e-09, Validation Loss: 1.482488132253934e-09
Epoch 289, Training Loss: 1.4814772741900128e-09, Validation Loss: 1.6650566481146711e-09
Epoch 290, Training Loss: 1.6651260370537102e-09, Validation Loss: 1.8178465399643073e-09
Epoch 291, Training Loss: 1.8184136418852859e-09, Validation Loss: 1.9355639313545225e-09
Epoch 292, Training Loss: 1.9354278180117035e-09, Validation Loss: 2.006643295970889e-09
Epoch 293, Training Loss: 2.0073496198591556e-09, Validation Loss: 2.0336501371787108e-09
Epoch 294, Training Loss: 2.0336390349484645e-09, Validation Loss: 2.0136317058216946e-09
Epoch 295, Training Loss: 2.0139190315404676e-09, Validation Loss: 1.9475454582362772e-09
Epoch 296, Training Loss: 1.946773631189558e-09, Validation Loss: 1.8414436642189003e-09
Epoch 297, Training Loss: 1.8410467594875968e-09, Validation Loss: 1.7035877153404044e-09
Epoch 298, Training Loss: 1.703031937694277e-09, Validation Loss: 1.5415697607323864e-09
Epoch 299, Training Loss: 1.5423879951015351e-09, Validation Loss: 1.3679076760197972e-09
Epoch 300, Training Loss: 1.367995938750255e-09, Validation Loss: 1.1884103701120807e-09
Epoch 301, Training Loss: 1.1881162720328575e-09, Validation Loss: 1.0126174343483285e-09
Epoch 302, Training Loss: 1.0144438622461394e-09, Validation Loss: 8.477202828593988e-10
Epoch 303, Training Loss: 8.485909197553099e-10, Validation Loss: 6.987198597485644e-10
Epoch 304, Training Loss: 6.988058465218216e-10, Validation Loss: 5.642983302855953e-10
Epoch 305, Training Loss: 5.631282107287916e-10, Validation Loss: 4.467890779569217e-10
Epoch 306, Training Loss: 4.473001968818835e-10, Validation Loss: 3.468802189932063e-10
Epoch 307, Training Loss: 3.4662900327830926e-10, Validation Loss: 2.636328655380993e-10
Epoch 308, Training Loss: 2.630602125019976e-10, Validation Loss: 1.9468215928242216e-10
Epoch 309, Training Loss: 1.944920474672429e-10, Validation Loss: 1.3976135526672095e-10
Epoch 310, Training Loss: 1.393279380756951e-10, Validation Loss: 9.614555679382519e-11
Epoch 311, Training Loss: 9.638447678872453e-11, Validation Loss: 6.489132148290722e-11
Epoch 312, Training Loss: 6.446387867953263e-11, Validation Loss: 4.204228284954148e-11
Epoch 313, Training Loss: 4.207817080881249e-11, Validation Loss: 2.8666092069529192e-11
Epoch 314, Training Loss: 2.8478415806110213e-11, Validation Loss: 2.206856572484206e-11
Epoch 315, Training Loss: 2.216135087940163e-11, Validation Loss: 2.1424952090232097e-11
Epoch 316, Training Loss: 2.1483479925588078e-11, Validation Loss: 2.5216261370641924e-11
Epoch 317, Training Loss: 2.5246365761844025e-11, Validation Loss: 3.1918741955072605e-11
Epoch 318, Training Loss: 3.200260542679523e-11, Validation Loss: 4.036836837029156e-11
Epoch 319, Training Loss: 4.0290978886581286e-11, Validation Loss: 4.897550073823531e-11
Epoch 320, Training Loss: 4.890712834715316e-11, Validation Loss: 5.6848588336766426e-11
Epoch 321, Training Loss: 5.6820794597234325e-11, Validation Loss: 6.329022028683795e-11
Epoch 322, Training Loss: 6.368627847308517e-11, Validation Loss: 6.789727807765544e-11
Epoch 323, Training Loss: 6.827360204963995e-11, Validation Loss: 7.032899262959802e-11
Epoch 324, Training Loss: 7.067926799386726e-11, Validation Loss: 7.109051541887013e-11
Epoch 325, Training Loss: 7.122129275227707e-11, Validation Loss: 7.013588321225228e-11
Epoch 326, Training Loss: 7.024333198435428e-11, Validation Loss: 6.764944160408959e-11
Epoch 327, Training Loss: 6.795364271283688e-11, Validation Loss: 6.433902022262572e-11
Epoch 328, Training Loss: 6.448885175869279e-11, Validation Loss: 6.03115751784955e-11
Epoch 329, Training Loss: 6.032455091009581e-11, Validation Loss: 5.54239015793101e-11
Epoch 330, Training Loss: 5.569119471138251e-11, Validation Loss: 5.071082789798176e-11
Epoch 331, Training Loss: 5.073779243969234e-11, Validation Loss: 4.551811358388669e-11
Epoch 332, Training Loss: 4.555139251904983e-11, Validation Loss: 4.027477656931566e-11
Epoch 333, Training Loss: 4.0197636885785926e-11, Validation Loss: 3.484632721262315e-11
Epoch 334, Training Loss: 3.5046160418161776e-11, Validation Loss: 2.981033475624173e-11
Epoch 335, Training Loss: 2.9731866274529395e-11, Validation Loss: 2.4933707876151345e-11
Epoch 336, Training Loss: 2.4832394820983872e-11, Validation Loss: 1.9973226197955718e-11
Epoch 337, Training Loss: 2.0027543859435504e-11, Validation Loss: 1.5740684797260762e-11
Epoch 338, Training Loss: 1.5878114795198073e-11, Validation Loss: 1.2064930651756178e-11
Epoch 339, Training Loss: 1.2081088733573164e-11, Validation Loss: 8.794360205344187e-12
Epoch 340, Training Loss: 8.782964806830496e-12, Validation Loss: 6.238630705784898e-12
Epoch 341, Training Loss: 6.194631613221091e-12, Validation Loss: 4.323841631959091e-12
Epoch 342, Training Loss: 4.265560994698436e-12, Validation Loss: 2.868707875414156e-12
Epoch 343, Training Loss: 2.9005142471866252e-12, Validation Loss: 1.929506467795994e-12
Epoch 344, Training Loss: 1.9477093549102875e-12, Validation Loss: 1.4093005191659347e-12
Epoch 345, Training Loss: 1.392875181513431e-12, Validation Loss: 1.112222835532306e-12
Epoch 346, Training Loss: 1.132421088324842e-12, Validation Loss: 1.104517193852017e-12
Epoch 347, Training Loss: 1.0521102218608025e-12, Validation Loss: 1.1625941095244618e-12
Epoch 348, Training Loss: 1.1988870183068934e-12, Validation Loss: 1.3146994343876672e-12
Epoch 349, Training Loss: 1.3261000370717868e-12, Validation Loss: 1.5485178243845876e-12
Epoch 350, Training Loss: 1.5141142463079293e-12, Validation Loss: 1.7326240268900062e-12
Epoch 351, Training Loss: 1.782581786173576e-12, Validation Loss: 1.9820766122141675e-12
Epoch 352, Training Loss: 1.9658203016803544e-12, Validation Loss: 2.1633515291663574e-12
Epoch 353, Training Loss: 2.192730589115066e-12, Validation Loss: 2.2659690963877654e-12
Epoch 354, Training Loss: 2.296956461839139e-12, Validation Loss: 2.4335618156040573e-12
Epoch 355, Training Loss: 2.3408161260035643e-12, Validation Loss: 2.428696133094377e-12
Epoch 356, Training Loss: 2.391056103112632e-12, Validation Loss: 2.431699589952596e-12
Epoch 357, Training Loss: 2.4171495967978407e-12, Validation Loss: 2.381298500400697e-12
Epoch 358, Training Loss: 2.3869541326132504e-12, Validation Loss: 2.2940139371430135e-12
Epoch 359, Training Loss: 2.298320821852995e-12, Validation Loss: 2.2291691062492625e-12
Epoch 360, Training Loss: 2.2294169548658926e-12, Validation Loss: 2.1093706208813456e-12
Epoch 361, Training Loss: 2.0967249204223437e-12, Validation Loss: 1.8859900620393777e-12
Epoch 362, Training Loss: 1.940931790289646e-12, Validation Loss: 1.820231899235525e-12
Epoch 363, Training Loss: 1.7693847689098652e-12, Validation Loss: 1.603877837833001e-12
Epoch 364, Training Loss: 1.5822525581410396e-12, Validation Loss: 1.4354465966565089e-12
Epoch 365, Training Loss: 1.414420447085063e-12, Validation Loss: 1.2568145309199696e-12
Epoch 366, Training Loss: 1.2367973398902388e-12, Validation Loss: 1.0627149117301005e-12
Epoch 367, Training Loss: 1.051885358330229e-12, Validation Loss: 8.933626950181905e-13
Epoch 368, Training Loss: 8.845649364895569e-13, Validation Loss: 7.120154075709872e-13
Epoch 369, Training Loss: 7.296778199022969e-13, Validation Loss: 5.796422369863663e-13
Epoch 370, Training Loss: 6.030720085641039e-13, Validation Loss: 4.727085693365107e-13
Epoch 371, Training Loss: 4.609992942938845e-13, Validation Loss: 4.0411665441948685e-13
Epoch 372, Training Loss: 3.8065300152385906e-13, Validation Loss: 3.013370802884552e-13
Epoch 373, Training Loss: 2.9893166934857884e-13, Validation Loss: 2.2436363205681487e-13
Epoch 374, Training Loss: 2.2283531356942499e-13, Validation Loss: 1.6892134121603702e-13
Epoch 375, Training Loss: 1.6267022451277313e-13, Validation Loss: 1.2208972981903043e-13
Epoch 376, Training Loss: 1.3182383244887685e-13, Validation Loss: 9.425440435735163e-14
Epoch 377, Training Loss: 8.328257652739576e-14, Validation Loss: 6.527558441687953e-14
Epoch 378, Training Loss: 6.2232513521783e-14, Validation Loss: 5.596048865724908e-14
Epoch 379, Training Loss: 4.796448069450954e-14, Validation Loss: 3.4659849588915964e-14
Epoch 380, Training Loss: 4.2775655115451575e-14, Validation Loss: 3.11303547772656e-14
Epoch 381, Training Loss: 3.635817775321515e-14, Validation Loss: 2.646111276058058e-14
Epoch 382, Training Loss: 3.0548717581176804e-14, Validation Loss: 2.6122973819904874e-14
Epoch 383, Training Loss: 2.539605692083481e-14, Validation Loss: 2.6641022558577393e-14
Epoch 384, Training Loss: 2.7602958913258528e-14, Validation Loss: 2.975605398474086e-14
Epoch 385, Training Loss: 2.957320328835118e-14, Validation Loss: 3.236934713866414e-14
Epoch 386, Training Loss: 3.380886607999567e-14, Validation Loss: 3.0339320872220174e-14
Epoch 387, Training Loss: 3.099821424936214e-14, Validation Loss: 2.997019069007033e-14
Epoch 388, Training Loss: 3.5530182718483336e-14, Validation Loss: 3.569294518149593e-14
Epoch 389, Training Loss: 3.2987674413896204e-14, Validation Loss: 3.4883761054456744e-14
Epoch 390, Training Loss: 3.140927595053286e-14, Validation Loss: 3.119240502284966e-14
Epoch 391, Training Loss: 3.407548155860522e-14, Validation Loss: 3.7475841115248987e-14
Epoch 392, Training Loss: 3.660410868725275e-14, Validation Loss: 3.4250187186174105e-14
Epoch 393, Training Loss: 3.579152626402918e-14, Validation Loss: 2.9647931923089746e-14
Epoch 394, Training Loss: 3.642936917836598e-14, Validation Loss: 2.9792449296418486e-14
Epoch 395, Training Loss: 3.381020100392054e-14, Validation Loss: 2.6957509643055384e-14
Epoch 396, Training Loss: 3.0767695926832775e-14, Validation Loss: 3.089115944922456e-14
Epoch 397, Training Loss: 2.90942603667875e-14, Validation Loss: 3.180538582611865e-14
Epoch 398, Training Loss: 2.7968577296809058e-14, Validation Loss: 2.8757422468718777e-14
Epoch 399, Training Loss: 3.180114049698701e-14, Validation Loss: 3.011391524056044e-14
Epoch 400, Training Loss: 2.6631593387808558e-14, Validation Loss: 2.7483403600885373e-14
Epoch 401, Training Loss: 2.7264828442912295e-14, Validation Loss: 2.6371345902896463e-14
Epoch 402, Training Loss: 2.5897566494179243e-14, Validation Loss: 2.8607019910472514e-14
Epoch 403, Training Loss: 2.5563965956034926e-14, Validation Loss: 2.5140325815597477e-14
Epoch 404, Training Loss: 2.5307301420489717e-14, Validation Loss: 2.1628278188594655e-14
Epoch 405, Training Loss: 2.5098451894817013e-14, Validation Loss: 2.3304822359556353e-14
Epoch 406, Training Loss: 2.4555158186184527e-14, Validation Loss: 2.1726623795968562e-14
Epoch 407, Training Loss: 2.6371622035637268e-14, Validation Loss: 2.2143358923819995e-14
Epoch 408, Training Loss: 2.249986831505575e-14, Validation Loss: 1.983230576020189e-14
Epoch 409, Training Loss: 2.4074622842680006e-14, Validation Loss: 1.9622204319833143e-14
Epoch 410, Training Loss: 1.9209231712333415e-14, Validation Loss: 1.6623150338873627e-14
Epoch 411, Training Loss: 1.6895678107455014e-14, Validation Loss: 1.6324344220136622e-14
Epoch 412, Training Loss: 1.4647634030717262e-14, Validation Loss: 1.6072041904269772e-14
Epoch 413, Training Loss: 1.2828576566380027e-14, Validation Loss: 1.5692071394460966e-14
Epoch 414, Training Loss: 1.4372671889445465e-14, Validation Loss: 1.704508963715299e-14
Epoch 415, Training Loss: 1.4904757658119883e-14, Validation Loss: 1.4080830075600785e-14
Epoch 416, Training Loss: 1.38865664572798e-14, Validation Loss: 1.4048420900972941e-14
Epoch 417, Training Loss: 1.2660216909651974e-14, Validation Loss: 9.388837600985463e-15
Epoch 418, Training Loss: 1.1568449885914541e-14, Validation Loss: 8.538055685906615e-15
Epoch 419, Training Loss: 8.012301488512924e-15, Validation Loss: 9.246173535745316e-15
Epoch 420, Training Loss: 8.178685017375033e-15, Validation Loss: 8.325985740968451e-15
Epoch 421, Training Loss: 7.604357715621044e-15, Validation Loss: 8.184839558769783e-15
Epoch 422, Training Loss: 6.4240617728519075e-15, Validation Loss: 9.513004160723471e-15
Epoch 423, Training Loss: 7.243993477442333e-15, Validation Loss: 9.140038613388458e-15
Epoch 424, Training Loss: 7.145022759753351e-15, Validation Loss: 8.238382205431622e-15
Epoch 425, Training Loss: 5.628757551202901e-15, Validation Loss: 5.7629487458716634e-15
Epoch 426, Training Loss: 6.269196198006562e-15, Validation Loss: 6.320728835484566e-15
Epoch 427, Training Loss: 5.454676610432618e-15, Validation Loss: 5.337791145909208e-15
Epoch 428, Training Loss: 4.8195010028467215e-15, Validation Loss: 4.333619610895605e-15
Epoch 429, Training Loss: 3.560891781906241e-15, Validation Loss: 4.970029769002125e-15
Epoch 430, Training Loss: 3.2988151293445508e-15, Validation Loss: 4.367013037808159e-15
Epoch 431, Training Loss: 3.706149885547355e-15, Validation Loss: 3.8679463074836086e-15
Epoch 432, Training Loss: 4.056455607477421e-15, Validation Loss: 5.632544211993601e-15
Epoch 433, Training Loss: 3.910280167154431e-15, Validation Loss: 4.526724488144746e-15
Epoch 434, Training Loss: 4.19851150306144e-15, Validation Loss: 5.707404136838989e-15
Epoch 435, Training Loss: 3.097053363616234e-15, Validation Loss: 9.176416137374188e-15
Epoch 436, Training Loss: 2.2490573399009057e-15, Validation Loss: 9.560724302905884e-15
Epoch 437, Training Loss: 4.8142383871454305e-15, Validation Loss: 9.620939028093245e-15
Epoch 438, Training Loss: 4.936469476598962e-15, Validation Loss: 6.413853755288072e-15
Epoch 439, Training Loss: 3.827847344244116e-15, Validation Loss: 8.620155201352186e-15
Epoch 440, Training Loss: 3.2967551452168283e-15, Validation Loss: 7.433303647087774e-15
Epoch 441, Training Loss: 1.958157638451809e-15, Validation Loss: 7.006294856619095e-15
Epoch 442, Training Loss: 1.8106894140930722e-15, Validation Loss: 8.31200800327286e-15
Epoch 443, Training Loss: 2.1352161117899277e-15, Validation Loss: 1.0975475153826748e-14
Epoch 444, Training Loss: 3.25558066189256e-15, Validation Loss: 7.522708821703413e-15
Epoch 445, Training Loss: 2.6538067397904527e-15, Validation Loss: 6.088809943976918e-15
Epoch 446, Training Loss: 3.056796428732079e-15, Validation Loss: 5.741965198669333e-15
Epoch 447, Training Loss: 2.7648290422529684e-15, Validation Loss: 5.989497024977246e-15
Epoch 448, Training Loss: 4.005055954172136e-15, Validation Loss: 1.868860884053419e-15
Epoch 449, Training Loss: 2.7058067276971047e-15, Validation Loss: 3.64666911440879e-15
Epoch 450, Training Loss: 3.2145561033999556e-15, Validation Loss: 2.613307553483383e-15
Epoch 451, Training Loss: 2.5002337372226173e-15, Validation Loss: 3.10586907077302e-15
Epoch 452, Training Loss: 2.718008237302303e-15, Validation Loss: 2.840589786637761e-15
Epoch 453, Training Loss: 2.3316400876428845e-15, Validation Loss: 3.725031944007548e-15
Epoch 454, Training Loss: 2.6486942606790626e-15, Validation Loss: 2.358069633179587e-15
Epoch 455, Training Loss: 2.9379928580996117e-15, Validation Loss: 2.528873191718706e-15
Epoch 456, Training Loss: 2.5030526628710796e-15, Validation Loss: 2.3668434122054837e-15
Epoch 457, Training Loss: 1.9974307445677283e-15, Validation Loss: 2.3924638295193213e-15
Epoch 458, Training Loss: 2.24989971416695e-15, Validation Loss: 2.525637314101958e-15
Epoch 459, Training Loss: 2.8903379374541375e-15, Validation Loss: 2.1296199768656553e-15
Epoch 460, Training Loss: 3.271518433828097e-15, Validation Loss: 2.5747434139443155e-15
Epoch 461, Training Loss: 2.094266727471392e-15, Validation Loss: 2.7264650142476898e-15
Epoch 462, Training Loss: 1.1449309407927303e-15, Validation Loss: 3.7536883391625815e-15
Epoch 463, Training Loss: 2.4964138303887372e-15, Validation Loss: 3.9503791303939235e-15
Epoch 464, Training Loss: 2.4078846995987963e-15, Validation Loss: 3.890597662559083e-15
Epoch 465, Training Loss: 9.526268273161e-16, Validation Loss: 4.078748667616207e-15
Epoch 466, Training Loss: 2.3266027827055632e-15, Validation Loss: 4.390732077913647e-15
Epoch 467, Training Loss: 2.7938022277302754e-15, Validation Loss: 3.828681671697162e-15
Epoch 468, Training Loss: 1.9691413264370924e-15, Validation Loss: 3.3739170938546165e-15
Epoch 469, Training Loss: 1.675572730050316e-15, Validation Loss: 5.569443645554945e-15
Epoch 470, Training Loss: 2.0557608214474485e-15, Validation Loss: 3.7064501587271564e-15
Epoch 471, Training Loss: 9.336449248472495e-16, Validation Loss: 3.1586779751443e-15
Epoch 472, Training Loss: 1.8276946593003864e-15, Validation Loss: 2.560865626136501e-15
Epoch 473, Training Loss: 1.8276946593003864e-15, Validation Loss: 4.465058372002265e-15
Epoch 474, Training Loss: 1.785986333461111e-15, Validation Loss: 3.928361355962995e-15
Epoch 475, Training Loss: 1.8853407570751986e-15, Validation Loss: 3.61611113028717e-15
Epoch 476, Training Loss: 1.7460292482402839e-15, Validation Loss: 2.7140549227792302e-15
Epoch 477, Training Loss: 1.7252125665285622e-15, Validation Loss: 3.834186115304894e-15
Epoch 478, Training Loss: 9.870211295349529e-16, Validation Loss: 4.279309552383554e-15
Epoch 479, Training Loss: 9.795483931160386e-16, Validation Loss: 5.076081682130152e-15
Epoch 480, Training Loss: 8.413793729082923e-16, Validation Loss: 4.3596404630352574e-15
Epoch 481, Training Loss: 1.132279127296948e-15, Validation Loss: 4.186168115437577e-15
Epoch 482, Training Loss: 1.145623178468874e-15, Validation Loss: 4.653209377059389e-15
Epoch 483, Training Loss: 1.2795220408917153e-15, Validation Loss: 3.949878533922096e-15
Epoch 484, Training Loss: 1.4209687080284214e-15, Validation Loss: 3.898637699294421e-15
Epoch 485, Training Loss: 9.405838187511568e-16, Validation Loss: 2.497247946083546e-15
Epoch 486, Training Loss: 1.111387377290276e-15, Validation Loss: 3.4962150989109814e-15
Epoch 487, Training Loss: 1.6659650470878472e-15, Validation Loss: 3.4962150989109814e-15
Epoch 488, Training Loss: 1.7445780690434004e-15, Validation Loss: 3.723063439438129e-15
Epoch 489, Training Loss: 1.0538913102262461e-15, Validation Loss: 3.723063439438129e-15
Epoch 490, Training Loss: 1.2314836260793717e-15, Validation Loss: 4.5156990837868106e-15
Epoch 491, Training Loss: 1.894414809280897e-15, Validation Loss: 3.826079586483197e-15
Epoch 492, Training Loss: 1.775461102058529e-15, Validation Loss: 3.9233575088270904e-15
Epoch 493, Training Loss: 1.1280090224516023e-15, Validation Loss: 2.886793528086352e-15
Epoch 494, Training Loss: 2.2573639802563918e-15, Validation Loss: 2.814568934498109e-15
Epoch 495, Training Loss: 2.965665000969936e-15, Validation Loss: 3.620714754355497e-15
Epoch 496, Training Loss: 2.1890425144890967e-15, Validation Loss: 3.4499114075746146e-15
Epoch 497, Training Loss: 2.6287116946621496e-15, Validation Loss: 3.3858600466526653e-15
Epoch 498, Training Loss: 1.9721855628495244e-15, Validation Loss: 3.566538103532638e-15
Epoch 499, Training Loss: 2.0257116923688917e-15, Validation Loss: 3.943507152092849e-15
Epoch 500, Training Loss: 2.834818527651644e-15, Validation Loss: 3.815504380136727e-15
