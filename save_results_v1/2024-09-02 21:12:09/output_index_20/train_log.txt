Epoch 1, Training Loss: 0.47100505232810974, Validation Loss: 0.46966177225112915
Epoch 2, Training Loss: 0.46966174244880676, Validation Loss: 0.46834254264831543
Epoch 3, Training Loss: 0.46834251284599304, Validation Loss: 0.46705129742622375
Epoch 4, Training Loss: 0.46705129742622375, Validation Loss: 0.4657709002494812
Epoch 5, Training Loss: 0.46577081084251404, Validation Loss: 0.46451514959335327
Epoch 6, Training Loss: 0.46451514959335327, Validation Loss: 0.46328261494636536
Epoch 7, Training Loss: 0.46328261494636536, Validation Loss: 0.46207401156425476
Epoch 8, Training Loss: 0.46207401156425476, Validation Loss: 0.4608795642852783
Epoch 9, Training Loss: 0.4608795642852783, Validation Loss: 0.4596891701221466
Epoch 10, Training Loss: 0.4596891701221466, Validation Loss: 0.45848220586776733
Epoch 11, Training Loss: 0.4584822356700897, Validation Loss: 0.45728203654289246
Epoch 12, Training Loss: 0.45728200674057007, Validation Loss: 0.45610326528549194
Epoch 13, Training Loss: 0.45610326528549194, Validation Loss: 0.4549364745616913
Epoch 14, Training Loss: 0.4549364745616913, Validation Loss: 0.45378410816192627
Epoch 15, Training Loss: 0.4537840783596039, Validation Loss: 0.4526430666446686
Epoch 16, Training Loss: 0.4526430666446686, Validation Loss: 0.45150449872016907
Epoch 17, Training Loss: 0.45150449872016907, Validation Loss: 0.4503747522830963
Epoch 18, Training Loss: 0.4503747522830963, Validation Loss: 0.4492366909980774
Epoch 19, Training Loss: 0.44923675060272217, Validation Loss: 0.44808125495910645
Epoch 20, Training Loss: 0.44808128476142883, Validation Loss: 0.44688650965690613
Epoch 21, Training Loss: 0.4468865692615509, Validation Loss: 0.4456341862678528
Epoch 22, Training Loss: 0.4456341862678528, Validation Loss: 0.44432222843170166
Epoch 23, Training Loss: 0.44432222843170166, Validation Loss: 0.4429561197757721
Epoch 24, Training Loss: 0.4429561197757721, Validation Loss: 0.4414905607700348
Epoch 25, Training Loss: 0.4414905607700348, Validation Loss: 0.4399777352809906
Epoch 26, Training Loss: 0.4399777352809906, Validation Loss: 0.4384195804595947
Epoch 27, Training Loss: 0.4384195804595947, Validation Loss: 0.4367925822734833
Epoch 28, Training Loss: 0.4367925226688385, Validation Loss: 0.4351750612258911
Epoch 29, Training Loss: 0.4351750314235687, Validation Loss: 0.4335204064846039
Epoch 30, Training Loss: 0.4335204064846039, Validation Loss: 0.4318605959415436
Epoch 31, Training Loss: 0.4318605661392212, Validation Loss: 0.43012621998786926
Epoch 32, Training Loss: 0.43012621998786926, Validation Loss: 0.428279310464859
Epoch 33, Training Loss: 0.4282793402671814, Validation Loss: 0.42632681131362915
Epoch 34, Training Loss: 0.42632681131362915, Validation Loss: 0.4242570698261261
Epoch 35, Training Loss: 0.4242570698261261, Validation Loss: 0.4220656752586365
Epoch 36, Training Loss: 0.4220656752586365, Validation Loss: 0.41973811388015747
Epoch 37, Training Loss: 0.41973811388015747, Validation Loss: 0.4173000156879425
Epoch 38, Training Loss: 0.4173000454902649, Validation Loss: 0.4146983325481415
Epoch 39, Training Loss: 0.4146983325481415, Validation Loss: 0.41190046072006226
Epoch 40, Training Loss: 0.41190043091773987, Validation Loss: 0.40890994668006897
Epoch 41, Training Loss: 0.40890994668006897, Validation Loss: 0.4057124853134155
Epoch 42, Training Loss: 0.4057125151157379, Validation Loss: 0.40229886770248413
Epoch 43, Training Loss: 0.40229886770248413, Validation Loss: 0.39865362644195557
Epoch 44, Training Loss: 0.39865362644195557, Validation Loss: 0.3947561979293823
Epoch 45, Training Loss: 0.3947561979293823, Validation Loss: 0.39058443903923035
Epoch 46, Training Loss: 0.39058443903923035, Validation Loss: 0.38614583015441895
Epoch 47, Training Loss: 0.38614583015441895, Validation Loss: 0.3813774585723877
Epoch 48, Training Loss: 0.3813774585723877, Validation Loss: 0.376282274723053
Epoch 49, Training Loss: 0.37628230452537537, Validation Loss: 0.3708847165107727
Epoch 50, Training Loss: 0.3708847165107727, Validation Loss: 0.3651247024536133
Epoch 51, Training Loss: 0.36512476205825806, Validation Loss: 0.35903140902519226
Epoch 52, Training Loss: 0.35903140902519226, Validation Loss: 0.3525347113609314
Epoch 53, Training Loss: 0.352534681558609, Validation Loss: 0.3454956114292145
Epoch 54, Training Loss: 0.3454956114292145, Validation Loss: 0.3379465639591217
Epoch 55, Training Loss: 0.3379465639591217, Validation Loss: 0.32992467284202576
Epoch 56, Training Loss: 0.32992467284202576, Validation Loss: 0.32145801186561584
Epoch 57, Training Loss: 0.32145801186561584, Validation Loss: 0.312523752450943
Epoch 58, Training Loss: 0.312523752450943, Validation Loss: 0.30318254232406616
Epoch 59, Training Loss: 0.30318254232406616, Validation Loss: 0.29338762164115906
Epoch 60, Training Loss: 0.29338762164115906, Validation Loss: 0.28318315744400024
Epoch 61, Training Loss: 0.28318315744400024, Validation Loss: 0.2726707458496094
Epoch 62, Training Loss: 0.2726707458496094, Validation Loss: 0.26191776990890503
Epoch 63, Training Loss: 0.26191776990890503, Validation Loss: 0.25106173753738403
Epoch 64, Training Loss: 0.25106173753738403, Validation Loss: 0.240048348903656
Epoch 65, Training Loss: 0.240048348903656, Validation Loss: 0.22908391058444977
Epoch 66, Training Loss: 0.22908391058444977, Validation Loss: 0.21831606328487396
Epoch 67, Training Loss: 0.21831609308719635, Validation Loss: 0.20784221589565277
Epoch 68, Training Loss: 0.20784221589565277, Validation Loss: 0.1978345364332199
Epoch 69, Training Loss: 0.1978345364332199, Validation Loss: 0.18849393725395203
Epoch 70, Training Loss: 0.18849392235279083, Validation Loss: 0.17992724478244781
Epoch 71, Training Loss: 0.17992722988128662, Validation Loss: 0.1721077710390091
Epoch 72, Training Loss: 0.1721077710390091, Validation Loss: 0.1649440973997116
Epoch 73, Training Loss: 0.1649440973997116, Validation Loss: 0.1583753079175949
Epoch 74, Training Loss: 0.15837529301643372, Validation Loss: 0.15210795402526855
Epoch 75, Training Loss: 0.15210793912410736, Validation Loss: 0.14585624635219574
Epoch 76, Training Loss: 0.14585624635219574, Validation Loss: 0.1394614279270172
Epoch 77, Training Loss: 0.1394614279270172, Validation Loss: 0.13264143466949463
Epoch 78, Training Loss: 0.13264143466949463, Validation Loss: 0.12537029385566711
Epoch 79, Training Loss: 0.12537029385566711, Validation Loss: 0.11775467544794083
Epoch 80, Training Loss: 0.11775468289852142, Validation Loss: 0.10994717478752136
Epoch 81, Training Loss: 0.10994715988636017, Validation Loss: 0.10188593715429306
Epoch 82, Training Loss: 0.10188592970371246, Validation Loss: 0.09369786083698273
Epoch 83, Training Loss: 0.09369785338640213, Validation Loss: 0.08578994870185852
Epoch 84, Training Loss: 0.08578995615243912, Validation Loss: 0.0780414566397667
Epoch 85, Training Loss: 0.0780414566397667, Validation Loss: 0.0705159455537796
Epoch 86, Training Loss: 0.0705159455537796, Validation Loss: 0.06325932592153549
Epoch 87, Training Loss: 0.06325932592153549, Validation Loss: 0.056405555456876755
Epoch 88, Training Loss: 0.056405555456876755, Validation Loss: 0.05009622126817703
Epoch 89, Training Loss: 0.05009622126817703, Validation Loss: 0.04421861469745636
Epoch 90, Training Loss: 0.04421861097216606, Validation Loss: 0.03879806771874428
Epoch 91, Training Loss: 0.03879806771874428, Validation Loss: 0.03383556008338928
Epoch 92, Training Loss: 0.033835552632808685, Validation Loss: 0.029370229691267014
Epoch 93, Training Loss: 0.029370231553912163, Validation Loss: 0.025410542264580727
Epoch 94, Training Loss: 0.025410538539290428, Validation Loss: 0.021926313638687134
Epoch 95, Training Loss: 0.021926317363977432, Validation Loss: 0.018904251977801323
Epoch 96, Training Loss: 0.018904251977801323, Validation Loss: 0.01634778454899788
Epoch 97, Training Loss: 0.01634778268635273, Validation Loss: 0.014208427630364895
Epoch 98, Training Loss: 0.014208429493010044, Validation Loss: 0.012439235113561153
Epoch 99, Training Loss: 0.012439235113561153, Validation Loss: 0.01099451258778572
Epoch 100, Training Loss: 0.01099451258778572, Validation Loss: 0.009811455383896828
Epoch 101, Training Loss: 0.009811456315219402, Validation Loss: 0.008832664228975773
Epoch 102, Training Loss: 0.008832658641040325, Validation Loss: 0.00799558311700821
Epoch 103, Training Loss: 0.007995584048330784, Validation Loss: 0.007275008596479893
Epoch 104, Training Loss: 0.007275010924786329, Validation Loss: 0.006656626705080271
Epoch 105, Training Loss: 0.006656627636402845, Validation Loss: 0.006081645376980305
Epoch 106, Training Loss: 0.006081643048673868, Validation Loss: 0.005533202551305294
Epoch 107, Training Loss: 0.005533202551305294, Validation Loss: 0.005017466843128204
Epoch 108, Training Loss: 0.005017466843128204, Validation Loss: 0.004522248171269894
Epoch 109, Training Loss: 0.004522250033915043, Validation Loss: 0.004042824264615774
Epoch 110, Training Loss: 0.004042822867631912, Validation Loss: 0.00358709879219532
Epoch 111, Training Loss: 0.0035870992578566074, Validation Loss: 0.0031581739895045757
Epoch 112, Training Loss: 0.0031581739895045757, Validation Loss: 0.002757498761638999
Epoch 113, Training Loss: 0.0027574999257922173, Validation Loss: 0.002386748092249036
Epoch 114, Training Loss: 0.002386748557910323, Validation Loss: 0.002046175068244338
Epoch 115, Training Loss: 0.0020461739040911198, Validation Loss: 0.001734233694151044
Epoch 116, Training Loss: 0.001734233577735722, Validation Loss: 0.001453638426028192
Epoch 117, Training Loss: 0.0014536367962136865, Validation Loss: 0.0012063873000442982
Epoch 118, Training Loss: 0.0012063883477821946, Validation Loss: 0.0009923942852765322
Epoch 119, Training Loss: 0.0009923925390467048, Validation Loss: 0.0008110693888738751
Epoch 120, Training Loss: 0.0008110693888738751, Validation Loss: 0.0006620501517318189
Epoch 121, Training Loss: 0.0006620504427701235, Validation Loss: 0.0005441781249828637
Epoch 122, Training Loss: 0.0005441781249828637, Validation Loss: 0.00045316849718801677
Epoch 123, Training Loss: 0.00045316870091482997, Validation Loss: 0.0003842984151560813
Epoch 124, Training Loss: 0.0003842988808173686, Validation Loss: 0.0003316081711091101
Epoch 125, Training Loss: 0.0003316083748359233, Validation Loss: 0.000291867065243423
Epoch 126, Training Loss: 0.0002918672398664057, Validation Loss: 0.0002609907533042133
Epoch 127, Training Loss: 0.00026099022943526506, Validation Loss: 0.0002360692888032645
Epoch 128, Training Loss: 0.0002360691869398579, Validation Loss: 0.00021540367743000388
Epoch 129, Training Loss: 0.00021540380839724094, Validation Loss: 0.00019815497216768563
Epoch 130, Training Loss: 0.00019815462292172015, Validation Loss: 0.0001839354808907956
Epoch 131, Training Loss: 0.0001839357428252697, Validation Loss: 0.00017262193432543427
Epoch 132, Training Loss: 0.00017262197798117995, Validation Loss: 0.00016401235188823193
Epoch 133, Training Loss: 0.00016401241009589285, Validation Loss: 0.000157792484969832
Epoch 134, Training Loss: 0.00015779239765834063, Validation Loss: 0.0001524026010883972
Epoch 135, Training Loss: 0.00015240276115946472, Validation Loss: 0.0001480377250118181
Epoch 136, Training Loss: 0.00014803763770032674, Validation Loss: 0.00014388149429578334
Epoch 137, Training Loss: 0.00014388134877663106, Validation Loss: 0.0001392020349157974
Epoch 138, Training Loss: 0.00013920162746217102, Validation Loss: 0.0001334925036644563
Epoch 139, Training Loss: 0.00013349299842957407, Validation Loss: 0.00012630601122509688
Epoch 140, Training Loss: 0.00012630558921955526, Validation Loss: 0.00011794482998084277
Epoch 141, Training Loss: 0.00011794453166658059, Validation Loss: 0.00010896469029830769
Epoch 142, Training Loss: 0.00010896472667809576, Validation Loss: 9.967702499125153e-05
Epoch 143, Training Loss: 9.967733058147132e-05, Validation Loss: 9.028663771459833e-05
Epoch 144, Training Loss: 9.028684871736914e-05, Validation Loss: 8.133101800922304e-05
Epoch 145, Training Loss: 8.133080700645223e-05, Validation Loss: 7.314725371543318e-05
Epoch 146, Training Loss: 7.314727554330602e-05, Validation Loss: 6.589545228052884e-05
Epoch 147, Training Loss: 6.589543772861362e-05, Validation Loss: 5.956986206001602e-05
Epoch 148, Training Loss: 5.956986206001602e-05, Validation Loss: 5.404589683166705e-05
Epoch 149, Training Loss: 5.404624607763253e-05, Validation Loss: 4.91412247356493e-05
Epoch 150, Training Loss: 4.914123201160692e-05, Validation Loss: 4.467110557015985e-05
Epoch 151, Training Loss: 4.4671051000477746e-05, Validation Loss: 4.048790651722811e-05
Epoch 152, Training Loss: 4.048794653499499e-05, Validation Loss: 3.649927748483606e-05
Epoch 153, Training Loss: 3.6499081033980474e-05, Validation Loss: 3.266330895712599e-05
Epoch 154, Training Loss: 3.266333806095645e-05, Validation Loss: 2.8976459361729212e-05
Epoch 155, Training Loss: 2.897623198805377e-05, Validation Loss: 2.5451952751609497e-05
Epoch 156, Training Loss: 2.5451783585594967e-05, Validation Loss: 2.210750062658917e-05
Epoch 157, Training Loss: 2.210758248111233e-05, Validation Loss: 1.895782224892173e-05
Epoch 158, Training Loss: 1.8957824067911133e-05, Validation Loss: 1.6014866559999064e-05
Epoch 159, Training Loss: 1.6014815628295764e-05, Validation Loss: 1.329329825239256e-05
Epoch 160, Training Loss: 1.3293309166328982e-05, Validation Loss: 1.081551999959629e-05
Epoch 161, Training Loss: 1.0815621863002889e-05, Validation Loss: 8.61308399180416e-06
Epoch 162, Training Loss: 8.613106729171705e-06, Validation Loss: 6.723095793859102e-06
Epoch 163, Training Loss: 6.722972557327012e-06, Validation Loss: 5.179509116715053e-06
Epoch 164, Training Loss: 5.179361323826015e-06, Validation Loss: 4.002952209702926e-06
Epoch 165, Training Loss: 4.002863533969503e-06, Validation Loss: 3.191451241946197e-06
Epoch 166, Training Loss: 3.191399400748196e-06, Validation Loss: 2.715828259169939e-06
Epoch 167, Training Loss: 2.7159044293512125e-06, Validation Loss: 2.5179333533742465e-06
Epoch 168, Training Loss: 2.5179626845783787e-06, Validation Loss: 2.522938757465454e-06
Epoch 169, Training Loss: 2.522928525650059e-06, Validation Loss: 2.648238250912982e-06
Epoch 170, Training Loss: 2.648237114044605e-06, Validation Loss: 2.815893594743102e-06
Epoch 171, Training Loss: 2.8158717668702593e-06, Validation Loss: 2.9628204174514394e-06
Epoch 172, Training Loss: 2.9628411084559048e-06, Validation Loss: 3.0477167456410825e-06
Epoch 173, Training Loss: 3.04772834169853e-06, Validation Loss: 3.052282181670307e-06
Epoch 174, Training Loss: 3.0522537599608768e-06, Validation Loss: 2.978358224936528e-06
Epoch 175, Training Loss: 2.9784855541947763e-06, Validation Loss: 2.841677087417338e-06
Epoch 176, Training Loss: 2.8417182420525933e-06, Validation Loss: 2.663904979272047e-06
Epoch 177, Training Loss: 2.6639158932084683e-06, Validation Loss: 2.46639751821931e-06
Epoch 178, Training Loss: 2.466364776410046e-06, Validation Loss: 2.2655776774627157e-06
Epoch 179, Training Loss: 2.2655872271570843e-06, Validation Loss: 2.0711918296001386e-06
Epoch 180, Training Loss: 2.0711690922325943e-06, Validation Loss: 1.8869079667638289e-06
Epoch 181, Training Loss: 1.8869155837819562e-06, Validation Loss: 1.7125483964264276e-06
Epoch 182, Training Loss: 1.7125198610301595e-06, Validation Loss: 1.5463347153854556e-06
Epoch 183, Training Loss: 1.546296630294819e-06, Validation Loss: 1.3869811255062814e-06
Epoch 184, Training Loss: 1.386984536111413e-06, Validation Loss: 1.2350936913207988e-06
Epoch 185, Training Loss: 1.2351395071164006e-06, Validation Loss: 1.0925630249403184e-06
Epoch 186, Training Loss: 1.0925576816589455e-06, Validation Loss: 9.621352319300058e-07
Epoch 187, Training Loss: 9.621277285987162e-07, Validation Loss: 8.460625053885451e-07
Epoch 188, Training Loss: 8.460733624815475e-07, Validation Loss: 7.455051331817231e-07
Epoch 189, Training Loss: 7.455122954524995e-07, Validation Loss: 6.599468633794459e-07
Epoch 190, Training Loss: 6.599584594368935e-07, Validation Loss: 5.874580892850645e-07
Epoch 191, Training Loss: 5.874540534023254e-07, Validation Loss: 5.252444452708005e-07
Epoch 192, Training Loss: 5.25251607541577e-07, Validation Loss: 4.705912601821183e-07
Epoch 193, Training Loss: 4.7058478003236814e-07, Validation Loss: 4.2124801780119014e-07
Epoch 194, Training Loss: 4.2125046206820116e-07, Validation Loss: 3.759398339298059e-07
Epoch 195, Training Loss: 3.759089963750739e-07, Validation Loss: 3.341815215662791e-07
Epoch 196, Training Loss: 3.3419041756133083e-07, Validation Loss: 2.9615233643198735e-07
Epoch 197, Training Loss: 2.961297411729902e-07, Validation Loss: 2.619116230562213e-07
Epoch 198, Training Loss: 2.619198653519561e-07, Validation Loss: 2.3155102724103926e-07
Epoch 199, Training Loss: 2.315539688879653e-07, Validation Loss: 2.0460892358187266e-07
Epoch 200, Training Loss: 2.0460436189750908e-07, Validation Loss: 1.8035504467661667e-07
Epoch 201, Training Loss: 1.8036817550637352e-07, Validation Loss: 1.580057471528562e-07
Epoch 202, Training Loss: 1.580093851316633e-07, Validation Loss: 1.368513693478235e-07
Epoch 203, Training Loss: 1.3685301780697046e-07, Validation Loss: 1.1668186061797314e-07
Epoch 204, Training Loss: 1.1669096977584559e-07, Validation Loss: 9.768360342832239e-08
Epoch 205, Training Loss: 9.767442321617636e-08, Validation Loss: 8.041253352075728e-08
Epoch 206, Training Loss: 8.041103427558483e-08, Validation Loss: 6.562485310723787e-08
Epoch 207, Training Loss: 6.56222667316797e-08, Validation Loss: 5.393412294552036e-08
Epoch 208, Training Loss: 5.3935774957381e-08, Validation Loss: 4.5671423976045844e-08
Epoch 209, Training Loss: 4.566390998661518e-08, Validation Loss: 4.071957349083277e-08
Epoch 210, Training Loss: 4.0716248150829415e-08, Validation Loss: 3.856461106011011e-08
Epoch 211, Training Loss: 3.8563445770023463e-08, Validation Loss: 3.8419706527292874e-08
Epoch 212, Training Loss: 3.84160152577806e-08, Validation Loss: 3.938212600473889e-08
Epoch 213, Training Loss: 3.937603665349343e-08, Validation Loss: 4.062246006242276e-08
Epoch 214, Training Loss: 4.0625703690011505e-08, Validation Loss: 4.153115895633164e-08
Epoch 215, Training Loss: 4.152795796130704e-08, Validation Loss: 4.172352063847029e-08
Epoch 216, Training Loss: 4.1726352151272295e-08, Validation Loss: 4.1094825320442396e-08
Epoch 217, Training Loss: 4.109685747266667e-08, Validation Loss: 3.968957784650229e-08
Epoch 218, Training Loss: 3.9681772534549964e-08, Validation Loss: 3.7647374995231075e-08
Epoch 219, Training Loss: 3.7657656548617524e-08, Validation Loss: 3.51639322104802e-08
Epoch 220, Training Loss: 3.5168387313433414e-08, Validation Loss: 3.2380267356302284e-08
Epoch 221, Training Loss: 3.238087131762768e-08, Validation Loss: 2.9419995328794357e-08
Epoch 222, Training Loss: 2.941832377700848e-08, Validation Loss: 2.6380739370779338e-08
Epoch 223, Training Loss: 2.6375172268444658e-08, Validation Loss: 2.3356165002041962e-08
Epoch 224, Training Loss: 2.334926563207773e-08, Validation Loss: 2.0454235638567297e-08
Epoch 225, Training Loss: 2.0452084470434784e-08, Validation Loss: 1.777776503786299e-08
Epoch 226, Training Loss: 1.7782586070325124e-08, Validation Loss: 1.54025840970462e-08
Epoch 227, Training Loss: 1.5403218256437867e-08, Validation Loss: 1.3393538722539233e-08
Epoch 228, Training Loss: 1.3396380893482274e-08, Validation Loss: 1.174247632462766e-08
Epoch 229, Training Loss: 1.1739565763946302e-08, Validation Loss: 1.0401196348652775e-08
Epoch 230, Training Loss: 1.0397118721527931e-08, Validation Loss: 9.284661928177229e-09
Epoch 231, Training Loss: 9.279749413337868e-09, Validation Loss: 8.288957076274528e-09
Epoch 232, Training Loss: 8.288769670627971e-09, Validation Loss: 7.334225671229433e-09
Epoch 233, Training Loss: 7.335782647999167e-09, Validation Loss: 6.361208448879552e-09
Epoch 234, Training Loss: 6.36444097423805e-09, Validation Loss: 5.362356336746643e-09
Epoch 235, Training Loss: 5.364800603757658e-09, Validation Loss: 4.36091163180663e-09
Epoch 236, Training Loss: 4.361790484352923e-09, Validation Loss: 3.4154938877151153e-09
Epoch 237, Training Loss: 3.415868476963624e-09, Validation Loss: 2.5823900795529653e-09
Epoch 238, Training Loss: 2.5820456883707266e-09, Validation Loss: 1.9146795260382987e-09
Epoch 239, Training Loss: 1.9145556251487506e-09, Validation Loss: 1.4355961974743536e-09
Epoch 240, Training Loss: 1.4347594223806936e-09, Validation Loss: 1.1420473455814317e-09
Epoch 241, Training Loss: 1.1425084212035586e-09, Validation Loss: 1.0091989466332052e-09
Epoch 242, Training Loss: 1.0105315473296628e-09, Validation Loss: 9.989999938397887e-10
Epoch 243, Training Loss: 9.989522542497298e-10, Validation Loss: 1.064079269141871e-09
Epoch 244, Training Loss: 1.0630639701858513e-09, Validation Loss: 1.163589335995141e-09
Epoch 245, Training Loss: 1.162808960231132e-09, Validation Loss: 1.2657553893902218e-09
Epoch 246, Training Loss: 1.2661710568906415e-09, Validation Loss: 1.3544954047262081e-09
Epoch 247, Training Loss: 1.3513320462621436e-09, Validation Loss: 1.4112745416738903e-09
Epoch 248, Training Loss: 1.4104620804644696e-09, Validation Loss: 1.4349024191062654e-09
Epoch 249, Training Loss: 1.434128926725009e-09, Validation Loss: 1.4246392954220255e-09
Epoch 250, Training Loss: 1.423874906869571e-09, Validation Loss: 1.380497938185954e-09
Epoch 251, Training Loss: 1.3794042574843957e-09, Validation Loss: 1.3030228007693268e-09
Epoch 252, Training Loss: 1.303790519990855e-09, Validation Loss: 1.2015366479545264e-09
Epoch 253, Training Loss: 1.2020251460853615e-09, Validation Loss: 1.0825129681535373e-09
Epoch 254, Training Loss: 1.0823882901078719e-09, Validation Loss: 9.54363921223944e-10
Epoch 255, Training Loss: 9.534518730092145e-10, Validation Loss: 8.276326290967972e-10
Epoch 256, Training Loss: 8.266287654379312e-10, Validation Loss: 7.113573063932677e-10
Epoch 257, Training Loss: 7.108150179568895e-10, Validation Loss: 6.099510896362403e-10
Epoch 258, Training Loss: 6.096521065757088e-10, Validation Loss: 5.256790003294043e-10
Epoch 259, Training Loss: 5.262667523986408e-10, Validation Loss: 4.591233226935998e-10
Epoch 260, Training Loss: 4.591396707276374e-10, Validation Loss: 4.068083092612085e-10
Epoch 261, Training Loss: 4.063304415158342e-10, Validation Loss: 3.622364630473385e-10
Epoch 262, Training Loss: 3.6244116041750374e-10, Validation Loss: 3.2298555496801384e-10
Epoch 263, Training Loss: 3.233910639277582e-10, Validation Loss: 2.8752891734207253e-10
Epoch 264, Training Loss: 2.877371674259166e-10, Validation Loss: 2.5321314489623603e-10
Epoch 265, Training Loss: 2.5329696673459523e-10, Validation Loss: 2.1964713381450451e-10
Epoch 266, Training Loss: 2.203170007541999e-10, Validation Loss: 1.8885699948345547e-10
Epoch 267, Training Loss: 1.8844358018466068e-10, Validation Loss: 1.6073385677994878e-10
Epoch 268, Training Loss: 1.6070703101611628e-10, Validation Loss: 1.3537206078328978e-10
Epoch 269, Training Loss: 1.3527445830163742e-10, Validation Loss: 1.1269893351872895e-10
Epoch 270, Training Loss: 1.1262192567418339e-10, Validation Loss: 9.385501403835761e-11
Epoch 271, Training Loss: 9.372490283876544e-11, Validation Loss: 7.77156811127e-11
Epoch 272, Training Loss: 7.701089765888014e-11, Validation Loss: 6.320268614024016e-11
Epoch 273, Training Loss: 6.283917830529617e-11, Validation Loss: 5.1804890238704715e-11
Epoch 274, Training Loss: 5.195377808520085e-11, Validation Loss: 4.294463742948729e-11
Epoch 275, Training Loss: 4.292310257225651e-11, Validation Loss: 3.7333868635469614e-11
Epoch 276, Training Loss: 3.703843828861686e-11, Validation Loss: 3.4322759911997736e-11
Epoch 277, Training Loss: 3.43142562975185e-11, Validation Loss: 3.377409463212189e-11
Epoch 278, Training Loss: 3.362637945869551e-11, Validation Loss: 3.5145220067533955e-11
Epoch 279, Training Loss: 3.502968401458695e-11, Validation Loss: 3.708510581956759e-11
Epoch 280, Training Loss: 3.738355458526854e-11, Validation Loss: 3.991407204750885e-11
Epoch 281, Training Loss: 4.014083163084159e-11, Validation Loss: 4.20276660695329e-11
Epoch 282, Training Loss: 4.2334625388606995e-11, Validation Loss: 4.318646829037931e-11
Epoch 283, Training Loss: 4.333049544169576e-11, Validation Loss: 4.322067356787862e-11
Epoch 284, Training Loss: 4.323531116456891e-11, Validation Loss: 4.186416491247513e-11
Epoch 285, Training Loss: 4.166532743821172e-11, Validation Loss: 3.937752554583618e-11
Epoch 286, Training Loss: 3.941331636059253e-11, Validation Loss: 3.605254636496191e-11
Epoch 287, Training Loss: 3.6538192610402476e-11, Validation Loss: 3.2668583116457484e-11
Epoch 288, Training Loss: 3.2721936271684626e-11, Validation Loss: 2.9157804642965246e-11
Epoch 289, Training Loss: 2.9117097621877974e-11, Validation Loss: 2.5775846734799046e-11
Epoch 290, Training Loss: 2.568388730861404e-11, Validation Loss: 2.225390878518585e-11
Epoch 291, Training Loss: 2.2301422861192854e-11, Validation Loss: 1.9168026541005467e-11
Epoch 292, Training Loss: 1.899824741968814e-11, Validation Loss: 1.61081460670065e-11
Epoch 293, Training Loss: 1.61452622104985e-11, Validation Loss: 1.3429752102056547e-11
Epoch 294, Training Loss: 1.3362791775883842e-11, Validation Loss: 1.0947282143292103e-11
Epoch 295, Training Loss: 1.082594517504143e-11, Validation Loss: 8.88228119527712e-12
Epoch 296, Training Loss: 8.783681247626074e-12, Validation Loss: 7.0739590400659136e-12
Epoch 297, Training Loss: 7.000202500995201e-12, Validation Loss: 5.679394454727316e-12
Epoch 298, Training Loss: 5.617973100613405e-12, Validation Loss: 4.726755445383368e-12
Epoch 299, Training Loss: 4.644720805885294e-12, Validation Loss: 3.902153773716055e-12
Epoch 300, Training Loss: 3.92434435642075e-12, Validation Loss: 3.3329456815972547e-12
Epoch 301, Training Loss: 3.4558020507724496e-12, Validation Loss: 3.00531930071124e-12
Epoch 302, Training Loss: 3.0015647085879227e-12, Validation Loss: 2.7119682367848785e-12
Epoch 303, Training Loss: 2.7200006569999546e-12, Validation Loss: 2.4916384060158503e-12
Epoch 304, Training Loss: 2.4908061724282504e-12, Validation Loss: 2.214533677963315e-12
Epoch 305, Training Loss: 2.304931202498639e-12, Validation Loss: 2.100991255971074e-12
Epoch 306, Training Loss: 2.0869729555617056e-12, Validation Loss: 2.027324055159374e-12
Epoch 307, Training Loss: 1.912814524829276e-12, Validation Loss: 1.8273867662121912e-12
Epoch 308, Training Loss: 1.8367518877376865e-12, Validation Loss: 1.7717011668513805e-12
Epoch 309, Training Loss: 1.7094448686444386e-12, Validation Loss: 1.7262767821116243e-12
Epoch 310, Training Loss: 1.712416558379004e-12, Validation Loss: 1.659811719491311e-12
Epoch 311, Training Loss: 1.6454784583508353e-12, Validation Loss: 1.6210874873370806e-12
Epoch 312, Training Loss: 1.6000449663128302e-12, Validation Loss: 1.59697613206361e-12
Epoch 313, Training Loss: 1.5465228923872143e-12, Validation Loss: 1.5351518884224036e-12
Epoch 314, Training Loss: 1.5114687930070647e-12, Validation Loss: 1.4906465818642634e-12
Epoch 315, Training Loss: 1.4751890030709203e-12, Validation Loss: 1.4584546677992583e-12
Epoch 316, Training Loss: 1.4098186593841655e-12, Validation Loss: 1.3415401602101529e-12
Epoch 317, Training Loss: 1.3394654309328846e-12, Validation Loss: 1.2599294437615205e-12
Epoch 318, Training Loss: 1.2546910125449395e-12, Validation Loss: 1.1651841600943125e-12
Epoch 319, Training Loss: 1.1590036656100589e-12, Validation Loss: 1.0343865521067475e-12
Epoch 320, Training Loss: 1.0393048184217935e-12, Validation Loss: 8.876126830065223e-13
Epoch 321, Training Loss: 9.23089512813724e-13, Validation Loss: 7.838541556288992e-13
Epoch 322, Training Loss: 7.699421612425428e-13, Validation Loss: 6.462090519805674e-13
Epoch 323, Training Loss: 6.532294778878456e-13, Validation Loss: 5.381189742935388e-13
Epoch 324, Training Loss: 5.314576361457879e-13, Validation Loss: 4.52013887474248e-13
Epoch 325, Training Loss: 4.569955525113301e-13, Validation Loss: 3.839233347468357e-13
Epoch 326, Training Loss: 3.830577890474862e-13, Validation Loss: 3.089910326301709e-13
Epoch 327, Training Loss: 3.1866734728422386e-13, Validation Loss: 2.5319598306004776e-13
Epoch 328, Training Loss: 2.7856566337490507e-13, Validation Loss: 2.2311240853965797e-13
Epoch 329, Training Loss: 2.4669597419556266e-13, Validation Loss: 2.0418797132704808e-13
Epoch 330, Training Loss: 2.0643514295985016e-13, Validation Loss: 1.8763457584544674e-13
Epoch 331, Training Loss: 1.9363358843855344e-13, Validation Loss: 1.8083619454309363e-13
Epoch 332, Training Loss: 1.7856533309282274e-13, Validation Loss: 1.642860652205369e-13
Epoch 333, Training Loss: 1.6037934597989273e-13, Validation Loss: 1.450776619064259e-13
Epoch 334, Training Loss: 1.406101119870093e-13, Validation Loss: 1.4620043457119758e-13
Epoch 335, Training Loss: 1.3663733772900644e-13, Validation Loss: 1.280219013482034e-13
Epoch 336, Training Loss: 1.3531093834371483e-13, Validation Loss: 1.1713395010881644e-13
Epoch 337, Training Loss: 1.157097692400938e-13, Validation Loss: 1.1315656121531695e-13
Epoch 338, Training Loss: 1.0136297590125284e-13, Validation Loss: 9.504284295344667e-14
Epoch 339, Training Loss: 9.408897543462108e-14, Validation Loss: 8.717460482860276e-14
Epoch 340, Training Loss: 9.035228619967695e-14, Validation Loss: 8.381110475769171e-14
Epoch 341, Training Loss: 7.944084165446494e-14, Validation Loss: 7.13637319810917e-14
Epoch 342, Training Loss: 6.602291819811021e-14, Validation Loss: 6.241415804325579e-14
Epoch 343, Training Loss: 6.062255461080496e-14, Validation Loss: 4.908274375587003e-14
Epoch 344, Training Loss: 5.754836033709451e-14, Validation Loss: 4.731459297166278e-14
Epoch 345, Training Loss: 4.483447033770682e-14, Validation Loss: 4.536095891266578e-14
Epoch 346, Training Loss: 4.0868326653615075e-14, Validation Loss: 2.972816627198546e-14
Epoch 347, Training Loss: 3.161587745076355e-14, Validation Loss: 2.609024954902065e-14
Epoch 348, Training Loss: 2.474433791275609e-14, Validation Loss: 1.899009412448336e-14
Epoch 349, Training Loss: 2.3424481009949073e-14, Validation Loss: 1.7865192018882287e-14
Epoch 350, Training Loss: 1.9250202695992105e-14, Validation Loss: 1.5598575897743036e-14
Epoch 351, Training Loss: 1.6167499129293543e-14, Validation Loss: 1.472470894671972e-14
Epoch 352, Training Loss: 1.4535224288287144e-14, Validation Loss: 1.399896010608392e-14
Epoch 353, Training Loss: 1.4834130356911925e-14, Validation Loss: 1.4794131767076682e-14
Epoch 354, Training Loss: 1.1691877832922543e-14, Validation Loss: 1.3372591947083574e-14
Epoch 355, Training Loss: 1.1506296302310915e-14, Validation Loss: 1.1127326138412816e-14
Epoch 356, Training Loss: 1.2935040984553368e-14, Validation Loss: 1.4921566179925197e-14
Epoch 357, Training Loss: 1.1790624086880502e-14, Validation Loss: 1.2191512075321754e-14
Epoch 358, Training Loss: 1.0649176039687763e-14, Validation Loss: 1.1449717889566117e-14
Epoch 359, Training Loss: 9.50442541103368e-15, Validation Loss: 9.44691272094806e-15
Epoch 360, Training Loss: 9.46572786380542e-15, Validation Loss: 9.206719588095158e-15
Epoch 361, Training Loss: 1.0406748433920004e-14, Validation Loss: 6.4416372829909606e-15
Epoch 362, Training Loss: 9.672026126240994e-15, Validation Loss: 8.544388951253236e-15
Epoch 363, Training Loss: 9.715760978406575e-15, Validation Loss: 6.796388233828218e-15
Epoch 364, Training Loss: 1.1792358810356479e-14, Validation Loss: 8.944910174428326e-15
Epoch 365, Training Loss: 8.089557669566094e-15, Validation Loss: 7.956384608499931e-15
Epoch 366, Training Loss: 8.148238418085978e-15, Validation Loss: 5.4525780863057954e-15
Epoch 367, Training Loss: 8.837724084183925e-15, Validation Loss: 1.0699049339622096e-14
Epoch 368, Training Loss: 5.332415027792985e-15, Validation Loss: 8.69337527041169e-15
Epoch 369, Training Loss: 4.233400790158845e-15, Validation Loss: 5.792917618578468e-15
Epoch 370, Training Loss: 4.040579668947034e-15, Validation Loss: 1.0397274370404965e-14
Epoch 371, Training Loss: 3.5070854962395695e-15, Validation Loss: 8.979203997363811e-15
Epoch 372, Training Loss: 3.206411246337395e-15, Validation Loss: 1.0305200194972528e-14
Epoch 373, Training Loss: 2.3930927514826577e-15, Validation Loss: 8.19537580160068e-15
Epoch 374, Training Loss: 2.6511663263356243e-15, Validation Loss: 7.094227040939458e-15
Epoch 375, Training Loss: 3.1625095286812047e-15, Validation Loss: 9.00949558962352e-15
Epoch 376, Training Loss: 5.1132727812617206e-15, Validation Loss: 9.848567274206577e-15
Epoch 377, Training Loss: 4.9636863392601375e-15, Validation Loss: 1.024521925087861e-14
Epoch 378, Training Loss: 2.429955625347165e-15, Validation Loss: 1.17973961152938e-14
Epoch 379, Training Loss: 2.4695874499162463e-15, Validation Loss: 8.56076887438724e-15
Epoch 380, Training Loss: 2.237768296538137e-15, Validation Loss: 6.498049253761623e-15
Epoch 381, Training Loss: 2.3514593880592143e-15, Validation Loss: 6.716257222952066e-15
Epoch 382, Training Loss: 1.489035005120356e-15, Validation Loss: 6.447241676486469e-15
Epoch 383, Training Loss: 2.268226119013744e-15, Validation Loss: 6.221727624609484e-15
Epoch 384, Training Loss: 1.870807577524446e-15, Validation Loss: 6.754921735895383e-15
Epoch 385, Training Loss: 1.888822062488414e-15, Validation Loss: 6.671855332340522e-15
Epoch 386, Training Loss: 1.539875722559572e-15, Validation Loss: 6.556696120963617e-15
Epoch 387, Training Loss: 1.3219677089115756e-15, Validation Loss: 7.011460487047925e-15
Epoch 388, Training Loss: 9.14874886494331e-16, Validation Loss: 6.57371004825864e-15
Epoch 389, Training Loss: 1.3260043503008343e-15, Validation Loss: 6.6874678436243135e-15
Epoch 390, Training Loss: 1.206408486225329e-15, Validation Loss: 6.489108821003354e-15
Epoch 391, Training Loss: 1.98453212684694e-15, Validation Loss: 6.899037192090651e-15
Epoch 392, Training Loss: 2.435426822911717e-15, Validation Loss: 6.815770465243764e-15
Epoch 393, Training Loss: 1.6619736160821482e-15, Validation Loss: 5.765328484936974e-15
Epoch 394, Training Loss: 1.6619736160821482e-15, Validation Loss: 5.772668025424933e-15
Epoch 395, Training Loss: 1.6759848115791552e-15, Validation Loss: 5.75665486755709e-15
Epoch 396, Training Loss: 1.5855122695708577e-15, Validation Loss: 5.75665486755709e-15
Epoch 397, Training Loss: 1.7845050845946e-15, Validation Loss: 5.725963899262752e-15
Epoch 398, Training Loss: 1.355361135824129e-15, Validation Loss: 5.697274046306301e-15
Epoch 399, Training Loss: 2.0305690028049215e-15, Validation Loss: 5.718958089756011e-15
Epoch 400, Training Loss: 1.913141437195269e-15, Validation Loss: 6.231368977131606e-15
Epoch 401, Training Loss: 1.8468217220405725e-15, Validation Loss: 6.408577587059625e-15
Epoch 402, Training Loss: 1.3920572500771456e-15, Validation Loss: 5.87054649412843e-15
Epoch 403, Training Loss: 1.953707327346935e-15, Validation Loss: 5.733102692942211e-15
Epoch 404, Training Loss: 1.949704249638211e-15, Validation Loss: 5.733102692942211e-15
Epoch 405, Training Loss: 1.4404960997153036e-15, Validation Loss: 6.376685102529606e-15
Epoch 406, Training Loss: 1.901932438446016e-15, Validation Loss: 6.030808092364259e-15
Epoch 407, Training Loss: 1.4132742607355633e-15, Validation Loss: 5.632889377919607e-15
Epoch 408, Training Loss: 1.3895218687077766e-15, Validation Loss: 5.632889377919607e-15
Epoch 409, Training Loss: 1.0712668147106288e-15, Validation Loss: 5.260190645962979e-15
Epoch 410, Training Loss: 1.0452126106486785e-15, Validation Loss: 5.999449662107484e-15
Epoch 411, Training Loss: 9.067016538280375e-16, Validation Loss: 6.059497945320709e-15
Epoch 412, Training Loss: 6.17269701657855e-16, Validation Loss: 5.905774594404736e-15
Epoch 413, Training Loss: 5.823416628031135e-16, Validation Loss: 5.255786921670204e-15
Epoch 414, Training Loss: 5.691311251994986e-16, Validation Loss: 5.255786921670204e-15
Epoch 415, Training Loss: 7.003029121090956e-16, Validation Loss: 5.323040914165722e-15
Epoch 416, Training Loss: 1.0473810149936496e-15, Validation Loss: 5.425523006937546e-15
Epoch 417, Training Loss: 1.0407090423472458e-15, Validation Loss: 5.129952977575526e-15
Epoch 418, Training Loss: 1.1255770849809168e-15, Validation Loss: 6.2673975235430675e-15
Epoch 419, Training Loss: 1.1031590874824109e-15, Validation Loss: 7.05636339764777e-15
Epoch 420, Training Loss: 1.097821509365288e-15, Validation Loss: 7.05636339764777e-15
Epoch 421, Training Loss: 1.0018445237492584e-15, Validation Loss: 6.948543726758823e-15
Epoch 422, Training Loss: 7.056071383039204e-16, Validation Loss: 7.008191363387997e-15
Epoch 423, Training Loss: 1.9053686393547898e-15, Validation Loss: 6.622815936342761e-15
Epoch 424, Training Loss: 2.113135233404429e-15, Validation Loss: 6.629221199489898e-15
Epoch 425, Training Loss: 1.6052614780108021e-15, Validation Loss: 6.525271198620482e-15
Epoch 426, Training Loss: 1.3003504751855802e-15, Validation Loss: 6.525271198620482e-15
Epoch 427, Training Loss: 1.1486288748822058e-15, Validation Loss: 5.474829218313692e-15
Epoch 428, Training Loss: 1.1893281727230645e-15, Validation Loss: 5.474829218313692e-15
Epoch 429, Training Loss: 1.1793200549347813e-15, Validation Loss: 6.640963617237684e-15
Epoch 430, Training Loss: 1.211345735395756e-15, Validation Loss: 5.0413152148100996e-15
Epoch 431, Training Loss: 1.121673957159969e-15, Validation Loss: 4.785109771122302e-15
Epoch 432, Training Loss: 1.045479531906182e-15, Validation Loss: 4.8875918638941265e-15
Epoch 433, Training Loss: 1.0300004283115833e-15, Validation Loss: 4.462317796901424e-15
Epoch 434, Training Loss: 1.2700595182005823e-15, Validation Loss: 4.580812624024617e-15
Epoch 435, Training Loss: 1.051217438970001e-15, Validation Loss: 4.580812624024617e-15
Epoch 436, Training Loss: 1.42912034135456e-15, Validation Loss: 5.8570354715867766e-15
Epoch 437, Training Loss: 1.3523921794648844e-15, Validation Loss: 5.8483618542068926e-15
Epoch 438, Training Loss: 1.4738228227832609e-15, Validation Loss: 5.8483618542068926e-15
Epoch 439, Training Loss: 1.4756909539484302e-15, Validation Loss: 5.7298670270836995e-15
Epoch 440, Training Loss: 1.0593573197139965e-15, Validation Loss: 5.781508508295426e-15
Epoch 441, Training Loss: 1.6134013587547976e-15, Validation Loss: 5.679025992007128e-15
Epoch 442, Training Loss: 1.6444928677540691e-15, Validation Loss: 6.362240226163605e-15
Epoch 443, Training Loss: 1.6444928677540691e-15, Validation Loss: 6.5349121276261305e-15
Epoch 444, Training Loss: 1.1135674283382717e-15, Validation Loss: 5.146999939155492e-15
Epoch 445, Training Loss: 1.7345650808156705e-15, Validation Loss: 4.512057689146564e-15
Epoch 446, Training Loss: 1.4420639577006713e-15, Validation Loss: 4.381953428448304e-15
Epoch 447, Training Loss: 2.2576843704686907e-15, Validation Loss: 4.858068107001104e-15
Epoch 448, Training Loss: 2.0799419180256642e-15, Validation Loss: 5.2679969016048746e-15
Epoch 449, Training Loss: 2.1373212004220914e-15, Validation Loss: 5.2679969016048746e-15
Epoch 450, Training Loss: 2.103293981106755e-15, Validation Loss: 4.6865972982577855e-15
Epoch 451, Training Loss: 1.6254109095183242e-15, Validation Loss: 6.29505314927092e-15
Epoch 452, Training Loss: 1.6346182635340969e-15, Validation Loss: 6.466924181081817e-15
Epoch 453, Training Loss: 1.7140153203614524e-15, Validation Loss: 6.480935376578824e-15
Epoch 454, Training Loss: 2.284339015011126e-15, Validation Loss: 6.508591002306677e-15
Epoch 455, Training Loss: 1.5695327812626685e-15, Validation Loss: 3.6955365627182584e-15
Epoch 456, Training Loss: 1.3211671568973018e-15, Validation Loss: 3.560094723902875e-15
Epoch 457, Training Loss: 1.3398821381086488e-15, Validation Loss: 3.663677535989656e-15
Epoch 458, Training Loss: 1.3058548129141938e-15, Validation Loss: 3.663677535989656e-15
Epoch 459, Training Loss: 1.2604851871604117e-15, Validation Loss: 4.088017749158011e-15
Epoch 460, Training Loss: 1.8337111343247336e-15, Validation Loss: 3.485268045100667e-15
Epoch 461, Training Loss: 1.401364765738931e-15, Validation Loss: 3.5066185693273955e-15
Epoch 462, Training Loss: 2.56847494661816e-16, Validation Loss: 3.5050172535406113e-15
Epoch 463, Training Loss: 3.856173608307958e-16, Validation Loss: 3.730531305417596e-15
Epoch 464, Training Loss: 4.1323950228745255e-16, Validation Loss: 3.920516983838473e-15
Epoch 465, Training Loss: 4.3458994710484245e-16, Validation Loss: 3.835648941204802e-15
Epoch 466, Training Loss: 3.785450327679164e-16, Validation Loss: 3.720356322138704e-15
Epoch 467, Training Loss: 3.8334887424915076e-16, Validation Loss: 3.4621495513547816e-15
Epoch 468, Training Loss: 3.625321925374291e-16, Validation Loss: 3.526200912276731e-15
Epoch 469, Training Loss: 3.625321925374291e-16, Validation Loss: 3.4733585501040345e-15
Epoch 470, Training Loss: 3.3717853766241734e-16, Validation Loss: 3.4733585501040345e-15
Epoch 471, Training Loss: 4.0122987211458705e-16, Validation Loss: 3.531004647878847e-15
Epoch 472, Training Loss: 9.344572294436664e-16, Validation Loss: 3.64242717340894e-15
Epoch 473, Training Loss: 9.344572294436664e-16, Validation Loss: 3.698472378913442e-15
Epoch 474, Training Loss: 7.679237228103337e-16, Validation Loss: 3.698472378913442e-15
Epoch 475, Training Loss: 7.599173556346493e-16, Validation Loss: 3.584781075634128e-15
Epoch 476, Training Loss: 7.6725652554569335e-16, Validation Loss: 3.8288434549900874e-15
Epoch 477, Training Loss: 7.592501054304497e-16, Validation Loss: 5.225162445462225e-15
Epoch 478, Training Loss: 7.592501054304497e-16, Validation Loss: 5.474962626002885e-15
Epoch 479, Training Loss: 7.592501054304497e-16, Validation Loss: 4.245177089224521e-15
Epoch 480, Training Loss: 7.720604199664869e-16, Validation Loss: 4.174720465155435e-15
Epoch 481, Training Loss: 4.453986169073994e-16, Validation Loss: 4.174720465155435e-15
Epoch 482, Training Loss: 5.158550821578081e-16, Validation Loss: 4.174720465155435e-15
Epoch 483, Training Loss: 1.2749967673710092e-15, Validation Loss: 4.13628973330556e-15
Epoch 484, Training Loss: 1.2513778889115335e-15, Validation Loss: 4.13628973330556e-15
Epoch 485, Training Loss: 1.1969342109520529e-15, Validation Loss: 4.497779678271172e-15
Epoch 486, Training Loss: 7.469736334094195e-16, Validation Loss: 4.525001199613557e-15
Epoch 487, Training Loss: 9.467337014646966e-16, Validation Loss: 4.367542009883719e-15
Epoch 488, Training Loss: 1.525864527062565e-15, Validation Loss: 3.532072332908861e-15
Epoch 489, Training Loss: 1.0743025807935882e-15, Validation Loss: 3.860335292936055e-15
Epoch 490, Training Loss: 1.934191688242196e-15, Validation Loss: 3.975627912002153e-15
Epoch 491, Training Loss: 1.649163301546111e-15, Validation Loss: 3.975627912002153e-15
Epoch 492, Training Loss: 1.6479623147060227e-15, Validation Loss: 3.565699117398383e-15
Epoch 493, Training Loss: 1.6746837689721726e-15, Validation Loss: 3.5870498533833485e-15
Epoch 494, Training Loss: 1.5695327812626685e-15, Validation Loss: 3.996978224470645e-15
Epoch 495, Training Loss: 1.1423904772256779e-15, Validation Loss: 4.57971190470966e-15
Epoch 496, Training Loss: 1.1606717775680306e-15, Validation Loss: 3.266793048773602e-15
Epoch 497, Training Loss: 9.743892213134311e-16, Validation Loss: 3.266793048773602e-15
Epoch 498, Training Loss: 9.651818672976585e-16, Validation Loss: 3.266793048773602e-15
Epoch 499, Training Loss: 9.651818672976585e-16, Validation Loss: 3.676721419860899e-15
Epoch 500, Training Loss: 1.2021717333022815e-15, Validation Loss: 3.676721419860899e-15
