Epoch 1, Training Loss: 0.506252110004425, Validation Loss: 0.5049920082092285
Epoch 2, Training Loss: 0.5049920082092285, Validation Loss: 0.5037477016448975
Epoch 3, Training Loss: 0.5037477016448975, Validation Loss: 0.5025522708892822
Epoch 4, Training Loss: 0.5025522708892822, Validation Loss: 0.5014447569847107
Epoch 5, Training Loss: 0.5014447569847107, Validation Loss: 0.5003771185874939
Epoch 6, Training Loss: 0.5003770589828491, Validation Loss: 0.49931806325912476
Epoch 7, Training Loss: 0.49931806325912476, Validation Loss: 0.49826711416244507
Epoch 8, Training Loss: 0.49826711416244507, Validation Loss: 0.4972183108329773
Epoch 9, Training Loss: 0.4972183108329773, Validation Loss: 0.49617117643356323
Epoch 10, Training Loss: 0.49617117643356323, Validation Loss: 0.4951109290122986
Epoch 11, Training Loss: 0.4951108694076538, Validation Loss: 0.4940357208251953
Epoch 12, Training Loss: 0.4940357208251953, Validation Loss: 0.4929426908493042
Epoch 13, Training Loss: 0.4929426610469818, Validation Loss: 0.49183928966522217
Epoch 14, Training Loss: 0.49183934926986694, Validation Loss: 0.4907371997833252
Epoch 15, Training Loss: 0.4907371699810028, Validation Loss: 0.489644855260849
Epoch 16, Training Loss: 0.48964494466781616, Validation Loss: 0.488518089056015
Epoch 17, Training Loss: 0.4885180592536926, Validation Loss: 0.4873370826244354
Epoch 18, Training Loss: 0.4873371124267578, Validation Loss: 0.4861339330673218
Epoch 19, Training Loss: 0.4861339330673218, Validation Loss: 0.4849241375923157
Epoch 20, Training Loss: 0.4849241375923157, Validation Loss: 0.4836771488189697
Epoch 21, Training Loss: 0.4836772084236145, Validation Loss: 0.482394814491272
Epoch 22, Training Loss: 0.482394814491272, Validation Loss: 0.481076717376709
Epoch 23, Training Loss: 0.481076717376709, Validation Loss: 0.4797156751155853
Epoch 24, Training Loss: 0.4797156751155853, Validation Loss: 0.4782944619655609
Epoch 25, Training Loss: 0.4782944321632385, Validation Loss: 0.47682368755340576
Epoch 26, Training Loss: 0.47682368755340576, Validation Loss: 0.47530442476272583
Epoch 27, Training Loss: 0.47530442476272583, Validation Loss: 0.47370296716690063
Epoch 28, Training Loss: 0.47370296716690063, Validation Loss: 0.4720113277435303
Epoch 29, Training Loss: 0.47201138734817505, Validation Loss: 0.47024548053741455
Epoch 30, Training Loss: 0.47024545073509216, Validation Loss: 0.4684116840362549
Epoch 31, Training Loss: 0.4684116840362549, Validation Loss: 0.46648943424224854
Epoch 32, Training Loss: 0.4664894938468933, Validation Loss: 0.4644410014152527
Epoch 33, Training Loss: 0.4644410014152527, Validation Loss: 0.4622959792613983
Epoch 34, Training Loss: 0.4622959792613983, Validation Loss: 0.46006619930267334
Epoch 35, Training Loss: 0.46006619930267334, Validation Loss: 0.45773768424987793
Epoch 36, Training Loss: 0.45773768424987793, Validation Loss: 0.45525798201560974
Epoch 37, Training Loss: 0.45525798201560974, Validation Loss: 0.4526306092739105
Epoch 38, Training Loss: 0.4526306390762329, Validation Loss: 0.44986629486083984
Epoch 39, Training Loss: 0.4498663544654846, Validation Loss: 0.44690364599227905
Epoch 40, Training Loss: 0.4469035863876343, Validation Loss: 0.44366154074668884
Epoch 41, Training Loss: 0.44366151094436646, Validation Loss: 0.44012221693992615
Epoch 42, Training Loss: 0.44012221693992615, Validation Loss: 0.4363572597503662
Epoch 43, Training Loss: 0.4363572299480438, Validation Loss: 0.43232059478759766
Epoch 44, Training Loss: 0.43232059478759766, Validation Loss: 0.42799946665763855
Epoch 45, Training Loss: 0.42799946665763855, Validation Loss: 0.4233636260032654
Epoch 46, Training Loss: 0.4233636260032654, Validation Loss: 0.4183877408504486
Epoch 47, Training Loss: 0.4183877408504486, Validation Loss: 0.41305646300315857
Epoch 48, Training Loss: 0.4130564332008362, Validation Loss: 0.40743499994277954
Epoch 49, Training Loss: 0.40743499994277954, Validation Loss: 0.4014502465724945
Epoch 50, Training Loss: 0.4014502167701721, Validation Loss: 0.39503607153892517
Epoch 51, Training Loss: 0.39503607153892517, Validation Loss: 0.388185977935791
Epoch 52, Training Loss: 0.388185977935791, Validation Loss: 0.38090333342552185
Epoch 53, Training Loss: 0.38090330362319946, Validation Loss: 0.3731442391872406
Epoch 54, Training Loss: 0.373144268989563, Validation Loss: 0.364885151386261
Epoch 55, Training Loss: 0.364885151386261, Validation Loss: 0.3561713695526123
Epoch 56, Training Loss: 0.3561713695526123, Validation Loss: 0.34705910086631775
Epoch 57, Training Loss: 0.34705910086631775, Validation Loss: 0.3375258147716522
Epoch 58, Training Loss: 0.3375258147716522, Validation Loss: 0.32763731479644775
Epoch 59, Training Loss: 0.32763731479644775, Validation Loss: 0.3174344301223755
Epoch 60, Training Loss: 0.3174344599246979, Validation Loss: 0.3070182502269745
Epoch 61, Training Loss: 0.3070182502269745, Validation Loss: 0.29648900032043457
Epoch 62, Training Loss: 0.2964889705181122, Validation Loss: 0.28593769669532776
Epoch 63, Training Loss: 0.28593772649765015, Validation Loss: 0.27556946873664856
Epoch 64, Training Loss: 0.27556943893432617, Validation Loss: 0.26561641693115234
Epoch 65, Training Loss: 0.26561641693115234, Validation Loss: 0.2563331127166748
Epoch 66, Training Loss: 0.2563331127166748, Validation Loss: 0.2477935552597046
Epoch 67, Training Loss: 0.2477935552597046, Validation Loss: 0.24016240239143372
Epoch 68, Training Loss: 0.24016240239143372, Validation Loss: 0.23369824886322021
Epoch 69, Training Loss: 0.23369824886322021, Validation Loss: 0.22833846509456635
Epoch 70, Training Loss: 0.22833846509456635, Validation Loss: 0.22395078837871552
Epoch 71, Training Loss: 0.22395078837871552, Validation Loss: 0.22037748992443085
Epoch 72, Training Loss: 0.22037747502326965, Validation Loss: 0.2173379361629486
Epoch 73, Training Loss: 0.2173379510641098, Validation Loss: 0.21445731818675995
Epoch 74, Training Loss: 0.21445731818675995, Validation Loss: 0.21130964159965515
Epoch 75, Training Loss: 0.21130965650081635, Validation Loss: 0.2076328694820404
Epoch 76, Training Loss: 0.2076328694820404, Validation Loss: 0.20330959558486938
Epoch 77, Training Loss: 0.20330959558486938, Validation Loss: 0.19841568171977997
Epoch 78, Training Loss: 0.19841566681861877, Validation Loss: 0.1930941641330719
Epoch 79, Training Loss: 0.1930941790342331, Validation Loss: 0.18753764033317566
Epoch 80, Training Loss: 0.18753765523433685, Validation Loss: 0.18191814422607422
Epoch 81, Training Loss: 0.18191814422607422, Validation Loss: 0.17628717422485352
Epoch 82, Training Loss: 0.17628717422485352, Validation Loss: 0.17073765397071838
Epoch 83, Training Loss: 0.17073765397071838, Validation Loss: 0.16532433032989502
Epoch 84, Training Loss: 0.16532433032989502, Validation Loss: 0.1600324511528015
Epoch 85, Training Loss: 0.1600324511528015, Validation Loss: 0.15499888360500336
Epoch 86, Training Loss: 0.15499889850616455, Validation Loss: 0.14996591210365295
Epoch 87, Training Loss: 0.14996591210365295, Validation Loss: 0.14479373395442963
Epoch 88, Training Loss: 0.14479373395442963, Validation Loss: 0.1395997405052185
Epoch 89, Training Loss: 0.1395997405052185, Validation Loss: 0.13424620032310486
Epoch 90, Training Loss: 0.13424620032310486, Validation Loss: 0.12877564132213593
Epoch 91, Training Loss: 0.12877565622329712, Validation Loss: 0.12324624508619308
Epoch 92, Training Loss: 0.12324623763561249, Validation Loss: 0.11748533695936203
Epoch 93, Training Loss: 0.11748532950878143, Validation Loss: 0.11148744821548462
Epoch 94, Training Loss: 0.11148744821548462, Validation Loss: 0.1052396297454834
Epoch 95, Training Loss: 0.1052396297454834, Validation Loss: 0.09880171716213226
Epoch 96, Training Loss: 0.09880172461271286, Validation Loss: 0.09218883514404297
Epoch 97, Training Loss: 0.09218883514404297, Validation Loss: 0.08549698442220688
Epoch 98, Training Loss: 0.08549697697162628, Validation Loss: 0.07898061722517014
Epoch 99, Training Loss: 0.07898062467575073, Validation Loss: 0.07255422323942184
Epoch 100, Training Loss: 0.07255421578884125, Validation Loss: 0.06621374189853668
Epoch 101, Training Loss: 0.06621373444795609, Validation Loss: 0.05997543781995773
Epoch 102, Training Loss: 0.05997543781995773, Validation Loss: 0.053880274295806885
Epoch 103, Training Loss: 0.053880274295806885, Validation Loss: 0.04808231443166733
Epoch 104, Training Loss: 0.048082321882247925, Validation Loss: 0.04239344596862793
Epoch 105, Training Loss: 0.04239344596862793, Validation Loss: 0.036906398832798004
Epoch 106, Training Loss: 0.0369064025580883, Validation Loss: 0.03164277225732803
Epoch 107, Training Loss: 0.03164278715848923, Validation Loss: 0.026675185188651085
Epoch 108, Training Loss: 0.026675183326005936, Validation Loss: 0.02205062471330166
Epoch 109, Training Loss: 0.022050626575946808, Validation Loss: 0.01788800209760666
Epoch 110, Training Loss: 0.017888007685542107, Validation Loss: 0.014257657341659069
Epoch 111, Training Loss: 0.014257657341659069, Validation Loss: 0.011189974844455719
Epoch 112, Training Loss: 0.011189974844455719, Validation Loss: 0.008725270628929138
Epoch 113, Training Loss: 0.008725269697606564, Validation Loss: 0.006788905709981918
Epoch 114, Training Loss: 0.006788905709981918, Validation Loss: 0.005349358078092337
Epoch 115, Training Loss: 0.005349354352802038, Validation Loss: 0.004327296745032072
Epoch 116, Training Loss: 0.0043272958137094975, Validation Loss: 0.0036512408405542374
Epoch 117, Training Loss: 0.0036512415390461683, Validation Loss: 0.00322176655754447
Epoch 118, Training Loss: 0.0032217667903751135, Validation Loss: 0.0029597447719424963
Epoch 119, Training Loss: 0.0029597454704344273, Validation Loss: 0.002810763893648982
Epoch 120, Training Loss: 0.0028107650578022003, Validation Loss: 0.002711460692808032
Epoch 121, Training Loss: 0.002711461391299963, Validation Loss: 0.0026266889180988073
Epoch 122, Training Loss: 0.0026266896165907383, Validation Loss: 0.0025441390462219715
Epoch 123, Training Loss: 0.002544139511883259, Validation Loss: 0.002443375065922737
Epoch 124, Training Loss: 0.002443375764414668, Validation Loss: 0.0023256181739270687
Epoch 125, Training Loss: 0.002325616776943207, Validation Loss: 0.0021952062379568815
Epoch 126, Training Loss: 0.002195206470787525, Validation Loss: 0.002051824703812599
Epoch 127, Training Loss: 0.002051824703812599, Validation Loss: 0.0018974307458847761
Epoch 128, Training Loss: 0.0018974313279613853, Validation Loss: 0.0017379471100866795
Epoch 129, Training Loss: 0.001737948041409254, Validation Loss: 0.0015751621685922146
Epoch 130, Training Loss: 0.001575161935761571, Validation Loss: 0.0014124484732747078
Epoch 131, Training Loss: 0.0014124477747827768, Validation Loss: 0.0012539008166640997
Epoch 132, Training Loss: 0.0012539003510028124, Validation Loss: 0.0011030377354472876
Epoch 133, Training Loss: 0.0011030370369553566, Validation Loss: 0.0009632438304834068
Epoch 134, Training Loss: 0.0009632434230297804, Validation Loss: 0.0008373927557840943
Epoch 135, Training Loss: 0.000837391649838537, Validation Loss: 0.0007262161816470325
Epoch 136, Training Loss: 0.0007262164726853371, Validation Loss: 0.0006308640586212277
Epoch 137, Training Loss: 0.0006308635347522795, Validation Loss: 0.0005519905244000256
Epoch 138, Training Loss: 0.0005519904079847038, Validation Loss: 0.00048633007099851966
Epoch 139, Training Loss: 0.00048632858670316637, Validation Loss: 0.0004318057035561651
Epoch 140, Training Loss: 0.0004318059072829783, Validation Loss: 0.0003860282595269382
Epoch 141, Training Loss: 0.00038602802669629455, Validation Loss: 0.00034657688229344785
Epoch 142, Training Loss: 0.00034657662035897374, Validation Loss: 0.000311750773107633
Epoch 143, Training Loss: 0.0003117504238616675, Validation Loss: 0.0002802786766551435
Epoch 144, Training Loss: 0.0002802786766551435, Validation Loss: 0.0002515554369892925
Epoch 145, Training Loss: 0.0002515554951969534, Validation Loss: 0.00022502275533042848
Epoch 146, Training Loss: 0.00022502275533042848, Validation Loss: 0.0002001112443394959
Epoch 147, Training Loss: 0.00020011153537780046, Validation Loss: 0.00017695248243398964
Epoch 148, Training Loss: 0.0001769526134012267, Validation Loss: 0.0001558303483761847
Epoch 149, Training Loss: 0.00015583023196086287, Validation Loss: 0.00013704999582841992
Epoch 150, Training Loss: 0.000137049937620759, Validation Loss: 0.00012127414083806798
Epoch 151, Training Loss: 0.00012127433728892356, Validation Loss: 0.0001079470239346847
Epoch 152, Training Loss: 0.00010794711852213368, Validation Loss: 9.69055327004753e-05
Epoch 153, Training Loss: 9.69055836321786e-05, Validation Loss: 8.791411528363824e-05
Epoch 154, Training Loss: 8.791415893938392e-05, Validation Loss: 8.063411223702133e-05
Epoch 155, Training Loss: 8.063414134085178e-05, Validation Loss: 7.467203249689192e-05
Epoch 156, Training Loss: 7.467194518540055e-05, Validation Loss: 6.964188651181757e-05
Epoch 157, Training Loss: 6.964201747905463e-05, Validation Loss: 6.520487659145147e-05
Epoch 158, Training Loss: 6.520487659145147e-05, Validation Loss: 6.109205423854291e-05
Epoch 159, Training Loss: 6.109217065386474e-05, Validation Loss: 5.714370490750298e-05
Epoch 160, Training Loss: 5.714363214792684e-05, Validation Loss: 5.328776751412079e-05
Epoch 161, Training Loss: 5.328772749635391e-05, Validation Loss: 4.95133972435724e-05
Epoch 162, Training Loss: 4.951313167111948e-05, Validation Loss: 4.585009446600452e-05
Epoch 163, Training Loss: 4.585024362313561e-05, Validation Loss: 4.233045183354989e-05
Epoch 164, Training Loss: 4.233072104398161e-05, Validation Loss: 3.89702181564644e-05
Epoch 165, Training Loss: 3.897048736689612e-05, Validation Loss: 3.5759636375587434e-05
Epoch 166, Training Loss: 3.575949085643515e-05, Validation Loss: 3.2665418984834105e-05
Epoch 167, Training Loss: 3.26652625517454e-05, Validation Loss: 2.9643057132489048e-05
Epoch 168, Training Loss: 2.9643224479514174e-05, Validation Loss: 2.6654015528038144e-05
Epoch 169, Training Loss: 2.6654077373677865e-05, Validation Loss: 2.367806519032456e-05
Epoch 170, Training Loss: 2.367833803873509e-05, Validation Loss: 2.0726880393340252e-05
Epoch 171, Training Loss: 2.0726860384456813e-05, Validation Loss: 1.7841861335909925e-05
Epoch 172, Training Loss: 1.7841746739577502e-05, Validation Loss: 1.5090433407749515e-05
Epoch 173, Training Loss: 1.50903233588906e-05, Validation Loss: 1.2553198757814243e-05
Epoch 174, Training Loss: 1.2553179658425506e-05, Validation Loss: 1.0308390301361214e-05
Epoch 175, Training Loss: 1.0308164746675175e-05, Validation Loss: 8.416114724241197e-06
Epoch 176, Training Loss: 8.416118362220004e-06, Validation Loss: 6.909461262694094e-06
Epoch 177, Training Loss: 6.90939214109676e-06, Validation Loss: 5.78715480514802e-06
Epoch 178, Training Loss: 5.787181635241723e-06, Validation Loss: 5.015944225306157e-06
Epoch 179, Training Loss: 5.016009708924685e-06, Validation Loss: 4.537241693469696e-06
Epoch 180, Training Loss: 4.5371707528829575e-06, Validation Loss: 4.276173967809882e-06
Epoch 181, Training Loss: 4.276197614672128e-06, Validation Loss: 4.153969257458812e-06
Epoch 182, Training Loss: 4.153945155849215e-06, Validation Loss: 4.09781159760314e-06
Epoch 183, Training Loss: 4.097858436580282e-06, Validation Loss: 4.048778464493807e-06
Epoch 184, Training Loss: 4.048708888149122e-06, Validation Loss: 3.965948963013943e-06
Epoch 185, Training Loss: 3.96601899410598e-06, Validation Loss: 3.8281614251900464e-06
Epoch 186, Training Loss: 3.828140506811906e-06, Validation Loss: 3.6308315429778304e-06
Epoch 187, Training Loss: 3.6308417747932253e-06, Validation Loss: 3.382519025763031e-06
Epoch 188, Training Loss: 3.3825135687948205e-06, Validation Loss: 3.099459263466997e-06
Epoch 189, Training Loss: 3.0993912787380395e-06, Validation Loss: 2.80080053016718e-06
Epoch 190, Training Loss: 2.8007520995743107e-06, Validation Loss: 2.504145413695369e-06
Epoch 191, Training Loss: 2.5041317712748423e-06, Validation Loss: 2.2234462448977865e-06
Epoch 192, Training Loss: 2.223363935627276e-06, Validation Loss: 1.9667527340061497e-06
Epoch 193, Training Loss: 1.9667404558276758e-06, Validation Loss: 1.7375703009747667e-06
Epoch 194, Training Loss: 1.7375413108311477e-06, Validation Loss: 1.5348041415563785e-06
Epoch 195, Training Loss: 1.5347732187365182e-06, Validation Loss: 1.3551987194659887e-06
Epoch 196, Training Loss: 1.3551969004765851e-06, Validation Loss: 1.1948418432439212e-06
Epoch 197, Training Loss: 1.194858668895904e-06, Validation Loss: 1.0502501481823856e-06
Epoch 198, Training Loss: 1.0502794793865178e-06, Validation Loss: 9.194150152325165e-07
Epoch 199, Training Loss: 9.194124572786677e-07, Validation Loss: 8.018271273613209e-07
Epoch 200, Training Loss: 8.01852820586646e-07, Validation Loss: 6.980632747399795e-07
Epoch 201, Training Loss: 6.980926059441117e-07, Validation Loss: 6.092488433750987e-07
Epoch 202, Training Loss: 6.092524245104869e-07, Validation Loss: 5.360658974495891e-07
Epoch 203, Training Loss: 5.361070520848443e-07, Validation Loss: 4.784534439750132e-07
Epoch 204, Training Loss: 4.784840825777792e-07, Validation Loss: 4.351455800133408e-07
Epoch 205, Training Loss: 4.351034021965461e-07, Validation Loss: 4.0363011066801846e-07
Epoch 206, Training Loss: 4.0361382502851484e-07, Validation Loss: 3.807682560363901e-07
Epoch 207, Training Loss: 3.807343489370396e-07, Validation Loss: 3.63066590125527e-07
Epoch 208, Training Loss: 3.6303148931438045e-07, Validation Loss: 3.473212473181775e-07
Epoch 209, Training Loss: 3.4731505138552166e-07, Validation Loss: 3.3098302765210974e-07
Epoch 210, Training Loss: 3.3100602081503894e-07, Validation Loss: 3.124854117686482e-07
Epoch 211, Training Loss: 3.125262537650997e-07, Validation Loss: 2.9121900979589554e-07
Epoch 212, Training Loss: 2.912133822974283e-07, Validation Loss: 2.6724848112280597e-07
Epoch 213, Training Loss: 2.6726277724264946e-07, Validation Loss: 2.4138822141139826e-07
Epoch 214, Training Loss: 2.413838728898554e-07, Validation Loss: 2.145332871350547e-07
Epoch 215, Training Loss: 2.1453115550684743e-07, Validation Loss: 1.8778700905386358e-07
Epoch 216, Training Loss: 1.8777231503008807e-07, Validation Loss: 1.6200611696604028e-07
Epoch 217, Training Loss: 1.6200219477013889e-07, Validation Loss: 1.3790520370093873e-07
Epoch 218, Training Loss: 1.379057437134179e-07, Validation Loss: 1.159966629415976e-07
Epoch 219, Training Loss: 1.1600040750181506e-07, Validation Loss: 9.664522337970993e-08
Epoch 220, Training Loss: 9.663269651127848e-08, Validation Loss: 8.001696727433227e-08
Epoch 221, Training Loss: 8.002758988823189e-08, Validation Loss: 6.629124271739784e-08
Epoch 222, Training Loss: 6.629522886214545e-08, Validation Loss: 5.5452598957117516e-08
Epoch 223, Training Loss: 5.544834991155767e-08, Validation Loss: 4.741551862252891e-08
Epoch 224, Training Loss: 4.7417238135949447e-08, Validation Loss: 4.1962614716339885e-08
Epoch 225, Training Loss: 4.1964362651469855e-08, Validation Loss: 3.870376730219505e-08
Epoch 226, Training Loss: 3.8707796079506807e-08, Validation Loss: 3.71771946561239e-08
Epoch 227, Training Loss: 3.716402119380291e-08, Validation Loss: 3.6775439582470426e-08
Epoch 228, Training Loss: 3.677835636040072e-08, Validation Loss: 3.6962035210308386e-08
Epoch 229, Training Loss: 3.6966866900911555e-08, Validation Loss: 3.718401231367352e-08
Epoch 230, Training Loss: 3.717954299986559e-08, Validation Loss: 3.700484185742425e-08
Epoch 231, Training Loss: 3.700467132716767e-08, Validation Loss: 3.614885812908142e-08
Epoch 232, Training Loss: 3.614640320392937e-08, Validation Loss: 3.451270202958767e-08
Epoch 233, Training Loss: 3.4508460089455184e-08, Validation Loss: 3.212538146613042e-08
Epoch 234, Training Loss: 3.2124567894697975e-08, Validation Loss: 2.9145970970034796e-08
Epoch 235, Training Loss: 2.914175034618438e-08, Validation Loss: 2.5799202774123842e-08
Epoch 236, Training Loss: 2.5797955771622583e-08, Validation Loss: 2.2337381722081773e-08
Epoch 237, Training Loss: 2.233584694977253e-08, Validation Loss: 1.8997230455397585e-08
Epoch 238, Training Loss: 1.8994917638792685e-08, Validation Loss: 1.595434540035967e-08
Epoch 239, Training Loss: 1.5954917387261958e-08, Validation Loss: 1.3332220660799976e-08
Epoch 240, Training Loss: 1.3329291448371805e-08, Validation Loss: 1.1171906066920201e-08
Epoch 241, Training Loss: 1.1171681357780017e-08, Validation Loss: 9.457431282555717e-09
Epoch 242, Training Loss: 9.456190497303396e-09, Validation Loss: 8.138742124685905e-09
Epoch 243, Training Loss: 8.141697094288247e-09, Validation Loss: 7.147811231789092e-09
Epoch 244, Training Loss: 7.149752789814556e-09, Validation Loss: 6.40019237607703e-09
Epoch 245, Training Loss: 6.402107288749903e-09, Validation Loss: 5.828741933555648e-09
Epoch 246, Training Loss: 5.831199523242958e-09, Validation Loss: 5.3861741733385315e-09
Epoch 247, Training Loss: 5.386878054736144e-09, Validation Loss: 5.0310271504372395e-09
Epoch 248, Training Loss: 5.030916128134777e-09, Validation Loss: 4.741124381979489e-09
Epoch 249, Training Loss: 4.740924985924266e-09, Validation Loss: 4.500535055740329e-09
Epoch 250, Training Loss: 4.500173567123511e-09, Validation Loss: 4.285095389633398e-09
Epoch 251, Training Loss: 4.2856260762391685e-09, Validation Loss: 4.074994564007284e-09
Epoch 252, Training Loss: 4.075737969344573e-09, Validation Loss: 3.8522003364960256e-09
Epoch 253, Training Loss: 3.854129460023614e-09, Validation Loss: 3.5959313304800844e-09
Epoch 254, Training Loss: 3.596871689381942e-09, Validation Loss: 3.291938721616816e-09
Epoch 255, Training Loss: 3.2963001217467536e-09, Validation Loss: 2.9439497506444923e-09
Epoch 256, Training Loss: 2.9447657645675918e-09, Validation Loss: 2.5611983645035252e-09
Epoch 257, Training Loss: 2.5605639830672544e-09, Validation Loss: 2.160173151466438e-09
Epoch 258, Training Loss: 2.1586588072608492e-09, Validation Loss: 1.7704455679279363e-09
Epoch 259, Training Loss: 1.7693344567248914e-09, Validation Loss: 1.4172554241298485e-09
Epoch 260, Training Loss: 1.418225314964161e-09, Validation Loss: 1.1285531398286253e-09
Epoch 261, Training Loss: 1.1267502486589365e-09, Validation Loss: 9.090926900157115e-10
Epoch 262, Training Loss: 9.100741826806313e-10, Validation Loss: 7.704627491555982e-10
Epoch 263, Training Loss: 7.718674588375052e-10, Validation Loss: 7.029696269533758e-10
Epoch 264, Training Loss: 7.013520875176482e-10, Validation Loss: 6.863157819836374e-10
Epoch 265, Training Loss: 6.865841228886893e-10, Validation Loss: 7.058214013255792e-10
Epoch 266, Training Loss: 7.053642114840386e-10, Validation Loss: 7.376739219466799e-10
Epoch 267, Training Loss: 7.371671606470898e-10, Validation Loss: 7.637857013520488e-10
Epoch 268, Training Loss: 7.632487419861889e-10, Validation Loss: 7.716373651156516e-10
Epoch 269, Training Loss: 7.712106508961369e-10, Validation Loss: 7.550262637323613e-10
Epoch 270, Training Loss: 7.545056801561145e-10, Validation Loss: 7.135024793214484e-10
Epoch 271, Training Loss: 7.131499279999787e-10, Validation Loss: 6.516511774634637e-10
Epoch 272, Training Loss: 6.503418914505232e-10, Validation Loss: 5.701496497145797e-10
Epoch 273, Training Loss: 5.696413896139063e-10, Validation Loss: 4.84108308995701e-10
Epoch 274, Training Loss: 4.836715472578135e-10, Validation Loss: 3.9827713349538385e-10
Epoch 275, Training Loss: 3.9874648027904414e-10, Validation Loss: 3.200876785847129e-10
Epoch 276, Training Loss: 3.206339638239797e-10, Validation Loss: 2.526845954697876e-10
Epoch 277, Training Loss: 2.527903997240344e-10, Validation Loss: 1.9916938931441308e-10
Epoch 278, Training Loss: 1.9894538794140715e-10, Validation Loss: 1.5948262155340842e-10
Epoch 279, Training Loss: 1.5955589627303368e-10, Validation Loss: 1.332479127036379e-10
Epoch 280, Training Loss: 1.3345620442084538e-10, Validation Loss: 1.1728661097887283e-10
Epoch 281, Training Loss: 1.1765236007654778e-10, Validation Loss: 1.1075503708601886e-10
Epoch 282, Training Loss: 1.1069847122291421e-10, Validation Loss: 1.098012653022451e-10
Epoch 283, Training Loss: 1.0911502257293648e-10, Validation Loss: 1.1160776469676392e-10
Epoch 284, Training Loss: 1.1130373012147032e-10, Validation Loss: 1.1441297909087211e-10
Epoch 285, Training Loss: 1.145056480189588e-10, Validation Loss: 1.1596117815981799e-10
Epoch 286, Training Loss: 1.1620530926403916e-10, Validation Loss: 1.1530015830985008e-10
Epoch 287, Training Loss: 1.1514215969565811e-10, Validation Loss: 1.1147960332635876e-10
Epoch 288, Training Loss: 1.1124322990552216e-10, Validation Loss: 1.0445551368309935e-10
Epoch 289, Training Loss: 1.0411509848706757e-10, Validation Loss: 9.471265438598664e-11
Epoch 290, Training Loss: 9.448469090456157e-11, Validation Loss: 8.298064319012255e-11
Epoch 291, Training Loss: 8.310712534820297e-11, Validation Loss: 7.067753327039128e-11
Epoch 292, Training Loss: 7.063942486507102e-11, Validation Loss: 5.85574921885268e-11
Epoch 293, Training Loss: 5.85745618675304e-11, Validation Loss: 4.760905558676143e-11
Epoch 294, Training Loss: 4.756289806451264e-11, Validation Loss: 3.7754868675854425e-11
Epoch 295, Training Loss: 3.7801591717956384e-11, Validation Loss: 3.022412181641343e-11
Epoch 296, Training Loss: 3.017459199172734e-11, Validation Loss: 2.4711515819730856e-11
Epoch 297, Training Loss: 2.481632954687285e-11, Validation Loss: 2.1246792519802327e-11
Epoch 298, Training Loss: 2.1175908249126962e-11, Validation Loss: 1.9034163134534765e-11
Epoch 299, Training Loss: 1.8900166154356413e-11, Validation Loss: 1.8039906374278658e-11
Epoch 300, Training Loss: 1.8003981985814654e-11, Validation Loss: 1.762049534059784e-11
Epoch 301, Training Loss: 1.758278939112401e-11, Validation Loss: 1.7237272373349377e-11
Epoch 302, Training Loss: 1.7441230751313874e-11, Validation Loss: 1.7000352514617845e-11
Epoch 303, Training Loss: 1.719194057947515e-11, Validation Loss: 1.6543381248235178e-11
Epoch 304, Training Loss: 1.6617748843650304e-11, Validation Loss: 1.59484890571715e-11
Epoch 305, Training Loss: 1.6075168973728182e-11, Validation Loss: 1.5239091238905544e-11
Epoch 306, Training Loss: 1.521469755738636e-11, Validation Loss: 1.4161892145092558e-11
Epoch 307, Training Loss: 1.4230096267997538e-11, Validation Loss: 1.2969627975756293e-11
Epoch 308, Training Loss: 1.3064558983255647e-11, Validation Loss: 1.1755037047922468e-11
Epoch 309, Training Loss: 1.1932115018264966e-11, Validation Loss: 1.0587494422842347e-11
Epoch 310, Training Loss: 1.0541633538307948e-11, Validation Loss: 9.305438364304308e-12
Epoch 311, Training Loss: 9.436897444037307e-12, Validation Loss: 8.077407666340353e-12
Epoch 312, Training Loss: 7.992766171138754e-12, Validation Loss: 6.817474969972315e-12
Epoch 313, Training Loss: 6.8262387929729496e-12, Validation Loss: 5.8647487907736995e-12
Epoch 314, Training Loss: 5.8279448975073755e-12, Validation Loss: 4.959286453720679e-12
Epoch 315, Training Loss: 4.928093523537402e-12, Validation Loss: 4.1312109982927225e-12
Epoch 316, Training Loss: 4.182176306655183e-12, Validation Loss: 3.524515748698498e-12
Epoch 317, Training Loss: 3.579856463348241e-12, Validation Loss: 2.9949424017183812e-12
Epoch 318, Training Loss: 3.0303554804378408e-12, Validation Loss: 2.701362354293191e-12
Epoch 319, Training Loss: 2.7826141998227305e-12, Validation Loss: 2.4963570707109417e-12
Epoch 320, Training Loss: 2.520788048784861e-12, Validation Loss: 2.38687888898248e-12
Epoch 321, Training Loss: 2.3471723696599778e-12, Validation Loss: 2.2766779780858393e-12
Epoch 322, Training Loss: 2.251603634442767e-12, Validation Loss: 2.194413921408067e-12
Epoch 323, Training Loss: 2.232968801182955e-12, Validation Loss: 2.1368098263030433e-12
Epoch 324, Training Loss: 2.117373117116461e-12, Validation Loss: 2.0414368979981834e-12
Epoch 325, Training Loss: 2.065780706217435e-12, Validation Loss: 1.9084551647341463e-12
Epoch 326, Training Loss: 1.8490246226493534e-12, Validation Loss: 1.6810788872057003e-12
Epoch 327, Training Loss: 1.6622007589783827e-12, Validation Loss: 1.461906767516452e-12
Epoch 328, Training Loss: 1.4629646235761462e-12, Validation Loss: 1.2473876098706427e-12
Epoch 329, Training Loss: 1.3137164966980919e-12, Validation Loss: 1.0806055486187183e-12
Epoch 330, Training Loss: 1.0818613799951082e-12, Validation Loss: 9.377451072600795e-13
Epoch 331, Training Loss: 8.894470988722591e-13, Validation Loss: 7.390908089537074e-13
Epoch 332, Training Loss: 7.392371220368843e-13, Validation Loss: 5.967571272205707e-13
Epoch 333, Training Loss: 6.154230770827329e-13, Validation Loss: 4.790322869277497e-13
Epoch 334, Training Loss: 5.077353468219137e-13, Validation Loss: 4.2643541692602427e-13
Epoch 335, Training Loss: 4.1986921751890893e-13, Validation Loss: 3.988873576062091e-13
Epoch 336, Training Loss: 3.77575412342096e-13, Validation Loss: 3.5974093712601296e-13
Epoch 337, Training Loss: 3.6417394165370875e-13, Validation Loss: 3.3818678109656664e-13
Epoch 338, Training Loss: 3.3394429799563086e-13, Validation Loss: 3.3234710556523384e-13
Epoch 339, Training Loss: 3.276914059113095e-13, Validation Loss: 3.0567559659681887e-13
Epoch 340, Training Loss: 3.072753097972669e-13, Validation Loss: 3.2118521709444126e-13
Epoch 341, Training Loss: 2.9924386536414604e-13, Validation Loss: 2.9708169518166683e-13
Epoch 342, Training Loss: 2.847914775099686e-13, Validation Loss: 2.706766560021945e-13
Epoch 343, Training Loss: 2.6059753313600886e-13, Validation Loss: 2.7032504923765743e-13
Epoch 344, Training Loss: 2.526661334583541e-13, Validation Loss: 2.6240121187015575e-13
Epoch 345, Training Loss: 2.387165985717754e-13, Validation Loss: 2.3374461003908276e-13
Epoch 346, Training Loss: 2.0672248364061313e-13, Validation Loss: 2.114565846641353e-13
Epoch 347, Training Loss: 1.9463844056454016e-13, Validation Loss: 1.792440978629073e-13
Epoch 348, Training Loss: 1.700439919080643e-13, Validation Loss: 1.634929577788366e-13
Epoch 349, Training Loss: 1.596580669321196e-13, Validation Loss: 1.5398869245702995e-13
Epoch 350, Training Loss: 1.4122634539679574e-13, Validation Loss: 1.3208753752227964e-13
Epoch 351, Training Loss: 1.2402974697636737e-13, Validation Loss: 1.222817149187233e-13
Epoch 352, Training Loss: 1.1323686671498023e-13, Validation Loss: 1.0987439663613305e-13
Epoch 353, Training Loss: 9.751015506110836e-14, Validation Loss: 8.458603148421215e-14
Epoch 354, Training Loss: 7.480793735121713e-14, Validation Loss: 8.860495209718142e-14
Epoch 355, Training Loss: 7.576525398820394e-14, Validation Loss: 7.146732749867268e-14
Epoch 356, Training Loss: 6.274886480642922e-14, Validation Loss: 5.5107296086402344e-14
Epoch 357, Training Loss: 5.815231515727756e-14, Validation Loss: 5.667620778075644e-14
Epoch 358, Training Loss: 4.7997098239242406e-14, Validation Loss: 4.768846315018546e-14
Epoch 359, Training Loss: 4.6189370687607645e-14, Validation Loss: 4.437514131106976e-14
Epoch 360, Training Loss: 3.9334285611633546e-14, Validation Loss: 4.2984326764205355e-14
Epoch 361, Training Loss: 3.212293170178071e-14, Validation Loss: 3.7528042061722375e-14
Epoch 362, Training Loss: 3.303178450165742e-14, Validation Loss: 3.1878627071001836e-14
Epoch 363, Training Loss: 3.167638609638361e-14, Validation Loss: 2.2357885264305197e-14
Epoch 364, Training Loss: 2.7203545609178446e-14, Validation Loss: 2.313099256405493e-14
Epoch 365, Training Loss: 2.7298377723887143e-14, Validation Loss: 1.8754864604701368e-14
Epoch 366, Training Loss: 2.073674890655519e-14, Validation Loss: 1.5899364073576616e-14
Epoch 367, Training Loss: 2.0689911372703818e-14, Validation Loss: 1.6492929187628645e-14
Epoch 368, Training Loss: 1.5152277625966534e-14, Validation Loss: 1.233913382440218e-14
Epoch 369, Training Loss: 1.268376527261859e-14, Validation Loss: 1.0634189485751993e-14
Epoch 370, Training Loss: 8.974890058563445e-15, Validation Loss: 1.2073142609074754e-14
Epoch 371, Training Loss: 8.879191429149707e-15, Validation Loss: 1.128008514231834e-14
Epoch 372, Training Loss: 1.0785977789899964e-14, Validation Loss: 1.0757933376049321e-14
Epoch 373, Training Loss: 4.8792443541989354e-15, Validation Loss: 7.351370150099866e-15
Epoch 374, Training Loss: 5.128177173001607e-15, Validation Loss: 8.736257160399385e-15
Epoch 375, Training Loss: 6.006344510298134e-15, Validation Loss: 9.931047954478411e-15
Epoch 376, Training Loss: 4.556115684381523e-15, Validation Loss: 7.905324615406495e-15
Epoch 377, Training Loss: 4.7988685508010276e-15, Validation Loss: 7.94117613193198e-15
Epoch 378, Training Loss: 4.808988053421875e-15, Validation Loss: 7.791845070363995e-15
Epoch 379, Training Loss: 3.6565531418703e-15, Validation Loss: 6.753179389122881e-15
Epoch 380, Training Loss: 4.3234098992658756e-15, Validation Loss: 7.792133908599008e-15
Epoch 381, Training Loss: 3.816870644280648e-15, Validation Loss: 7.049094160894434e-15
Epoch 382, Training Loss: 2.3930601407141884e-15, Validation Loss: 7.166332414640375e-15
Epoch 383, Training Loss: 5.215491446786949e-15, Validation Loss: 6.977826079261878e-15
Epoch 384, Training Loss: 2.5817475293851613e-15, Validation Loss: 5.769880016479045e-15
Epoch 385, Training Loss: 2.800467106475746e-15, Validation Loss: 6.122028882102337e-15
Epoch 386, Training Loss: 2.9743731349424207e-15, Validation Loss: 6.539519139826247e-15
Epoch 387, Training Loss: 2.7696757647771575e-15, Validation Loss: 6.49441632945085e-15
Epoch 388, Training Loss: 2.9629530132310646e-15, Validation Loss: 6.605438631913365e-15
Epoch 389, Training Loss: 2.9347637567464415e-15, Validation Loss: 6.641578563157391e-15
Epoch 390, Training Loss: 4.9781235923296134e-15, Validation Loss: 6.6580584361791706e-15
Epoch 391, Training Loss: 4.930563115857758e-15, Validation Loss: 6.31328214532878e-15
Epoch 392, Training Loss: 5.236452547616177e-15, Validation Loss: 6.413318006948934e-15
Epoch 393, Training Loss: 2.496998918397053e-15, Validation Loss: 6.20804253679717e-15
Epoch 394, Training Loss: 2.820814108418215e-15, Validation Loss: 6.966839214903042e-15
Epoch 395, Training Loss: 3.3068257316849715e-15, Validation Loss: 6.441651682551064e-15
Epoch 396, Training Loss: 3.025222216831991e-15, Validation Loss: 6.370672862669995e-15
Epoch 397, Training Loss: 2.2918678673627957e-15, Validation Loss: 5.396480788275038e-15
Epoch 398, Training Loss: 1.5385641979198672e-15, Validation Loss: 5.249029292817009e-15
Epoch 399, Training Loss: 1.042758544442246e-15, Validation Loss: 5.39575826917103e-15
Epoch 400, Training Loss: 1.7026763020547959e-15, Validation Loss: 4.848741850735361e-15
Epoch 401, Training Loss: 2.1295628021417157e-15, Validation Loss: 4.848741850735361e-15
Epoch 402, Training Loss: 1.8537417694614033e-15, Validation Loss: 4.848741850735361e-15
Epoch 403, Training Loss: 2.135345284314384e-15, Validation Loss: 4.836598786403523e-15
Epoch 404, Training Loss: 2.2481023102528764e-15, Validation Loss: 4.847440808128378e-15
Epoch 405, Training Loss: 2.277592609344482e-15, Validation Loss: 3.2978990632120952e-15
Epoch 406, Training Loss: 1.460537852159406e-15, Validation Loss: 3.2978990632120952e-15
Epoch 407, Training Loss: 1.460537852159406e-15, Validation Loss: 3.38174410180372e-15
Epoch 408, Training Loss: 1.460537852159406e-15, Validation Loss: 3.558107584608616e-15
Epoch 409, Training Loss: 1.4547553699867377e-15, Validation Loss: 3.7061376035696196e-15
Epoch 410, Training Loss: 5.765516102734791e-16, Validation Loss: 3.646144801014439e-15
Epoch 411, Training Loss: 6.008377389371544e-16, Validation Loss: 4.358538049654406e-15
Epoch 412, Training Loss: 6.189078104382856e-16, Validation Loss: 4.454670783453612e-15
Epoch 413, Training Loss: 6.189078104382856e-16, Validation Loss: 4.444551280832765e-15
Epoch 414, Training Loss: 6.189078104382856e-16, Validation Loss: 4.444551280832765e-15
Epoch 415, Training Loss: 5.911522348226567e-16, Validation Loss: 5.045199284389734e-15
Epoch 416, Training Loss: 1.154937364515119e-15, Validation Loss: 5.045199284389734e-15
Epoch 417, Training Loss: 1.874124770304131e-15, Validation Loss: 5.045199284389734e-15
Epoch 418, Training Loss: 1.8561994355578617e-15, Validation Loss: 5.045199284389734e-15
Epoch 419, Training Loss: 1.7405510626539167e-15, Validation Loss: 6.3566502322282e-15
Epoch 420, Training Loss: 1.7217582602905407e-15, Validation Loss: 5.297890811895847e-15
Epoch 421, Training Loss: 1.7217582602905407e-15, Validation Loss: 5.297890811895847e-15
Epoch 422, Training Loss: 1.9046270620094686e-15, Validation Loss: 5.264931065852288e-15
Epoch 423, Training Loss: 1.5907866378542918e-15, Validation Loss: 5.85704987114688e-15
Epoch 424, Training Loss: 1.4622725756353828e-15, Validation Loss: 5.9044659285012284e-15
Epoch 425, Training Loss: 5.204622531766018e-16, Validation Loss: 5.918343716309043e-15
Epoch 426, Training Loss: 5.308705940324627e-16, Validation Loss: 5.918343716309043e-15
Epoch 427, Training Loss: 5.516872757441844e-16, Validation Loss: 5.0579208722245465e-15
Epoch 428, Training Loss: 5.482178287922307e-16, Validation Loss: 5.777541853003434e-15
Epoch 429, Training Loss: 4.410986276808833e-16, Validation Loss: 5.777541853003434e-15
Epoch 430, Training Loss: 4.295337956844447e-16, Validation Loss: 5.829583557282738e-15
Epoch 431, Training Loss: 4.1695705048361287e-16, Validation Loss: 5.940605859745254e-15
Epoch 432, Training Loss: 4.238959443875201e-16, Validation Loss: 5.940605859745254e-15
Epoch 433, Training Loss: 4.238959443875201e-16, Validation Loss: 6.102513242997598e-15
Epoch 434, Training Loss: 4.340151823105712e-16, Validation Loss: 6.105404589963051e-15
Epoch 435, Training Loss: 4.478929701183857e-16, Validation Loss: 8.152378715132157e-15
Epoch 436, Training Loss: 1.2605747608945839e-15, Validation Loss: 8.148764425546223e-15
Epoch 437, Training Loss: 1.4899919405925166e-15, Validation Loss: 8.273085992313578e-15
Epoch 438, Training Loss: 2.045103452905095e-15, Validation Loss: 8.273085992313578e-15
Epoch 439, Training Loss: 2.0485728998570485e-15, Validation Loss: 8.264412374933694e-15
Epoch 440, Training Loss: 2.0398992824771645e-15, Validation Loss: 7.587581381067725e-15
Epoch 441, Training Loss: 2.1408025058353066e-15, Validation Loss: 8.350137191393513e-15
Epoch 442, Training Loss: 2.234477573538054e-15, Validation Loss: 8.350137191393513e-15
Epoch 443, Training Loss: 2.2075893596604137e-15, Validation Loss: 5.938437455400283e-15
Epoch 444, Training Loss: 3.082757353290713e-15, Validation Loss: 5.965759350146918e-15
Epoch 445, Training Loss: 2.459991625415039e-15, Validation Loss: 5.881191580693048e-15
Epoch 446, Training Loss: 1.4422870450031544e-15, Validation Loss: 5.881191580693048e-15
Epoch 447, Training Loss: 1.246841603962513e-15, Validation Loss: 6.0532184665662396e-15
Epoch 448, Training Loss: 1.3526597359970983e-15, Validation Loss: 6.460155540800308e-15
Epoch 449, Training Loss: 1.6383470084470287e-15, Validation Loss: 6.123619186460807e-15
Epoch 450, Training Loss: 1.6053872624034694e-15, Validation Loss: 6.123619186460807e-15
Epoch 451, Training Loss: 1.3359268118823264e-15, Validation Loss: 6.123619186460807e-15
Epoch 452, Training Loss: 1.3567434935940481e-15, Validation Loss: 6.1843345081199954e-15
Epoch 453, Training Loss: 1.3509611173004982e-15, Validation Loss: 6.1843345081199954e-15
Epoch 454, Training Loss: 1.3544305642524518e-15, Validation Loss: 5.259726895424357e-15
Epoch 455, Training Loss: 1.3787166929161271e-15, Validation Loss: 5.259726895424357e-15
Epoch 456, Training Loss: 1.320892612343273e-15, Validation Loss: 5.259726895424357e-15
Epoch 457, Training Loss: 1.3207479814675294e-15, Validation Loss: 4.813758542980811e-15
Epoch 458, Training Loss: 6.083548916462403e-16, Validation Loss: 5.571254178479701e-15
Epoch 459, Training Loss: 5.584815917119071e-16, Validation Loss: 5.571254178479701e-15
Epoch 460, Training Loss: 1.3362159677546954e-15, Validation Loss: 5.352100920520122e-15
Epoch 461, Training Loss: 1.3391072088410295e-15, Validation Loss: 5.818741535557883e-15
Epoch 462, Training Loss: 1.5889073893816897e-15, Validation Loss: 5.889865198072932e-15
Epoch 463, Training Loss: 1.5889073893816897e-15, Validation Loss: 5.889865198072932e-15
Epoch 464, Training Loss: 1.5889073893816897e-15, Validation Loss: 5.889865198072932e-15
Epoch 465, Training Loss: 1.5889073893816897e-15, Validation Loss: 5.453148562995771e-15
Epoch 466, Training Loss: 1.5889073893816897e-15, Validation Loss: 5.4496791160438176e-15
Epoch 467, Training Loss: 1.2246154594265602e-15, Validation Loss: 5.4496791160438176e-15
Epoch 468, Training Loss: 1.2593099289460964e-15, Validation Loss: 5.4600874568996784e-15
Epoch 469, Training Loss: 1.2397942898413573e-15, Validation Loss: 5.364677665720954e-15
Epoch 470, Training Loss: 1.2159418420466762e-15, Validation Loss: 5.364677665720954e-15
Epoch 471, Training Loss: 7.524815180884998e-16, Validation Loss: 5.165184465983621e-15
Epoch 472, Training Loss: 7.503131137435288e-16, Validation Loss: 4.216579986375795e-15
Epoch 473, Training Loss: 7.850075832630649e-16, Validation Loss: 4.216579986375795e-15
Epoch 474, Training Loss: 7.850075832630649e-16, Validation Loss: 4.216579986375795e-15
Epoch 475, Training Loss: 7.850075832630649e-16, Validation Loss: 4.216579986375795e-15
Epoch 476, Training Loss: 7.850075832630649e-16, Validation Loss: 4.216579986375795e-15
Epoch 477, Training Loss: 7.850075832630649e-16, Validation Loss: 4.0864757256775346e-15
Epoch 478, Training Loss: 4.172461798862022e-16, Validation Loss: 4.0864757256775346e-15
Epoch 479, Training Loss: 4.172461798862022e-16, Validation Loss: 4.017086786638462e-15
Epoch 480, Training Loss: 4.172461798862022e-16, Validation Loss: 4.017086786638462e-15
Epoch 481, Training Loss: 1.0213636568649049e-15, Validation Loss: 4.017086786638462e-15
Epoch 482, Training Loss: 1.0502757500908911e-15, Validation Loss: 4.017086786638462e-15
Epoch 483, Training Loss: 1.0502757500908911e-15, Validation Loss: 4.1142313012931635e-15
Epoch 484, Training Loss: 1.0381326857590535e-15, Validation Loss: 4.121170195197071e-15
Epoch 485, Training Loss: 1.0381326857590535e-15, Validation Loss: 4.121170195197071e-15
Epoch 486, Training Loss: 1.0381326857590535e-15, Validation Loss: 4.364031481833824e-15
Epoch 487, Training Loss: 4.2591979726608624e-16, Validation Loss: 4.2989793514846934e-15
Epoch 488, Training Loss: 4.526634596773219e-16, Validation Loss: 4.2989793514846934e-15
Epoch 489, Training Loss: 5.278348279495033e-16, Validation Loss: 4.623372641492356e-15
Epoch 490, Training Loss: 5.278348279495033e-16, Validation Loss: 4.6667407283917765e-15
Epoch 491, Training Loss: 5.0181397580985115e-16, Validation Loss: 4.6667407283917765e-15
Epoch 492, Training Loss: 5.0181397580985115e-16, Validation Loss: 4.6667407283917765e-15
Epoch 493, Training Loss: 5.0181397580985115e-16, Validation Loss: 4.6667407283917765e-15
Epoch 494, Training Loss: 5.0181397580985115e-16, Validation Loss: 4.7060608448362684e-15
Epoch 495, Training Loss: 4.3965303360749583e-16, Validation Loss: 4.7060608448362684e-15
Epoch 496, Training Loss: 4.3965303360749583e-16, Validation Loss: 4.348707808785046e-15
Epoch 497, Training Loss: 4.2808820161105725e-16, Validation Loss: 4.3088091688375796e-15
Epoch 498, Training Loss: 4.2808820161105725e-16, Validation Loss: 4.3088091688375796e-15
Epoch 499, Training Loss: 4.2808820161105725e-16, Validation Loss: 4.310255054078543e-15
Epoch 500, Training Loss: 4.419659894188717e-16, Validation Loss: 5.065582285232462e-15
