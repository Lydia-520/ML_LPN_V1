Epoch 1, Training Loss: 0.453443318605423, Validation Loss: 0.4520385265350342
Epoch 2, Training Loss: 0.4520385265350342, Validation Loss: 0.45072805881500244
Epoch 3, Training Loss: 0.45072802901268005, Validation Loss: 0.4494226276874542
Epoch 4, Training Loss: 0.4494226276874542, Validation Loss: 0.4481148421764374
Epoch 5, Training Loss: 0.4481148421764374, Validation Loss: 0.44679442048072815
Epoch 6, Training Loss: 0.44679445028305054, Validation Loss: 0.44547751545906067
Epoch 7, Training Loss: 0.44547751545906067, Validation Loss: 0.44414323568344116
Epoch 8, Training Loss: 0.4441432058811188, Validation Loss: 0.44279298186302185
Epoch 9, Training Loss: 0.44279298186302185, Validation Loss: 0.44142791628837585
Epoch 10, Training Loss: 0.44142791628837585, Validation Loss: 0.4400627613067627
Epoch 11, Training Loss: 0.4400627613067627, Validation Loss: 0.43870359659194946
Epoch 12, Training Loss: 0.43870362639427185, Validation Loss: 0.43737319111824036
Epoch 13, Training Loss: 0.43737319111824036, Validation Loss: 0.4360053241252899
Epoch 14, Training Loss: 0.43600526452064514, Validation Loss: 0.4346182346343994
Epoch 15, Training Loss: 0.4346182346343994, Validation Loss: 0.43319573998451233
Epoch 16, Training Loss: 0.43319573998451233, Validation Loss: 0.43172287940979004
Epoch 17, Training Loss: 0.43172287940979004, Validation Loss: 0.4302017390727997
Epoch 18, Training Loss: 0.4302017390727997, Validation Loss: 0.4286539852619171
Epoch 19, Training Loss: 0.4286539852619171, Validation Loss: 0.42707473039627075
Epoch 20, Training Loss: 0.4270747900009155, Validation Loss: 0.42545512318611145
Epoch 21, Training Loss: 0.42545512318611145, Validation Loss: 0.42380911111831665
Epoch 22, Training Loss: 0.42380914092063904, Validation Loss: 0.42207667231559753
Epoch 23, Training Loss: 0.42207664251327515, Validation Loss: 0.4202830493450165
Epoch 24, Training Loss: 0.4202830493450165, Validation Loss: 0.4183996021747589
Epoch 25, Training Loss: 0.4183996021747589, Validation Loss: 0.4165011942386627
Epoch 26, Training Loss: 0.4165011942386627, Validation Loss: 0.4145488142967224
Epoch 27, Training Loss: 0.4145488142967224, Validation Loss: 0.4125218987464905
Epoch 28, Training Loss: 0.4125218689441681, Validation Loss: 0.41038113832473755
Epoch 29, Training Loss: 0.41038110852241516, Validation Loss: 0.40812551975250244
Epoch 30, Training Loss: 0.40812554955482483, Validation Loss: 0.4057500958442688
Epoch 31, Training Loss: 0.4057500958442688, Validation Loss: 0.40324872732162476
Epoch 32, Training Loss: 0.40324872732162476, Validation Loss: 0.40063586831092834
Epoch 33, Training Loss: 0.40063586831092834, Validation Loss: 0.39784762263298035
Epoch 34, Training Loss: 0.39784762263298035, Validation Loss: 0.39490199089050293
Epoch 35, Training Loss: 0.39490196108818054, Validation Loss: 0.39175155758857727
Epoch 36, Training Loss: 0.39175158739089966, Validation Loss: 0.38837316632270813
Epoch 37, Training Loss: 0.38837316632270813, Validation Loss: 0.38474002480506897
Epoch 38, Training Loss: 0.38474002480506897, Validation Loss: 0.38082513213157654
Epoch 39, Training Loss: 0.3808251619338989, Validation Loss: 0.37664005160331726
Epoch 40, Training Loss: 0.37664005160331726, Validation Loss: 0.37218910455703735
Epoch 41, Training Loss: 0.37218910455703735, Validation Loss: 0.3674648106098175
Epoch 42, Training Loss: 0.3674648106098175, Validation Loss: 0.36235311627388
Epoch 43, Training Loss: 0.36235311627388, Validation Loss: 0.35683441162109375
Epoch 44, Training Loss: 0.35683441162109375, Validation Loss: 0.3509463667869568
Epoch 45, Training Loss: 0.3509463667869568, Validation Loss: 0.3446415662765503
Epoch 46, Training Loss: 0.3446415066719055, Validation Loss: 0.3379190266132355
Epoch 47, Training Loss: 0.3379190266132355, Validation Loss: 0.33077526092529297
Epoch 48, Training Loss: 0.3307752311229706, Validation Loss: 0.3231664299964905
Epoch 49, Training Loss: 0.3231664299964905, Validation Loss: 0.31510189175605774
Epoch 50, Training Loss: 0.31510189175605774, Validation Loss: 0.30663278698921204
Epoch 51, Training Loss: 0.30663278698921204, Validation Loss: 0.2977496087551117
Epoch 52, Training Loss: 0.2977496087551117, Validation Loss: 0.28852033615112305
Epoch 53, Training Loss: 0.28852033615112305, Validation Loss: 0.2789342701435089
Epoch 54, Training Loss: 0.2789342701435089, Validation Loss: 0.2691177725791931
Epoch 55, Training Loss: 0.2691177725791931, Validation Loss: 0.25921592116355896
Epoch 56, Training Loss: 0.25921592116355896, Validation Loss: 0.2492808699607849
Epoch 57, Training Loss: 0.24928084015846252, Validation Loss: 0.23941832780838013
Epoch 58, Training Loss: 0.23941831290721893, Validation Loss: 0.2298307865858078
Epoch 59, Training Loss: 0.2298307716846466, Validation Loss: 0.2206723541021347
Epoch 60, Training Loss: 0.2206723541021347, Validation Loss: 0.21204406023025513
Epoch 61, Training Loss: 0.21204406023025513, Validation Loss: 0.20415104925632477
Epoch 62, Training Loss: 0.20415104925632477, Validation Loss: 0.1971115916967392
Epoch 63, Training Loss: 0.197111576795578, Validation Loss: 0.1908305287361145
Epoch 64, Training Loss: 0.1908305287361145, Validation Loss: 0.18523891270160675
Epoch 65, Training Loss: 0.18523891270160675, Validation Loss: 0.18022722005844116
Epoch 66, Training Loss: 0.18022722005844116, Validation Loss: 0.17538303136825562
Epoch 67, Training Loss: 0.17538303136825562, Validation Loss: 0.1705232411623001
Epoch 68, Training Loss: 0.17052322626113892, Validation Loss: 0.16534502804279327
Epoch 69, Training Loss: 0.16534505784511566, Validation Loss: 0.15960507094860077
Epoch 70, Training Loss: 0.15960508584976196, Validation Loss: 0.1533135175704956
Epoch 71, Training Loss: 0.1533135175704956, Validation Loss: 0.14658425748348236
Epoch 72, Training Loss: 0.14658425748348236, Validation Loss: 0.1394822597503662
Epoch 73, Training Loss: 0.1394822597503662, Validation Loss: 0.13225558400154114
Epoch 74, Training Loss: 0.13225558400154114, Validation Loss: 0.12483085691928864
Epoch 75, Training Loss: 0.12483086436986923, Validation Loss: 0.1175403892993927
Epoch 76, Training Loss: 0.11754041165113449, Validation Loss: 0.11047179996967316
Epoch 77, Training Loss: 0.11047179996967316, Validation Loss: 0.10368181020021439
Epoch 78, Training Loss: 0.10368181020021439, Validation Loss: 0.09695736318826675
Epoch 79, Training Loss: 0.09695735573768616, Validation Loss: 0.09046903252601624
Epoch 80, Training Loss: 0.09046903997659683, Validation Loss: 0.08409883826971054
Epoch 81, Training Loss: 0.08409883826971054, Validation Loss: 0.07774170488119125
Epoch 82, Training Loss: 0.07774169743061066, Validation Loss: 0.07142890989780426
Epoch 83, Training Loss: 0.07142890989780426, Validation Loss: 0.06524715572595596
Epoch 84, Training Loss: 0.06524715572595596, Validation Loss: 0.0591789186000824
Epoch 85, Training Loss: 0.0591789186000824, Validation Loss: 0.05338114872574806
Epoch 86, Training Loss: 0.05338114872574806, Validation Loss: 0.04810727387666702
Epoch 87, Training Loss: 0.048107266426086426, Validation Loss: 0.04307100549340248
Epoch 88, Training Loss: 0.04307100549340248, Validation Loss: 0.038324691355228424
Epoch 89, Training Loss: 0.03832469880580902, Validation Loss: 0.03388693928718567
Epoch 90, Training Loss: 0.033886950463056564, Validation Loss: 0.02981349267065525
Epoch 91, Training Loss: 0.02981349639594555, Validation Loss: 0.026121653616428375
Epoch 92, Training Loss: 0.026121653616428375, Validation Loss: 0.022867480292916298
Epoch 93, Training Loss: 0.02286747843027115, Validation Loss: 0.019999561831355095
Epoch 94, Training Loss: 0.019999563694000244, Validation Loss: 0.01745966076850891
Epoch 95, Training Loss: 0.017459668219089508, Validation Loss: 0.015205067582428455
Epoch 96, Training Loss: 0.015205067582428455, Validation Loss: 0.013241945765912533
Epoch 97, Training Loss: 0.013241944834589958, Validation Loss: 0.011571753770112991
Epoch 98, Training Loss: 0.011571756564080715, Validation Loss: 0.010067167691886425
Epoch 99, Training Loss: 0.01006716676056385, Validation Loss: 0.008691302500665188
Epoch 100, Training Loss: 0.008691303431987762, Validation Loss: 0.007439232897013426
Epoch 101, Training Loss: 0.0074392324313521385, Validation Loss: 0.006343664601445198
Epoch 102, Training Loss: 0.006343664135783911, Validation Loss: 0.005385862663388252
Epoch 103, Training Loss: 0.005385862197726965, Validation Loss: 0.004533901810646057
Epoch 104, Training Loss: 0.004533903673291206, Validation Loss: 0.0037960412446409464
Epoch 105, Training Loss: 0.003796039614826441, Validation Loss: 0.0031691831536591053
Epoch 106, Training Loss: 0.0031691831536591053, Validation Loss: 0.0026448701974004507
Epoch 107, Training Loss: 0.0026448690332472324, Validation Loss: 0.00221418053843081
Epoch 108, Training Loss: 0.0022141821682453156, Validation Loss: 0.0018659346969798207
Epoch 109, Training Loss: 0.0018659337656572461, Validation Loss: 0.001583661651238799
Epoch 110, Training Loss: 0.001583661767654121, Validation Loss: 0.0013525179820135236
Epoch 111, Training Loss: 0.0013525171671062708, Validation Loss: 0.0011639791773632169
Epoch 112, Training Loss: 0.0011639791773632169, Validation Loss: 0.0010083221131935716
Epoch 113, Training Loss: 0.0010083228116855025, Validation Loss: 0.0008825125405564904
Epoch 114, Training Loss: 0.0008825134136714041, Validation Loss: 0.0007771723321639001
Epoch 115, Training Loss: 0.0007771730306558311, Validation Loss: 0.0006882866728119552
Epoch 116, Training Loss: 0.0006882878369651735, Validation Loss: 0.0006170526030473411
Epoch 117, Training Loss: 0.0006170523120090365, Validation Loss: 0.0005637590656988323
Epoch 118, Training Loss: 0.0005637597641907632, Validation Loss: 0.0005228494992479682
Epoch 119, Training Loss: 0.00052284897537902, Validation Loss: 0.0004895125748589635
Epoch 120, Training Loss: 0.0004895126912742853, Validation Loss: 0.00046031351666897535
Epoch 121, Training Loss: 0.000460313749499619, Validation Loss: 0.0004335573175922036
Epoch 122, Training Loss: 0.0004335571138653904, Validation Loss: 0.00040760173578746617
Epoch 123, Training Loss: 0.0004076023760717362, Validation Loss: 0.0003819937992375344
Epoch 124, Training Loss: 0.0003819932462647557, Validation Loss: 0.0003557052696123719
Epoch 125, Training Loss: 0.00035570524050854146, Validation Loss: 0.0003299191303085536
Epoch 126, Training Loss: 0.00032991962507367134, Validation Loss: 0.0003052007232327014
Epoch 127, Training Loss: 0.00030520022846758366, Validation Loss: 0.00028242776170372963
Epoch 128, Training Loss: 0.0002824272960424423, Validation Loss: 0.0002620656741783023
Epoch 129, Training Loss: 0.00026206622715108097, Validation Loss: 0.00024412971106357872
Epoch 130, Training Loss: 0.0002441300603095442, Validation Loss: 0.00022823005565442145
Epoch 131, Training Loss: 0.00022822964820079505, Validation Loss: 0.00021369621390476823
Epoch 132, Training Loss: 0.00021369622845668346, Validation Loss: 0.00019990646978840232
Epoch 133, Training Loss: 0.00019990703731309623, Validation Loss: 0.00018600374460220337
Epoch 134, Training Loss: 0.0001860038173617795, Validation Loss: 0.0001716710248729214
Epoch 135, Training Loss: 0.00017167109763249755, Validation Loss: 0.00015637009346392006
Epoch 136, Training Loss: 0.00015636967145837843, Validation Loss: 0.00014015144552104175
Epoch 137, Training Loss: 0.00014015156193636358, Validation Loss: 0.0001233655057149008
Epoch 138, Training Loss: 0.000123365709441714, Validation Loss: 0.00010653798381099477
Epoch 139, Training Loss: 0.00010653754725353792, Validation Loss: 9.02310130186379e-05
Epoch 140, Training Loss: 9.023073653224856e-05, Validation Loss: 7.497700426029041e-05
Epoch 141, Training Loss: 7.497696060454473e-05, Validation Loss: 6.119906902313232e-05
Epoch 142, Training Loss: 6.119906174717471e-05, Validation Loss: 4.917630576528609e-05
Epoch 143, Training Loss: 4.917596379527822e-05, Validation Loss: 3.90363966289442e-05
Epoch 144, Training Loss: 3.903657852788456e-05, Validation Loss: 3.077531437156722e-05
Epoch 145, Training Loss: 3.0775321647524834e-05, Validation Loss: 2.428194238746073e-05
Epoch 146, Training Loss: 2.428190055070445e-05, Validation Loss: 1.937219531100709e-05
Epoch 147, Training Loss: 1.937221531989053e-05, Validation Loss: 1.5820305634406395e-05
Epoch 148, Training Loss: 1.5820269254618324e-05, Validation Loss: 1.3384941667027306e-05
Epoch 149, Training Loss: 1.338499532721471e-05, Validation Loss: 1.1828773494926281e-05
Epoch 150, Training Loss: 1.1828770766442176e-05, Validation Loss: 1.0932874829450157e-05
Epoch 151, Training Loss: 1.0932881195913069e-05, Validation Loss: 1.0504079000384081e-05
Epoch 152, Training Loss: 1.0503950761631131e-05, Validation Loss: 1.0379747436672915e-05
Epoch 153, Training Loss: 1.0379761988588143e-05, Validation Loss: 1.0429405847389717e-05
Epoch 154, Training Loss: 1.0429491339891683e-05, Validation Loss: 1.0552364074101206e-05
Epoch 155, Training Loss: 1.055238681146875e-05, Validation Loss: 1.0675404155335855e-05
Epoch 156, Training Loss: 1.0675397788872942e-05, Validation Loss: 1.0747664418886416e-05
Epoch 157, Training Loss: 1.0747580745373853e-05, Validation Loss: 1.0736353033280466e-05
Epoch 158, Training Loss: 1.0736380318121519e-05, Validation Loss: 1.062287174136145e-05
Epoch 159, Training Loss: 1.062281535268994e-05, Validation Loss: 1.0398181075288448e-05
Epoch 160, Training Loss: 1.03981565189315e-05, Validation Loss: 1.0061512512038462e-05
Epoch 161, Training Loss: 1.0061654393211938e-05, Validation Loss: 9.619051525078248e-06
Epoch 162, Training Loss: 9.619089723855723e-06, Validation Loss: 9.082683391170576e-06
Epoch 163, Training Loss: 9.08256242837524e-06, Validation Loss: 8.4696212070412e-06
Epoch 164, Training Loss: 8.469639396935236e-06, Validation Loss: 7.801931133144535e-06
Epoch 165, Training Loss: 7.801932042639237e-06, Validation Loss: 7.103632924554404e-06
Epoch 166, Training Loss: 7.103667485353071e-06, Validation Loss: 6.398584901035065e-06
Epoch 167, Training Loss: 6.398601271939697e-06, Validation Loss: 5.707611762773013e-06
Epoch 168, Training Loss: 5.707720447389875e-06, Validation Loss: 5.046568730904255e-06
Epoch 169, Training Loss: 5.04648414789699e-06, Validation Loss: 4.424758571985876e-06
Epoch 170, Training Loss: 4.424789040058386e-06, Validation Loss: 3.8464895624201745e-06
Epoch 171, Training Loss: 3.846509116556263e-06, Validation Loss: 3.3117291877715616e-06
Epoch 172, Training Loss: 3.3117423754447373e-06, Validation Loss: 2.8193649086460937e-06
Epoch 173, Training Loss: 2.8193724119773833e-06, Validation Loss: 2.3684715415583923e-06
Epoch 174, Training Loss: 2.3684567622694885e-06, Validation Loss: 1.960256895472412e-06
Epoch 175, Training Loss: 1.9602334759838413e-06, Validation Loss: 1.5979918543962413e-06
Epoch 176, Training Loss: 1.5979887848516228e-06, Validation Loss: 1.285919097426813e-06
Epoch 177, Training Loss: 1.2859234175266465e-06, Validation Loss: 1.02770650300954e-06
Epoch 178, Training Loss: 1.0277396995661547e-06, Validation Loss: 8.246126981248381e-07
Epoch 179, Training Loss: 8.245791036642913e-07, Validation Loss: 6.741568085999461e-07
Epoch 180, Training Loss: 6.741765332662908e-07, Validation Loss: 5.703394094780379e-07
Epoch 181, Training Loss: 5.703313377125596e-07, Validation Loss: 5.038081098973635e-07
Epoch 182, Training Loss: 5.038305062043946e-07, Validation Loss: 4.6394563923968235e-07
Epoch 183, Training Loss: 4.6393290631385753e-07, Validation Loss: 4.403714797263092e-07
Epoch 184, Training Loss: 4.4034902657585917e-07, Validation Loss: 4.2451634385543e-07
Epoch 185, Training Loss: 4.2456994719941576e-07, Validation Loss: 4.109786004846683e-07
Epoch 186, Training Loss: 4.1099511349784734e-07, Validation Loss: 3.970385762386286e-07
Epoch 187, Training Loss: 3.970389457208512e-07, Validation Loss: 3.823817280590447e-07
Epoch 188, Training Loss: 3.8239784316829173e-07, Validation Loss: 3.680877114220493e-07
Epoch 189, Training Loss: 3.6805641911996645e-07, Validation Loss: 3.551156453340809e-07
Epoch 190, Training Loss: 3.551134852841642e-07, Validation Loss: 3.440017906086723e-07
Epoch 191, Training Loss: 3.4399923265482357e-07, Validation Loss: 3.3417137501601246e-07
Epoch 192, Training Loss: 3.3414283961974434e-07, Validation Loss: 3.2426208917968324e-07
Epoch 193, Training Loss: 3.2425188578599773e-07, Validation Loss: 3.126462786440243e-07
Epoch 194, Training Loss: 3.1264016797649674e-07, Validation Loss: 2.979779765155399e-07
Epoch 195, Training Loss: 2.9798576406392385e-07, Validation Loss: 2.797149250000075e-07
Epoch 196, Training Loss: 2.7971105964752496e-07, Validation Loss: 2.581765556897153e-07
Epoch 197, Training Loss: 2.5817061555244436e-07, Validation Loss: 2.345062597441938e-07
Epoch 198, Training Loss: 2.344962553024743e-07, Validation Loss: 2.1015678441926866e-07
Epoch 199, Training Loss: 2.101626108697019e-07, Validation Loss: 1.8656724876109365e-07
Epoch 200, Training Loss: 1.8656857037058217e-07, Validation Loss: 1.6468034402805642e-07
Epoch 201, Training Loss: 1.6467429020394775e-07, Validation Loss: 1.4483417487554107e-07
Epoch 202, Training Loss: 1.4483539700904657e-07, Validation Loss: 1.2691263862052438e-07
Epoch 203, Training Loss: 1.269054621388932e-07, Validation Loss: 1.1039252001410205e-07
Epoch 204, Training Loss: 1.1040030756248598e-07, Validation Loss: 9.485524543606516e-08
Epoch 205, Training Loss: 9.48655625165884e-08, Validation Loss: 8.006762186596461e-08
Epoch 206, Training Loss: 8.008080243371296e-08, Validation Loss: 6.617644743300843e-08
Epoch 207, Training Loss: 6.617396053343327e-08, Validation Loss: 5.355304111276382e-08
Epoch 208, Training Loss: 5.356121945965242e-08, Validation Loss: 4.2758337315262906e-08
Epoch 209, Training Loss: 4.275992182556365e-08, Validation Loss: 3.42449304469028e-08
Epoch 210, Training Loss: 3.424976569021965e-08, Validation Loss: 2.8176005528735004e-08
Epoch 211, Training Loss: 2.8179204747402764e-08, Validation Loss: 2.4385425234640934e-08
Epoch 212, Training Loss: 2.4391525244027434e-08, Validation Loss: 2.2419417433638955e-08
Epoch 213, Training Loss: 2.242621910397702e-08, Validation Loss: 2.16207762804288e-08
Epoch 214, Training Loss: 2.16277058484593e-08, Validation Loss: 2.1331834076931955e-08
Epoch 215, Training Loss: 2.1329846333628666e-08, Validation Loss: 2.10266879463461e-08
Epoch 216, Training Loss: 2.1026298924198272e-08, Validation Loss: 2.0403071232522052e-08
Epoch 217, Training Loss: 2.0403653877565375e-08, Validation Loss: 1.9411171336969346e-08
Epoch 218, Training Loss: 1.9408862073078126e-08, Validation Loss: 1.8151693481627262e-08
Epoch 219, Training Loss: 1.815042338648709e-08, Validation Loss: 1.6824998283482273e-08
Epoch 220, Training Loss: 1.682598949059866e-08, Validation Loss: 1.5601841596435406e-08
Epoch 221, Training Loss: 1.560079354590016e-08, Validation Loss: 1.457851706021529e-08
Epoch 222, Training Loss: 1.4578136919851659e-08, Validation Loss: 1.3752453398296893e-08
Epoch 223, Training Loss: 1.3753274075156696e-08, Validation Loss: 1.3036348001094211e-08
Epoch 224, Training Loss: 1.3038636836881778e-08, Validation Loss: 1.233863322624984e-08
Epoch 225, Training Loss: 1.2340317212533591e-08, Validation Loss: 1.1557027335129533e-08
Epoch 226, Training Loss: 1.1559620816115057e-08, Validation Loss: 1.065417976064964e-08
Epoch 227, Training Loss: 1.0657472238051469e-08, Validation Loss: 9.652513455193912e-09
Epoch 228, Training Loss: 9.654540278347667e-09, Validation Loss: 8.616889424217788e-09
Epoch 229, Training Loss: 8.617324631643442e-09, Validation Loss: 7.608058183450339e-09
Epoch 230, Training Loss: 7.609017416143615e-09, Validation Loss: 6.6969976231234796e-09
Epoch 231, Training Loss: 6.6953451671736275e-09, Validation Loss: 5.899947197463007e-09
Epoch 232, Training Loss: 5.900847810380583e-09, Validation Loss: 5.205323727608402e-09
Epoch 233, Training Loss: 5.206178599337363e-09, Validation Loss: 4.5864028130893075e-09
Epoch 234, Training Loss: 4.5873478349278685e-09, Validation Loss: 4.005523912553599e-09
Epoch 235, Training Loss: 4.005536347051475e-09, Validation Loss: 3.440735918402993e-09
Epoch 236, Training Loss: 3.4389429082182232e-09, Validation Loss: 2.8921882666566034e-09
Epoch 237, Training Loss: 2.890563344237762e-09, Validation Loss: 2.3778636837334943e-09
Epoch 238, Training Loss: 2.3779458402373166e-09, Validation Loss: 1.9316750421438655e-09
Epoch 239, Training Loss: 1.9331507505881973e-09, Validation Loss: 1.5811101317098064e-09
Epoch 240, Training Loss: 1.5794887620046438e-09, Validation Loss: 1.330461851800635e-09
Epoch 241, Training Loss: 1.329819032669377e-09, Validation Loss: 1.1760012963435429e-09
Epoch 242, Training Loss: 1.1758061191358138e-09, Validation Loss: 1.092700707694405e-09
Epoch 243, Training Loss: 1.0917746706695652e-09, Validation Loss: 1.049251019402675e-09
Epoch 244, Training Loss: 1.0488356849691627e-09, Validation Loss: 1.0145921880422293e-09
Epoch 245, Training Loss: 1.013408024164164e-09, Validation Loss: 9.663893019151715e-10
Epoch 246, Training Loss: 9.66987379058537e-10, Validation Loss: 9.012148804998787e-10
Epoch 247, Training Loss: 8.998534695159321e-10, Validation Loss: 8.192701517195644e-10
Epoch 248, Training Loss: 8.193496991992788e-10, Validation Loss: 7.379210020808102e-10
Epoch 249, Training Loss: 7.372000232486187e-10, Validation Loss: 6.640274996527751e-10
Epoch 250, Training Loss: 6.635111349240219e-10, Validation Loss: 6.091476212333191e-10
Epoch 251, Training Loss: 6.091606108427072e-10, Validation Loss: 5.739299591134284e-10
Epoch 252, Training Loss: 5.730176333429426e-10, Validation Loss: 5.540172209883565e-10
Epoch 253, Training Loss: 5.543123182683019e-10, Validation Loss: 5.408682945962084e-10
Epoch 254, Training Loss: 5.409295233960165e-10, Validation Loss: 5.254969237533658e-10
Epoch 255, Training Loss: 5.268642744304941e-10, Validation Loss: 5.052925855508761e-10
Epoch 256, Training Loss: 5.045238116174744e-10, Validation Loss: 4.736251946191317e-10
Epoch 257, Training Loss: 4.740667303160251e-10, Validation Loss: 4.352243565541869e-10
Epoch 258, Training Loss: 4.3489786771822025e-10, Validation Loss: 3.91365218010975e-10
Epoch 259, Training Loss: 3.922698832425908e-10, Validation Loss: 3.492984790298692e-10
Epoch 260, Training Loss: 3.4878336330201876e-10, Validation Loss: 3.078069188422461e-10
Epoch 261, Training Loss: 3.0806804329763793e-10, Validation Loss: 2.7179386519193827e-10
Epoch 262, Training Loss: 2.723046510499927e-10, Validation Loss: 2.3994034537011544e-10
Epoch 263, Training Loss: 2.3996524212144266e-10, Validation Loss: 2.1043572440149205e-10
Epoch 264, Training Loss: 2.1076279610454662e-10, Validation Loss: 1.8277131197397267e-10
Epoch 265, Training Loss: 1.823210055151847e-10, Validation Loss: 1.5584361579001893e-10
Epoch 266, Training Loss: 1.5561706090405636e-10, Validation Loss: 1.3164731804682361e-10
Epoch 267, Training Loss: 1.311407926696262e-10, Validation Loss: 1.096380625176252e-10
Epoch 268, Training Loss: 1.0921832882537785e-10, Validation Loss: 9.07436070729517e-11
Epoch 269, Training Loss: 9.100363518310672e-11, Validation Loss: 7.653228745185814e-11
Epoch 270, Training Loss: 7.647697058965619e-11, Validation Loss: 6.568835059228562e-11
Epoch 271, Training Loss: 6.576217348452928e-11, Validation Loss: 5.7538081937869023e-11
Epoch 272, Training Loss: 5.774966269078696e-11, Validation Loss: 5.088238511086196e-11
Epoch 273, Training Loss: 5.1286676294726163e-11, Validation Loss: 4.5294466094469854e-11
Epoch 274, Training Loss: 4.526891708711567e-11, Validation Loss: 3.968909229046247e-11
Epoch 275, Training Loss: 3.982596544216399e-11, Validation Loss: 3.457050964938979e-11
Epoch 276, Training Loss: 3.4505624052494355e-11, Validation Loss: 3.007821769429597e-11
Epoch 277, Training Loss: 3.001743992259165e-11, Validation Loss: 2.611426526410998e-11
Epoch 278, Training Loss: 2.6527051388836043e-11, Validation Loss: 2.417738405313674e-11
Epoch 279, Training Loss: 2.4345723353969007e-11, Validation Loss: 2.3458788731001157e-11
Epoch 280, Training Loss: 2.3477482111178283e-11, Validation Loss: 2.3901771187273546e-11
Epoch 281, Training Loss: 2.3700288259709268e-11, Validation Loss: 2.4588076366627298e-11
Epoch 282, Training Loss: 2.4591889288827495e-11, Validation Loss: 2.5626792354849215e-11
Epoch 283, Training Loss: 2.5679128962119435e-11, Validation Loss: 2.6118805035446613e-11
Epoch 284, Training Loss: 2.632822258819001e-11, Validation Loss: 2.6093070412680497e-11
Epoch 285, Training Loss: 2.6135727262954767e-11, Validation Loss: 2.5115057603053437e-11
Epoch 286, Training Loss: 2.5157226996030957e-11, Validation Loss: 2.339724421152045e-11
Epoch 287, Training Loss: 2.33909801250487e-11, Validation Loss: 2.091482022292812e-11
Epoch 288, Training Loss: 2.1046437162497433e-11, Validation Loss: 1.8448081604005573e-11
Epoch 289, Training Loss: 1.83971640005387e-11, Validation Loss: 1.5753381238381436e-11
Epoch 290, Training Loss: 1.5769446512492458e-11, Validation Loss: 1.3280300470430717e-11
Epoch 291, Training Loss: 1.3241305621414234e-11, Validation Loss: 1.1099790357682604e-11
Epoch 292, Training Loss: 1.1058416335418819e-11, Validation Loss: 9.188060902387551e-12
Epoch 293, Training Loss: 9.183558427605654e-12, Validation Loss: 7.709019186896704e-12
Epoch 294, Training Loss: 7.701217268063498e-12, Validation Loss: 6.361331600368558e-12
Epoch 295, Training Loss: 6.377307536220567e-12, Validation Loss: 5.430606051654019e-12
Epoch 296, Training Loss: 5.42177067131e-12, Validation Loss: 4.607082944307894e-12
Epoch 297, Training Loss: 4.645611152709339e-12, Validation Loss: 4.0694331585044985e-12
Epoch 298, Training Loss: 4.01679817879641e-12, Validation Loss: 3.5388061838531604e-12
Epoch 299, Training Loss: 3.557604081119714e-12, Validation Loss: 3.227399467467529e-12
Epoch 300, Training Loss: 3.215990408006464e-12, Validation Loss: 2.9309278528483196e-12
Epoch 301, Training Loss: 2.9346199949265017e-12, Validation Loss: 2.687887456012672e-12
Epoch 302, Training Loss: 2.671219365493749e-12, Validation Loss: 2.487255193472926e-12
Epoch 303, Training Loss: 2.5113730539594314e-12, Validation Loss: 2.363163484342401e-12
Epoch 304, Training Loss: 2.3606032493322937e-12, Validation Loss: 2.1805957647197394e-12
Epoch 305, Training Loss: 2.134897293670779e-12, Validation Loss: 1.960338792336702e-12
Epoch 306, Training Loss: 1.974238481028401e-12, Validation Loss: 1.8072104143035395e-12
Epoch 307, Training Loss: 1.7906545387094686e-12, Validation Loss: 1.6079370907667867e-12
Epoch 308, Training Loss: 1.6066402765482768e-12, Validation Loss: 1.4411951449952443e-12
Epoch 309, Training Loss: 1.4543687434920294e-12, Validation Loss: 1.2933369653023163e-12
Epoch 310, Training Loss: 1.2926097909052303e-12, Validation Loss: 1.1726977895698543e-12
Epoch 311, Training Loss: 1.1511979520692495e-12, Validation Loss: 1.029108655931088e-12
Epoch 312, Training Loss: 1.06813939203948e-12, Validation Loss: 9.828416292628761e-13
Epoch 313, Training Loss: 9.43811652096005e-13, Validation Loss: 9.24525538591181e-13
Epoch 314, Training Loss: 8.945979807634119e-13, Validation Loss: 8.271727486991454e-13
Epoch 315, Training Loss: 8.285844341378301e-13, Validation Loss: 7.287308235147394e-13
Epoch 316, Training Loss: 7.435757738705195e-13, Validation Loss: 6.751635383585308e-13
Epoch 317, Training Loss: 6.801504888812038e-13, Validation Loss: 6.33333012770021e-13
Epoch 318, Training Loss: 6.294666394027204e-13, Validation Loss: 5.972826400135745e-13
Epoch 319, Training Loss: 5.979171693350216e-13, Validation Loss: 5.232908832815408e-13
Epoch 320, Training Loss: 5.517313494095288e-13, Validation Loss: 4.857829091244048e-13
Epoch 321, Training Loss: 5.010564988090771e-13, Validation Loss: 4.698883968555501e-13
Epoch 322, Training Loss: 4.800888961549454e-13, Validation Loss: 4.140913144063535e-13
Epoch 323, Training Loss: 4.2146242550632207e-13, Validation Loss: 3.8757576792045056e-13
Epoch 324, Training Loss: 3.8349889670136195e-13, Validation Loss: 3.371833519859313e-13
Epoch 325, Training Loss: 3.5888468846029253e-13, Validation Loss: 3.081186835621891e-13
Epoch 326, Training Loss: 3.182130394688981e-13, Validation Loss: 2.8663261542917484e-13
Epoch 327, Training Loss: 2.966832508832784e-13, Validation Loss: 2.512186151378687e-13
Epoch 328, Training Loss: 2.466125448383899e-13, Validation Loss: 2.1564938420051694e-13
Epoch 329, Training Loss: 2.159356813366889e-13, Validation Loss: 1.8961699886025501e-13
Epoch 330, Training Loss: 1.8818264004363816e-13, Validation Loss: 1.644467575350264e-13
Epoch 331, Training Loss: 1.4913387907412867e-13, Validation Loss: 1.2295650879835113e-13
Epoch 332, Training Loss: 1.2547572030875698e-13, Validation Loss: 1.053496618283814e-13
Epoch 333, Training Loss: 9.358116224208318e-14, Validation Loss: 8.24663213693129e-14
Epoch 334, Training Loss: 8.804025217190592e-14, Validation Loss: 6.411028392189211e-14
Epoch 335, Training Loss: 6.340431922980533e-14, Validation Loss: 5.54394651388658e-14
Epoch 336, Training Loss: 5.627453459277308e-14, Validation Loss: 4.457709429448592e-14
Epoch 337, Training Loss: 4.8998304735424145e-14, Validation Loss: 3.643370259892413e-14
Epoch 338, Training Loss: 4.253999699699827e-14, Validation Loss: 3.329245042084546e-14
Epoch 339, Training Loss: 3.984570377639496e-14, Validation Loss: 3.296071843738278e-14
Epoch 340, Training Loss: 3.389006265831947e-14, Validation Loss: 2.5970050491607582e-14
Epoch 341, Training Loss: 2.8673281603870324e-14, Validation Loss: 2.2345611756899482e-14
Epoch 342, Training Loss: 2.5200499036170422e-14, Validation Loss: 2.344062206979195e-14
Epoch 343, Training Loss: 2.3766883914481257e-14, Validation Loss: 2.5465645759649436e-14
Epoch 344, Training Loss: 2.2328532184551046e-14, Validation Loss: 2.062549959926281e-14
Epoch 345, Training Loss: 2.161469347418659e-14, Validation Loss: 2.083807098770575e-14
Epoch 346, Training Loss: 1.9227713971242504e-14, Validation Loss: 1.9583666014798967e-14
Epoch 347, Training Loss: 1.9880635766106325e-14, Validation Loss: 1.7123426632246856e-14
Epoch 348, Training Loss: 1.9495461085869588e-14, Validation Loss: 1.4363681481743308e-14
Epoch 349, Training Loss: 1.3333055837237533e-14, Validation Loss: 1.4324850103309382e-14
Epoch 350, Training Loss: 1.4248522270366402e-14, Validation Loss: 1.8637974057980275e-14
Epoch 351, Training Loss: 1.3086324457064775e-14, Validation Loss: 1.8120626662588082e-14
Epoch 352, Training Loss: 1.5204956299022174e-14, Validation Loss: 1.7748460714355277e-14
Epoch 353, Training Loss: 1.5424065087752022e-14, Validation Loss: 2.0503401493982e-14
Epoch 354, Training Loss: 1.3052164465334956e-14, Validation Loss: 1.4867218851963467e-14
Epoch 355, Training Loss: 1.2714360102673416e-14, Validation Loss: 1.3131561098645838e-14
Epoch 356, Training Loss: 1.2206086124212211e-14, Validation Loss: 2.1787964227942824e-14
Epoch 357, Training Loss: 1.3022407350864965e-14, Validation Loss: 2.136342453851539e-14
Epoch 358, Training Loss: 1.0552760820400648e-14, Validation Loss: 2.1185415482452216e-14
Epoch 359, Training Loss: 1.0474231548827755e-14, Validation Loss: 2.054430132687312e-14
Epoch 360, Training Loss: 1.3292623566533296e-14, Validation Loss: 1.966039364729305e-14
Epoch 361, Training Loss: 1.028261152033515e-14, Validation Loss: 1.8222573854053715e-14
Epoch 362, Training Loss: 1.1420856935954321e-14, Validation Loss: 1.9560579284788604e-14
Epoch 363, Training Loss: 1.1449213057929553e-14, Validation Loss: 1.932599181598063e-14
Epoch 364, Training Loss: 1.0251786297318672e-14, Validation Loss: 1.6686543978712033e-14
Epoch 365, Training Loss: 1.028634778266549e-14, Validation Loss: 1.5837862705342376e-14
Epoch 366, Training Loss: 9.966758016501705e-15, Validation Loss: 1.596896815898429e-14
Epoch 367, Training Loss: 8.533743441172144e-15, Validation Loss: 1.5750660663422546e-14
Epoch 368, Training Loss: 6.824506763061745e-15, Validation Loss: 1.1955017935349511e-14
Epoch 369, Training Loss: 6.991640763115122e-15, Validation Loss: 1.2448080049110976e-14
Epoch 370, Training Loss: 7.610136174387213e-15, Validation Loss: 8.68559781389e-15
Epoch 371, Training Loss: 6.035540888957042e-15, Validation Loss: 8.481567905687173e-15
Epoch 372, Training Loss: 4.335912105567349e-15, Validation Loss: 6.510254998531558e-15
Epoch 373, Training Loss: 3.5452786353477395e-15, Validation Loss: 6.399098864863376e-15
Epoch 374, Training Loss: 3.06429330558999e-15, Validation Loss: 9.146433712140228e-15
Epoch 375, Training Loss: 3.3910216536749962e-15, Validation Loss: 8.789080676089005e-15
Epoch 376, Training Loss: 3.4849637485143657e-15, Validation Loss: 9.792084576184818e-15
Epoch 377, Training Loss: 3.632481736058754e-15, Validation Loss: 9.792084576184818e-15
Epoch 378, Training Loss: 4.018924848134004e-15, Validation Loss: 9.961020215317005e-15
Epoch 379, Training Loss: 4.2841376401829036e-15, Validation Loss: 7.713352221207833e-15
Epoch 380, Training Loss: 3.1716458378085264e-15, Validation Loss: 7.306626481694105e-15
Epoch 381, Training Loss: 3.0552192533842915e-15, Validation Loss: 7.0779097982435514e-15
Epoch 382, Training Loss: 3.405499987842414e-15, Validation Loss: 7.751649968884989e-15
Epoch 383, Training Loss: 2.2547110730655913e-15, Validation Loss: 7.582180698996032e-15
Epoch 384, Training Loss: 2.194996520833584e-15, Validation Loss: 7.37948486768513e-15
Epoch 385, Training Loss: 1.9453297479821163e-15, Validation Loss: 6.4171135615855805e-15
Epoch 386, Training Loss: 3.3511230137275297e-15, Validation Loss: 6.4397983744624715e-15
Epoch 387, Training Loss: 3.3755427618386343e-15, Validation Loss: 6.463817687747762e-15
Epoch 388, Training Loss: 2.632280244468932e-15, Validation Loss: 6.353329016042016e-15
Epoch 389, Training Loss: 2.784935910354891e-15, Validation Loss: 5.411707899567828e-15
Epoch 390, Training Loss: 2.933054656017119e-15, Validation Loss: 5.411707899567828e-15
Epoch 391, Training Loss: 1.7516412650323172e-15, Validation Loss: 6.444401998530799e-15
Epoch 392, Training Loss: 2.0829734489438874e-15, Validation Loss: 6.0947887260351125e-15
Epoch 393, Training Loss: 2.0733657659814187e-15, Validation Loss: 5.320167778408635e-15
Epoch 394, Training Loss: 3.3390466532402883e-15, Validation Loss: 7.015526245194746e-15
Epoch 395, Training Loss: 2.3389118654950627e-15, Validation Loss: 6.9359962041946714e-15
Epoch 396, Training Loss: 2.0045773733019497e-15, Validation Loss: 5.390757810166914e-15
Epoch 397, Training Loss: 2.394022793658743e-15, Validation Loss: 5.750379200450883e-15
Epoch 398, Training Loss: 2.840780792567367e-15, Validation Loss: 5.750379200450883e-15
Epoch 399, Training Loss: 3.3240346883161003e-15, Validation Loss: 5.5368748052165434e-15
Epoch 400, Training Loss: 2.7692566952265034e-15, Validation Loss: 5.222756448375549e-15
Epoch 401, Training Loss: 2.4357228609267825e-15, Validation Loss: 5.081309569480606e-15
Epoch 402, Training Loss: 2.116800556725435e-15, Validation Loss: 6.025599686771592e-15
Epoch 403, Training Loss: 1.54500895397817e-15, Validation Loss: 6.477828883244769e-15
Epoch 404, Training Loss: 1.6063915258415578e-15, Validation Loss: 4.854527932798055e-15
Epoch 405, Training Loss: 2.228890332459728e-15, Validation Loss: 4.579307446477346e-15
Epoch 406, Training Loss: 1.6913929761644213e-15, Validation Loss: 4.007515737850962e-15
Epoch 407, Training Loss: 2.1396187772915187e-15, Validation Loss: 4.894559980434714e-15
Epoch 408, Training Loss: 2.121604504085788e-15, Validation Loss: 5.402033512760763e-15
Epoch 409, Training Loss: 1.633213035874602e-15, Validation Loss: 5.580843438475567e-15
Epoch 410, Training Loss: 1.7020682382777857e-15, Validation Loss: 6.039477474579407e-15
Epoch 411, Training Loss: 1.6760473861381336e-15, Validation Loss: 4.907236675523322e-15
Epoch 412, Training Loss: 1.6450224751043399e-15, Validation Loss: 5.2555158711270825e-15
Epoch 413, Training Loss: 1.0959824949576804e-15, Validation Loss: 4.3249036418683585e-15
Epoch 414, Training Loss: 7.084719096106529e-16, Validation Loss: 4.905702275339371e-15
Epoch 415, Training Loss: 1.0289287198750698e-15, Validation Loss: 5.102526474259905e-15
Epoch 416, Training Loss: 2.418509033856207e-15, Validation Loss: 3.1589691427199185e-15
Epoch 417, Training Loss: 2.3732728157916175e-15, Validation Loss: 4.401564782276083e-15
Epoch 418, Training Loss: 1.79981329929209e-15, Validation Loss: 5.711548245533431e-15
Epoch 419, Training Loss: 1.79981329929209e-15, Validation Loss: 6.265658988418828e-15
Epoch 420, Training Loss: 9.611410966227818e-16, Validation Loss: 6.134220227312168e-15
Epoch 421, Training Loss: 1.6923937455916023e-15, Validation Loss: 7.810363751689815e-15
Epoch 422, Training Loss: 1.535734896117801e-15, Validation Loss: 7.795018055784409e-15
Epoch 423, Training Loss: 1.5063780047153879e-15, Validation Loss: 7.341320951213641e-15
Epoch 424, Training Loss: 1.0964495277489728e-15, Validation Loss: 7.323306254491437e-15
Epoch 425, Training Loss: 1.0448081524163646e-15, Validation Loss: 5.35392797058735e-15
Epoch 426, Training Loss: 5.337319242678469e-16, Validation Loss: 5.343252814353104e-15
Epoch 427, Training Loss: 5.337319242678469e-16, Validation Loss: 5.354595432549786e-15
Epoch 428, Training Loss: 5.337319242678469e-16, Validation Loss: 6.342053313448167e-15
Epoch 429, Training Loss: 5.390695023849699e-16, Validation Loss: 6.779337037083515e-15
Epoch 430, Training Loss: 5.742977614799538e-16, Validation Loss: 7.496711686486284e-15
Epoch 431, Training Loss: 1.1954621735688433e-15, Validation Loss: 7.469623572833092e-15
Epoch 432, Training Loss: 1.1767805442797945e-15, Validation Loss: 7.051555215122681e-15
Epoch 433, Training Loss: 1.1681069268999105e-15, Validation Loss: 4.3299744046070964e-15
Epoch 434, Training Loss: 1.2498391476837276e-15, Validation Loss: 4.3299744046070964e-15
Epoch 435, Training Loss: 5.909777989750815e-16, Validation Loss: 4.3299744046070964e-15
Epoch 436, Training Loss: 5.322640691098144e-16, Validation Loss: 3.840915792070829e-15
Epoch 437, Training Loss: 5.322640691098144e-16, Validation Loss: 3.840915792070829e-15
Epoch 438, Training Loss: 5.242576489945707e-16, Validation Loss: 3.803886052715713e-15
Epoch 439, Training Loss: 5.242576489945707e-16, Validation Loss: 3.803886052715713e-15
Epoch 440, Training Loss: 5.242576489945707e-16, Validation Loss: 3.869271490529588e-15
Epoch 441, Training Loss: 1.3345069729044914e-15, Validation Loss: 3.869271490529588e-15
Epoch 442, Training Loss: 2.1304782329994608e-15, Validation Loss: 3.826570865592604e-15
Epoch 443, Training Loss: 2.666908010143872e-15, Validation Loss: 4.3516584480568065e-15
Epoch 444, Training Loss: 1.5345339092777128e-15, Validation Loss: 5.000177789177274e-15
Epoch 445, Training Loss: 1.8676009225443782e-15, Validation Loss: 5.08237725451062e-15
Epoch 446, Training Loss: 2.126208128154115e-15, Validation Loss: 5.083044292956583e-15
Epoch 447, Training Loss: 8.545223066948045e-16, Validation Loss: 5.228627657249442e-15
Epoch 448, Training Loss: 8.486509390022337e-16, Validation Loss: 4.305888175718973e-15
Epoch 449, Training Loss: 8.486509390022337e-16, Validation Loss: 4.305888175718973e-15
Epoch 450, Training Loss: 4.3872243556603897e-16, Validation Loss: 4.356595379589878e-15
Epoch 451, Training Loss: 5.24524517312515e-16, Validation Loss: 4.456408895061378e-15
Epoch 452, Training Loss: 4.924988368515404e-16, Validation Loss: 4.456408895061378e-15
Epoch 453, Training Loss: 6.786480383565066e-16, Validation Loss: 4.355528118076338e-15
Epoch 454, Training Loss: 6.775805121451701e-16, Validation Loss: 4.355528118076338e-15
Epoch 455, Training Loss: 6.775805121451701e-16, Validation Loss: 4.499643574271605e-15
Epoch 456, Training Loss: 6.374817077243555e-16, Validation Loss: 4.53807430612148e-15
Epoch 457, Training Loss: 6.40150496782917e-16, Validation Loss: 4.503379836601944e-15
Epoch 458, Training Loss: 1.0501457305334876e-15, Validation Loss: 4.516056531690552e-15
Epoch 459, Training Loss: 1.0501457305334876e-15, Validation Loss: 4.516056531690552e-15
Epoch 460, Training Loss: 1.0501457305334876e-15, Validation Loss: 4.466950643606431e-15
Epoch 461, Training Loss: 1.0392036530417381e-15, Validation Loss: 3.783736409449954e-15
Epoch 462, Training Loss: 1.0392036530417381e-15, Validation Loss: 3.684857171319276e-15
Epoch 463, Training Loss: 1.0392036530417381e-15, Validation Loss: 3.8001497903853744e-15
Epoch 464, Training Loss: 1.0750324055567662e-15, Validation Loss: 3.8001497903853744e-15
Epoch 465, Training Loss: 1.0750324055567662e-15, Validation Loss: 3.684857171319276e-15
Epoch 466, Training Loss: 1.0750324055567662e-15, Validation Loss: 3.684857171319276e-15
Epoch 467, Training Loss: 1.0216563067481812e-15, Validation Loss: 3.78627200257756e-15
Epoch 468, Training Loss: 1.0036418217842136e-15, Validation Loss: 3.78627200257756e-15
Epoch 469, Training Loss: 9.979039147203946e-16, Validation Loss: 3.78627200257756e-15
Epoch 470, Training Loss: 1.4365887367296195e-15, Validation Loss: 3.78627200257756e-15
Epoch 471, Training Loss: 1.4365887367296195e-15, Validation Loss: 3.78627200257756e-15
Epoch 472, Training Loss: 1.4317848952483852e-15, Validation Loss: 3.4275844661179385e-15
Epoch 473, Training Loss: 1.4828925339451047e-15, Validation Loss: 5.0256650105601555e-15
Epoch 474, Training Loss: 1.4408588415749653e-15, Validation Loss: 5.209812514392082e-15
Epoch 475, Training Loss: 1.3447819060711597e-15, Validation Loss: 5.209812514392082e-15
Epoch 476, Training Loss: 1.3994923994090254e-15, Validation Loss: 5.209812514392082e-15
Epoch 477, Training Loss: 1.640352041312298e-15, Validation Loss: 5.061560572798898e-15
Epoch 478, Training Loss: 2.4070999235731652e-15, Validation Loss: 6.416980153896388e-15
Epoch 479, Training Loss: 1.8506539108521878e-15, Validation Loss: 5.4642163190010695e-15
Epoch 480, Training Loss: 1.838977985190761e-15, Validation Loss: 5.3361140206736445e-15
Epoch 481, Training Loss: 1.2941413001657325e-15, Validation Loss: 5.200672181858261e-15
Epoch 482, Training Loss: 2.0720981811758526e-15, Validation Loss: 5.4221827325100485e-15
Epoch 483, Training Loss: 1.9734190545789634e-15, Validation Loss: 6.654503862416018e-15
Epoch 484, Training Loss: 1.982492895026425e-15, Validation Loss: 6.8414537747539354e-15
Epoch 485, Training Loss: 1.953136003624012e-15, Validation Loss: 7.322238992977896e-15
Epoch 486, Training Loss: 1.904430338607469e-15, Validation Loss: 7.290213524275158e-15
Epoch 487, Training Loss: 2.274993912262306e-15, Validation Loss: 6.796484372067731e-15
Epoch 488, Training Loss: 2.1869234498133033e-15, Validation Loss: 6.799820411330492e-15
Epoch 489, Training Loss: 1.7663197107335238e-15, Validation Loss: 6.516659838162221e-15
Epoch 490, Training Loss: 1.792340562873176e-15, Validation Loss: 6.590719316872454e-15
Epoch 491, Training Loss: 2.6362168300912963e-15, Validation Loss: 4.5417440763654594e-15
Epoch 492, Training Loss: 3.1294121397837165e-15, Validation Loss: 4.591116779827965e-15
Epoch 493, Training Loss: 2.298212567654204e-15, Validation Loss: 2.9913013001515347e-15
Epoch 494, Training Loss: 2.275794570155698e-15, Validation Loss: 2.2884714770025428e-15
Epoch 495, Training Loss: 1.5186545826155365e-15, Validation Loss: 2.641687815897612e-15
Epoch 496, Training Loss: 4.737505037178953e-16, Validation Loss: 2.6297450748578e-15
Epoch 497, Training Loss: 1.2277547752873215e-15, Validation Loss: 3.320965676189961e-15
Epoch 498, Training Loss: 6.441537333103185e-16, Validation Loss: 3.320965676189961e-15
Epoch 499, Training Loss: 2.066894010747922e-15, Validation Loss: 3.302283941021794e-15
Epoch 500, Training Loss: 2.066894010747922e-15, Validation Loss: 3.3070878883821467e-15
