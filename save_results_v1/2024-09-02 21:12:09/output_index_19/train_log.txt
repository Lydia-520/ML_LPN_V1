Epoch 1, Training Loss: 0.4540073573589325, Validation Loss: 0.4526517689228058
Epoch 2, Training Loss: 0.4526517689228058, Validation Loss: 0.4513307511806488
Epoch 3, Training Loss: 0.4513307511806488, Validation Loss: 0.4500286877155304
Epoch 4, Training Loss: 0.4500287175178528, Validation Loss: 0.4487440586090088
Epoch 5, Training Loss: 0.4487440586090088, Validation Loss: 0.4474846422672272
Epoch 6, Training Loss: 0.4474846422672272, Validation Loss: 0.44622600078582764
Epoch 7, Training Loss: 0.44622600078582764, Validation Loss: 0.4449909031391144
Epoch 8, Training Loss: 0.44499093294143677, Validation Loss: 0.44376471638679504
Epoch 9, Training Loss: 0.44376471638679504, Validation Loss: 0.44256138801574707
Epoch 10, Training Loss: 0.44256138801574707, Validation Loss: 0.4413524866104126
Epoch 11, Training Loss: 0.4413524866104126, Validation Loss: 0.44012561440467834
Epoch 12, Training Loss: 0.44012561440467834, Validation Loss: 0.4389030635356903
Epoch 13, Training Loss: 0.4389030635356903, Validation Loss: 0.43771663308143616
Epoch 14, Training Loss: 0.43771669268608093, Validation Loss: 0.4365254342556
Epoch 15, Training Loss: 0.4365254342556, Validation Loss: 0.4353136420249939
Epoch 16, Training Loss: 0.4353136122226715, Validation Loss: 0.43407684564590454
Epoch 17, Training Loss: 0.43407684564590454, Validation Loss: 0.4328065514564514
Epoch 18, Training Loss: 0.4328065514564514, Validation Loss: 0.43150946497917175
Epoch 19, Training Loss: 0.43150946497917175, Validation Loss: 0.4301656484603882
Epoch 20, Training Loss: 0.4301656484603882, Validation Loss: 0.4287576973438263
Epoch 21, Training Loss: 0.4287576973438263, Validation Loss: 0.42729341983795166
Epoch 22, Training Loss: 0.42729341983795166, Validation Loss: 0.4257698953151703
Epoch 23, Training Loss: 0.4257698953151703, Validation Loss: 0.42418262362480164
Epoch 24, Training Loss: 0.42418262362480164, Validation Loss: 0.4225374758243561
Epoch 25, Training Loss: 0.4225374758243561, Validation Loss: 0.42083290219306946
Epoch 26, Training Loss: 0.42083290219306946, Validation Loss: 0.4190555512905121
Epoch 27, Training Loss: 0.4190555214881897, Validation Loss: 0.4172230362892151
Epoch 28, Training Loss: 0.4172230660915375, Validation Loss: 0.415323942899704
Epoch 29, Training Loss: 0.415323942899704, Validation Loss: 0.4133681654930115
Epoch 30, Training Loss: 0.4133681654930115, Validation Loss: 0.41133415699005127
Epoch 31, Training Loss: 0.41133415699005127, Validation Loss: 0.40921270847320557
Epoch 32, Training Loss: 0.40921270847320557, Validation Loss: 0.4069769084453583
Epoch 33, Training Loss: 0.40697693824768066, Validation Loss: 0.40460947155952454
Epoch 34, Training Loss: 0.40460947155952454, Validation Loss: 0.4021126329898834
Epoch 35, Training Loss: 0.4021126329898834, Validation Loss: 0.39946234226226807
Epoch 36, Training Loss: 0.3994623124599457, Validation Loss: 0.3966507017612457
Epoch 37, Training Loss: 0.3966507017612457, Validation Loss: 0.3936489224433899
Epoch 38, Training Loss: 0.39364898204803467, Validation Loss: 0.39047420024871826
Epoch 39, Training Loss: 0.39047420024871826, Validation Loss: 0.38706061244010925
Epoch 40, Training Loss: 0.38706061244010925, Validation Loss: 0.383402556180954
Epoch 41, Training Loss: 0.383402556180954, Validation Loss: 0.3795430660247803
Epoch 42, Training Loss: 0.3795430362224579, Validation Loss: 0.37547028064727783
Epoch 43, Training Loss: 0.37547025084495544, Validation Loss: 0.37112852931022644
Epoch 44, Training Loss: 0.37112852931022644, Validation Loss: 0.3665151298046112
Epoch 45, Training Loss: 0.3665151000022888, Validation Loss: 0.3615576922893524
Epoch 46, Training Loss: 0.3615576922893524, Validation Loss: 0.35627293586730957
Epoch 47, Training Loss: 0.35627293586730957, Validation Loss: 0.3506588041782379
Epoch 48, Training Loss: 0.3506588041782379, Validation Loss: 0.3447047173976898
Epoch 49, Training Loss: 0.3447047173976898, Validation Loss: 0.3384360671043396
Epoch 50, Training Loss: 0.3384360671043396, Validation Loss: 0.3318221867084503
Epoch 51, Training Loss: 0.3318221867084503, Validation Loss: 0.3248820900917053
Epoch 52, Training Loss: 0.3248820900917053, Validation Loss: 0.3176034092903137
Epoch 53, Training Loss: 0.3176034390926361, Validation Loss: 0.30997225642204285
Epoch 54, Training Loss: 0.30997222661972046, Validation Loss: 0.30209943652153015
Epoch 55, Training Loss: 0.30209946632385254, Validation Loss: 0.2939926087856293
Epoch 56, Training Loss: 0.2939926087856293, Validation Loss: 0.2857794463634491
Epoch 57, Training Loss: 0.2857794463634491, Validation Loss: 0.27747657895088196
Epoch 58, Training Loss: 0.27747660875320435, Validation Loss: 0.26913294196128845
Epoch 59, Training Loss: 0.26913294196128845, Validation Loss: 0.26096200942993164
Epoch 60, Training Loss: 0.26096200942993164, Validation Loss: 0.25307971239089966
Epoch 61, Training Loss: 0.25307968258857727, Validation Loss: 0.24554523825645447
Epoch 62, Training Loss: 0.24554525315761566, Validation Loss: 0.23851270973682404
Epoch 63, Training Loss: 0.23851270973682404, Validation Loss: 0.23202992975711823
Epoch 64, Training Loss: 0.23202992975711823, Validation Loss: 0.2261127382516861
Epoch 65, Training Loss: 0.2261127233505249, Validation Loss: 0.22071564197540283
Epoch 66, Training Loss: 0.22071564197540283, Validation Loss: 0.215822234749794
Epoch 67, Training Loss: 0.215822234749794, Validation Loss: 0.21120578050613403
Epoch 68, Training Loss: 0.21120578050613403, Validation Loss: 0.2065257430076599
Epoch 69, Training Loss: 0.2065257430076599, Validation Loss: 0.20163805782794952
Epoch 70, Training Loss: 0.20163804292678833, Validation Loss: 0.19636692106723785
Epoch 71, Training Loss: 0.19636690616607666, Validation Loss: 0.1905984729528427
Epoch 72, Training Loss: 0.1905984729528427, Validation Loss: 0.18429945409297943
Epoch 73, Training Loss: 0.18429946899414062, Validation Loss: 0.17770059406757355
Epoch 74, Training Loss: 0.17770059406757355, Validation Loss: 0.17070195078849792
Epoch 75, Training Loss: 0.17070195078849792, Validation Loss: 0.16338759660720825
Epoch 76, Training Loss: 0.16338759660720825, Validation Loss: 0.15586429834365845
Epoch 77, Training Loss: 0.15586428344249725, Validation Loss: 0.14817941188812256
Epoch 78, Training Loss: 0.14817941188812256, Validation Loss: 0.14035660028457642
Epoch 79, Training Loss: 0.1403566151857376, Validation Loss: 0.13242213428020477
Epoch 80, Training Loss: 0.13242211937904358, Validation Loss: 0.1243528351187706
Epoch 81, Training Loss: 0.1243528425693512, Validation Loss: 0.11616595089435577
Epoch 82, Training Loss: 0.11616595089435577, Validation Loss: 0.10825452953577042
Epoch 83, Training Loss: 0.10825452208518982, Validation Loss: 0.10024163126945496
Epoch 84, Training Loss: 0.10024163126945496, Validation Loss: 0.09211236238479614
Epoch 85, Training Loss: 0.09211236238479614, Validation Loss: 0.08383398503065109
Epoch 86, Training Loss: 0.08383399248123169, Validation Loss: 0.07551079243421555
Epoch 87, Training Loss: 0.07551080733537674, Validation Loss: 0.06731051951646805
Epoch 88, Training Loss: 0.06731051206588745, Validation Loss: 0.05930195748806
Epoch 89, Training Loss: 0.05930195748806, Validation Loss: 0.051630452275276184
Epoch 90, Training Loss: 0.051630452275276184, Validation Loss: 0.04437866434454918
Epoch 91, Training Loss: 0.04437866434454918, Validation Loss: 0.037665992975234985
Epoch 92, Training Loss: 0.037665992975234985, Validation Loss: 0.03160688281059265
Epoch 93, Training Loss: 0.031606875360012054, Validation Loss: 0.02634212002158165
Epoch 94, Training Loss: 0.0263421218842268, Validation Loss: 0.02191043831408024
Epoch 95, Training Loss: 0.02191043458878994, Validation Loss: 0.01832299865782261
Epoch 96, Training Loss: 0.018323000520467758, Validation Loss: 0.015481222420930862
Epoch 97, Training Loss: 0.015481222420930862, Validation Loss: 0.013313883915543556
Epoch 98, Training Loss: 0.013313882052898407, Validation Loss: 0.011656676419079304
Epoch 99, Training Loss: 0.011656679213047028, Validation Loss: 0.010352510958909988
Epoch 100, Training Loss: 0.010352513752877712, Validation Loss: 0.009295216761529446
Epoch 101, Training Loss: 0.00929521955549717, Validation Loss: 0.008322760462760925
Epoch 102, Training Loss: 0.0083227613940835, Validation Loss: 0.007365628145635128
Epoch 103, Training Loss: 0.00736562954261899, Validation Loss: 0.006419842131435871
Epoch 104, Training Loss: 0.0064198412001132965, Validation Loss: 0.005523029249161482
Epoch 105, Training Loss: 0.0055230348370969296, Validation Loss: 0.004702512640506029
Epoch 106, Training Loss: 0.004702512174844742, Validation Loss: 0.004000496119260788
Epoch 107, Training Loss: 0.004000495653599501, Validation Loss: 0.0034336550161242485
Epoch 108, Training Loss: 0.0034336557146161795, Validation Loss: 0.0030068985652178526
Epoch 109, Training Loss: 0.0030068964697420597, Validation Loss: 0.002700327429920435
Epoch 110, Training Loss: 0.002700328826904297, Validation Loss: 0.0024845136795192957
Epoch 111, Training Loss: 0.0024845132138580084, Validation Loss: 0.002326127141714096
Epoch 112, Training Loss: 0.0023261266760528088, Validation Loss: 0.002192302141338587
Epoch 113, Training Loss: 0.0021923023741692305, Validation Loss: 0.002056193072348833
Epoch 114, Training Loss: 0.002056193072348833, Validation Loss: 0.0018989841919392347
Epoch 115, Training Loss: 0.0018989848904311657, Validation Loss: 0.0017177269328385592
Epoch 116, Training Loss: 0.001717729726806283, Validation Loss: 0.0015170248225331306
Epoch 117, Training Loss: 0.0015170242404565215, Validation Loss: 0.0013091547880321741
Epoch 118, Training Loss: 0.0013091563014313579, Validation Loss: 0.0011078481329604983
Epoch 119, Training Loss: 0.001107850344851613, Validation Loss: 0.0009258555946871638
Epoch 120, Training Loss: 0.0009258560603484511, Validation Loss: 0.0007732844678685069
Epoch 121, Training Loss: 0.0007732840604148805, Validation Loss: 0.0006555537111125886
Epoch 122, Training Loss: 0.0006555511499755085, Validation Loss: 0.0005705293733626604
Epoch 123, Training Loss: 0.0005705292569473386, Validation Loss: 0.0005129862693138421
Epoch 124, Training Loss: 0.0005129858618602157, Validation Loss: 0.00047514232574030757
Epoch 125, Training Loss: 0.0004751428496092558, Validation Loss: 0.0004481289070099592
Epoch 126, Training Loss: 0.000448129401775077, Validation Loss: 0.0004239182744640857
Epoch 127, Training Loss: 0.0004239179252181202, Validation Loss: 0.0003970505786128342
Epoch 128, Training Loss: 0.0003970501129515469, Validation Loss: 0.0003650337166618556
Epoch 129, Training Loss: 0.0003650335129350424, Validation Loss: 0.00032819207990542054
Epoch 130, Training Loss: 0.00032819199259392917, Validation Loss: 0.00028896782896481454
Epoch 131, Training Loss: 0.0002889684110414237, Validation Loss: 0.00025073898723348975
Epoch 132, Training Loss: 0.0002507387544028461, Validation Loss: 0.00021680280042346567
Epoch 133, Training Loss: 0.00021680237841792405, Validation Loss: 0.00018940767040476203
Epoch 134, Training Loss: 0.00018940669542644173, Validation Loss: 0.00016922890790738165
Epoch 135, Training Loss: 0.00016922922804951668, Validation Loss: 0.00015555332356598228
Epoch 136, Training Loss: 0.00015555352729279548, Validation Loss: 0.00014683858898933977
Epoch 137, Training Loss: 0.0001468389673391357, Validation Loss: 0.0001413542340742424
Epoch 138, Training Loss: 0.00014135421952232718, Validation Loss: 0.0001372924743918702
Epoch 139, Training Loss: 0.00013729280908592045, Validation Loss: 0.0001329824299318716
Epoch 140, Training Loss: 0.00013298245903570205, Validation Loss: 0.00012714946933556348
Epoch 141, Training Loss: 0.00012715041521005332, Validation Loss: 0.00012006056203972548
Epoch 142, Training Loss: 0.00012006032920908183, Validation Loss: 0.00011189595534233376
Epoch 143, Training Loss: 0.00011189609358552843, Validation Loss: 0.00010288380144629627
Epoch 144, Training Loss: 0.00010288391058566049, Validation Loss: 9.35043572098948e-05
Epoch 145, Training Loss: 9.350407344754785e-05, Validation Loss: 8.421683742199093e-05
Epoch 146, Training Loss: 8.42172303237021e-05, Validation Loss: 7.534807082265615e-05
Epoch 147, Training Loss: 7.534804899478331e-05, Validation Loss: 6.706108979415148e-05
Epoch 148, Training Loss: 6.706091517116874e-05, Validation Loss: 5.9383972256910056e-05
Epoch 149, Training Loss: 5.9384372434578836e-05, Validation Loss: 5.2265459089539945e-05
Epoch 150, Training Loss: 5.226552821113728e-05, Validation Loss: 4.563163747661747e-05
Epoch 151, Training Loss: 4.563164839055389e-05, Validation Loss: 3.9438284147763625e-05
Epoch 152, Training Loss: 3.9438335079466924e-05, Validation Loss: 3.369297701283358e-05
Epoch 153, Training Loss: 3.3692696888465434e-05, Validation Loss: 2.8452799597289413e-05
Epoch 154, Training Loss: 2.845273593266029e-05, Validation Loss: 2.3801805582479574e-05
Epoch 155, Training Loss: 2.3801856514182873e-05, Validation Loss: 1.981810237339232e-05
Epoch 156, Training Loss: 1.9818062355625443e-05, Validation Loss: 1.6544387108297087e-05
Epoch 157, Training Loss: 1.654409606999252e-05, Validation Loss: 1.39703633976751e-05
Epoch 158, Training Loss: 1.3970405234431382e-05, Validation Loss: 1.2031779988319613e-05
Epoch 159, Training Loss: 1.2031941878376529e-05, Validation Loss: 1.062165574694518e-05
Epoch 160, Training Loss: 1.062160936271539e-05, Validation Loss: 9.61201931204414e-06
Epoch 161, Training Loss: 9.611931091058068e-06, Validation Loss: 8.876261745172087e-06
Epoch 162, Training Loss: 8.87630449142307e-06, Validation Loss: 8.308308679261245e-06
Epoch 163, Training Loss: 8.308345059049316e-06, Validation Loss: 7.83118412073236e-06
Epoch 164, Training Loss: 7.83117957325885e-06, Validation Loss: 7.39806682759081e-06
Epoch 165, Training Loss: 7.398254638246726e-06, Validation Loss: 6.9855213951086625e-06
Epoch 166, Training Loss: 6.985507297940785e-06, Validation Loss: 6.583055892406264e-06
Epoch 167, Training Loss: 6.583102731383406e-06, Validation Loss: 6.184686753840651e-06
Epoch 168, Training Loss: 6.184763606142951e-06, Validation Loss: 5.782530479336856e-06
Epoch 169, Training Loss: 5.782599600934191e-06, Validation Loss: 5.366404366213828e-06
Epoch 170, Training Loss: 5.366349796531722e-06, Validation Loss: 4.9263312575931195e-06
Epoch 171, Training Loss: 4.926417659589788e-06, Validation Loss: 4.457713657757267e-06
Epoch 172, Training Loss: 4.4577332118933555e-06, Validation Loss: 3.965114501625067e-06
Epoch 173, Training Loss: 3.965098585467786e-06, Validation Loss: 3.4641436741367215e-06
Epoch 174, Training Loss: 3.4641261663637124e-06, Validation Loss: 2.9786344839521917e-06
Epoch 175, Training Loss: 2.9786847335344646e-06, Validation Loss: 2.5368851765961153e-06
Epoch 176, Training Loss: 2.5368597107444657e-06, Validation Loss: 2.163886847483809e-06
Epoch 177, Training Loss: 2.163887756978511e-06, Validation Loss: 1.8761955971058342e-06
Epoch 178, Training Loss: 1.8761946876111324e-06, Validation Loss: 1.6777726159489248e-06
Epoch 179, Training Loss: 1.6778112694737501e-06, Validation Loss: 1.5593964235449675e-06
Epoch 180, Training Loss: 1.5593791431456339e-06, Validation Loss: 1.5010963352324325e-06
Epoch 181, Training Loss: 1.5010903098300332e-06, Validation Loss: 1.477143314332352e-06
Epoch 182, Training Loss: 1.4771591168027953e-06, Validation Loss: 1.4619101875723572e-06
Epoch 183, Training Loss: 1.4618353816331364e-06, Validation Loss: 1.4347466503750184e-06
Epoch 184, Training Loss: 1.4346780972118722e-06, Validation Loss: 1.3832367358190822e-06
Epoch 185, Training Loss: 1.3832690228809952e-06, Validation Loss: 1.3046210369793698e-06
Epoch 186, Training Loss: 1.3046191043031286e-06, Validation Loss: 1.2036155112582492e-06
Epoch 187, Training Loss: 1.2036093721690122e-06, Validation Loss: 1.089584884539363e-06
Epoch 188, Training Loss: 1.0896004596361308e-06, Validation Loss: 9.731734280649107e-07
Epoch 189, Training Loss: 9.732008265928016e-07, Validation Loss: 8.630184993307921e-07
Epoch 190, Training Loss: 8.630867682768439e-07, Validation Loss: 7.638568604306784e-07
Epoch 191, Training Loss: 7.638324177605682e-07, Validation Loss: 6.760425321772345e-07
Epoch 192, Training Loss: 6.760308792763681e-07, Validation Loss: 5.970414349576458e-07
Epoch 193, Training Loss: 5.970561574031308e-07, Validation Loss: 5.226260100243962e-07
Epoch 194, Training Loss: 5.226123107604508e-07, Validation Loss: 4.493191454457701e-07
Epoch 195, Training Loss: 4.4932485820936563e-07, Validation Loss: 3.7561446220024663e-07
Epoch 196, Training Loss: 3.756007629363012e-07, Validation Loss: 3.0262799555202946e-07
Epoch 197, Training Loss: 3.0260414973781735e-07, Validation Loss: 2.3353759104338678e-07
Epoch 198, Training Loss: 2.3351805111815338e-07, Validation Loss: 1.727753158320411e-07
Epoch 199, Training Loss: 1.7276677510835725e-07, Validation Loss: 1.2441871888313472e-07
Epoch 200, Training Loss: 1.2442089314390614e-07, Validation Loss: 9.100531173089621e-08
Epoch 201, Training Loss: 9.099382936028633e-08, Validation Loss: 7.280266345333075e-08
Epoch 202, Training Loss: 7.279805913640303e-08, Validation Loss: 6.779752226293567e-08
Epoch 203, Training Loss: 6.780379635529243e-08, Validation Loss: 7.221194664452923e-08
Epoch 204, Training Loss: 7.220388908990572e-08, Validation Loss: 8.144079544081251e-08
Epoch 205, Training Loss: 8.143596375020934e-08, Validation Loss: 9.116189403357566e-08
Epoch 206, Training Loss: 9.1153793846388e-08, Validation Loss: 9.810511869545735e-08
Epoch 207, Training Loss: 9.811085277533493e-08, Validation Loss: 1.0060674782153001e-07
Epoch 208, Training Loss: 1.005904266548896e-07, Validation Loss: 9.845597048752097e-08
Epoch 209, Training Loss: 9.84610935006458e-08, Validation Loss: 9.27270136230618e-08
Epoch 210, Training Loss: 9.273312429058933e-08, Validation Loss: 8.501862680532213e-08
Epoch 211, Training Loss: 8.503368320589288e-08, Validation Loss: 7.696629467091043e-08
Epoch 212, Training Loss: 7.696227299902603e-08, Validation Loss: 6.9713564698759e-08
Epoch 213, Training Loss: 6.972229726898149e-08, Validation Loss: 6.377597117079858e-08
Epoch 214, Training Loss: 6.378492400926916e-08, Validation Loss: 5.903322986000603e-08
Epoch 215, Training Loss: 5.903077493485398e-08, Validation Loss: 5.493539845247142e-08
Epoch 216, Training Loss: 5.492745103197194e-08, Validation Loss: 5.081576048837633e-08
Epoch 217, Training Loss: 5.0812211327411205e-08, Validation Loss: 4.619523963356187e-08
Epoch 218, Training Loss: 4.6196468872494734e-08, Validation Loss: 4.088468230634135e-08
Epoch 219, Training Loss: 4.089107719096319e-08, Validation Loss: 3.509198265305713e-08
Epoch 220, Training Loss: 3.509763857323378e-08, Validation Loss: 2.9228349518461982e-08
Epoch 221, Training Loss: 2.9233843790166247e-08, Validation Loss: 2.3835120543935773e-08
Epoch 222, Training Loss: 2.3835077911371627e-08, Validation Loss: 1.9356084735022705e-08
Epoch 223, Training Loss: 1.935458726620709e-08, Validation Loss: 1.6035450300933007e-08
Epoch 224, Training Loss: 1.603043919828906e-08, Validation Loss: 1.3850728564079873e-08
Epoch 225, Training Loss: 1.3852863745000832e-08, Validation Loss: 1.2600939847118298e-08
Epoch 226, Training Loss: 1.2602097143599167e-08, Validation Loss: 1.1932459464958356e-08
Epoch 227, Training Loss: 1.1932577592688176e-08, Validation Loss: 1.1470415728354055e-08
Epoch 228, Training Loss: 1.1469459160196038e-08, Validation Loss: 1.0950299333956082e-08
Epoch 229, Training Loss: 1.0950722995062279e-08, Validation Loss: 1.0220134072369547e-08
Epoch 230, Training Loss: 1.0219638468811354e-08, Validation Loss: 9.271690970535928e-09
Epoch 231, Training Loss: 9.272637768731329e-09, Validation Loss: 8.204101398234798e-09
Epoch 232, Training Loss: 8.207512891544866e-09, Validation Loss: 7.160164017250281e-09
Epoch 233, Training Loss: 7.158210468816151e-09, Validation Loss: 6.265211904832313e-09
Epoch 234, Training Loss: 6.264466279048975e-09, Validation Loss: 5.583107309803381e-09
Epoch 235, Training Loss: 5.58100854419763e-09, Validation Loss: 5.120438295591612e-09
Epoch 236, Training Loss: 5.119956902888134e-09, Validation Loss: 4.814701526356657e-09
Epoch 237, Training Loss: 4.8185131440448e-09, Validation Loss: 4.586378832271976e-09
Epoch 238, Training Loss: 4.584664647921954e-09, Validation Loss: 4.329968383842697e-09
Epoch 239, Training Loss: 4.335998671223251e-09, Validation Loss: 4.008184895099021e-09
Epoch 240, Training Loss: 4.006857956539989e-09, Validation Loss: 3.5885290294856986e-09
Epoch 241, Training Loss: 3.5903477968446396e-09, Validation Loss: 3.103400647574972e-09
Epoch 242, Training Loss: 3.103990398045653e-09, Validation Loss: 2.590814895953031e-09
Epoch 243, Training Loss: 2.593761649904991e-09, Validation Loss: 2.1137598338327734e-09
Epoch 244, Training Loss: 2.1151078666292733e-09, Validation Loss: 1.7106066563243871e-09
Epoch 245, Training Loss: 1.711288111216902e-09, Validation Loss: 1.409131145102549e-09
Epoch 246, Training Loss: 1.4088160638081604e-09, Validation Loss: 1.2061974752342053e-09
Epoch 247, Training Loss: 1.2052928655137407e-09, Validation Loss: 1.083792056100208e-09
Epoch 248, Training Loss: 1.083913292454497e-09, Validation Loss: 1.0187826138263745e-09
Epoch 249, Training Loss: 1.0189372678937048e-09, Validation Loss: 9.834690839483073e-10
Epoch 250, Training Loss: 9.832182845670445e-10, Validation Loss: 9.54886947290845e-10
Epoch 251, Training Loss: 9.551642810023964e-10, Validation Loss: 9.245691989789862e-10
Epoch 252, Training Loss: 9.251662769216296e-10, Validation Loss: 8.886397728780082e-10
Epoch 253, Training Loss: 8.884289970367831e-10, Validation Loss: 8.515841920520018e-10
Epoch 254, Training Loss: 8.505316451135059e-10, Validation Loss: 8.150409791518598e-10
Epoch 255, Training Loss: 8.163983378217665e-10, Validation Loss: 7.82396536447294e-10
Epoch 256, Training Loss: 7.819509484363607e-10, Validation Loss: 7.496241960502914e-10
Epoch 257, Training Loss: 7.500911558544487e-10, Validation Loss: 7.170047888749309e-10
Epoch 258, Training Loss: 7.169185245459175e-10, Validation Loss: 6.766782134626226e-10
Epoch 259, Training Loss: 6.764232507450174e-10, Validation Loss: 6.248709882861192e-10
Epoch 260, Training Loss: 6.247930506297905e-10, Validation Loss: 5.630520494293023e-10
Epoch 261, Training Loss: 5.636129896124942e-10, Validation Loss: 4.939292308492327e-10
Epoch 262, Training Loss: 4.933456976274897e-10, Validation Loss: 4.1969921982243363e-10
Epoch 263, Training Loss: 4.1957706753414925e-10, Validation Loss: 3.461590181164098e-10
Epoch 264, Training Loss: 3.4593888864620226e-10, Validation Loss: 2.7847960049065534e-10
Epoch 265, Training Loss: 2.7879840103217646e-10, Validation Loss: 2.2004666144770368e-10
Epoch 266, Training Loss: 2.2076099281953532e-10, Validation Loss: 1.7369919391718724e-10
Epoch 267, Training Loss: 1.7368718963073349e-10, Validation Loss: 1.3788654940061207e-10
Epoch 268, Training Loss: 1.3815205923695117e-10, Validation Loss: 1.135145172304064e-10
Epoch 269, Training Loss: 1.1339893607464901e-10, Validation Loss: 9.718338633835089e-11
Epoch 270, Training Loss: 9.701311975973681e-11, Validation Loss: 8.65618687839742e-11
Epoch 271, Training Loss: 8.672287193922656e-11, Validation Loss: 8.126042894129881e-11
Epoch 272, Training Loss: 8.179253108142603e-11, Validation Loss: 7.920382405490756e-11
Epoch 273, Training Loss: 7.908321913996375e-11, Validation Loss: 7.900095161383902e-11
Epoch 274, Training Loss: 7.889547348760573e-11, Validation Loss: 7.937164814286746e-11
Epoch 275, Training Loss: 7.892311110202499e-11, Validation Loss: 7.842045068873205e-11
Epoch 276, Training Loss: 7.890196829229978e-11, Validation Loss: 7.670702267814633e-11
Epoch 277, Training Loss: 7.677310176479324e-11, Validation Loss: 7.241359595289154e-11
Epoch 278, Training Loss: 7.271744317804973e-11, Validation Loss: 6.696639076597677e-11
Epoch 279, Training Loss: 6.704686111858038e-11, Validation Loss: 5.977388722877564e-11
Epoch 280, Training Loss: 5.97413160607907e-11, Validation Loss: 5.190685381517568e-11
Epoch 281, Training Loss: 5.183615342518877e-11, Validation Loss: 4.462401628768653e-11
Epoch 282, Training Loss: 4.4479839950151145e-11, Validation Loss: 3.8140185454338393e-11
Epoch 283, Training Loss: 3.7923577472787073e-11, Validation Loss: 3.362705947029809e-11
Epoch 284, Training Loss: 3.356809968879659e-11, Validation Loss: 3.0387033167489363e-11
Epoch 285, Training Loss: 3.0565709685514975e-11, Validation Loss: 2.8523058914764476e-11
Epoch 286, Training Loss: 2.885300158517179e-11, Validation Loss: 2.760516468192087e-11
Epoch 287, Training Loss: 2.775060563287024e-11, Validation Loss: 2.6722313598015468e-11
Epoch 288, Training Loss: 2.6678924694434336e-11, Validation Loss: 2.5390677407810536e-11
Epoch 289, Training Loss: 2.5681139506628092e-11, Validation Loss: 2.3708946264577868e-11
Epoch 290, Training Loss: 2.3736965518161846e-11, Validation Loss: 2.1513129819239474e-11
Epoch 291, Training Loss: 2.1423064711090234e-11, Validation Loss: 1.8686481181862113e-11
Epoch 292, Training Loss: 1.8679663718601525e-11, Validation Loss: 1.5824376531359263e-11
Epoch 293, Training Loss: 1.5865626520894516e-11, Validation Loss: 1.3353461565668301e-11
Epoch 294, Training Loss: 1.3369020300524337e-11, Validation Loss: 1.1442548297768695e-11
Epoch 295, Training Loss: 1.1463698913749543e-11, Validation Loss: 9.946639865920925e-12
Epoch 296, Training Loss: 1.011278907836477e-11, Validation Loss: 8.893989711378225e-12
Epoch 297, Training Loss: 8.900783755871888e-12, Validation Loss: 7.999390212731772e-12
Epoch 298, Training Loss: 7.930942361178417e-12, Validation Loss: 7.127280970270489e-12
Epoch 299, Training Loss: 7.2521264167513255e-12, Validation Loss: 6.507141180056575e-12
Epoch 300, Training Loss: 6.467994109055075e-12, Validation Loss: 5.80233517483153e-12
Epoch 301, Training Loss: 5.827536370128783e-12, Validation Loss: 5.110181375278522e-12
Epoch 302, Training Loss: 5.159693852729852e-12, Validation Loss: 4.324008165412785e-12
Epoch 303, Training Loss: 4.369628790745761e-12, Validation Loss: 3.752441933568829e-12
Epoch 304, Training Loss: 3.716305041479018e-12, Validation Loss: 3.2303942507083683e-12
Epoch 305, Training Loss: 3.2570276770754747e-12, Validation Loss: 2.8774326671365813e-12
Epoch 306, Training Loss: 2.8925596726875336e-12, Validation Loss: 2.5828512505848833e-12
Epoch 307, Training Loss: 2.601944050842353e-12, Validation Loss: 2.3913046022505657e-12
Epoch 308, Training Loss: 2.4088114315701237e-12, Validation Loss: 2.2135802305728314e-12
Epoch 309, Training Loss: 2.2212650555714086e-12, Validation Loss: 2.0155700025670242e-12
Epoch 310, Training Loss: 2.0773463244722068e-12, Validation Loss: 1.8606674360988062e-12
Epoch 311, Training Loss: 1.950970201364255e-12, Validation Loss: 1.7454184798870731e-12
Epoch 312, Training Loss: 1.765413444772268e-12, Validation Loss: 1.6339732301570709e-12
Epoch 313, Training Loss: 1.6275310092683792e-12, Validation Loss: 1.5225808894930859e-12
Epoch 314, Training Loss: 1.5257409051450121e-12, Validation Loss: 1.4124463317694014e-12
Epoch 315, Training Loss: 1.40771151246194e-12, Validation Loss: 1.2612277758630719e-12
Epoch 316, Training Loss: 1.2604687259221148e-12, Validation Loss: 1.1315231520855895e-12
Epoch 317, Training Loss: 1.1505873294057056e-12, Validation Loss: 1.0215737760929655e-12
Epoch 318, Training Loss: 1.0177634559779825e-12, Validation Loss: 9.493023771581233e-13
Epoch 319, Training Loss: 9.47690493788289e-13, Validation Loss: 8.55091117270973e-13
Epoch 320, Training Loss: 7.937000666077831e-13, Validation Loss: 7.425346687343903e-13
Epoch 321, Training Loss: 7.798863551483626e-13, Validation Loss: 6.78706494217779e-13
Epoch 322, Training Loss: 6.627920326289505e-13, Validation Loss: 5.913469041697594e-13
Epoch 323, Training Loss: 6.072439101036109e-13, Validation Loss: 5.542637746339119e-13
Epoch 324, Training Loss: 5.355876332713283e-13, Validation Loss: 4.92506101006096e-13
Epoch 325, Training Loss: 4.765221420580112e-13, Validation Loss: 4.2776562457144673e-13
Epoch 326, Training Loss: 4.265786671380639e-13, Validation Loss: 3.5710001036921846e-13
Epoch 327, Training Loss: 3.6236400165201577e-13, Validation Loss: 3.471636769291492e-13
Epoch 328, Training Loss: 3.309207291871119e-13, Validation Loss: 2.9902680808921445e-13
Epoch 329, Training Loss: 3.1282008233768366e-13, Validation Loss: 2.663444280664312e-13
Epoch 330, Training Loss: 2.522574976595443e-13, Validation Loss: 2.3048533567826546e-13
Epoch 331, Training Loss: 2.163095142457619e-13, Validation Loss: 2.2319483500982118e-13
Epoch 332, Training Loss: 1.8566822612784556e-13, Validation Loss: 2.0017218134785186e-13
Epoch 333, Training Loss: 1.8561819019758535e-13, Validation Loss: 1.8430893475914617e-13
Epoch 334, Training Loss: 1.6257408288512798e-13, Validation Loss: 1.6765245875599577e-13
Epoch 335, Training Loss: 1.4863801921054243e-13, Validation Loss: 1.3060432184526516e-13
Epoch 336, Training Loss: 1.4155694574424088e-13, Validation Loss: 1.3677988320963397e-13
Epoch 337, Training Loss: 1.3468946010591898e-13, Validation Loss: 1.2188626572883637e-13
Epoch 338, Training Loss: 1.294183672988919e-13, Validation Loss: 1.0885735401196944e-13
Epoch 339, Training Loss: 1.1330081431436614e-13, Validation Loss: 9.704308754146518e-14
Epoch 340, Training Loss: 1.052291324281189e-13, Validation Loss: 8.0624390627268e-14
Epoch 341, Training Loss: 9.18295252122156e-14, Validation Loss: 7.911569619920011e-14
Epoch 342, Training Loss: 8.90401508492171e-14, Validation Loss: 8.068448253267801e-14
Epoch 343, Training Loss: 7.683764513327293e-14, Validation Loss: 7.026177599803174e-14
Epoch 344, Training Loss: 6.60461811109736e-14, Validation Loss: 6.228408766387541e-14
Epoch 345, Training Loss: 6.210026796179408e-14, Validation Loss: 5.3606628142542634e-14
Epoch 346, Training Loss: 5.6627642299692665e-14, Validation Loss: 5.363731784028755e-14
Epoch 347, Training Loss: 4.632735235471537e-14, Validation Loss: 4.753205004614548e-14
Epoch 348, Training Loss: 3.926307385769198e-14, Validation Loss: 3.960940191290174e-14
Epoch 349, Training Loss: 3.641312308643764e-14, Validation Loss: 3.8622361195729885e-14
Epoch 350, Training Loss: 3.193890871179203e-14, Validation Loss: 3.490901957694387e-14
Epoch 351, Training Loss: 2.7618979694422896e-14, Validation Loss: 2.9017498852975526e-14
Epoch 352, Training Loss: 2.6117676475852745e-14, Validation Loss: 2.6374966121713028e-14
Epoch 353, Training Loss: 2.0554684256740563e-14, Validation Loss: 2.307965897931953e-14
Epoch 354, Training Loss: 2.0734495798915495e-14, Validation Loss: 1.799681924481971e-14
Epoch 355, Training Loss: 1.7341208967381304e-14, Validation Loss: 2.3405953011260833e-14
Epoch 356, Training Loss: 1.3909209342025802e-14, Validation Loss: 1.6086654916675804e-14
Epoch 357, Training Loss: 1.1758419047192947e-14, Validation Loss: 1.578861620978901e-14
Epoch 358, Training Loss: 9.579406461590525e-15, Validation Loss: 1.742549382783079e-14
Epoch 359, Training Loss: 8.48591233767364e-15, Validation Loss: 1.1996659769102427e-14
Epoch 360, Training Loss: 7.575583159369868e-15, Validation Loss: 1.2902486120258596e-14
Epoch 361, Training Loss: 8.101354297422505e-15, Validation Loss: 8.535685687720198e-15
Epoch 362, Training Loss: 9.231109901811346e-15, Validation Loss: 1.1759936930234426e-14
Epoch 363, Training Loss: 7.644171652273785e-15, Validation Loss: 1.0244989704949903e-14
Epoch 364, Training Loss: 5.310067334029101e-15, Validation Loss: 9.548314423195661e-15
Epoch 365, Training Loss: 4.882724812579203e-15, Validation Loss: 8.889036493095644e-15
Epoch 366, Training Loss: 5.474833029961955e-15, Validation Loss: 1.0961513509757156e-14
Epoch 367, Training Loss: 4.485706917673957e-15, Validation Loss: 9.627761878483378e-15
Epoch 368, Training Loss: 3.4979485518375373e-15, Validation Loss: 9.36401699453207e-15
Epoch 369, Training Loss: 3.895900935841842e-15, Validation Loss: 1.1247426092971056e-14
Epoch 370, Training Loss: 3.409677766096509e-15, Validation Loss: 9.255612870909518e-15
Epoch 371, Training Loss: 5.046623146774069e-15, Validation Loss: 9.015120735426235e-15
Epoch 372, Training Loss: 2.598978085356445e-15, Validation Loss: 9.380113161628744e-15
Epoch 373, Training Loss: 2.8606210570491413e-15, Validation Loss: 8.873374006867964e-15
Epoch 374, Training Loss: 2.7352540398666372e-15, Validation Loss: 8.705939310118312e-15
Epoch 375, Training Loss: 3.0166794660424576e-15, Validation Loss: 9.301533068079015e-15
Epoch 376, Training Loss: 2.2940671884103415e-15, Validation Loss: 6.8849129176951854e-15
Epoch 377, Training Loss: 2.9193348398539676e-15, Validation Loss: 7.187772512601276e-15
Epoch 378, Training Loss: 2.626466845593689e-15, Validation Loss: 6.928764660407488e-15
Epoch 379, Training Loss: 1.480348364608908e-15, Validation Loss: 5.624119198783736e-15
Epoch 380, Training Loss: 1.8471423240111083e-15, Validation Loss: 5.904277040153991e-15
Epoch 381, Training Loss: 2.009605784393325e-15, Validation Loss: 4.922990641309305e-15
Epoch 382, Training Loss: 1.5755579383747251e-15, Validation Loss: 4.899838689762003e-15
Epoch 383, Training Loss: 1.695103721627224e-15, Validation Loss: 4.328847850787248e-15
Epoch 384, Training Loss: 1.6380914162551947e-15, Validation Loss: 3.869179587454811e-15
Epoch 385, Training Loss: 1.1155059691171816e-15, Validation Loss: 4.866144989669648e-15
Epoch 386, Training Loss: 1.0595611370169296e-15, Validation Loss: 5.4384703290528014e-15
Epoch 387, Training Loss: 1.1844612272872597e-15, Validation Loss: 5.457152064220969e-15
Epoch 388, Training Loss: 9.624499742845265e-16, Validation Loss: 5.4041095905144835e-15
Epoch 389, Training Loss: 9.971444438040627e-16, Validation Loss: 5.377421276412395e-15
Epoch 390, Training Loss: 9.649185459301808e-16, Validation Loss: 5.997768725223658e-15
Epoch 391, Training Loss: 1.1650789958717132e-15, Validation Loss: 6.125871447067556e-15
Epoch 392, Training Loss: 1.2229587688608492e-15, Validation Loss: 6.125871447067556e-15
Epoch 393, Training Loss: 1.2229587688608492e-15, Validation Loss: 6.083970844749254e-15
Epoch 394, Training Loss: 8.810513786028091e-16, Validation Loss: 4.903074779136988e-15
Epoch 395, Training Loss: 8.370827982833449e-16, Validation Loss: 4.926510063205146e-15
Epoch 396, Training Loss: 1.654838210534478e-15, Validation Loss: 5.277291394135096e-15
Epoch 397, Training Loss: 9.692888124215393e-16, Validation Loss: 4.3316168014918225e-15
Epoch 398, Training Loss: 1.3912936498751958e-15, Validation Loss: 4.3661444055207495e-15
Epoch 399, Training Loss: 1.830045175729017e-15, Validation Loss: 4.3661444055207495e-15
Epoch 400, Training Loss: 1.830045175729017e-15, Validation Loss: 4.362141327812026e-15
Epoch 401, Training Loss: 1.4056718223966007e-15, Validation Loss: 3.913281204886553e-15
Epoch 402, Training Loss: 1.3608359332787073e-15, Validation Loss: 3.944673092944745e-15
Epoch 403, Training Loss: 1.4366299237066798e-15, Validation Loss: 4.735073417345623e-15
Epoch 404, Training Loss: 1.4446363967614826e-15, Validation Loss: 4.895685263705141e-15
Epoch 405, Training Loss: 9.274218796628906e-16, Validation Loss: 4.826896871025672e-15
Epoch 406, Training Loss: 8.755803398569344e-16, Validation Loss: 5.460237805247816e-15
Epoch 407, Training Loss: 1.0206966184189421e-15, Validation Loss: 6.294856637627157e-15
Epoch 408, Training Loss: 1.7009084384147577e-15, Validation Loss: 5.466459262245399e-15
Epoch 409, Training Loss: 7.006401371012212e-16, Validation Loss: 5.466459262245399e-15
Epoch 410, Training Loss: 6.728512095632942e-16, Validation Loss: 5.394401745906002e-15
Epoch 411, Training Loss: 1.2061119188146716e-15, Validation Loss: 5.38649554037633e-15
Epoch 412, Training Loss: 1.1518684582680983e-15, Validation Loss: 5.497918065906424e-15
Epoch 413, Training Loss: 5.245323523672771e-16, Validation Loss: 3.984004644334025e-15
Epoch 414, Training Loss: 4.076386557424111e-16, Validation Loss: 4.382624278542529e-15
Epoch 415, Training Loss: 5.512204017715696e-16, Validation Loss: 4.400004971103714e-15
Epoch 416, Training Loss: 5.834461937663331e-16, Validation Loss: 4.400004971103714e-15
Epoch 417, Training Loss: 1.448272603324927e-15, Validation Loss: 4.400004971103714e-15
Epoch 418, Training Loss: 1.448272603324927e-15, Validation Loss: 4.277239827376938e-15
Epoch 419, Training Loss: 1.448272603324927e-15, Validation Loss: 4.3252784539475186e-15
Epoch 420, Training Loss: 1.448272603324927e-15, Validation Loss: 4.3336183403461844e-15
Epoch 421, Training Loss: 1.0209301877541475e-15, Validation Loss: 4.3336183403461844e-15
Epoch 422, Training Loss: 9.18447989103205e-16, Validation Loss: 4.3336183403461844e-15
Epoch 423, Training Loss: 8.944287816970331e-16, Validation Loss: 4.306930026244096e-15
Epoch 424, Training Loss: 7.983517932536684e-16, Validation Loss: 4.306930026244096e-15
Epoch 425, Training Loss: 3.980309727799424e-16, Validation Loss: 4.229201200806358e-15
Epoch 426, Training Loss: 3.714096272202462e-16, Validation Loss: 4.1771594965270536e-15
Epoch 427, Training Loss: 8.039562926282948e-16, Validation Loss: 4.1771594965270536e-15
Epoch 428, Training Loss: 8.039562926282948e-16, Validation Loss: 4.1771594965270536e-15
Epoch 429, Training Loss: 8.840204408411723e-16, Validation Loss: 4.1771594965270536e-15
Epoch 430, Training Loss: 1.0379437974118158e-15, Validation Loss: 4.170570850746836e-15
Epoch 431, Training Loss: 1.4901395360835757e-15, Validation Loss: 4.1745743519720335e-15
Epoch 432, Training Loss: 1.4794642739702113e-15, Validation Loss: 4.1745743519720335e-15
Epoch 433, Training Loss: 1.4794642739702113e-15, Validation Loss: 3.793468818013906e-15
Epoch 434, Training Loss: 1.5301715837202348e-15, Validation Loss: 4.1745743519720335e-15
Epoch 435, Training Loss: 1.8103961289350854e-15, Validation Loss: 4.087170716210757e-15
Epoch 436, Training Loss: 1.9651869531228357e-15, Validation Loss: 4.149220538278344e-15
Epoch 437, Training Loss: 1.0794771050683647e-15, Validation Loss: 4.2488002726564014e-15
Epoch 438, Training Loss: 4.1891435833626034e-16, Validation Loss: 4.336236942702621e-15
Epoch 439, Training Loss: 8.196021558343842e-16, Validation Loss: 4.336236942702621e-15
Epoch 440, Training Loss: 8.196021558343842e-16, Validation Loss: 4.0672213962370234e-15
Epoch 441, Training Loss: 1.2207903645158782e-15, Validation Loss: 4.294503629391402e-15
Epoch 442, Training Loss: 1.2816724457865572e-15, Validation Loss: 4.294503629391402e-15
Epoch 443, Training Loss: 2.5467195406426437e-15, Validation Loss: 4.294503629391402e-15
Epoch 444, Training Loss: 2.5853505957845442e-15, Validation Loss: 4.139713016961888e-15
Epoch 445, Training Loss: 2.3594695668831614e-15, Validation Loss: 3.742377908217895e-15
Epoch 446, Training Loss: 2.0897945258587875e-16, Validation Loss: 3.742377908217895e-15
Epoch 447, Training Loss: 1.0985590633041096e-15, Validation Loss: 3.727140632529737e-15
Epoch 448, Training Loss: 1.1117696009077245e-15, Validation Loss: 5.316664450138791e-15
Epoch 449, Training Loss: 1.1117696009077245e-15, Validation Loss: 5.316664450138791e-15
Epoch 450, Training Loss: 3.0914894159439574e-15, Validation Loss: 5.316664450138791e-15
Epoch 451, Training Loss: 1.1706167914017434e-15, Validation Loss: 4.5469224122884986e-15
Epoch 452, Training Loss: 1.0293035319542299e-15, Validation Loss: 4.897803693106224e-15
Epoch 453, Training Loss: 1.01989596052555e-15, Validation Loss: 3.931129036118149e-15
Epoch 454, Training Loss: 1.5434822829698625e-15, Validation Loss: 3.75984161000791e-15
Epoch 455, Training Loss: 4.012861362781084e-15, Validation Loss: 3.929527720331364e-15
Epoch 456, Training Loss: 1.5612965505209229e-15, Validation Loss: 4.783829057306054e-15
Epoch 457, Training Loss: 1.4254543827588433e-15, Validation Loss: 4.553727898503213e-15
Epoch 458, Training Loss: 1.545750743081728e-15, Validation Loss: 4.540917795725413e-15
Epoch 459, Training Loss: 1.6232795628647956e-15, Validation Loss: 4.540917795725413e-15
Epoch 460, Training Loss: 1.6550383220682668e-15, Validation Loss: 4.1822302592657914e-15
Epoch 461, Training Loss: 3.583416929072575e-15, Validation Loss: 4.119546856553658e-15
Epoch 462, Training Loss: 3.605834926571081e-15, Validation Loss: 4.207617107244424e-15
Epoch 463, Training Loss: 1.3035900585714726e-15, Validation Loss: 4.187935026165549e-15
Epoch 464, Training Loss: 1.3406196920474705e-15, Validation Loss: 4.2251646652962174e-15
Epoch 465, Training Loss: 6.6434440473446e-16, Validation Loss: 4.295487881676111e-15
Epoch 466, Training Loss: 1.3532297891706005e-15, Validation Loss: 4.220527583426474e-15
Epoch 467, Training Loss: 1.3563989629427524e-15, Validation Loss: 4.258958315276349e-15
Epoch 468, Training Loss: 6.843937804750877e-16, Validation Loss: 4.258958315276349e-15
Epoch 469, Training Loss: 6.843937804750877e-16, Validation Loss: 4.2082511114054436e-15
Epoch 470, Training Loss: 6.924002005903314e-16, Validation Loss: 4.2082511114054436e-15
Epoch 471, Training Loss: 6.883302602183337e-16, Validation Loss: 4.2082511114054436e-15
Epoch 472, Training Loss: 6.883302602183337e-16, Validation Loss: 4.2082511114054436e-15
Epoch 473, Training Loss: 6.935010787239659e-16, Validation Loss: 4.2315199534994664e-15
Epoch 474, Training Loss: 6.935010787239659e-16, Validation Loss: 4.2315199534994664e-15
Epoch 475, Training Loss: 1.3556984666953731e-15, Validation Loss: 4.188184900884989e-15
Epoch 476, Training Loss: 1.3556984666953731e-15, Validation Loss: 4.188184900884989e-15
Epoch 477, Training Loss: 1.368508675352292e-15, Validation Loss: 4.1393958031231415e-15
Epoch 478, Training Loss: 1.368508675352292e-15, Validation Loss: 4.1393958031231415e-15
Epoch 479, Training Loss: 7.581028522429529e-16, Validation Loss: 4.5693404097870045e-15
Epoch 480, Training Loss: 1.1136377320728938e-15, Validation Loss: 4.5693404097870045e-15
Epoch 481, Training Loss: 5.599273710737518e-16, Validation Loss: 4.5693404097870045e-15
Epoch 482, Training Loss: 5.508534247471717e-16, Validation Loss: 4.516748557608459e-15
Epoch 483, Training Loss: 5.508534247471717e-16, Validation Loss: 4.616028018806714e-15
Epoch 484, Training Loss: 9.068053094849577e-16, Validation Loss: 4.22851722170145e-15
Epoch 485, Training Loss: 9.25487044653125e-16, Validation Loss: 4.22851722170145e-15
Epoch 486, Training Loss: 5.491854051157912e-16, Validation Loss: 4.22851722170145e-15
Epoch 487, Training Loss: 5.381766237794454e-16, Validation Loss: 4.237190839081334e-15
Epoch 488, Training Loss: 2.2018843810024192e-16, Validation Loss: 4.1610298716289636e-15
Epoch 489, Training Loss: 3.1709943635929694e-16, Validation Loss: 4.1610298716289636e-15
Epoch 490, Training Loss: 2.897441896903641e-16, Validation Loss: 4.1610298716289636e-15
Epoch 491, Training Loss: 2.897441896903641e-16, Validation Loss: 3.4487924770512917e-15
Epoch 492, Training Loss: 2.897441896903641e-16, Validation Loss: 4.211654066271038e-15
Epoch 493, Training Loss: 2.897441896903641e-16, Validation Loss: 4.16194720831084e-15
Epoch 494, Training Loss: 2.897441896903641e-16, Validation Loss: 3.4304444728643427e-15
Epoch 495, Training Loss: 4.86902172531676e-16, Validation Loss: 3.4304444728643427e-15
Epoch 496, Training Loss: 4.767606999937595e-16, Validation Loss: 4.723480500913027e-15
Epoch 497, Training Loss: 7.338000476181286e-16, Validation Loss: 5.403608994042656e-15
Epoch 498, Training Loss: 7.338000476181286e-16, Validation Loss: 6.027442406948344e-15
Epoch 499, Training Loss: 7.081795244251725e-16, Validation Loss: 6.027442406948344e-15
Epoch 500, Training Loss: 4.67403209388086e-16, Validation Loss: 6.189055022735044e-15
