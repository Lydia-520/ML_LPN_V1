Epoch 1, Training Loss: 0.44366148114204407, Validation Loss: 0.4422263503074646
Epoch 2, Training Loss: 0.4422263503074646, Validation Loss: 0.44083371758461
Epoch 3, Training Loss: 0.44083371758461, Validation Loss: 0.4394744038581848
Epoch 4, Training Loss: 0.4394744038581848, Validation Loss: 0.43811696767807007
Epoch 5, Training Loss: 0.43811696767807007, Validation Loss: 0.43677881360054016
Epoch 6, Training Loss: 0.43677881360054016, Validation Loss: 0.4354751408100128
Epoch 7, Training Loss: 0.43547511100769043, Validation Loss: 0.4341912865638733
Epoch 8, Training Loss: 0.4341912865638733, Validation Loss: 0.43293297290802
Epoch 9, Training Loss: 0.43293297290802, Validation Loss: 0.43167388439178467
Epoch 10, Training Loss: 0.43167388439178467, Validation Loss: 0.4303983747959137
Epoch 11, Training Loss: 0.4303983747959137, Validation Loss: 0.4290876090526581
Epoch 12, Training Loss: 0.4290875792503357, Validation Loss: 0.42775413393974304
Epoch 13, Training Loss: 0.42775413393974304, Validation Loss: 0.42638662457466125
Epoch 14, Training Loss: 0.42638662457466125, Validation Loss: 0.424993634223938
Epoch 15, Training Loss: 0.424993634223938, Validation Loss: 0.4235759377479553
Epoch 16, Training Loss: 0.4235759675502777, Validation Loss: 0.4221333861351013
Epoch 17, Training Loss: 0.4221333861351013, Validation Loss: 0.42064622044563293
Epoch 18, Training Loss: 0.42064622044563293, Validation Loss: 0.41909757256507874
Epoch 19, Training Loss: 0.41909757256507874, Validation Loss: 0.417503297328949
Epoch 20, Training Loss: 0.417503297328949, Validation Loss: 0.41588205099105835
Epoch 21, Training Loss: 0.41588205099105835, Validation Loss: 0.41427066922187805
Epoch 22, Training Loss: 0.41427063941955566, Validation Loss: 0.41267257928848267
Epoch 23, Training Loss: 0.41267257928848267, Validation Loss: 0.4110155999660492
Epoch 24, Training Loss: 0.4110155999660492, Validation Loss: 0.40928685665130615
Epoch 25, Training Loss: 0.4092867970466614, Validation Loss: 0.40746980905532837
Epoch 26, Training Loss: 0.407469779253006, Validation Loss: 0.4055739641189575
Epoch 27, Training Loss: 0.4055739641189575, Validation Loss: 0.4036059081554413
Epoch 28, Training Loss: 0.4036058783531189, Validation Loss: 0.40152209997177124
Epoch 29, Training Loss: 0.40152207016944885, Validation Loss: 0.39932048320770264
Epoch 30, Training Loss: 0.39932048320770264, Validation Loss: 0.39698314666748047
Epoch 31, Training Loss: 0.39698314666748047, Validation Loss: 0.3944930136203766
Epoch 32, Training Loss: 0.394493043422699, Validation Loss: 0.3918430507183075
Epoch 33, Training Loss: 0.3918430507183075, Validation Loss: 0.3890271782875061
Epoch 34, Training Loss: 0.3890271782875061, Validation Loss: 0.38604408502578735
Epoch 35, Training Loss: 0.38604414463043213, Validation Loss: 0.38292863965034485
Epoch 36, Training Loss: 0.38292860984802246, Validation Loss: 0.3796394169330597
Epoch 37, Training Loss: 0.3796394169330597, Validation Loss: 0.3761400282382965
Epoch 38, Training Loss: 0.3761400282382965, Validation Loss: 0.37242835760116577
Epoch 39, Training Loss: 0.37242835760116577, Validation Loss: 0.3684682548046112
Epoch 40, Training Loss: 0.3684682548046112, Validation Loss: 0.3642190098762512
Epoch 41, Training Loss: 0.3642190098762512, Validation Loss: 0.3596957325935364
Epoch 42, Training Loss: 0.3596957325935364, Validation Loss: 0.3548705577850342
Epoch 43, Training Loss: 0.3548705577850342, Validation Loss: 0.34973055124282837
Epoch 44, Training Loss: 0.3497304916381836, Validation Loss: 0.3442825973033905
Epoch 45, Training Loss: 0.34428268671035767, Validation Loss: 0.338503897190094
Epoch 46, Training Loss: 0.3385039269924164, Validation Loss: 0.332371324300766
Epoch 47, Training Loss: 0.332371324300766, Validation Loss: 0.3258777856826782
Epoch 48, Training Loss: 0.3258777856826782, Validation Loss: 0.319000244140625
Epoch 49, Training Loss: 0.319000244140625, Validation Loss: 0.3117462396621704
Epoch 50, Training Loss: 0.311746209859848, Validation Loss: 0.3041210174560547
Epoch 51, Training Loss: 0.3041210174560547, Validation Loss: 0.2961266040802002
Epoch 52, Training Loss: 0.2961266040802002, Validation Loss: 0.28779229521751404
Epoch 53, Training Loss: 0.28779229521751404, Validation Loss: 0.2791418135166168
Epoch 54, Training Loss: 0.27914178371429443, Validation Loss: 0.27020713686943054
Epoch 55, Training Loss: 0.27020716667175293, Validation Loss: 0.26100772619247437
Epoch 56, Training Loss: 0.26100772619247437, Validation Loss: 0.2517077326774597
Epoch 57, Training Loss: 0.2517077326774597, Validation Loss: 0.24235263466835022
Epoch 58, Training Loss: 0.2423526644706726, Validation Loss: 0.23296567797660828
Epoch 59, Training Loss: 0.23296569287776947, Validation Loss: 0.2236795872449875
Epoch 60, Training Loss: 0.2236795872449875, Validation Loss: 0.2145172655582428
Epoch 61, Training Loss: 0.2145172357559204, Validation Loss: 0.205632746219635
Epoch 62, Training Loss: 0.2056327611207962, Validation Loss: 0.19699731469154358
Epoch 63, Training Loss: 0.19699731469154358, Validation Loss: 0.18862345814704895
Epoch 64, Training Loss: 0.18862347304821014, Validation Loss: 0.18054524064064026
Epoch 65, Training Loss: 0.18054522573947906, Validation Loss: 0.17300012707710266
Epoch 66, Training Loss: 0.17300014197826385, Validation Loss: 0.16573841869831085
Epoch 67, Training Loss: 0.16573841869831085, Validation Loss: 0.15867316722869873
Epoch 68, Training Loss: 0.15867316722869873, Validation Loss: 0.15175211429595947
Epoch 69, Training Loss: 0.15175211429595947, Validation Loss: 0.1449836790561676
Epoch 70, Training Loss: 0.1449836939573288, Validation Loss: 0.1382552534341812
Epoch 71, Training Loss: 0.13825522363185883, Validation Loss: 0.13137970864772797
Epoch 72, Training Loss: 0.13137969374656677, Validation Loss: 0.12433712929487228
Epoch 73, Training Loss: 0.12433712929487228, Validation Loss: 0.11713822185993195
Epoch 74, Training Loss: 0.11713823676109314, Validation Loss: 0.10980679094791412
Epoch 75, Training Loss: 0.10980678349733353, Validation Loss: 0.10231611132621765
Epoch 76, Training Loss: 0.10231612622737885, Validation Loss: 0.09472918510437012
Epoch 77, Training Loss: 0.09472918510437012, Validation Loss: 0.08709313720464706
Epoch 78, Training Loss: 0.08709313720464706, Validation Loss: 0.07954054325819016
Epoch 79, Training Loss: 0.07954052835702896, Validation Loss: 0.07220111042261124
Epoch 80, Training Loss: 0.07220111042261124, Validation Loss: 0.0651782900094986
Epoch 81, Training Loss: 0.0651782974600792, Validation Loss: 0.05835350975394249
Epoch 82, Training Loss: 0.05835350975394249, Validation Loss: 0.051730528473854065
Epoch 83, Training Loss: 0.051730524748563766, Validation Loss: 0.04537774622440338
Epoch 84, Training Loss: 0.04537774622440338, Validation Loss: 0.03932182118296623
Epoch 85, Training Loss: 0.03932182863354683, Validation Loss: 0.03369828313589096
Epoch 86, Training Loss: 0.03369828313589096, Validation Loss: 0.02847052924335003
Epoch 87, Training Loss: 0.02847052551805973, Validation Loss: 0.023657290264964104
Epoch 88, Training Loss: 0.023657290264964104, Validation Loss: 0.019368851557374
Epoch 89, Training Loss: 0.0193688552826643, Validation Loss: 0.01569885015487671
Epoch 90, Training Loss: 0.015698852017521858, Validation Loss: 0.012558584101498127
Epoch 91, Training Loss: 0.012558577582240105, Validation Loss: 0.009954441338777542
Epoch 92, Training Loss: 0.009954439476132393, Validation Loss: 0.007874881848692894
Epoch 93, Training Loss: 0.007874882780015469, Validation Loss: 0.006288621108978987
Epoch 94, Training Loss: 0.006288620177656412, Validation Loss: 0.005158952437341213
Epoch 95, Training Loss: 0.005158951971679926, Validation Loss: 0.00439630588516593
Epoch 96, Training Loss: 0.004396307282149792, Validation Loss: 0.0038938168436288834
Epoch 97, Training Loss: 0.0038938217330724, Validation Loss: 0.003551545785740018
Epoch 98, Training Loss: 0.0035515467170625925, Validation Loss: 0.003299746895208955
Epoch 99, Training Loss: 0.003299744101241231, Validation Loss: 0.003095695748925209
Epoch 100, Training Loss: 0.0030956966802477837, Validation Loss: 0.0028870238456875086
Epoch 101, Training Loss: 0.002887023612856865, Validation Loss: 0.002670971443876624
Epoch 102, Training Loss: 0.0026709726080298424, Validation Loss: 0.002448429586365819
Epoch 103, Training Loss: 0.0024484307505190372, Validation Loss: 0.0022349264472723007
Epoch 104, Training Loss: 0.002234925050288439, Validation Loss: 0.002039987128227949
Epoch 105, Training Loss: 0.00203998782671988, Validation Loss: 0.0018720158841460943
Epoch 106, Training Loss: 0.0018720160005614161, Validation Loss: 0.0017333435826003551
Epoch 107, Training Loss: 0.0017333427676931024, Validation Loss: 0.001614967011846602
Epoch 108, Training Loss: 0.0016149666626006365, Validation Loss: 0.0015068039065226912
Epoch 109, Training Loss: 0.0015068015782162547, Validation Loss: 0.0013986554695293307
Epoch 110, Training Loss: 0.0013986548874527216, Validation Loss: 0.0012868402991443872
Epoch 111, Training Loss: 0.0012868392514064908, Validation Loss: 0.0011671313550323248
Epoch 112, Training Loss: 0.0011671314714476466, Validation Loss: 0.0010409490205347538
Epoch 113, Training Loss: 0.0010409498354420066, Validation Loss: 0.0009115213179029524
Epoch 114, Training Loss: 0.0009115218417719007, Validation Loss: 0.0007836854201741517
Epoch 115, Training Loss: 0.0007836848963052034, Validation Loss: 0.0006632804870605469
Epoch 116, Training Loss: 0.0006632799631915987, Validation Loss: 0.0005560099380090833
Epoch 117, Training Loss: 0.0005560099962167442, Validation Loss: 0.0004661746206693351
Epoch 118, Training Loss: 0.0004661749699153006, Validation Loss: 0.0003955105785280466
Epoch 119, Training Loss: 0.00039551008376292884, Validation Loss: 0.0003434821264818311
Epoch 120, Training Loss: 0.00034348361077718437, Validation Loss: 0.0003071886894758791
Epoch 121, Training Loss: 0.00030718959169462323, Validation Loss: 0.0002824912953656167
Epoch 122, Training Loss: 0.0002824919647537172, Validation Loss: 0.0002649406960699707
Epoch 123, Training Loss: 0.0002649411908350885, Validation Loss: 0.00025063904467970133
Epoch 124, Training Loss: 0.00025063869543373585, Validation Loss: 0.0002367064298596233
Epoch 125, Training Loss: 0.0002367066335864365, Validation Loss: 0.00022158463252708316
Epoch 126, Training Loss: 0.00022158453066367656, Validation Loss: 0.00020495327771641314
Epoch 127, Training Loss: 0.0002049531613010913, Validation Loss: 0.00018740179075393826
Epoch 128, Training Loss: 0.00018740195082500577, Validation Loss: 0.00016993431199807674
Epoch 129, Training Loss: 0.0001699342392385006, Validation Loss: 0.00015358634118456393
Epoch 130, Training Loss: 0.00015358610835392028, Validation Loss: 0.0001391433906974271
Epoch 131, Training Loss: 0.00013914323062635958, Validation Loss: 0.00012689766299445182
Epoch 132, Training Loss: 0.0001268977066501975, Validation Loss: 0.00011664805060718209
Epoch 133, Training Loss: 0.00011664810153888538, Validation Loss: 0.00010781512537505478
Epoch 134, Training Loss: 0.00010781551827676594, Validation Loss: 9.972339466912672e-05
Epoch 135, Training Loss: 9.972351108444855e-05, Validation Loss: 9.221259824698791e-05
Epoch 136, Training Loss: 9.22121835174039e-05, Validation Loss: 8.450923633063212e-05
Epoch 137, Training Loss: 8.450905443169177e-05, Validation Loss: 7.63502685003914e-05
Epoch 138, Training Loss: 7.635023212060332e-05, Validation Loss: 6.780627154512331e-05
Epoch 139, Training Loss: 6.780606781831011e-05, Validation Loss: 5.915583824389614e-05
Epoch 140, Training Loss: 5.915560177527368e-05, Validation Loss: 5.0744463806040585e-05
Epoch 141, Training Loss: 5.074455475551076e-05, Validation Loss: 4.3003750761272386e-05
Epoch 142, Training Loss: 4.300354339648038e-05, Validation Loss: 3.6261222703615203e-05
Epoch 143, Training Loss: 3.626131729106419e-05, Validation Loss: 3.070144521188922e-05
Epoch 144, Training Loss: 3.07013324345462e-05, Validation Loss: 2.6349345716880634e-05
Epoch 145, Training Loss: 2.6349503968958743e-05, Validation Loss: 2.3093474737834185e-05
Epoch 146, Training Loss: 2.3093500203685835e-05, Validation Loss: 2.0727282389998436e-05
Epoch 147, Training Loss: 2.072722236334812e-05, Validation Loss: 1.9007784430868924e-05
Epoch 148, Training Loss: 1.9007817172678187e-05, Validation Loss: 1.7704631318338215e-05
Epoch 149, Training Loss: 1.7704795027384534e-05, Validation Loss: 1.6632944607408717e-05
Epoch 150, Training Loss: 1.6632908227620646e-05, Validation Loss: 1.566589344292879e-05
Epoch 151, Training Loss: 1.5665715181967244e-05, Validation Loss: 1.4732515410287306e-05
Epoch 152, Training Loss: 1.4732605450262781e-05, Validation Loss: 1.3804266018269118e-05
Epoch 153, Training Loss: 1.3804311493004207e-05, Validation Loss: 1.287513441639021e-05
Epoch 154, Training Loss: 1.2875148058810737e-05, Validation Loss: 1.1945865480811335e-05
Epoch 155, Training Loss: 1.1945957339776214e-05, Validation Loss: 1.1014687515853439e-05
Epoch 156, Training Loss: 1.101475481846137e-05, Validation Loss: 1.0074481906485744e-05
Epoch 157, Training Loss: 1.0074521924252622e-05, Validation Loss: 9.116319233726244e-06
Epoch 158, Training Loss: 9.116321052715648e-06, Validation Loss: 8.135745702020358e-06
Epoch 159, Training Loss: 8.135798452713061e-06, Validation Loss: 7.138178261811845e-06
Epoch 160, Training Loss: 7.138195087463828e-06, Validation Loss: 6.141888661659323e-06
Epoch 161, Training Loss: 6.141937774373218e-06, Validation Loss: 5.1768843150057364e-06
Epoch 162, Training Loss: 5.176921149541158e-06, Validation Loss: 4.280282610125141e-06
Epoch 163, Training Loss: 4.280279881641036e-06, Validation Loss: 3.4890015285782283e-06
Epoch 164, Training Loss: 3.489026539682527e-06, Validation Loss: 2.833030521287583e-06
Epoch 165, Training Loss: 2.8329820906947134e-06, Validation Loss: 2.3297870939131826e-06
Epoch 166, Training Loss: 2.3297961888602003e-06, Validation Loss: 1.9810722733382136e-06
Epoch 167, Training Loss: 1.9811436686723027e-06, Validation Loss: 1.773763415258145e-06
Epoch 168, Training Loss: 1.773783424141584e-06, Validation Loss: 1.681831804489775e-06
Epoch 169, Training Loss: 1.6818447647892754e-06, Validation Loss: 1.672003349995066e-06
Epoch 170, Training Loss: 1.6719819768695743e-06, Validation Loss: 1.7084473711292958e-06
Epoch 171, Training Loss: 1.708482386675314e-06, Validation Loss: 1.7582684677108773e-06
Epoch 172, Training Loss: 1.7582789268999477e-06, Validation Loss: 1.794657805476163e-06
Epoch 173, Training Loss: 1.7946506432053866e-06, Validation Loss: 1.7995497501033242e-06
Epoch 174, Training Loss: 1.7995181451624376e-06, Validation Loss: 1.7635343283473048e-06
Epoch 175, Training Loss: 1.7635255744608003e-06, Validation Loss: 1.6852574162840028e-06
Epoch 176, Training Loss: 1.6852974340508808e-06, Validation Loss: 1.5697227127020597e-06
Epoch 177, Training Loss: 1.569669848322519e-06, Validation Loss: 1.4258315559345647e-06
Epoch 178, Training Loss: 1.4258087048801826e-06, Validation Loss: 1.2644302387343487e-06
Epoch 179, Training Loss: 1.2644442222153884e-06, Validation Loss: 1.0965721912725712e-06
Epoch 180, Training Loss: 1.096520804821921e-06, Validation Loss: 9.319084597336769e-07
Epoch 181, Training Loss: 9.319253990724974e-07, Validation Loss: 7.782190891703067e-07
Epoch 182, Training Loss: 7.782222724017629e-07, Validation Loss: 6.408573653970961e-07
Epoch 183, Training Loss: 6.408404829016945e-07, Validation Loss: 5.22878906394908e-07
Epoch 184, Training Loss: 5.228923214417591e-07, Validation Loss: 4.254074781329109e-07
Epoch 185, Training Loss: 4.2540369804555667e-07, Validation Loss: 3.479125325611676e-07
Epoch 186, Training Loss: 3.479015049379086e-07, Validation Loss: 2.888110373078234e-07
Epoch 187, Training Loss: 2.888101846565405e-07, Validation Loss: 2.457346397477522e-07
Epoch 188, Training Loss: 2.457358334595483e-07, Validation Loss: 2.1602374999929452e-07
Epoch 189, Training Loss: 2.1603725031127397e-07, Validation Loss: 1.9686247298977833e-07
Epoch 190, Training Loss: 1.9684448204770888e-07, Validation Loss: 1.8543093460721138e-07
Epoch 191, Training Loss: 1.854097178011216e-07, Validation Loss: 1.7905553306718502e-07
Epoch 192, Training Loss: 1.7905576044086047e-07, Validation Loss: 1.7532819640564412e-07
Epoch 193, Training Loss: 1.7532515528273507e-07, Validation Loss: 1.72162373246465e-07
Epoch 194, Training Loss: 1.721657554298872e-07, Validation Loss: 1.6788681023172103e-07
Epoch 195, Training Loss: 1.679015468880607e-07, Validation Loss: 1.6141434855398984e-07
Epoch 196, Training Loss: 1.6140890579663392e-07, Validation Loss: 1.5215512405575282e-07
Epoch 197, Training Loss: 1.521627694955896e-07, Validation Loss: 1.4026964834101818e-07
Epoch 198, Training Loss: 1.4026556982571492e-07, Validation Loss: 1.2635361201773776e-07
Epoch 199, Training Loss: 1.2633927326533012e-07, Validation Loss: 1.113784122708239e-07
Epoch 200, Training Loss: 1.1138237709928944e-07, Validation Loss: 9.656086064069314e-08
Epoch 201, Training Loss: 9.655494181970425e-08, Validation Loss: 8.288841257808599e-08
Epoch 202, Training Loss: 8.288580488624575e-08, Validation Loss: 7.119275835520966e-08
Epoch 203, Training Loss: 7.119113121234477e-08, Validation Loss: 6.184916401252849e-08
Epoch 204, Training Loss: 6.185597101193707e-08, Validation Loss: 5.483653353621776e-08
Epoch 205, Training Loss: 5.482628395725442e-08, Validation Loss: 4.9744262042850096e-08
Epoch 206, Training Loss: 4.97347087957678e-08, Validation Loss: 4.597594838173791e-08
Epoch 207, Training Loss: 4.598405212163925e-08, Validation Loss: 4.291452526672401e-08
Epoch 208, Training Loss: 4.291240074394409e-08, Validation Loss: 4.002455611384903e-08
Epoch 209, Training Loss: 4.002281528414642e-08, Validation Loss: 3.7004685538022386e-08
Epoch 210, Training Loss: 3.699622652675316e-08, Validation Loss: 3.375094692614766e-08
Epoch 211, Training Loss: 3.374168144887335e-08, Validation Loss: 3.0381471560758655e-08
Epoch 212, Training Loss: 3.037731133304078e-08, Validation Loss: 2.711712987490955e-08
Epoch 213, Training Loss: 2.7120021783844095e-08, Validation Loss: 2.416374478286798e-08
Epoch 214, Training Loss: 2.4160673461892657e-08, Validation Loss: 2.1643945302685097e-08
Epoch 215, Training Loss: 2.1647769798960326e-08, Validation Loss: 1.9593839439835392e-08
Epoch 216, Training Loss: 1.9599172063067272e-08, Validation Loss: 1.7934931761942607e-08
Epoch 217, Training Loss: 1.7935953167125263e-08, Validation Loss: 1.6499010158099736e-08
Epoch 218, Training Loss: 1.6502475830293406e-08, Validation Loss: 1.5143005072104643e-08
Epoch 219, Training Loss: 1.5140253495360412e-08, Validation Loss: 1.3742296189889203e-08
Epoch 220, Training Loss: 1.3739658299982693e-08, Validation Loss: 1.2262445281407963e-08
Epoch 221, Training Loss: 1.226162460454816e-08, Validation Loss: 1.074762856489997e-08
Epoch 222, Training Loss: 1.0744379608240706e-08, Validation Loss: 9.281854396192557e-09
Epoch 223, Training Loss: 9.276044821149299e-09, Validation Loss: 7.966805881665096e-09
Epoch 224, Training Loss: 7.970415438762757e-09, Validation Loss: 6.891700543576462e-09
Epoch 225, Training Loss: 6.894405046864449e-09, Validation Loss: 6.075788760995238e-09
Epoch 226, Training Loss: 6.07616801318045e-09, Validation Loss: 5.4923350312208186e-09
Epoch 227, Training Loss: 5.492283960961686e-09, Validation Loss: 5.0657962269440304e-09
Epoch 228, Training Loss: 5.063582442232928e-09, Validation Loss: 4.712972678788674e-09
Epoch 229, Training Loss: 4.70806815755509e-09, Validation Loss: 4.344609561002244e-09
Epoch 230, Training Loss: 4.344051784954672e-09, Validation Loss: 3.929396363844262e-09
Epoch 231, Training Loss: 3.930694436604654e-09, Validation Loss: 3.457520714178486e-09
Epoch 232, Training Loss: 3.4622005262718858e-09, Validation Loss: 2.9682514224305123e-09
Epoch 233, Training Loss: 2.967212253679463e-09, Validation Loss: 2.5087103505683217e-09
Epoch 234, Training Loss: 2.5102311340674532e-09, Validation Loss: 2.1305772701651904e-09
Epoch 235, Training Loss: 2.1296817642735277e-09, Validation Loss: 1.860906539974394e-09
Epoch 236, Training Loss: 1.8613104391107527e-09, Validation Loss: 1.7087340431487519e-09
Epoch 237, Training Loss: 1.7072055991107504e-09, Validation Loss: 1.6452701423474991e-09
Epoch 238, Training Loss: 1.6463636010044524e-09, Validation Loss: 1.634096968849974e-09
Epoch 239, Training Loss: 1.6335870434147637e-09, Validation Loss: 1.628075341209012e-09
Epoch 240, Training Loss: 1.6280112813404912e-09, Validation Loss: 1.5955944343559736e-09
Epoch 241, Training Loss: 1.5956289622920394e-09, Validation Loss: 1.5168593048286994e-09
Epoch 242, Training Loss: 1.5168729605719022e-09, Validation Loss: 1.3894975170458679e-09
Epoch 243, Training Loss: 1.3901053641518502e-09, Validation Loss: 1.231554302982829e-09
Epoch 244, Training Loss: 1.2317933340000309e-09, Validation Loss: 1.0664283900396754e-09
Epoch 245, Training Loss: 1.0668991246021164e-09, Validation Loss: 9.133024336804851e-10
Epoch 246, Training Loss: 9.124968558538171e-10, Validation Loss: 7.842771987398578e-10
Epoch 247, Training Loss: 7.841481353132451e-10, Validation Loss: 6.855807588301843e-10
Epoch 248, Training Loss: 6.860191859026088e-10, Validation Loss: 6.134294738835422e-10
Epoch 249, Training Loss: 6.127003349121196e-10, Validation Loss: 5.552196480351768e-10
Epoch 250, Training Loss: 5.556252680172236e-10, Validation Loss: 5.03566188747584e-10
Epoch 251, Training Loss: 5.02867691931641e-10, Validation Loss: 4.489746907587744e-10
Epoch 252, Training Loss: 4.483248772224613e-10, Validation Loss: 3.9167194487710333e-10
Epoch 253, Training Loss: 3.91907950536563e-10, Validation Loss: 3.3606317728640533e-10
Epoch 254, Training Loss: 3.3608751892622024e-10, Validation Loss: 2.8572727517328644e-10
Epoch 255, Training Loss: 2.8570773524805304e-10, Validation Loss: 2.454834113763127e-10
Epoch 256, Training Loss: 2.457196113248017e-10, Validation Loss: 2.1847922082596227e-10
Epoch 257, Training Loss: 2.1883493628305217e-10, Validation Loss: 2.0293801361592756e-10
Epoch 258, Training Loss: 2.030588475143702e-10, Validation Loss: 1.9557298835959358e-10
Epoch 259, Training Loss: 1.9569552922593658e-10, Validation Loss: 1.9117660232659262e-10
Epoch 260, Training Loss: 1.916438396865061e-10, Validation Loss: 1.86383394829015e-10
Epoch 261, Training Loss: 1.8616490293776877e-10, Validation Loss: 1.7703510879485407e-10
Epoch 262, Training Loss: 1.7690174325402097e-10, Validation Loss: 1.6238534128465432e-10
Epoch 263, Training Loss: 1.6255370660633872e-10, Validation Loss: 1.4381698609788884e-10
Epoch 264, Training Loss: 1.4390270919317771e-10, Validation Loss: 1.238117802726535e-10
Epoch 265, Training Loss: 1.23778598482005e-10, Validation Loss: 1.0494376895264779e-10
Epoch 266, Training Loss: 1.0473123063237111e-10, Validation Loss: 8.976266951954415e-11
Epoch 267, Training Loss: 8.935481521366029e-11, Validation Loss: 7.807415131066975e-11
Epoch 268, Training Loss: 7.795984691139068e-11, Validation Loss: 7.04628508318983e-11
Epoch 269, Training Loss: 7.051947220615418e-11, Validation Loss: 6.482965553278319e-11
Epoch 270, Training Loss: 6.478249880981224e-11, Validation Loss: 6.006913022549298e-11
Epoch 271, Training Loss: 6.036669081277424e-11, Validation Loss: 5.522562962489985e-11
Epoch 272, Training Loss: 5.5307966539963616e-11, Validation Loss: 4.960662089437129e-11
Epoch 273, Training Loss: 4.956162216740445e-11, Validation Loss: 4.3218994355553875e-11
Epoch 274, Training Loss: 4.325080918410329e-11, Validation Loss: 3.677807711155445e-11
Epoch 275, Training Loss: 3.656856414901988e-11, Validation Loss: 3.130433412490419e-11
Epoch 276, Training Loss: 3.096595202478625e-11, Validation Loss: 2.6502250047300002e-11
Epoch 277, Training Loss: 2.6489038393306963e-11, Validation Loss: 2.3507000165845504e-11
Epoch 278, Training Loss: 2.3393339348976028e-11, Validation Loss: 2.1680077871844006e-11
Epoch 279, Training Loss: 2.17914193634261e-11, Validation Loss: 2.1186630574931975e-11
Epoch 280, Training Loss: 2.124780386358882e-11, Validation Loss: 2.101372548191094e-11
Epoch 281, Training Loss: 2.1064209404508816e-11, Validation Loss: 2.07962379955573e-11
Epoch 282, Training Loss: 2.0764223673808146e-11, Validation Loss: 2.029269113856813e-11
Epoch 283, Training Loss: 2.01788030729233e-11, Validation Loss: 1.8940682355861327e-11
Epoch 284, Training Loss: 1.8991166278459204e-11, Validation Loss: 1.7375859431845164e-11
Epoch 285, Training Loss: 1.7374631247624173e-11, Validation Loss: 1.537181493205253e-11
Epoch 286, Training Loss: 1.5307286688193145e-11, Validation Loss: 1.3452531623381336e-11
Epoch 287, Training Loss: 1.3490877685817804e-11, Validation Loss: 1.1763719338919731e-11
Epoch 288, Training Loss: 1.1817609391062689e-11, Validation Loss: 1.0059049947164223e-11
Epoch 289, Training Loss: 1.0188782977038624e-11, Validation Loss: 8.927116858237216e-12
Epoch 290, Training Loss: 8.838233096775117e-12, Validation Loss: 7.733557717826134e-12
Epoch 291, Training Loss: 7.73771151318936e-12, Validation Loss: 6.7842038410648176e-12
Epoch 292, Training Loss: 6.7988735301394154e-12, Validation Loss: 5.9188309635416214e-12
Epoch 293, Training Loss: 5.730812525917006e-12, Validation Loss: 4.963896481358088e-12
Epoch 294, Training Loss: 5.007583323696219e-12, Validation Loss: 4.16100227190741e-12
Epoch 295, Training Loss: 4.121090187853005e-12, Validation Loss: 3.5185691166228494e-12
Epoch 296, Training Loss: 3.4869566001988206e-12, Validation Loss: 2.99187714533633e-12
Epoch 297, Training Loss: 2.97181224941101e-12, Validation Loss: 2.684995021456915e-12
Epoch 298, Training Loss: 2.643309833169627e-12, Validation Loss: 2.4283654514317687e-12
Epoch 299, Training Loss: 2.4934195333448095e-12, Validation Loss: 2.416485848227845e-12
Epoch 300, Training Loss: 2.4221759580694835e-12, Validation Loss: 2.385703396987071e-12
Epoch 301, Training Loss: 2.3713570170003084e-12, Validation Loss: 2.368072534938981e-12
Epoch 302, Training Loss: 2.4147888549874708e-12, Validation Loss: 2.2978411708118873e-12
Epoch 303, Training Loss: 2.3007210286224433e-12, Validation Loss: 2.1301419829422574e-12
Epoch 304, Training Loss: 2.1489966924026493e-12, Validation Loss: 1.9061789906932303e-12
Epoch 305, Training Loss: 1.9158667707852572e-12, Validation Loss: 1.5848877115212656e-12
Epoch 306, Training Loss: 1.6139992987940222e-12, Validation Loss: 1.3733515193126156e-12
Epoch 307, Training Loss: 1.389070499249745e-12, Validation Loss: 1.1182038368168223e-12
Epoch 308, Training Loss: 1.176087005561044e-12, Validation Loss: 9.670226858854436e-13
Epoch 309, Training Loss: 9.806513240340209e-13, Validation Loss: 8.578860278413147e-13
Epoch 310, Training Loss: 7.990897440274258e-13, Validation Loss: 7.612640986337516e-13
Epoch 311, Training Loss: 7.391514158551493e-13, Validation Loss: 6.634159367691073e-13
Epoch 312, Training Loss: 6.553524541617894e-13, Validation Loss: 6.30182483887104e-13
Epoch 313, Training Loss: 6.044634194221632e-13, Validation Loss: 5.637920685863662e-13
Epoch 314, Training Loss: 5.868987479167032e-13, Validation Loss: 5.455278698392185e-13
Epoch 315, Training Loss: 5.481426402186018e-13, Validation Loss: 5.132973039667643e-13
Epoch 316, Training Loss: 4.982250506255226e-13, Validation Loss: 4.608071736689201e-13
Epoch 317, Training Loss: 4.5077472570626e-13, Validation Loss: 4.3258587901010004e-13
Epoch 318, Training Loss: 4.021011225808363e-13, Validation Loss: 3.946258467571462e-13
Epoch 319, Training Loss: 3.75035343492397e-13, Validation Loss: 3.5829005777879286e-13
Epoch 320, Training Loss: 3.675438046361196e-13, Validation Loss: 3.435558586749321e-13
Epoch 321, Training Loss: 3.338901420971152e-13, Validation Loss: 3.0992997881659767e-13
Epoch 322, Training Loss: 3.034465582453516e-13, Validation Loss: 2.9544576962865776e-13
Epoch 323, Training Loss: 3.041138575774621e-13, Validation Loss: 2.850086161000631e-13
Epoch 324, Training Loss: 2.6560841742163943e-13, Validation Loss: 2.5272614404860116e-13
Epoch 325, Training Loss: 2.552641800192268e-13, Validation Loss: 2.317946724318676e-13
Epoch 326, Training Loss: 2.311085350870101e-13, Validation Loss: 1.994841059916111e-13
Epoch 327, Training Loss: 2.0736897984353908e-13, Validation Loss: 1.7893510024374892e-13
Epoch 328, Training Loss: 1.7546841800733515e-13, Validation Loss: 1.5187574505318158e-13
Epoch 329, Training Loss: 1.3986180920008695e-13, Validation Loss: 1.2429872398283387e-13
Epoch 330, Training Loss: 1.248602322879641e-13, Validation Loss: 1.029615439131562e-13
Epoch 331, Training Loss: 1.0281430925813267e-13, Validation Loss: 8.122569592839204e-14
Epoch 332, Training Loss: 9.205156981714063e-14, Validation Loss: 7.43840143017753e-14
Epoch 333, Training Loss: 7.804440958509434e-14, Validation Loss: 6.120752911670593e-14
Epoch 334, Training Loss: 6.924083024604719e-14, Validation Loss: 5.086007976535731e-14
Epoch 335, Training Loss: 5.670616903016672e-14, Validation Loss: 4.883402438937007e-14
Epoch 336, Training Loss: 4.1221275118340575e-14, Validation Loss: 3.6551480836173947e-14
Epoch 337, Training Loss: 3.4959536621918114e-14, Validation Loss: 2.986164850007737e-14
Epoch 338, Training Loss: 3.2407599146562147e-14, Validation Loss: 2.6946464333423188e-14
Epoch 339, Training Loss: 2.6203009963090933e-14, Validation Loss: 2.444755112056534e-14
Epoch 340, Training Loss: 2.2731704620851043e-14, Validation Loss: 2.2760014156014176e-14
Epoch 341, Training Loss: 1.7136877515449254e-14, Validation Loss: 2.0940135069718105e-14
Epoch 342, Training Loss: 1.3720839378951813e-14, Validation Loss: 1.683782745122344e-14
Epoch 343, Training Loss: 1.2889310522764055e-14, Validation Loss: 1.582161322528225e-14
Epoch 344, Training Loss: 1.374501708739824e-14, Validation Loss: 1.491300775902614e-14
Epoch 345, Training Loss: 1.2007153660285961e-14, Validation Loss: 1.9694351198148476e-14
Epoch 346, Training Loss: 1.0839822827323972e-14, Validation Loss: 2.026528359184987e-14
Epoch 347, Training Loss: 1.0394728189365519e-14, Validation Loss: 2.037447799721221e-14
Epoch 348, Training Loss: 1.1499133791708933e-14, Validation Loss: 1.874989760349867e-14
Epoch 349, Training Loss: 1.033843692078984e-14, Validation Loss: 1.7701431751057824e-14
Epoch 350, Training Loss: 9.604490495290514e-15, Validation Loss: 2.175334599138854e-14
Epoch 351, Training Loss: 9.086900848475406e-15, Validation Loss: 1.646444177554659e-14
Epoch 352, Training Loss: 7.910945526044474e-15, Validation Loss: 1.5786964495541865e-14
Epoch 353, Training Loss: 9.157202889031619e-15, Validation Loss: 1.661536271795657e-14
Epoch 354, Training Loss: 6.925113948404822e-15, Validation Loss: 1.6690889257731448e-14
Epoch 355, Training Loss: 6.84971996928619e-15, Validation Loss: 1.3657017987475043e-14
Epoch 356, Training Loss: 5.631810681461279e-15, Validation Loss: 1.3207165565451862e-14
Epoch 357, Training Loss: 6.6798504763296556e-15, Validation Loss: 1.2380636744751747e-14
Epoch 358, Training Loss: 7.251354193753973e-15, Validation Loss: 1.1805054140169927e-14
Epoch 359, Training Loss: 6.995316462589732e-15, Validation Loss: 1.1154853862165633e-14
Epoch 360, Training Loss: 6.8660253535208354e-15, Validation Loss: 1.1368796596950177e-14
Epoch 361, Training Loss: 7.118223484335173e-15, Validation Loss: 1.1527932064882632e-14
Epoch 362, Training Loss: 4.448150323825648e-15, Validation Loss: 1.1235238982925961e-14
Epoch 363, Training Loss: 4.596227353115224e-15, Validation Loss: 1.0316711372725714e-14
Epoch 364, Training Loss: 4.770971520683207e-15, Validation Loss: 1.0713904603451042e-14
Epoch 365, Training Loss: 4.748024127592667e-15, Validation Loss: 1.3255930946291187e-14
Epoch 366, Training Loss: 3.738886438409313e-15, Validation Loss: 1.0008315146959896e-14
Epoch 367, Training Loss: 4.590073235236948e-15, Validation Loss: 1.1271247200546688e-14
Epoch 368, Training Loss: 3.48235636934448e-15, Validation Loss: 1.1777843206739382e-14
Epoch 369, Training Loss: 3.944347832292999e-15, Validation Loss: 1.0896790875224507e-14
Epoch 370, Training Loss: 3.8536797315530044e-15, Validation Loss: 1.089898045539316e-14
Epoch 371, Training Loss: 3.225380549191155e-15, Validation Loss: 6.70634100823856e-15
Epoch 372, Training Loss: 3.9050298334308755e-15, Validation Loss: 6.5642825715557e-15
Epoch 373, Training Loss: 3.4927536987720267e-15, Validation Loss: 6.564336781664324e-15
Epoch 374, Training Loss: 3.075807659716728e-15, Validation Loss: 3.584686631460509e-15
Epoch 375, Training Loss: 3.0668134403663084e-15, Validation Loss: 4.158443033008049e-15
Epoch 376, Training Loss: 2.5372643236106808e-15, Validation Loss: 5.401535033871304e-15
Epoch 377, Training Loss: 2.0529014499757548e-15, Validation Loss: 2.8622005617375337e-15
Epoch 378, Training Loss: 2.4973747892673972e-15, Validation Loss: 3.639473993038338e-15
Epoch 379, Training Loss: 2.2755976349954615e-15, Validation Loss: 3.4839998250203903e-15
Epoch 380, Training Loss: 2.478439791248001e-15, Validation Loss: 4.341337351594513e-15
Epoch 381, Training Loss: 2.2679425747346507e-15, Validation Loss: 3.666872544266699e-15
Epoch 382, Training Loss: 1.9507054425818657e-15, Validation Loss: 3.9456128759997235e-15
Epoch 383, Training Loss: 1.3769461822981288e-15, Validation Loss: 3.405543186522724e-15
Epoch 384, Training Loss: 1.435652130048193e-15, Validation Loss: 6.9387211091859885e-15
Epoch 385, Training Loss: 1.2205387957305437e-15, Validation Loss: 4.613416616230329e-15
Epoch 386, Training Loss: 1.8931741177714064e-15, Validation Loss: 4.7951792987992615e-15
Epoch 387, Training Loss: 1.6348468565507372e-15, Validation Loss: 5.09333193161746e-15
Epoch 388, Training Loss: 1.6602388926061713e-15, Validation Loss: 5.093512349635225e-15
Epoch 389, Training Loss: 1.4120947673565117e-15, Validation Loss: 5.127939580259902e-15
Epoch 390, Training Loss: 1.5572778027026749e-15, Validation Loss: 4.919739728857743e-15
Epoch 391, Training Loss: 1.0927388881652885e-15, Validation Loss: 4.919739728857743e-15
Epoch 392, Training Loss: 1.0927388881652885e-15, Validation Loss: 4.916537097284174e-15
Epoch 393, Training Loss: 1.1023465711277572e-15, Validation Loss: 4.884511205064963e-15
Epoch 394, Training Loss: 1.0863337308972699e-15, Validation Loss: 4.884511205064963e-15
Epoch 395, Training Loss: 7.644758222589759e-16, Validation Loss: 4.884511205064963e-15
Epoch 396, Training Loss: 9.072568839249627e-16, Validation Loss: 5.357530825228496e-15
Epoch 397, Training Loss: 8.964850600556113e-16, Validation Loss: 4.575578383927059e-15
Epoch 398, Training Loss: 4.2255048549036584e-16, Validation Loss: 4.7956790482381415e-15
Epoch 399, Training Loss: 1.0526798413534356e-15, Validation Loss: 4.8036098177232835e-15
Epoch 400, Training Loss: 1.0526041377837748e-15, Validation Loss: 4.8809299497639715e-15
Epoch 401, Training Loss: 1.462456911180529e-15, Validation Loss: 4.4709257692278955e-15
Epoch 402, Training Loss: 1.3341118320345973e-15, Validation Loss: 4.2253200958420386e-15
Epoch 403, Training Loss: 1.3207756159174335e-15, Validation Loss: 4.272615874517877e-15
Epoch 404, Training Loss: 1.3394650802612445e-15, Validation Loss: 4.272540065069098e-15
Epoch 405, Training Loss: 1.5102764738551258e-15, Validation Loss: 4.413911134515261e-15
Epoch 406, Training Loss: 6.344657410365382e-16, Validation Loss: 4.381809856363744e-15
Epoch 407, Training Loss: 6.545106169146336e-16, Validation Loss: 4.3817344704314386e-15
Epoch 408, Training Loss: 1.091647909729225e-15, Validation Loss: 4.79158745558643e-15
Epoch 409, Training Loss: 5.610764771458207e-16, Validation Loss: 4.6409913503117194e-15
Epoch 410, Training Loss: 6.109702117500064e-16, Validation Loss: 4.640915964379414e-15
Epoch 411, Training Loss: 6.029509273218763e-16, Validation Loss: 4.598139953510124e-15
Epoch 412, Training Loss: 5.308802819717969e-16, Validation Loss: 4.598139953510124e-15
Epoch 413, Training Loss: 3.1150446610532707e-16, Validation Loss: 4.5874647972758784e-15
Epoch 414, Training Loss: 2.090223336288335e-16, Validation Loss: 4.5874647972758784e-15
Epoch 415, Training Loss: 2.090223336288335e-16, Validation Loss: 4.4809796267953304e-15
Epoch 416, Training Loss: 3.493014055524189e-16, Validation Loss: 4.4809796267953304e-15
Epoch 417, Training Loss: 4.01610004619447e-16, Validation Loss: 4.467635469744286e-15
Epoch 418, Training Loss: 4.01610004619447e-16, Validation Loss: 4.45696031351004e-15
Epoch 419, Training Loss: 3.7942554998636685e-16, Validation Loss: 4.45696031351004e-15
Epoch 420, Training Loss: 3.260494511777819e-16, Validation Loss: 4.45696031351004e-15
Epoch 421, Training Loss: 3.260494511777819e-16, Validation Loss: 4.467635469744286e-15
Epoch 422, Training Loss: 3.3725842345725527e-16, Validation Loss: 4.467710432160118e-15
Epoch 423, Training Loss: 2.9454956641881535e-16, Validation Loss: 4.467785818092424e-15
Epoch 424, Training Loss: 5.739989176682507e-16, Validation Loss: 4.570343296796554e-15
Epoch 425, Training Loss: 5.739909767343702e-16, Validation Loss: 4.570419106245333e-15
Epoch 426, Training Loss: 6.39635659569664e-16, Validation Loss: 4.160566121090342e-15
Epoch 427, Training Loss: 3.321813873807518e-16, Validation Loss: 4.1713166632568934e-15
Epoch 428, Training Loss: 3.321735523259897e-16, Validation Loss: 4.1713166632568934e-15
Epoch 429, Training Loss: 3.321735523259897e-16, Validation Loss: 4.1713166632568934e-15
Epoch 430, Training Loss: 4.624112207134428e-16, Validation Loss: 4.1392911945541556e-15
Epoch 431, Training Loss: 7.859287845327632e-16, Validation Loss: 4.1392911945541556e-15
Epoch 432, Training Loss: 7.539031570113477e-16, Validation Loss: 6.242309678194816e-15
Epoch 433, Training Loss: 7.539031570113477e-16, Validation Loss: 6.242309678194816e-15
Epoch 434, Training Loss: 6.791765869155933e-16, Validation Loss: 4.214017711710351e-15
Epoch 435, Training Loss: 6.791765869155933e-16, Validation Loss: 4.214017711710351e-15
Epoch 436, Training Loss: 6.791765869155933e-16, Validation Loss: 4.1606415070226475e-15
Epoch 437, Training Loss: 6.765077978570318e-16, Validation Loss: 4.1606415070226475e-15
Epoch 438, Training Loss: 6.765077978570318e-16, Validation Loss: 4.1606415070226475e-15
Epoch 439, Training Loss: 5.665113052332003e-16, Validation Loss: 4.163310507839446e-15
Epoch 440, Training Loss: 5.585048851179566e-16, Validation Loss: 4.163310507839446e-15
Epoch 441, Training Loss: 5.472958863687036e-16, Validation Loss: 4.163310507839446e-15
Epoch 442, Training Loss: 5.472958863687036e-16, Validation Loss: 4.3982571186170546e-15
Epoch 443, Training Loss: 5.472958863687036e-16, Validation Loss: 4.958622776301451e-15
Epoch 444, Training Loss: 5.472958863687036e-16, Validation Loss: 4.958622776301451e-15
Epoch 445, Training Loss: 5.666864292950451e-16, Validation Loss: 4.027293110136403e-15
Epoch 446, Training Loss: 5.453360109474348e-16, Validation Loss: 4.168656556286041e-15
Epoch 447, Training Loss: 1.0145036429042107e-15, Validation Loss: 6.840214142035629e-15
Epoch 448, Training Loss: 2.979711560092491e-16, Validation Loss: 6.840214142035629e-15
Epoch 449, Training Loss: 9.732622439771093e-16, Validation Loss: 6.768156202179758e-15
Epoch 450, Training Loss: 9.750970232199805e-16, Validation Loss: 6.768156202179758e-15
Epoch 451, Training Loss: 1.0132526811202345e-15, Validation Loss: 6.116967860242493e-15
Epoch 452, Training Loss: 1.0132526811202345e-15, Validation Loss: 5.846884628746881e-15
Epoch 453, Training Loss: 1.0132526811202345e-15, Validation Loss: 5.846884628746881e-15
Epoch 454, Training Loss: 9.67882949487334e-16, Validation Loss: 5.846884628746881e-15
Epoch 455, Training Loss: 9.056664736873743e-16, Validation Loss: 5.868234941215373e-15
Epoch 456, Training Loss: 9.163416299216203e-16, Validation Loss: 5.868234941215373e-15
Epoch 457, Training Loss: 9.616696451818685e-16, Validation Loss: 3.687862867732608e-15
Epoch 458, Training Loss: 9.616696451818685e-16, Validation Loss: 3.693200445849731e-15
Epoch 459, Training Loss: 9.211454714028546e-16, Validation Loss: 3.5544225677715865e-15
Epoch 460, Training Loss: 2.2187679975724635e-16, Validation Loss: 3.767843530260622e-15
Epoch 461, Training Loss: 2.9918879234070675e-16, Validation Loss: 3.767843530260622e-15
Epoch 462, Training Loss: 5.359201809475192e-16, Validation Loss: 3.789076528665919e-15
Epoch 463, Training Loss: 5.358029198238837e-16, Validation Loss: 3.788959214602724e-15
Epoch 464, Training Loss: 4.984892126732004e-16, Validation Loss: 3.788842747572477e-15
Epoch 465, Training Loss: 3.476887871697447e-16, Validation Loss: 3.788725433509282e-15
Epoch 466, Training Loss: 9.256389811880387e-16, Validation Loss: 3.591408684929919e-15
Epoch 467, Training Loss: 8.510038906505877e-16, Validation Loss: 3.628696345817474e-15
Epoch 468, Training Loss: 8.509701152118159e-16, Validation Loss: 3.585919911431711e-15
Epoch 469, Training Loss: 9.045793068995734e-16, Validation Loss: 3.671246198889847e-15
Epoch 470, Training Loss: 9.77937865845953e-16, Validation Loss: 3.649820500489049e-15
Epoch 471, Training Loss: 9.779041962862996e-16, Validation Loss: 3.649745114556744e-15
Epoch 472, Training Loss: 8.964719310449289e-16, Validation Loss: 3.636859202330164e-15
Epoch 473, Training Loss: 4.0908525566742343e-16, Validation Loss: 3.871638947617164e-15
Epoch 474, Training Loss: 1.183276228194051e-15, Validation Loss: 3.770149153943048e-15
Epoch 475, Training Loss: 1.4015302548010008e-15, Validation Loss: 3.767672006088803e-15
Epoch 476, Training Loss: 1.4308326184574345e-15, Validation Loss: 3.6564413335212625e-15
Epoch 477, Training Loss: 5.820980878912187e-16, Validation Loss: 3.655031447180558e-15
Epoch 478, Training Loss: 5.820436660243576e-16, Validation Loss: 3.654956061248252e-15
Epoch 479, Training Loss: 5.553012476927632e-16, Validation Loss: 3.6548806753159465e-15
Epoch 480, Training Loss: 5.552469317050206e-16, Validation Loss: 3.6548057129001145e-15
Epoch 481, Training Loss: 5.551926686568371e-16, Validation Loss: 3.649392748850686e-15
Epoch 482, Training Loss: 5.222786623924295e-16, Validation Loss: 3.649317786434854e-15
Epoch 483, Training Loss: 5.328996085180511e-16, Validation Loss: 4.062907880953131e-15
Epoch 484, Training Loss: 5.328453984094269e-16, Validation Loss: 4.062832918537299e-15
Epoch 485, Training Loss: 5.327911353612434e-16, Validation Loss: 4.062682993705635e-15
Epoch 486, Training Loss: 5.326827151439948e-16, Validation Loss: 4.062532645357497e-15
Epoch 487, Training Loss: 4.86137195901187e-16, Validation Loss: 4.115758501697063e-15
Epoch 488, Training Loss: 4.753537253288109e-16, Validation Loss: 3.624548848991244e-15
Epoch 489, Training Loss: 5.119416311228156e-16, Validation Loss: 3.624398500643106e-15
Epoch 490, Training Loss: 5.118335814824815e-16, Validation Loss: 4.1793609351569675e-15
Epoch 491, Training Loss: 2.6370597337529327e-16, Validation Loss: 4.179285549224662e-15
Epoch 492, Training Loss: 2.6371457605366383e-16, Validation Loss: 4.1920215366195775e-15
Epoch 493, Training Loss: 1.1169276080400295e-15, Validation Loss: 3.634166061074369e-15
Epoch 494, Training Loss: 1.1089091706448467e-15, Validation Loss: 3.1083366895066087e-15
Epoch 495, Training Loss: 1.0635272629133294e-15, Validation Loss: 3.1082617270907767e-15
Epoch 496, Training Loss: 1.0635149809355943e-15, Validation Loss: 3.1081871881914183e-15
Epoch 497, Training Loss: 8.580048826574405e-16, Validation Loss: 3.0894309141238927e-15
Epoch 498, Training Loss: 8.579926536192645e-16, Validation Loss: 3.660480410130245e-15
Epoch 499, Training Loss: 1.3890432421530187e-16, Validation Loss: 3.660405871230886e-15
Epoch 500, Training Loss: 1.388922010562443e-16, Validation Loss: 3.660331332331528e-15
