Epoch 1, Training Loss: 0.43945005536079407, Validation Loss: 0.4380660653114319
Epoch 2, Training Loss: 0.4380660653114319, Validation Loss: 0.4367234408855438
Epoch 3, Training Loss: 0.4367234408855438, Validation Loss: 0.43539518117904663
Epoch 4, Training Loss: 0.43539518117904663, Validation Loss: 0.434066504240036
Epoch 5, Training Loss: 0.4340665340423584, Validation Loss: 0.43274107575416565
Epoch 6, Training Loss: 0.43274107575416565, Validation Loss: 0.43142449855804443
Epoch 7, Training Loss: 0.4314245283603668, Validation Loss: 0.4301283359527588
Epoch 8, Training Loss: 0.4301283359527588, Validation Loss: 0.4288592040538788
Epoch 9, Training Loss: 0.4288592040538788, Validation Loss: 0.4275968670845032
Epoch 10, Training Loss: 0.4275968670845032, Validation Loss: 0.42633917927742004
Epoch 11, Training Loss: 0.42633917927742004, Validation Loss: 0.4250708520412445
Epoch 12, Training Loss: 0.4250708520412445, Validation Loss: 0.4237895607948303
Epoch 13, Training Loss: 0.42378953099250793, Validation Loss: 0.42246562242507935
Epoch 14, Training Loss: 0.42246562242507935, Validation Loss: 0.421110063791275
Epoch 15, Training Loss: 0.421110063791275, Validation Loss: 0.4197034537792206
Epoch 16, Training Loss: 0.4197034537792206, Validation Loss: 0.41825464367866516
Epoch 17, Training Loss: 0.41825464367866516, Validation Loss: 0.4168192148208618
Epoch 18, Training Loss: 0.4168192148208618, Validation Loss: 0.41534674167633057
Epoch 19, Training Loss: 0.41534674167633057, Validation Loss: 0.41385897994041443
Epoch 20, Training Loss: 0.4138590097427368, Validation Loss: 0.4123082458972931
Epoch 21, Training Loss: 0.4123081862926483, Validation Loss: 0.4106750786304474
Epoch 22, Training Loss: 0.4106750786304474, Validation Loss: 0.4089844226837158
Epoch 23, Training Loss: 0.4089844226837158, Validation Loss: 0.4072391092777252
Epoch 24, Training Loss: 0.4072391092777252, Validation Loss: 0.4054041802883148
Epoch 25, Training Loss: 0.40540415048599243, Validation Loss: 0.4034841060638428
Epoch 26, Training Loss: 0.4034840762615204, Validation Loss: 0.40143370628356934
Epoch 27, Training Loss: 0.40143370628356934, Validation Loss: 0.3992834985256195
Epoch 28, Training Loss: 0.3992834687232971, Validation Loss: 0.39701762795448303
Epoch 29, Training Loss: 0.39701759815216064, Validation Loss: 0.39462244510650635
Epoch 30, Training Loss: 0.39462244510650635, Validation Loss: 0.3921029567718506
Epoch 31, Training Loss: 0.3921029567718506, Validation Loss: 0.3894572854042053
Epoch 32, Training Loss: 0.38945722579956055, Validation Loss: 0.3866608142852783
Epoch 33, Training Loss: 0.3866608142852783, Validation Loss: 0.38370954990386963
Epoch 34, Training Loss: 0.38370954990386963, Validation Loss: 0.38059282302856445
Epoch 35, Training Loss: 0.38059288263320923, Validation Loss: 0.3773094415664673
Epoch 36, Training Loss: 0.3773094415664673, Validation Loss: 0.3738374710083008
Epoch 37, Training Loss: 0.3738374710083008, Validation Loss: 0.37014368176460266
Epoch 38, Training Loss: 0.3701436519622803, Validation Loss: 0.3661940097808838
Epoch 39, Training Loss: 0.3661940097808838, Validation Loss: 0.3619857430458069
Epoch 40, Training Loss: 0.3619857728481293, Validation Loss: 0.35748130083084106
Epoch 41, Training Loss: 0.35748130083084106, Validation Loss: 0.3526855707168579
Epoch 42, Training Loss: 0.3526855707168579, Validation Loss: 0.3476089835166931
Epoch 43, Training Loss: 0.3476090133190155, Validation Loss: 0.3422169089317322
Epoch 44, Training Loss: 0.3422168791294098, Validation Loss: 0.33647051453590393
Epoch 45, Training Loss: 0.33647051453590393, Validation Loss: 0.330369234085083
Epoch 46, Training Loss: 0.330369234085083, Validation Loss: 0.32389047741889954
Epoch 47, Training Loss: 0.3238905072212219, Validation Loss: 0.3170458972454071
Epoch 48, Training Loss: 0.3170458972454071, Validation Loss: 0.30981332063674927
Epoch 49, Training Loss: 0.30981332063674927, Validation Loss: 0.30218860507011414
Epoch 50, Training Loss: 0.30218860507011414, Validation Loss: 0.29419612884521484
Epoch 51, Training Loss: 0.29419612884521484, Validation Loss: 0.2858205735683441
Epoch 52, Training Loss: 0.2858205735683441, Validation Loss: 0.2770838439464569
Epoch 53, Training Loss: 0.2770838737487793, Validation Loss: 0.2680188715457916
Epoch 54, Training Loss: 0.2680188715457916, Validation Loss: 0.25881579518318176
Epoch 55, Training Loss: 0.25881582498550415, Validation Loss: 0.24957843124866486
Epoch 56, Training Loss: 0.24957841634750366, Validation Loss: 0.24023227393627167
Epoch 57, Training Loss: 0.24023228883743286, Validation Loss: 0.23082873225212097
Epoch 58, Training Loss: 0.23082870244979858, Validation Loss: 0.2214871197938919
Epoch 59, Training Loss: 0.2214871197938919, Validation Loss: 0.21234150230884552
Epoch 60, Training Loss: 0.21234150230884552, Validation Loss: 0.20341630280017853
Epoch 61, Training Loss: 0.20341631770133972, Validation Loss: 0.19484828412532806
Epoch 62, Training Loss: 0.19484828412532806, Validation Loss: 0.18672321736812592
Epoch 63, Training Loss: 0.1867232322692871, Validation Loss: 0.17901986837387085
Epoch 64, Training Loss: 0.17901986837387085, Validation Loss: 0.17178930342197418
Epoch 65, Training Loss: 0.17178931832313538, Validation Loss: 0.16485095024108887
Epoch 66, Training Loss: 0.16485098004341125, Validation Loss: 0.15813593566417694
Epoch 67, Training Loss: 0.15813593566417694, Validation Loss: 0.15160515904426575
Epoch 68, Training Loss: 0.15160515904426575, Validation Loss: 0.14530915021896362
Epoch 69, Training Loss: 0.14530915021896362, Validation Loss: 0.13902612030506134
Epoch 70, Training Loss: 0.13902612030506134, Validation Loss: 0.13268998265266418
Epoch 71, Training Loss: 0.13268998265266418, Validation Loss: 0.126344695687294
Epoch 72, Training Loss: 0.1263446807861328, Validation Loss: 0.11993492394685745
Epoch 73, Training Loss: 0.11993490904569626, Validation Loss: 0.11337073147296906
Epoch 74, Training Loss: 0.11337073147296906, Validation Loss: 0.10667885839939117
Epoch 75, Training Loss: 0.10667885094881058, Validation Loss: 0.0999937430024147
Epoch 76, Training Loss: 0.0999937355518341, Validation Loss: 0.09328188747167587
Epoch 77, Training Loss: 0.09328189492225647, Validation Loss: 0.08665894716978073
Epoch 78, Training Loss: 0.08665894716978073, Validation Loss: 0.08015365898609161
Epoch 79, Training Loss: 0.0801536813378334, Validation Loss: 0.07383020222187042
Epoch 80, Training Loss: 0.07383019477128983, Validation Loss: 0.06778005510568619
Epoch 81, Training Loss: 0.06778006255626678, Validation Loss: 0.06210105121135712
Epoch 82, Training Loss: 0.062101054936647415, Validation Loss: 0.05665818601846695
Epoch 83, Training Loss: 0.056658197194337845, Validation Loss: 0.05159924924373627
Epoch 84, Training Loss: 0.05159923806786537, Validation Loss: 0.04674583673477173
Epoch 85, Training Loss: 0.04674583300948143, Validation Loss: 0.042127471417188644
Epoch 86, Training Loss: 0.042127471417188644, Validation Loss: 0.037635114043951035
Epoch 87, Training Loss: 0.03763511776924133, Validation Loss: 0.03334160894155502
Epoch 88, Training Loss: 0.033341605216264725, Validation Loss: 0.02931240014731884
Epoch 89, Training Loss: 0.02931239642202854, Validation Loss: 0.025488274171948433
Epoch 90, Training Loss: 0.025488272309303284, Validation Loss: 0.02188275009393692
Epoch 91, Training Loss: 0.021882755681872368, Validation Loss: 0.01852324791252613
Epoch 92, Training Loss: 0.01852325350046158, Validation Loss: 0.015424342826008797
Epoch 93, Training Loss: 0.01542434748262167, Validation Loss: 0.012653342448174953
Epoch 94, Training Loss: 0.012653342448174953, Validation Loss: 0.010231025516986847
Epoch 95, Training Loss: 0.010231024585664272, Validation Loss: 0.008184554055333138
Epoch 96, Training Loss: 0.008184554986655712, Validation Loss: 0.006540874484926462
Epoch 97, Training Loss: 0.006540872622281313, Validation Loss: 0.005279723554849625
Epoch 98, Training Loss: 0.005279727280139923, Validation Loss: 0.004358046688139439
Epoch 99, Training Loss: 0.004358046688139439, Validation Loss: 0.0037244046106934547
Epoch 100, Training Loss: 0.003724405076354742, Validation Loss: 0.003326002275571227
Epoch 101, Training Loss: 0.0033260048367083073, Validation Loss: 0.0030742334201931953
Epoch 102, Training Loss: 0.003074232954531908, Validation Loss: 0.0028927784878760576
Epoch 103, Training Loss: 0.002892778953537345, Validation Loss: 0.002726734383031726
Epoch 104, Training Loss: 0.0027267360128462315, Validation Loss: 0.0025476121809333563
Epoch 105, Training Loss: 0.0025476086884737015, Validation Loss: 0.0023437722120434046
Epoch 106, Training Loss: 0.00234377128072083, Validation Loss: 0.002120132325217128
Epoch 107, Training Loss: 0.002120132092386484, Validation Loss: 0.0018952202517539263
Epoch 108, Training Loss: 0.0018952202517539263, Validation Loss: 0.0016769901849329472
Epoch 109, Training Loss: 0.0016769890207797289, Validation Loss: 0.001476363861002028
Epoch 110, Training Loss: 0.001476365141570568, Validation Loss: 0.0013026841916143894
Epoch 111, Training Loss: 0.0013026843080297112, Validation Loss: 0.001160481246188283
Epoch 112, Training Loss: 0.0011604822939261794, Validation Loss: 0.001046724384650588
Epoch 113, Training Loss: 0.00104672578163445, Validation Loss: 0.0009556824807077646
Epoch 114, Training Loss: 0.0009556824225001037, Validation Loss: 0.0008795402245596051
Epoch 115, Training Loss: 0.0008795409230515361, Validation Loss: 0.0008105309098027647
Epoch 116, Training Loss: 0.0008105312590487301, Validation Loss: 0.0007451956626027822
Epoch 117, Training Loss: 0.0007451956626027822, Validation Loss: 0.0006805840530432761
Epoch 118, Training Loss: 0.000680584751535207, Validation Loss: 0.0006135086296126246
Epoch 119, Training Loss: 0.0006135082221589983, Validation Loss: 0.000544575450476259
Epoch 120, Training Loss: 0.0005445744609460235, Validation Loss: 0.0004765848570968956
Epoch 121, Training Loss: 0.00047658453695476055, Validation Loss: 0.00041282724123448133
Epoch 122, Training Loss: 0.0004128271248191595, Validation Loss: 0.0003563063801266253
Epoch 123, Training Loss: 0.0003563060599844903, Validation Loss: 0.0003090804093517363
Epoch 124, Training Loss: 0.0003090804675593972, Validation Loss: 0.00027165605570189655
Epoch 125, Training Loss: 0.0002716556773521006, Validation Loss: 0.00024332221073564142
Epoch 126, Training Loss: 0.00024332193424925208, Validation Loss: 0.0002225440548500046
Epoch 127, Training Loss: 0.0002225440548500046, Validation Loss: 0.0002065648150164634
Epoch 128, Training Loss: 0.00020656496053561568, Validation Loss: 0.00019280158448964357
Epoch 129, Training Loss: 0.00019280177366454154, Validation Loss: 0.0001791377435438335
Epoch 130, Training Loss: 0.00017913775809574872, Validation Loss: 0.00016419729217886925
Epoch 131, Training Loss: 0.0001641972630750388, Validation Loss: 0.00014750017726328224
Epoch 132, Training Loss: 0.00014749981346540153, Validation Loss: 0.00012973415141459554
Epoch 133, Training Loss: 0.00012973403499927372, Validation Loss: 0.0001113842154154554
Epoch 134, Training Loss: 0.00011138417175970972, Validation Loss: 9.370758198201656e-05
Epoch 135, Training Loss: 9.37076547415927e-05, Validation Loss: 7.799406012054533e-05
Epoch 136, Training Loss: 7.799424201948568e-05, Validation Loss: 6.519664020743221e-05
Epoch 137, Training Loss: 6.519676389871165e-05, Validation Loss: 5.579462231253274e-05
Epoch 138, Training Loss: 5.5794687796151266e-05, Validation Loss: 4.9750949983717874e-05
Epoch 139, Training Loss: 4.975100819137879e-05, Validation Loss: 4.657575118471868e-05
Epoch 140, Training Loss: 4.6575762098655105e-05, Validation Loss: 4.546686614048667e-05
Epoch 141, Training Loss: 4.5467088057193905e-05, Validation Loss: 4.5490982301998883e-05
Epoch 142, Training Loss: 4.54910405096598e-05, Validation Loss: 4.575891580316238e-05
Epoch 143, Training Loss: 4.5758799387840554e-05, Validation Loss: 4.5563934691017494e-05
Epoch 144, Training Loss: 4.55640911241062e-05, Validation Loss: 4.4467091356636956e-05
Epoch 145, Training Loss: 4.446720777195878e-05, Validation Loss: 4.2315092287026346e-05
Epoch 146, Training Loss: 4.231498314766213e-05, Validation Loss: 3.920595918316394e-05
Epoch 147, Training Loss: 3.920595190720633e-05, Validation Loss: 3.5417888284428045e-05
Epoch 148, Training Loss: 3.5417724575381726e-05, Validation Loss: 3.1315510568674654e-05
Epoch 149, Training Loss: 3.131550693069585e-05, Validation Loss: 2.7262745788902976e-05
Epoch 150, Training Loss: 2.7262734874966554e-05, Validation Loss: 2.355364995310083e-05
Epoch 151, Training Loss: 2.3553560822620057e-05, Validation Loss: 2.036897058133036e-05
Epoch 152, Training Loss: 2.0368814148241654e-05, Validation Loss: 1.7767686586012132e-05
Epoch 153, Training Loss: 1.7767704775906168e-05, Validation Loss: 1.5702804375905544e-05
Epoch 154, Training Loss: 1.5702742530265823e-05, Validation Loss: 1.4055654901312664e-05
Epoch 155, Training Loss: 1.4055691281100735e-05, Validation Loss: 1.2678588063863572e-05
Epoch 156, Training Loss: 1.2678596249315888e-05, Validation Loss: 1.1433491636125837e-05
Epoch 157, Training Loss: 1.1433718100306578e-05, Validation Loss: 1.0222307537333108e-05
Epoch 158, Training Loss: 1.0222276614513248e-05, Validation Loss: 8.998383236757945e-06
Epoch 159, Training Loss: 8.998480552691035e-06, Validation Loss: 7.765933332848363e-06
Epoch 160, Training Loss: 7.765912414470222e-06, Validation Loss: 6.566111096617533e-06
Epoch 161, Training Loss: 6.566252068296308e-06, Validation Loss: 5.459060048451647e-06
Epoch 162, Training Loss: 5.458952728076838e-06, Validation Loss: 4.5020119614491705e-06
Epoch 163, Training Loss: 4.502032879827311e-06, Validation Loss: 3.735105792657123e-06
Epoch 164, Training Loss: 3.735133986992878e-06, Validation Loss: 3.171086063957773e-06
Epoch 165, Training Loss: 3.1711135761725018e-06, Validation Loss: 2.794627107505221e-06
Epoch 166, Training Loss: 2.794663487293292e-06, Validation Loss: 2.5676010864117416e-06
Epoch 167, Training Loss: 2.567594037827803e-06, Validation Loss: 2.439218405925203e-06
Epoch 168, Training Loss: 2.4392268187511945e-06, Validation Loss: 2.3571310521219857e-06
Epoch 169, Training Loss: 2.3571617475681705e-06, Validation Loss: 2.2778597212891327e-06
Epoch 170, Training Loss: 2.277842440889799e-06, Validation Loss: 2.1726816612499533e-06
Epoch 171, Training Loss: 2.1727125840698136e-06, Validation Loss: 2.030673613262479e-06
Epoch 172, Training Loss: 2.0306717942730756e-06, Validation Loss: 1.8564762740425067e-06
Epoch 173, Training Loss: 1.8564468291515368e-06, Validation Loss: 1.6656658772262745e-06
Epoch 174, Training Loss: 1.6657011201459682e-06, Validation Loss: 1.47873765854456e-06
Epoch 175, Training Loss: 1.4787178770347964e-06, Validation Loss: 1.3142995385351242e-06
Epoch 176, Training Loss: 1.3143095429768437e-06, Validation Loss: 1.1850271448565763e-06
Epoch 177, Training Loss: 1.1850728469653404e-06, Validation Loss: 1.094962840397784e-06
Epoch 178, Training Loss: 1.0949603392873541e-06, Validation Loss: 1.039559379023558e-06
Epoch 179, Training Loss: 1.0395342542324215e-06, Validation Loss: 1.007859964374802e-06
Epoch 180, Training Loss: 1.0078590548801003e-06, Validation Loss: 9.858193834588747e-07
Epoch 181, Training Loss: 9.858476914814673e-07, Validation Loss: 9.599521035852376e-07
Epoch 182, Training Loss: 9.599738177712425e-07, Validation Loss: 9.200343811244238e-07
Epoch 183, Training Loss: 9.200127806252567e-07, Validation Loss: 8.611436896899249e-07
Epoch 184, Training Loss: 8.61168587107386e-07, Validation Loss: 7.83864834374981e-07
Epoch 185, Training Loss: 7.838885949240648e-07, Validation Loss: 6.934378120604379e-07
Epoch 186, Training Loss: 6.934399152669357e-07, Validation Loss: 5.976853003630822e-07
Epoch 187, Training Loss: 5.976589250167308e-07, Validation Loss: 5.049737978879421e-07
Epoch 188, Training Loss: 5.049324727224302e-07, Validation Loss: 4.2233884300912905e-07
Epoch 189, Training Loss: 4.223434757477662e-07, Validation Loss: 3.5420069366409734e-07
Epoch 190, Training Loss: 3.54175512029542e-07, Validation Loss: 3.017938183802471e-07
Epoch 191, Training Loss: 3.01772416833046e-07, Validation Loss: 2.6351457904638664e-07
Epoch 192, Training Loss: 2.6351935389357095e-07, Validation Loss: 2.3594381559632893e-07
Epoch 193, Training Loss: 2.3594918729941128e-07, Validation Loss: 2.1482489387381065e-07
Epoch 194, Training Loss: 2.1481557155311748e-07, Validation Loss: 1.9625466052275442e-07
Epoch 195, Training Loss: 1.9624195601863903e-07, Validation Loss: 1.7749248115705996e-07
Epoch 196, Training Loss: 1.7748826053320954e-07, Validation Loss: 1.5735864167254476e-07
Epoch 197, Training Loss: 1.573633454654555e-07, Validation Loss: 1.360769914526827e-07
Epoch 198, Training Loss: 1.3609809457193478e-07, Validation Loss: 1.1491763984849968e-07
Epoch 199, Training Loss: 1.1492411999824981e-07, Validation Loss: 9.55362864374365e-08
Epoch 200, Training Loss: 9.553630064829122e-08, Validation Loss: 7.948272440216897e-08
Epoch 201, Training Loss: 7.949373781457325e-08, Validation Loss: 6.77203786381142e-08
Epoch 202, Training Loss: 6.772336291760439e-08, Validation Loss: 6.03443339741716e-08
Epoch 203, Training Loss: 6.033598509702642e-08, Validation Loss: 5.672640668308304e-08
Epoch 204, Training Loss: 5.6730836917040506e-08, Validation Loss: 5.5671868892659404e-08
Epoch 205, Training Loss: 5.5674089338708654e-08, Validation Loss: 5.57905863729502e-08
Epoch 206, Training Loss: 5.578855422072593e-08, Validation Loss: 5.579032347213797e-08
Epoch 207, Training Loss: 5.579455120141574e-08, Validation Loss: 5.4790156411854696e-08
Epoch 208, Training Loss: 5.478741016418098e-08, Validation Loss: 5.233579969399216e-08
Epoch 209, Training Loss: 5.233220434774921e-08, Validation Loss: 4.850851453852556e-08
Epoch 210, Training Loss: 4.8506489491728644e-08, Validation Loss: 4.373875484020573e-08
Epoch 211, Training Loss: 4.3736903876379074e-08, Validation Loss: 3.859061337152525e-08
Epoch 212, Training Loss: 3.859377883941306e-08, Validation Loss: 3.3657222786587226e-08
Epoch 213, Training Loss: 3.36568923842151e-08, Validation Loss: 2.933936649185398e-08
Epoch 214, Training Loss: 2.9339757290358648e-08, Validation Loss: 2.5844267170782587e-08
Epoch 215, Training Loss: 2.5846397022633028e-08, Validation Loss: 2.3137571858455885e-08
Epoch 216, Training Loss: 2.3140476201888305e-08, Validation Loss: 2.103344520776318e-08
Epoch 217, Training Loss: 2.10298889413707e-08, Validation Loss: 1.9254501992804762e-08
Epoch 218, Training Loss: 1.925225490140292e-08, Validation Loss: 1.7554873110725566e-08
Epoch 219, Training Loss: 1.7552634901107922e-08, Validation Loss: 1.5777366968450224e-08
Epoch 220, Training Loss: 1.578120034650965e-08, Validation Loss: 1.3889413175149912e-08
Epoch 221, Training Loss: 1.3887383687460897e-08, Validation Loss: 1.1936442945170711e-08
Epoch 222, Training Loss: 1.1936096555587028e-08, Validation Loss: 1.0069963529701909e-08
Epoch 223, Training Loss: 1.0068029965282221e-08, Validation Loss: 8.443607590891133e-09
Epoch 224, Training Loss: 8.441895182897952e-09, Validation Loss: 7.167781479466839e-09
Epoch 225, Training Loss: 7.166971460748073e-09, Validation Loss: 6.301039245926177e-09
Epoch 226, Training Loss: 6.3026330821003285e-09, Validation Loss: 5.826104487738348e-09
Epoch 227, Training Loss: 5.826351845428235e-09, Validation Loss: 5.642163625196872e-09
Epoch 228, Training Loss: 5.645289125055797e-09, Validation Loss: 5.630611976670252e-09
Epoch 229, Training Loss: 5.633325805831646e-09, Validation Loss: 5.652361689811869e-09
Epoch 230, Training Loss: 5.649699374998818e-09, Validation Loss: 5.586886064889995e-09
Epoch 231, Training Loss: 5.582919015978405e-09, Validation Loss: 5.370868194631839e-09
Epoch 232, Training Loss: 5.3710422776021005e-09, Validation Loss: 4.994658464596569e-09
Epoch 233, Training Loss: 4.995148294995033e-09, Validation Loss: 4.480915638538363e-09
Epoch 234, Training Loss: 4.4817616284831274e-09, Validation Loss: 3.895732625380788e-09
Epoch 235, Training Loss: 3.8953396064300705e-09, Validation Loss: 3.3046145819781714e-09
Epoch 236, Training Loss: 3.30335980791574e-09, Validation Loss: 2.7650066680706686e-09
Epoch 237, Training Loss: 2.765749407274143e-09, Validation Loss: 2.3226636169937365e-09
Epoch 238, Training Loss: 2.3225186218667204e-09, Validation Loss: 1.984391539977537e-09
Epoch 239, Training Loss: 1.9847270493755786e-09, Validation Loss: 1.7388541717622275e-09
Epoch 240, Training Loss: 1.7395271889597552e-09, Validation Loss: 1.5616617998759352e-09
Epoch 241, Training Loss: 1.5605295944354225e-09, Validation Loss: 1.4171845919008774e-09
Epoch 242, Training Loss: 1.4170379314393244e-09, Validation Loss: 1.2813714533876919e-09
Epoch 243, Training Loss: 1.2830052575907303e-09, Validation Loss: 1.1365165475396566e-09
Epoch 244, Training Loss: 1.138371175102293e-09, Validation Loss: 9.831464531373513e-10
Epoch 245, Training Loss: 9.824130398072839e-10, Validation Loss: 8.238419946238196e-10
Epoch 246, Training Loss: 8.24798174203778e-10, Validation Loss: 6.778746453051099e-10
Epoch 247, Training Loss: 6.775485728027775e-10, Validation Loss: 5.54385815032532e-10
Epoch 248, Training Loss: 5.540385927815805e-10, Validation Loss: 4.6415427057411307e-10
Epoch 249, Training Loss: 4.639644501924778e-10, Validation Loss: 4.104744044663988e-10
Epoch 250, Training Loss: 4.0985800864312694e-10, Validation Loss: 3.8757319575921656e-10
Epoch 251, Training Loss: 3.879584986599127e-10, Validation Loss: 3.8717215544714634e-10
Epoch 252, Training Loss: 3.8659414558495087e-10, Validation Loss: 3.957768834883524e-10
Epoch 253, Training Loss: 3.9559228115493283e-10, Validation Loss: 4.028871125605349e-10
Epoch 254, Training Loss: 4.029910016800642e-10, Validation Loss: 4.019107824326795e-10
Epoch 255, Training Loss: 4.0121467259623955e-10, Validation Loss: 3.891038879988429e-10
Epoch 256, Training Loss: 3.8832417836864863e-10, Validation Loss: 3.646719870520343e-10
Epoch 257, Training Loss: 3.6490419019763465e-10, Validation Loss: 3.35516281424475e-10
Epoch 258, Training Loss: 3.349973631827652e-10, Validation Loss: 3.0395189143384016e-10
Epoch 259, Training Loss: 3.038583551440155e-10, Validation Loss: 2.751560923552887e-10
Epoch 260, Training Loss: 2.7430976934361695e-10, Validation Loss: 2.5063184860840693e-10
Epoch 261, Training Loss: 2.5018609406401993e-10, Validation Loss: 2.3070244326017786e-10
Epoch 262, Training Loss: 2.2997009851977168e-10, Validation Loss: 2.1481458278849175e-10
Epoch 263, Training Loss: 2.1434311270329687e-10, Validation Loss: 1.998194110175433e-10
Epoch 264, Training Loss: 1.993235576591701e-10, Validation Loss: 1.8216438080198571e-10
Epoch 265, Training Loss: 1.8266289869561803e-10, Validation Loss: 1.6267934221936287e-10
Epoch 266, Training Loss: 1.628845391898892e-10, Validation Loss: 1.4108604562412808e-10
Epoch 267, Training Loss: 1.4092338407323268e-10, Validation Loss: 1.1734388460915568e-10
Epoch 268, Training Loss: 1.1790787790566526e-10, Validation Loss: 9.431632558287717e-11
Epoch 269, Training Loss: 9.444479920350801e-11, Validation Loss: 7.388064465763122e-11
Epoch 270, Training Loss: 7.400201978979837e-11, Validation Loss: 5.746183390220594e-11
Epoch 271, Training Loss: 5.7220270188729216e-11, Validation Loss: 4.568760994527743e-11
Epoch 272, Training Loss: 4.5559542249939966e-11, Validation Loss: 3.8750461173187034e-11
Epoch 273, Training Loss: 3.864876821357832e-11, Validation Loss: 3.5245081159152036e-11
Epoch 274, Training Loss: 3.529374709154709e-11, Validation Loss: 3.4223165967794955e-11
Epoch 275, Training Loss: 3.423226632714993e-11, Validation Loss: 3.378355234451291e-11
Epoch 276, Training Loss: 3.362882541879664e-11, Validation Loss: 3.253681699066924e-11
Epoch 277, Training Loss: 3.276749011016378e-11, Validation Loss: 3.0803592315775674e-11
Epoch 278, Training Loss: 3.101023257623403e-11, Validation Loss: 2.8336829410724462e-11
Epoch 279, Training Loss: 2.8231224649677422e-11, Validation Loss: 2.514377248075128e-11
Epoch 280, Training Loss: 2.5112250820469306e-11, Validation Loss: 2.170931490130812e-11
Epoch 281, Training Loss: 2.1817847875582608e-11, Validation Loss: 1.8915442129285864e-11
Epoch 282, Training Loss: 1.8842625376658262e-11, Validation Loss: 1.659375935270102e-11
Epoch 283, Training Loss: 1.661396020757877e-11, Validation Loss: 1.5157167188029064e-11
Epoch 284, Training Loss: 1.5285633869766002e-11, Validation Loss: 1.46642854109702e-11
Epoch 285, Training Loss: 1.459536137782269e-11, Validation Loss: 1.455964689089928e-11
Epoch 286, Training Loss: 1.4533007609840443e-11, Validation Loss: 1.4208996826359233e-11
Epoch 287, Training Loss: 1.4242637451367113e-11, Validation Loss: 1.4009461125896738e-11
Epoch 288, Training Loss: 1.3996455036635602e-11, Validation Loss: 1.3373285985551764e-11
Epoch 289, Training Loss: 1.3349360679371092e-11, Validation Loss: 1.252309800997553e-11
Epoch 290, Training Loss: 1.2602402628403286e-11, Validation Loss: 1.1501246136025323e-11
Epoch 291, Training Loss: 1.1358767225411182e-11, Validation Loss: 1.015272501486697e-11
Epoch 292, Training Loss: 1.0067446876149688e-11, Validation Loss: 8.828669566252056e-12
Epoch 293, Training Loss: 8.739775396449101e-12, Validation Loss: 7.507074822887816e-12
Epoch 294, Training Loss: 7.441118901607702e-12, Validation Loss: 6.4626659058986125e-12
Epoch 295, Training Loss: 6.483100081083881e-12, Validation Loss: 5.590706717018001e-12
Epoch 296, Training Loss: 5.468461187346785e-12, Validation Loss: 4.8173283938302e-12
Epoch 297, Training Loss: 4.859780546734305e-12, Validation Loss: 4.235071494884668e-12
Epoch 298, Training Loss: 4.258704500159638e-12, Validation Loss: 3.661369818441784e-12
Epoch 299, Training Loss: 3.655120910800447e-12, Validation Loss: 3.3509933109604484e-12
Epoch 300, Training Loss: 3.2638666075390788e-12, Validation Loss: 2.91460323757764e-12
Epoch 301, Training Loss: 2.9332825231265236e-12, Validation Loss: 2.5537584200097108e-12
Epoch 302, Training Loss: 2.6043308135048626e-12, Validation Loss: 2.2838981140332892e-12
Epoch 303, Training Loss: 2.275799774326126e-12, Validation Loss: 2.0665019175025723e-12
Epoch 304, Training Loss: 2.0738491219446376e-12, Validation Loss: 1.8730253893012305e-12
Epoch 305, Training Loss: 1.8351552916184843e-12, Validation Loss: 1.6486105015867114e-12
Epoch 306, Training Loss: 1.6512281993119604e-12, Validation Loss: 1.5023866482485881e-12
Epoch 307, Training Loss: 1.4942708528864479e-12, Validation Loss: 1.3238988898212067e-12
Epoch 308, Training Loss: 1.3263663171253492e-12, Validation Loss: 1.1907140854902631e-12
Epoch 309, Training Loss: 1.225669739313151e-12, Validation Loss: 1.1050813042423613e-12
Epoch 310, Training Loss: 1.1149711796193396e-12, Validation Loss: 9.853398479087172e-13
Epoch 311, Training Loss: 1.004019133457601e-12, Validation Loss: 9.052360098495138e-13
Epoch 312, Training Loss: 9.094846186927241e-13, Validation Loss: 7.675248240787691e-13
Epoch 313, Training Loss: 8.259970398633021e-13, Validation Loss: 7.113660788898857e-13
Epoch 314, Training Loss: 7.317856715559345e-13, Validation Loss: 5.951517490637714e-13
Epoch 315, Training Loss: 6.112228778665241e-13, Validation Loss: 4.959358661585367e-13
Epoch 316, Training Loss: 5.03230974686214e-13, Validation Loss: 4.58357147809646e-13
Epoch 317, Training Loss: 4.3722618299317506e-13, Validation Loss: 3.686331567689244e-13
Epoch 318, Training Loss: 3.850289499122278e-13, Validation Loss: 3.110957129924541e-13
Epoch 319, Training Loss: 3.343792256971234e-13, Validation Loss: 3.0087545410846517e-13
Epoch 320, Training Loss: 2.98335547889092e-13, Validation Loss: 2.6451329191226614e-13
Epoch 321, Training Loss: 2.793861875790421e-13, Validation Loss: 2.6358212487642696e-13
Epoch 322, Training Loss: 2.639752294791159e-13, Validation Loss: 2.5537840071809814e-13
Epoch 323, Training Loss: 2.5229108082183704e-13, Validation Loss: 2.359984495152456e-13
Epoch 324, Training Loss: 2.4717673654389705e-13, Validation Loss: 2.2137848466278337e-13
Epoch 325, Training Loss: 2.3840364361468747e-13, Validation Loss: 2.1509581767630015e-13
Epoch 326, Training Loss: 2.2372879102724313e-13, Validation Loss: 2.0415247725842633e-13
Epoch 327, Training Loss: 2.1300529970489507e-13, Validation Loss: 1.9513978920162461e-13
Epoch 328, Training Loss: 2.0447630134229344e-13, Validation Loss: 1.8800332655683621e-13
Epoch 329, Training Loss: 1.965089197050393e-13, Validation Loss: 1.7484395821356497e-13
Epoch 330, Training Loss: 1.838229546878567e-13, Validation Loss: 1.5554826307204173e-13
Epoch 331, Training Loss: 1.6453803380542253e-13, Validation Loss: 1.3616557425870368e-13
Epoch 332, Training Loss: 1.4188460519329316e-13, Validation Loss: 1.1902536790377172e-13
Epoch 333, Training Loss: 1.2812704185388019e-13, Validation Loss: 1.0563535587709491e-13
Epoch 334, Training Loss: 1.0527206005788575e-13, Validation Loss: 8.704111921237906e-14
Epoch 335, Training Loss: 9.260118577969143e-14, Validation Loss: 8.014579668327859e-14
Epoch 336, Training Loss: 8.137439425634843e-14, Validation Loss: 5.386382800291051e-14
Epoch 337, Training Loss: 7.036325732137638e-14, Validation Loss: 5.397117418238194e-14
Epoch 338, Training Loss: 6.216116624256987e-14, Validation Loss: 4.6017416223051444e-14
Epoch 339, Training Loss: 4.353907574641651e-14, Validation Loss: 3.597678931025264e-14
Epoch 340, Training Loss: 4.192032802157776e-14, Validation Loss: 4.038443028337585e-14
Epoch 341, Training Loss: 3.262190525848106e-14, Validation Loss: 3.54671058689672e-14
Epoch 342, Training Loss: 3.051963046976809e-14, Validation Loss: 2.8885331220017754e-14
Epoch 343, Training Loss: 2.7071677825884002e-14, Validation Loss: 2.877498654391304e-14
Epoch 344, Training Loss: 2.6482452908653704e-14, Validation Loss: 2.6693442039551173e-14
Epoch 345, Training Loss: 2.7041687777353517e-14, Validation Loss: 2.3296087755804266e-14
Epoch 346, Training Loss: 2.595004865559112e-14, Validation Loss: 2.561281773423487e-14
Epoch 347, Training Loss: 2.0881921883385106e-14, Validation Loss: 2.572750091309542e-14
Epoch 348, Training Loss: 1.9483643282189496e-14, Validation Loss: 3.1710741752724245e-14
Epoch 349, Training Loss: 1.796025960875032e-14, Validation Loss: 2.5087247342990733e-14
Epoch 350, Training Loss: 1.8280724359948618e-14, Validation Loss: 2.460620039158607e-14
Epoch 351, Training Loss: 1.853573718124668e-14, Validation Loss: 1.975256269041558e-14
Epoch 352, Training Loss: 1.9526677638107698e-14, Validation Loss: 1.8822142737635883e-14
Epoch 353, Training Loss: 1.5157486878592148e-14, Validation Loss: 1.615444804564225e-14
Epoch 354, Training Loss: 1.5083257993292465e-14, Validation Loss: 1.5375523323610772e-14
Epoch 355, Training Loss: 1.4012014577867004e-14, Validation Loss: 1.5445791482849094e-14
Epoch 356, Training Loss: 1.8419544589674125e-14, Validation Loss: 1.3305359553928212e-14
Epoch 357, Training Loss: 1.2208367183939167e-14, Validation Loss: 1.2409482451770492e-14
Epoch 358, Training Loss: 1.1257894573166172e-14, Validation Loss: 1.0952779753038017e-14
Epoch 359, Training Loss: 9.752897443913045e-15, Validation Loss: 1.3038211291594836e-14
Epoch 360, Training Loss: 8.695766444421788e-15, Validation Loss: 1.2132443385712028e-14
Epoch 361, Training Loss: 8.072584823369013e-15, Validation Loss: 8.708557488958275e-15
Epoch 362, Training Loss: 6.7107684494538584e-15, Validation Loss: 1.1760772951753366e-14
Epoch 363, Training Loss: 6.472844517866651e-15, Validation Loss: 9.860402865578561e-15
Epoch 364, Training Loss: 6.257855697392248e-15, Validation Loss: 9.424944074428072e-15
Epoch 365, Training Loss: 6.1306203372863376e-15, Validation Loss: 1.0706228790883024e-14
Epoch 366, Training Loss: 6.142963724910201e-15, Validation Loss: 9.401964070569063e-15
Epoch 367, Training Loss: 5.225812119732769e-15, Validation Loss: 9.109140545538515e-15
Epoch 368, Training Loss: 5.35985254253692e-15, Validation Loss: 8.51832320636738e-15
Epoch 369, Training Loss: 4.983167673530513e-15, Validation Loss: 6.534345039067944e-15
Epoch 370, Training Loss: 4.251514589735878e-15, Validation Loss: 7.052859645861453e-15
Epoch 371, Training Loss: 4.44031569258002e-15, Validation Loss: 7.722390909787984e-15
Epoch 372, Training Loss: 4.705628434516695e-15, Validation Loss: 7.429995136395799e-15
Epoch 373, Training Loss: 4.353679468668955e-15, Validation Loss: 7.227411113433935e-15
Epoch 374, Training Loss: 3.417646228547804e-15, Validation Loss: 5.652148366041328e-15
Epoch 375, Training Loss: 3.6402414048885504e-15, Validation Loss: 5.433372884776225e-15
Epoch 376, Training Loss: 2.926319050020553e-15, Validation Loss: 5.4241126970803674e-15
Epoch 377, Training Loss: 3.26405649707926e-15, Validation Loss: 5.38141164862691e-15
Epoch 378, Training Loss: 2.7786174680848475e-15, Validation Loss: 5.819659719272707e-15
Epoch 379, Training Loss: 2.8927087826735023e-15, Validation Loss: 5.5629320797729274e-15
Epoch 380, Training Loss: 2.9106398348921654e-15, Validation Loss: 4.83673854683982e-15
Epoch 381, Training Loss: 2.3307667966742654e-15, Validation Loss: 5.980446901452307e-15
Epoch 382, Training Loss: 2.703265417097105e-15, Validation Loss: 5.793546964058278e-15
Epoch 383, Training Loss: 2.1878774206701484e-15, Validation Loss: 5.793546964058278e-15
Epoch 384, Training Loss: 2.014938703829238e-15, Validation Loss: 5.760557148345091e-15
Epoch 385, Training Loss: 1.9830466428156926e-15, Validation Loss: 6.231868303054012e-15
Epoch 386, Training Loss: 2.5550382512176282e-15, Validation Loss: 5.748867670156508e-15
Epoch 387, Training Loss: 2.654067625938207e-15, Validation Loss: 5.713639146363728e-15
Epoch 388, Training Loss: 1.9924789899580797e-15, Validation Loss: 7.514999974850452e-15
Epoch 389, Training Loss: 1.9924789899580797e-15, Validation Loss: 4.595566243899892e-15
Epoch 390, Training Loss: 1.8995046302609482e-15, Validation Loss: 5.802741930217197e-15
Epoch 391, Training Loss: 2.1136345593268354e-15, Validation Loss: 5.194724316502641e-15
Epoch 392, Training Loss: 1.9266598712752107e-15, Validation Loss: 4.442808510543789e-15
Epoch 393, Training Loss: 1.6458766019525274e-15, Validation Loss: 3.497784439204007e-15
Epoch 394, Training Loss: 1.4046832290680366e-15, Validation Loss: 4.628135931271241e-15
Epoch 395, Training Loss: 1.0598067765716333e-15, Validation Loss: 2.7947083412256006e-15
Epoch 396, Training Loss: 1.2415525184816204e-15, Validation Loss: 2.6922262484537765e-15
Epoch 397, Training Loss: 2.0967627218087138e-15, Validation Loss: 2.5977505228576368e-15
Epoch 398, Training Loss: 2.123300475804428e-15, Validation Loss: 2.5577184752209776e-15
Epoch 399, Training Loss: 2.038307495811037e-15, Validation Loss: 2.5577184752209776e-15
Epoch 400, Training Loss: 1.82168411350667e-15, Validation Loss: 2.974986175037996e-15
Epoch 401, Training Loss: 1.5190415707933133e-15, Validation Loss: 2.945629283635583e-15
Epoch 402, Training Loss: 1.7615692323279665e-15, Validation Loss: 3.802752722632287e-15
Epoch 403, Training Loss: 2.6168043172478854e-15, Validation Loss: 3.2561814200104e-15
Epoch 404, Training Loss: 2.6071299304408204e-15, Validation Loss: 3.618940643847473e-15
Epoch 405, Training Loss: 2.4361262603679124e-15, Validation Loss: 2.8987949261577613e-15
Epoch 406, Training Loss: 2.660839654351505e-15, Validation Loss: 2.874775824630708e-15
Epoch 407, Training Loss: 2.079749006271927e-15, Validation Loss: 2.874775824630708e-15
Epoch 408, Training Loss: 1.8391395567254496e-15, Validation Loss: 6.887330773243123e-15
Epoch 409, Training Loss: 2.093276545956052e-15, Validation Loss: 6.970063869333239e-15
Epoch 410, Training Loss: 2.0714756119596207e-15, Validation Loss: 3.604967141316619e-15
Epoch 411, Training Loss: 2.152340576884568e-15, Validation Loss: 3.5016843906514024e-15
Epoch 412, Training Loss: 1.959719567206546e-15, Validation Loss: 3.0930068754689635e-15
Epoch 413, Training Loss: 1.4036073913459052e-15, Validation Loss: 3.5361620197364415e-15
Epoch 414, Training Loss: 1.289115641931436e-15, Validation Loss: 2.5150771425903017e-15
Epoch 415, Training Loss: 1.4175935993709682e-15, Validation Loss: 3.5044865873991565e-15
Epoch 416, Training Loss: 1.341549310707082e-15, Validation Loss: 3.4544881383468664e-15
Epoch 417, Training Loss: 1.7172504568243718e-15, Validation Loss: 3.4544881383468664e-15
Epoch 418, Training Loss: 1.7042400307545457e-15, Validation Loss: 3.4544881383468664e-15
Epoch 419, Training Loss: 1.7042400307545457e-15, Validation Loss: 3.4544881383468664e-15
Epoch 420, Training Loss: 1.6248430798063086e-15, Validation Loss: 3.4058241897029756e-15
Epoch 421, Training Loss: 2.0783562723484042e-15, Validation Loss: 3.4058241897029756e-15
Epoch 422, Training Loss: 1.2113867106145794e-15, Validation Loss: 3.863494725829314e-15
Epoch 423, Training Loss: 1.1687851885324244e-15, Validation Loss: 3.613764001990328e-15
Epoch 424, Training Loss: 1.523002190975556e-15, Validation Loss: 3.737272840644793e-15
Epoch 425, Training Loss: 1.5293407502780967e-15, Validation Loss: 3.812400851417987e-15
Epoch 426, Training Loss: 1.0478385186642853e-15, Validation Loss: 4.3601753643414485e-15
Epoch 427, Training Loss: 1.0478559887188224e-15, Validation Loss: 4.360427356643257e-15
Epoch 428, Training Loss: 1.515431939888589e-15, Validation Loss: 4.184538847563533e-15
Epoch 429, Training Loss: 1.951082372243394e-15, Validation Loss: 4.184538847563533e-15
Epoch 430, Training Loss: 1.951082372243394e-15, Validation Loss: 3.9779733462331004e-15
Epoch 431, Training Loss: 2.210490235746523e-15, Validation Loss: 3.286218902385932e-15
Epoch 432, Training Loss: 2.2151605636594462e-15, Validation Loss: 3.0896865063157267e-15
Epoch 433, Training Loss: 1.6006682300960789e-15, Validation Loss: 3.253150736125124e-15
Epoch 434, Training Loss: 1.3329869722806436e-15, Validation Loss: 3.1650802736761215e-15
Epoch 435, Training Loss: 9.438751770259502e-16, Validation Loss: 3.1650802736761215e-15
Epoch 436, Training Loss: 8.741526128847781e-16, Validation Loss: 2.2315320164639774e-15
Epoch 437, Training Loss: 7.281022687401857e-16, Validation Loss: 3.0600627995349284e-15
Epoch 438, Training Loss: 7.281022687401857e-16, Validation Loss: 3.1213202222803594e-15
Epoch 439, Training Loss: 7.064182252904756e-16, Validation Loss: 3.1213202222803594e-15
Epoch 440, Training Loss: 7.064182252904756e-16, Validation Loss: 3.615174311847507e-15
Epoch 441, Training Loss: 1.2038167771649677e-15, Validation Loss: 3.615174311847507e-15
Epoch 442, Training Loss: 1.2038167771649677e-15, Validation Loss: 3.615174311847507e-15
Epoch 443, Training Loss: 1.203016225150694e-15, Validation Loss: 4.180827572705138e-15
Epoch 444, Training Loss: 1.203016225150694e-15, Validation Loss: 4.521767651337414e-15
Epoch 445, Training Loss: 1.203016225150694e-15, Validation Loss: 4.510425033140732e-15
Epoch 446, Training Loss: 1.203016225150694e-15, Validation Loss: 3.703912024500709e-15
Epoch 447, Training Loss: 1.203016225150694e-15, Validation Loss: 3.703912024500709e-15
Epoch 448, Training Loss: 1.203016225150694e-15, Validation Loss: 3.63986066357876e-15
Epoch 449, Training Loss: 1.15064089576929e-15, Validation Loss: 3.296335440391464e-15
Epoch 450, Training Loss: 1.1439021133991716e-15, Validation Loss: 3.2653189996871427e-15
Epoch 451, Training Loss: 1.150240566822594e-15, Validation Loss: 3.2653189996871427e-15
Epoch 452, Training Loss: 1.151041224715986e-15, Validation Loss: 3.2653189996871427e-15
Epoch 453, Training Loss: 1.534548520596053e-15, Validation Loss: 3.2653189996871427e-15
Epoch 454, Training Loss: 7.996262602019309e-16, Validation Loss: 3.2653189996871427e-15
Epoch 455, Training Loss: 2.477172735838027e-16, Validation Loss: 3.2653189996871427e-15
Epoch 456, Training Loss: 7.194286513603017e-16, Validation Loss: 3.2653189996871427e-15
Epoch 457, Training Loss: 2.991584844430628e-16, Validation Loss: 3.1737621496272413e-15
Epoch 458, Training Loss: 1.3820262623992865e-15, Validation Loss: 3.216462986322462e-15
Epoch 459, Training Loss: 1.409047989845238e-15, Validation Loss: 3.8930053537116534e-15
Epoch 460, Training Loss: 1.409047989845238e-15, Validation Loss: 3.8930053537116534e-15
Epoch 461, Training Loss: 1.409047989845238e-15, Validation Loss: 3.8930053537116534e-15
Epoch 462, Training Loss: 1.409047989845238e-15, Validation Loss: 3.8930053537116534e-15
Epoch 463, Training Loss: 2.296959594166978e-15, Validation Loss: 3.8930053537116534e-15
Epoch 464, Training Loss: 2.296959594166978e-15, Validation Loss: 3.889419016212979e-15
Epoch 465, Training Loss: 1.550494656981944e-15, Validation Loss: 3.6222716009125504e-15
Epoch 466, Training Loss: 8.147049819102743e-16, Validation Loss: 3.6222716009125504e-15
Epoch 467, Training Loss: 7.559912520450072e-16, Validation Loss: 3.6222716009125504e-15
Epoch 468, Training Loss: 1.4392054332619249e-15, Validation Loss: 3.6222716009125504e-15
Epoch 469, Training Loss: 1.4622238712409157e-15, Validation Loss: 3.6222716009125504e-15
Epoch 470, Training Loss: 1.3597417784690915e-15, Validation Loss: 3.6115964446783045e-15
Epoch 471, Training Loss: 6.813314387334082e-16, Validation Loss: 3.6115964446783045e-15
Epoch 472, Training Loss: 8.708166265615762e-16, Validation Loss: 3.608093539924934e-15
Epoch 473, Training Loss: 4.608880966556019e-16, Validation Loss: 3.5091810557510766e-15
Epoch 474, Training Loss: 4.2165665397277574e-16, Validation Loss: 2.9903653287448187e-15
Epoch 475, Training Loss: 7.80344137492838e-16, Validation Loss: 3.0432074791592783e-15
Epoch 476, Training Loss: 7.80344137492838e-16, Validation Loss: 3.040455469113649e-15
Epoch 477, Training Loss: 7.80344137492838e-16, Validation Loss: 2.9944183813974306e-15
Epoch 478, Training Loss: 7.683344808501929e-16, Validation Loss: 2.9944183813974306e-15
Epoch 479, Training Loss: 8.76487829780799e-16, Validation Loss: 2.9944183813974306e-15
Epoch 480, Training Loss: 8.76487829780799e-16, Validation Loss: 3.1065083688899603e-15
Epoch 481, Training Loss: 4.2332467360415627e-16, Validation Loss: 3.534584632630417e-15
Epoch 482, Training Loss: 1.2148923682250281e-15, Validation Loss: 3.5277791464157025e-15
Epoch 483, Training Loss: 1.6248208451914432e-15, Validation Loss: 3.717097786390617e-15
Epoch 484, Training Loss: 1.6248208451914432e-15, Validation Loss: 3.5569691723275065e-15
Epoch 485, Training Loss: 2.0603699512299328e-15, Validation Loss: 3.6770657387539575e-15
Epoch 486, Training Loss: 2.0579679775497564e-15, Validation Loss: 3.5198062370414345e-15
Epoch 487, Training Loss: 2.0579679775497564e-15, Validation Loss: 3.5401557800827455e-15
Epoch 488, Training Loss: 2.0702444495707866e-15, Validation Loss: 3.1355982331557515e-15
Epoch 489, Training Loss: 1.763398611735799e-15, Validation Loss: 3.167623913616726e-15
Epoch 490, Training Loss: 2.1222861538500908e-15, Validation Loss: 3.2156625401873066e-15
Epoch 491, Training Loss: 1.5184689765209694e-15, Validation Loss: 3.2156625401873066e-15
Epoch 492, Training Loss: 9.42273861239166e-16, Validation Loss: 2.7384799648462552e-15
Epoch 493, Training Loss: 1.7666678412748453e-15, Validation Loss: 2.7347437025159165e-15
Epoch 494, Training Loss: 1.2238329068624157e-15, Validation Loss: 2.8397112017132216e-15
Epoch 495, Training Loss: 2.1140796751406175e-15, Validation Loss: 4.0262622710395945e-15
Epoch 496, Training Loss: 2.2254354968261145e-15, Validation Loss: 4.0262622710395945e-15
Epoch 497, Training Loss: 2.120351318840325e-15, Validation Loss: 3.859461578450962e-15
Epoch 498, Training Loss: 1.6079406432229675e-15, Validation Loss: 3.859461578450962e-15
Epoch 499, Training Loss: 1.6079406432229675e-15, Validation Loss: 3.859461578450962e-15
Epoch 500, Training Loss: 2.0162679102817167e-15, Validation Loss: 3.690659770524442e-15
