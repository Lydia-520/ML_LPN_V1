Epoch 1, Training Loss: 0.4431743919849396, Validation Loss: 0.44199836254119873
Epoch 2, Training Loss: 0.44199830293655396, Validation Loss: 0.4408884346485138
Epoch 3, Training Loss: 0.4408884644508362, Validation Loss: 0.4398341476917267
Epoch 4, Training Loss: 0.4398340880870819, Validation Loss: 0.4387854337692261
Epoch 5, Training Loss: 0.4387854337692261, Validation Loss: 0.4377327859401703
Epoch 6, Training Loss: 0.4377327859401703, Validation Loss: 0.4366896152496338
Epoch 7, Training Loss: 0.4366895258426666, Validation Loss: 0.4356520473957062
Epoch 8, Training Loss: 0.4356520473957062, Validation Loss: 0.43459227681159973
Epoch 9, Training Loss: 0.43459227681159973, Validation Loss: 0.4335179030895233
Epoch 10, Training Loss: 0.4335178732872009, Validation Loss: 0.4324454665184021
Epoch 11, Training Loss: 0.4324454665184021, Validation Loss: 0.43137192726135254
Epoch 12, Training Loss: 0.43137192726135254, Validation Loss: 0.4302952289581299
Epoch 13, Training Loss: 0.4302952289581299, Validation Loss: 0.4292129874229431
Epoch 14, Training Loss: 0.4292129576206207, Validation Loss: 0.42814579606056213
Epoch 15, Training Loss: 0.42814579606056213, Validation Loss: 0.42712533473968506
Epoch 16, Training Loss: 0.42712533473968506, Validation Loss: 0.4260790944099426
Epoch 17, Training Loss: 0.4260790944099426, Validation Loss: 0.42500731348991394
Epoch 18, Training Loss: 0.42500731348991394, Validation Loss: 0.4239247441291809
Epoch 19, Training Loss: 0.4239247441291809, Validation Loss: 0.422835111618042
Epoch 20, Training Loss: 0.422835111618042, Validation Loss: 0.42172616720199585
Epoch 21, Training Loss: 0.42172619700431824, Validation Loss: 0.42058709263801575
Epoch 22, Training Loss: 0.42058709263801575, Validation Loss: 0.41939523816108704
Epoch 23, Training Loss: 0.41939520835876465, Validation Loss: 0.4181514382362366
Epoch 24, Training Loss: 0.41815146803855896, Validation Loss: 0.4168505072593689
Epoch 25, Training Loss: 0.4168505370616913, Validation Loss: 0.4154846668243408
Epoch 26, Training Loss: 0.4154846668243408, Validation Loss: 0.41402676701545715
Epoch 27, Training Loss: 0.41402676701545715, Validation Loss: 0.41256287693977356
Epoch 28, Training Loss: 0.4125628173351288, Validation Loss: 0.4110623300075531
Epoch 29, Training Loss: 0.4110623300075531, Validation Loss: 0.4094981551170349
Epoch 30, Training Loss: 0.4094981551170349, Validation Loss: 0.4078856408596039
Epoch 31, Training Loss: 0.4078856408596039, Validation Loss: 0.40618425607681274
Epoch 32, Training Loss: 0.40618422627449036, Validation Loss: 0.404380738735199
Epoch 33, Training Loss: 0.404380738735199, Validation Loss: 0.4024776220321655
Epoch 34, Training Loss: 0.40247756242752075, Validation Loss: 0.4005069136619568
Epoch 35, Training Loss: 0.4005069136619568, Validation Loss: 0.3983975350856781
Epoch 36, Training Loss: 0.3983975350856781, Validation Loss: 0.3961490988731384
Epoch 37, Training Loss: 0.39614906907081604, Validation Loss: 0.3937739133834839
Epoch 38, Training Loss: 0.3937739133834839, Validation Loss: 0.39123690128326416
Epoch 39, Training Loss: 0.39123690128326416, Validation Loss: 0.3885226249694824
Epoch 40, Training Loss: 0.3885226249694824, Validation Loss: 0.38562288880348206
Epoch 41, Training Loss: 0.38562285900115967, Validation Loss: 0.38252437114715576
Epoch 42, Training Loss: 0.38252437114715576, Validation Loss: 0.3791976571083069
Epoch 43, Training Loss: 0.3791976571083069, Validation Loss: 0.3756111264228821
Epoch 44, Training Loss: 0.3756111264228821, Validation Loss: 0.37177857756614685
Epoch 45, Training Loss: 0.37177857756614685, Validation Loss: 0.3676859438419342
Epoch 46, Training Loss: 0.3676859438419342, Validation Loss: 0.3632933795452118
Epoch 47, Training Loss: 0.363293319940567, Validation Loss: 0.3585987091064453
Epoch 48, Training Loss: 0.3585986793041229, Validation Loss: 0.3535975217819214
Epoch 49, Training Loss: 0.3535975217819214, Validation Loss: 0.3482799530029297
Epoch 50, Training Loss: 0.3482799530029297, Validation Loss: 0.34258174896240234
Epoch 51, Training Loss: 0.34258174896240234, Validation Loss: 0.33651110529899597
Epoch 52, Training Loss: 0.33651110529899597, Validation Loss: 0.33004117012023926
Epoch 53, Training Loss: 0.33004114031791687, Validation Loss: 0.32317855954170227
Epoch 54, Training Loss: 0.32317855954170227, Validation Loss: 0.3159432113170624
Epoch 55, Training Loss: 0.3159432113170624, Validation Loss: 0.30833670496940613
Epoch 56, Training Loss: 0.30833670496940613, Validation Loss: 0.30039891600608826
Epoch 57, Training Loss: 0.30039894580841064, Validation Loss: 0.2921803295612335
Epoch 58, Training Loss: 0.2921803295612335, Validation Loss: 0.28370919823646545
Epoch 59, Training Loss: 0.28370922803878784, Validation Loss: 0.2749782204627991
Epoch 60, Training Loss: 0.2749782204627991, Validation Loss: 0.26610785722732544
Epoch 61, Training Loss: 0.26610785722732544, Validation Loss: 0.2571921944618225
Epoch 62, Training Loss: 0.2571921944618225, Validation Loss: 0.24827328324317932
Epoch 63, Training Loss: 0.24827326834201813, Validation Loss: 0.23951469361782074
Epoch 64, Training Loss: 0.23951469361782074, Validation Loss: 0.2310929149389267
Epoch 65, Training Loss: 0.23109294474124908, Validation Loss: 0.22308780252933502
Epoch 66, Training Loss: 0.22308780252933502, Validation Loss: 0.21564875543117523
Epoch 67, Training Loss: 0.21564872562885284, Validation Loss: 0.2088935226202011
Epoch 68, Training Loss: 0.20889350771903992, Validation Loss: 0.20284529030323029
Epoch 69, Training Loss: 0.20284529030323029, Validation Loss: 0.19739745557308197
Epoch 70, Training Loss: 0.19739745557308197, Validation Loss: 0.19233843684196472
Epoch 71, Training Loss: 0.19233843684196472, Validation Loss: 0.18747854232788086
Epoch 72, Training Loss: 0.18747857213020325, Validation Loss: 0.18252813816070557
Epoch 73, Training Loss: 0.18252815306186676, Validation Loss: 0.17727668583393097
Epoch 74, Training Loss: 0.17727668583393097, Validation Loss: 0.17157122492790222
Epoch 75, Training Loss: 0.17157122492790222, Validation Loss: 0.1654084026813507
Epoch 76, Training Loss: 0.1654084324836731, Validation Loss: 0.15865299105644226
Epoch 77, Training Loss: 0.15865299105644226, Validation Loss: 0.15146894752979279
Epoch 78, Training Loss: 0.1514689177274704, Validation Loss: 0.1440277397632599
Epoch 79, Training Loss: 0.1440277397632599, Validation Loss: 0.13652585446834564
Epoch 80, Training Loss: 0.13652586936950684, Validation Loss: 0.12904509902000427
Epoch 81, Training Loss: 0.12904506921768188, Validation Loss: 0.12186652421951294
Epoch 82, Training Loss: 0.12186652421951294, Validation Loss: 0.11482539772987366
Epoch 83, Training Loss: 0.11482539027929306, Validation Loss: 0.10799076408147812
Epoch 84, Training Loss: 0.10799076408147812, Validation Loss: 0.10136757045984268
Epoch 85, Training Loss: 0.10136756300926208, Validation Loss: 0.09510474652051926
Epoch 86, Training Loss: 0.09510474652051926, Validation Loss: 0.08897250145673752
Epoch 87, Training Loss: 0.08897250145673752, Validation Loss: 0.08302932232618332
Epoch 88, Training Loss: 0.08302932977676392, Validation Loss: 0.07730299979448318
Epoch 89, Training Loss: 0.07730300724506378, Validation Loss: 0.07183195650577545
Epoch 90, Training Loss: 0.07183195650577545, Validation Loss: 0.0666642114520073
Epoch 91, Training Loss: 0.06666421890258789, Validation Loss: 0.06181512027978897
Epoch 92, Training Loss: 0.06181512027978897, Validation Loss: 0.05729358270764351
Epoch 93, Training Loss: 0.05729358270764351, Validation Loss: 0.053172048181295395
Epoch 94, Training Loss: 0.05317205935716629, Validation Loss: 0.04940861091017723
Epoch 95, Training Loss: 0.049408603459596634, Validation Loss: 0.04593176394701004
Epoch 96, Training Loss: 0.04593176394701004, Validation Loss: 0.04270576685667038
Epoch 97, Training Loss: 0.04270576685667038, Validation Loss: 0.0397024042904377
Epoch 98, Training Loss: 0.0397023968398571, Validation Loss: 0.03688549995422363
Epoch 99, Training Loss: 0.03688549995422363, Validation Loss: 0.03424219414591789
Epoch 100, Training Loss: 0.034242190420627594, Validation Loss: 0.0317511148750782
Epoch 101, Training Loss: 0.0317511260509491, Validation Loss: 0.029385842382907867
Epoch 102, Training Loss: 0.029385851696133614, Validation Loss: 0.027119513601064682
Epoch 103, Training Loss: 0.027119513601064682, Validation Loss: 0.025003351271152496
Epoch 104, Training Loss: 0.025003351271152496, Validation Loss: 0.023014003410935402
Epoch 105, Training Loss: 0.023014001548290253, Validation Loss: 0.02115190587937832
Epoch 106, Training Loss: 0.02115190029144287, Validation Loss: 0.019395411014556885
Epoch 107, Training Loss: 0.019395414739847183, Validation Loss: 0.017814738675951958
Epoch 108, Training Loss: 0.017814740538597107, Validation Loss: 0.01634121872484684
Epoch 109, Training Loss: 0.01634122058749199, Validation Loss: 0.014950177632272243
Epoch 110, Training Loss: 0.014950176700949669, Validation Loss: 0.013621518388390541
Epoch 111, Training Loss: 0.013621523045003414, Validation Loss: 0.012350201606750488
Epoch 112, Training Loss: 0.012350199744105339, Validation Loss: 0.011145122349262238
Epoch 113, Training Loss: 0.011145124211907387, Validation Loss: 0.009981964714825153
Epoch 114, Training Loss: 0.009981967508792877, Validation Loss: 0.008901364170014858
Epoch 115, Training Loss: 0.008901364170014858, Validation Loss: 0.0078840721398592
Epoch 116, Training Loss: 0.007884068414568901, Validation Loss: 0.006938124541193247
Epoch 117, Training Loss: 0.006938124541193247, Validation Loss: 0.006070801056921482
Epoch 118, Training Loss: 0.006070803385227919, Validation Loss: 0.0052901073358953
Epoch 119, Training Loss: 0.0052901073358953, Validation Loss: 0.004598379135131836
Epoch 120, Training Loss: 0.00459838192909956, Validation Loss: 0.003981714136898518
Epoch 121, Training Loss: 0.003981715999543667, Validation Loss: 0.0034353851806372404
Epoch 122, Training Loss: 0.003435386111959815, Validation Loss: 0.00295405276119709
Epoch 123, Training Loss: 0.002954050898551941, Validation Loss: 0.002528206678107381
Epoch 124, Training Loss: 0.002528206678107381, Validation Loss: 0.002145719714462757
Epoch 125, Training Loss: 0.0021457199472934008, Validation Loss: 0.0018008348997682333
Epoch 126, Training Loss: 0.0018008343176916242, Validation Loss: 0.0014923359267413616
Epoch 127, Training Loss: 0.0014923353446647525, Validation Loss: 0.0012295757187530398
Epoch 128, Training Loss: 0.0012295754859223962, Validation Loss: 0.0009999340400099754
Epoch 129, Training Loss: 0.0009999341564252973, Validation Loss: 0.0008005223353393376
Epoch 130, Training Loss: 0.0008005225099623203, Validation Loss: 0.0006304357666522264
Epoch 131, Training Loss: 0.0006304351263679564, Validation Loss: 0.0004902450018562376
Epoch 132, Training Loss: 0.0004902445944026113, Validation Loss: 0.00037719166721217334
Epoch 133, Training Loss: 0.00037719152169302106, Validation Loss: 0.0002882421249523759
Epoch 134, Training Loss: 0.0002882429107557982, Validation Loss: 0.00022019317839294672
Epoch 135, Training Loss: 0.00022019290190655738, Validation Loss: 0.00016952119767665863
Epoch 136, Training Loss: 0.00016952095029409975, Validation Loss: 0.00013269060582388192
Epoch 137, Training Loss: 0.00013269091141410172, Validation Loss: 0.00010674988152459264
Epoch 138, Training Loss: 0.00010674968507373706, Validation Loss: 8.972750947577879e-05
Epoch 139, Training Loss: 8.972798241302371e-05, Validation Loss: 7.964998803799972e-05
Epoch 140, Training Loss: 7.964990072650835e-05, Validation Loss: 7.476280006812885e-05
Epoch 141, Training Loss: 7.476330938516185e-05, Validation Loss: 7.387378718703985e-05
Epoch 142, Training Loss: 7.387423829641193e-05, Validation Loss: 7.585631828987971e-05
Epoch 143, Training Loss: 7.58564128773287e-05, Validation Loss: 8.008655277080834e-05
Epoch 144, Training Loss: 8.008643635548651e-05, Validation Loss: 8.564203744754195e-05
Epoch 145, Training Loss: 8.564199379179627e-05, Validation Loss: 9.155366569757462e-05
Epoch 146, Training Loss: 9.155343286693096e-05, Validation Loss: 9.686037810752168e-05
Epoch 147, Training Loss: 9.686050907475874e-05, Validation Loss: 0.000100984369055368
Epoch 148, Training Loss: 0.00010098444181494415, Validation Loss: 0.00010347260831622407
Epoch 149, Training Loss: 0.00010347240458941087, Validation Loss: 0.00010411372932139784
Epoch 150, Training Loss: 0.00010411351831862703, Validation Loss: 0.00010293827654095367
Epoch 151, Training Loss: 0.00010293842206010595, Validation Loss: 0.00010017041495302692
Epoch 152, Training Loss: 0.00010017008753493428, Validation Loss: 9.614601003704593e-05
Epoch 153, Training Loss: 9.614612645236775e-05, Validation Loss: 9.120911272475496e-05
Epoch 154, Training Loss: 9.120883623836562e-05, Validation Loss: 8.572217484470457e-05
Epoch 155, Training Loss: 8.57221893966198e-05, Validation Loss: 7.994141924427822e-05
Epoch 156, Training Loss: 7.994143379619345e-05, Validation Loss: 7.402075425488874e-05
Epoch 157, Training Loss: 7.4020579631906e-05, Validation Loss: 6.802867574151605e-05
Epoch 158, Training Loss: 6.802861025789753e-05, Validation Loss: 6.198353366926312e-05
Epoch 159, Training Loss: 6.198343908181414e-05, Validation Loss: 5.5892069212859496e-05
Epoch 160, Training Loss: 5.5892047384986654e-05, Validation Loss: 4.9781745474319905e-05
Epoch 161, Training Loss: 4.978194192517549e-05, Validation Loss: 4.371894465293735e-05
Epoch 162, Training Loss: 4.3718970118789e-05, Validation Loss: 3.7805581087013707e-05
Epoch 163, Training Loss: 3.780547922360711e-05, Validation Loss: 3.216699042241089e-05
Epoch 164, Training Loss: 3.216716504539363e-05, Validation Loss: 2.693013993848581e-05
Epoch 165, Training Loss: 2.693026362976525e-05, Validation Loss: 2.2199901650310494e-05
Epoch 166, Training Loss: 2.2200103558134288e-05, Validation Loss: 1.8044986063614488e-05
Epoch 167, Training Loss: 1.8044936950900592e-05, Validation Loss: 1.4489728528133128e-05
Epoch 168, Training Loss: 1.448978127882583e-05, Validation Loss: 1.1517921848280821e-05
Epoch 169, Training Loss: 1.1517979146447033e-05, Validation Loss: 9.0825933511951e-06
Epoch 170, Training Loss: 9.082606084120926e-06, Validation Loss: 7.118779194570379e-06
Epoch 171, Training Loss: 7.1187341745826416e-06, Validation Loss: 5.5575014812347945e-06
Epoch 172, Training Loss: 5.557461918215267e-06, Validation Loss: 4.33478726336034e-06
Epoch 173, Training Loss: 4.334753157309024e-06, Validation Loss: 3.396103920749738e-06
Epoch 174, Training Loss: 3.3961632652790286e-06, Validation Loss: 2.697618583624717e-06
Epoch 175, Training Loss: 2.6975692435371457e-06, Validation Loss: 2.202866880907095e-06
Epoch 176, Training Loss: 2.2028784769645426e-06, Validation Loss: 1.8801212036123616e-06
Epoch 177, Training Loss: 1.880089143924124e-06, Validation Loss: 1.6989754385576816e-06
Epoch 178, Training Loss: 1.6989947653200943e-06, Validation Loss: 1.629236408007273e-06
Epoch 179, Training Loss: 1.6292758573399624e-06, Validation Loss: 1.6409545651185908e-06
Epoch 180, Training Loss: 1.6409580894105602e-06, Validation Loss: 1.7057344621207449e-06
Epoch 181, Training Loss: 1.7057559489330743e-06, Validation Loss: 1.7984256146519328e-06
Epoch 182, Training Loss: 1.7983992393055814e-06, Validation Loss: 1.8982649407917052e-06
Epoch 183, Training Loss: 1.8982489109475864e-06, Validation Loss: 1.989603106267168e-06
Epoch 184, Training Loss: 1.9895073819498066e-06, Validation Loss: 2.0614777440641774e-06
Epoch 185, Training Loss: 2.0614279492292553e-06, Validation Loss: 2.107055252054124e-06
Epoch 186, Training Loss: 2.107090040226467e-06, Validation Loss: 2.122785417668638e-06
Epoch 187, Training Loss: 2.1227940578683047e-06, Validation Loss: 2.107300815623603e-06
Epoch 188, Training Loss: 2.107278760377085e-06, Validation Loss: 2.06113531930896e-06
Epoch 189, Training Loss: 2.0611946638382506e-06, Validation Loss: 1.9867484297719784e-06
Epoch 190, Training Loss: 1.986733423109399e-06, Validation Loss: 1.8877511820392101e-06
Epoch 191, Training Loss: 1.887774942588294e-06, Validation Loss: 1.769367599990801e-06
Epoch 192, Training Loss: 1.7693590734779718e-06, Validation Loss: 1.637459945413866e-06
Epoch 193, Training Loss: 1.637449372537958e-06, Validation Loss: 1.4981305866967887e-06
Epoch 194, Training Loss: 1.498172082392557e-06, Validation Loss: 1.3573011301559745e-06
Epoch 195, Training Loss: 1.357284645564505e-06, Validation Loss: 1.2194634564366424e-06
Epoch 196, Training Loss: 1.2194519740660326e-06, Validation Loss: 1.0878371767830686e-06
Epoch 197, Training Loss: 1.0878403600145248e-06, Validation Loss: 9.641682936489815e-07
Epoch 198, Training Loss: 9.641310043662088e-07, Validation Loss: 8.488264029438142e-07
Epoch 199, Training Loss: 8.488443086207553e-07, Validation Loss: 7.415808340738295e-07
Epoch 200, Training Loss: 7.415791287712636e-07, Validation Loss: 6.418662792384566e-07
Epoch 201, Training Loss: 6.418637212846079e-07, Validation Loss: 5.493152457347605e-07
Epoch 202, Training Loss: 5.493444064086361e-07, Validation Loss: 4.640717747861345e-07
Epoch 203, Training Loss: 4.640629072127922e-07, Validation Loss: 3.8641002220174414e-07
Epoch 204, Training Loss: 3.8640908428533294e-07, Validation Loss: 3.170469824453903e-07
Epoch 205, Training Loss: 3.1705036462881253e-07, Validation Loss: 2.564787564551807e-07
Epoch 206, Training Loss: 2.564768806223583e-07, Validation Loss: 2.0498211483754858e-07
Epoch 207, Training Loss: 2.0497658681506437e-07, Validation Loss: 1.6235554767263238e-07
Epoch 208, Training Loss: 1.6235181021784229e-07, Validation Loss: 1.2807851135221426e-07
Epoch 209, Training Loss: 1.280751860122109e-07, Validation Loss: 1.0128744065696083e-07
Epoch 210, Training Loss: 1.0128309924084533e-07, Validation Loss: 8.098434989278758e-08
Epoch 211, Training Loss: 8.097509862636798e-08, Validation Loss: 6.617341341552674e-08
Epoch 212, Training Loss: 6.617322156898808e-08, Validation Loss: 5.5968758516655726e-08
Epoch 213, Training Loss: 5.595719798634491e-08, Validation Loss: 4.9518781963797665e-08
Epoch 214, Training Loss: 4.9527461243314974e-08, Validation Loss: 4.612516235624753e-08
Epoch 215, Training Loss: 4.612471116161032e-08, Validation Loss: 4.50424018083595e-08
Epoch 216, Training Loss: 4.504137152139265e-08, Validation Loss: 4.551534971142246e-08
Epoch 217, Training Loss: 4.5522615010895606e-08, Validation Loss: 4.682784648935012e-08
Epoch 218, Training Loss: 4.682377152676054e-08, Validation Loss: 4.8292459808862986e-08
Epoch 219, Training Loss: 4.8286537435160426e-08, Validation Loss: 4.9352280484527e-08
Epoch 220, Training Loss: 4.934781117071907e-08, Validation Loss: 4.9652491895813e-08
Epoch 221, Training Loss: 4.9651408318140966e-08, Validation Loss: 4.908796213953792e-08
Epoch 222, Training Loss: 4.9088956899367986e-08, Validation Loss: 4.775025885805917e-08
Epoch 223, Training Loss: 4.774027928533542e-08, Validation Loss: 4.584875767932317e-08
Epoch 224, Training Loss: 4.584609314406407e-08, Validation Loss: 4.367620221046309e-08
Epoch 225, Training Loss: 4.3679882821834326e-08, Validation Loss: 4.146534848814554e-08
Epoch 226, Training Loss: 4.146794907455842e-08, Validation Loss: 3.9371720106373687e-08
Epoch 227, Training Loss: 3.9371013116351605e-08, Validation Loss: 3.738793097340931e-08
Epoch 228, Training Loss: 3.738366061156739e-08, Validation Loss: 3.5448991297926113e-08
Epoch 229, Training Loss: 3.544147020306809e-08, Validation Loss: 3.342021059893341e-08
Epoch 230, Training Loss: 3.341677867751969e-08, Validation Loss: 3.1187855853431756e-08
Epoch 231, Training Loss: 3.1188033489115696e-08, Validation Loss: 2.8667706430951512e-08
Epoch 232, Training Loss: 2.8663937001738304e-08, Validation Loss: 2.5894184574326573e-08
Epoch 233, Training Loss: 2.589585612611245e-08, Validation Loss: 2.2948439593051262e-08
Epoch 234, Training Loss: 2.294059697760531e-08, Validation Loss: 1.9947185236901532e-08
Epoch 235, Training Loss: 1.9945936458043434e-08, Validation Loss: 1.704803231916685e-08
Epoch 236, Training Loss: 1.7047129929892435e-08, Validation Loss: 1.4362016464986027e-08
Epoch 237, Training Loss: 1.4362377065424425e-08, Validation Loss: 1.1971140523314716e-08
Epoch 238, Training Loss: 1.1970334945488048e-08, Validation Loss: 9.895292585326843e-09
Epoch 239, Training Loss: 9.893184049758474e-09, Validation Loss: 8.123228312229003e-09
Epoch 240, Training Loss: 8.120626837637701e-09, Validation Loss: 6.620839432258663e-09
Epoch 241, Training Loss: 6.623231296742915e-09, Validation Loss: 5.3569055857849435e-09
Epoch 242, Training Loss: 5.359902299773012e-09, Validation Loss: 4.300545697333291e-09
Epoch 243, Training Loss: 4.29986801719906e-09, Validation Loss: 3.432368611555603e-09
Epoch 244, Training Loss: 3.4326042008814284e-09, Validation Loss: 2.743550497896763e-09
Epoch 245, Training Loss: 2.741666449423974e-09, Validation Loss: 2.2192754300931483e-09
Epoch 246, Training Loss: 2.219871175768162e-09, Validation Loss: 1.84771586919652e-09
Epoch 247, Training Loss: 1.8474622942576957e-09, Validation Loss: 1.605018007388992e-09
Epoch 248, Training Loss: 1.6043665285181419e-09, Validation Loss: 1.4600557429744754e-09
Epoch 249, Training Loss: 1.4601863052021713e-09, Validation Loss: 1.3799006381987056e-09
Epoch 250, Training Loss: 1.38059064180851e-09, Validation Loss: 1.33668154322919e-09
Epoch 251, Training Loss: 1.3377877694509266e-09, Validation Loss: 1.3127687825686962e-09
Epoch 252, Training Loss: 1.3121637110202755e-09, Validation Loss: 1.292322360235687e-09
Epoch 253, Training Loss: 1.2911708369145458e-09, Validation Loss: 1.274478744761609e-09
Epoch 254, Training Loss: 1.2754877154463884e-09, Validation Loss: 1.263456561595433e-09
Epoch 255, Training Loss: 1.2647155545053579e-09, Validation Loss: 1.260123116963996e-09
Epoch 256, Training Loss: 1.2593882603439965e-09, Validation Loss: 1.2604378651914772e-09
Epoch 257, Training Loss: 1.2602328069988289e-09, Validation Loss: 1.2617039635287597e-09
Epoch 258, Training Loss: 1.2623743161910284e-09, Validation Loss: 1.2572873853144984e-09
Epoch 259, Training Loss: 1.2561639506358802e-09, Validation Loss: 1.2355592104995594e-09
Epoch 260, Training Loss: 1.2362282308941985e-09, Validation Loss: 1.1945406885871535e-09
Epoch 261, Training Loss: 1.196609256126635e-09, Validation Loss: 1.1327795368387683e-09
Epoch 262, Training Loss: 1.1320561155159226e-09, Validation Loss: 1.051632003701286e-09
Epoch 263, Training Loss: 1.0526748361883165e-09, Validation Loss: 9.589543603638617e-10
Epoch 264, Training Loss: 9.595144678797851e-10, Validation Loss: 8.608579404878469e-10
Epoch 265, Training Loss: 8.614965962827625e-10, Validation Loss: 7.664646695104693e-10
Epoch 266, Training Loss: 7.662952494769115e-10, Validation Loss: 6.788861695028459e-10
Epoch 267, Training Loss: 6.78488210059669e-10, Validation Loss: 5.994450491542125e-10
Epoch 268, Training Loss: 5.995501317634933e-10, Validation Loss: 5.285647475261612e-10
Epoch 269, Training Loss: 5.28526278298358e-10, Validation Loss: 4.6441955836584725e-10
Epoch 270, Training Loss: 4.641374229397144e-10, Validation Loss: 4.047123747241699e-10
Epoch 271, Training Loss: 4.0510317322883793e-10, Validation Loss: 3.486561317433967e-10
Epoch 272, Training Loss: 3.49002216015748e-10, Validation Loss: 2.950527322465035e-10
Epoch 273, Training Loss: 2.954244071595724e-10, Validation Loss: 2.4580817936659116e-10
Epoch 274, Training Loss: 2.4532603726257207e-10, Validation Loss: 1.9983560639591502e-10
Epoch 275, Training Loss: 1.9960776087568632e-10, Validation Loss: 1.60106261581916e-10
Epoch 276, Training Loss: 1.601657972916115e-10, Validation Loss: 1.2663964321646404e-10
Epoch 277, Training Loss: 1.2641288016368435e-10, Validation Loss: 9.892778957132364e-11
Epoch 278, Training Loss: 9.890434304882234e-11, Validation Loss: 7.720926675780504e-11
Epoch 279, Training Loss: 7.76586780992794e-11, Validation Loss: 6.133296648336284e-11
Epoch 280, Training Loss: 6.144358632997893e-11, Validation Loss: 4.934799791023181e-11
Epoch 281, Training Loss: 4.941618642062551e-11, Validation Loss: 4.1439886244720725e-11
Epoch 282, Training Loss: 4.140598974800014e-11, Validation Loss: 3.648089122454401e-11
Epoch 283, Training Loss: 3.6681775672509076e-11, Validation Loss: 3.417157182217245e-11
Epoch 284, Training Loss: 3.410882687404637e-11, Validation Loss: 3.371121090611773e-11
Epoch 285, Training Loss: 3.359296174565429e-11, Validation Loss: 3.4525372144544875e-11
Epoch 286, Training Loss: 3.441574109031009e-11, Validation Loss: 3.607946580386212e-11
Epoch 287, Training Loss: 3.6132926511944774e-11, Validation Loss: 3.783648047650523e-11
Epoch 288, Training Loss: 3.792774080912942e-11, Validation Loss: 3.9589085482072406e-11
Epoch 289, Training Loss: 3.952857138833643e-11, Validation Loss: 4.033559250493646e-11
Epoch 290, Training Loss: 4.03770523960123e-11, Validation Loss: 4.0939682199869765e-11
Epoch 291, Training Loss: 4.0659017819244525e-11, Validation Loss: 4.059475672280044e-11
Epoch 292, Training Loss: 4.0531047268421716e-11, Validation Loss: 3.9515137689738467e-11
Epoch 293, Training Loss: 3.931189401784607e-11, Validation Loss: 3.8118470185866116e-11
Epoch 294, Training Loss: 3.793781608307789e-11, Validation Loss: 3.612198387625831e-11
Epoch 295, Training Loss: 3.621960023569848e-11, Validation Loss: 3.4039712021316504e-11
Epoch 296, Training Loss: 3.4077095312223804e-11, Validation Loss: 3.1751826862214116e-11
Epoch 297, Training Loss: 3.186064259641519e-11, Validation Loss: 2.934632398199355e-11
Epoch 298, Training Loss: 2.93387744654261e-11, Validation Loss: 2.661964051964283e-11
Epoch 299, Training Loss: 2.6632055935560395e-11, Validation Loss: 2.3932135786997044e-11
Epoch 300, Training Loss: 2.3910507254698565e-11, Validation Loss: 2.1059643612320045e-11
Epoch 301, Training Loss: 2.1007568948294697e-11, Validation Loss: 1.8150536629235603e-11
Epoch 302, Training Loss: 1.8105338409069027e-11, Validation Loss: 1.537436324083874e-11
Epoch 303, Training Loss: 1.5328068675435347e-11, Validation Loss: 1.2775207974824454e-11
Epoch 304, Training Loss: 1.2611935801265517e-11, Validation Loss: 1.0298401020847336e-11
Epoch 305, Training Loss: 1.0318146510812642e-11, Validation Loss: 8.306972297533743e-12
Epoch 306, Training Loss: 8.315694487170955e-12, Validation Loss: 6.4512960945561915e-12
Epoch 307, Training Loss: 6.403561274986869e-12, Validation Loss: 4.981346064802938e-12
Epoch 308, Training Loss: 4.964844941418578e-12, Validation Loss: 3.7848387618444335e-12
Epoch 309, Training Loss: 3.807306466624416e-12, Validation Loss: 2.9062709270416542e-12
Epoch 310, Training Loss: 2.9276134468070314e-12, Validation Loss: 2.2746732882689136e-12
Epoch 311, Training Loss: 2.195841165147927e-12, Validation Loss: 1.7862576652191708e-12
Epoch 312, Training Loss: 1.7400948303797348e-12, Validation Loss: 1.3940129432732373e-12
Epoch 313, Training Loss: 1.3677735159756121e-12, Validation Loss: 1.176050793208483e-12
Epoch 314, Training Loss: 1.195611318283163e-12, Validation Loss: 1.0092227617844451e-12
Epoch 315, Training Loss: 1.0367922883072755e-12, Validation Loss: 9.622516542254211e-13
Epoch 316, Training Loss: 9.621424750666518e-13, Validation Loss: 9.49286114125536e-13
Epoch 317, Training Loss: 9.510585678371153e-13, Validation Loss: 1.0110249226355505e-12
Epoch 318, Training Loss: 9.849853137983144e-13, Validation Loss: 1.109831952901541e-12
Epoch 319, Training Loss: 1.0798090937028104e-12, Validation Loss: 1.1857457290348483e-12
Epoch 320, Training Loss: 1.17039277575115e-12, Validation Loss: 1.2605347538344192e-12
Epoch 321, Training Loss: 1.2510922202738084e-12, Validation Loss: 1.30963621024216e-12
Epoch 322, Training Loss: 1.3374506580357548e-12, Validation Loss: 1.34651079349013e-12
Epoch 323, Training Loss: 1.3458921477305097e-12, Validation Loss: 1.3683376263659563e-12
Epoch 324, Training Loss: 1.3719099641040788e-12, Validation Loss: 1.3561917431084702e-12
Epoch 325, Training Loss: 1.4010369470476847e-12, Validation Loss: 1.3191533369122377e-12
Epoch 326, Training Loss: 1.3541291568955338e-12, Validation Loss: 1.3383984675749416e-12
Epoch 327, Training Loss: 1.3063994330764217e-12, Validation Loss: 1.2477395418958315e-12
Epoch 328, Training Loss: 1.226301395498841e-12, Validation Loss: 1.1738756668100425e-12
Epoch 329, Training Loss: 1.1752501099041024e-12, Validation Loss: 1.0695374707409e-12
Epoch 330, Training Loss: 1.0783600574992835e-12, Validation Loss: 9.595347520013897e-13
Epoch 331, Training Loss: 9.892536009109554e-13, Validation Loss: 8.846988896679675e-13
Epoch 332, Training Loss: 8.820187418975833e-13, Validation Loss: 7.994527891248826e-13
Epoch 333, Training Loss: 7.913859997009387e-13, Validation Loss: 7.07454277451558e-13
Epoch 334, Training Loss: 6.834268394262377e-13, Validation Loss: 5.890028048627372e-13
Epoch 335, Training Loss: 6.21669003168096e-13, Validation Loss: 5.245906790560251e-13
Epoch 336, Training Loss: 5.192744563335683e-13, Validation Loss: 4.601653259828087e-13
Epoch 337, Training Loss: 4.5223335709901336e-13, Validation Loss: 3.976665459599904e-13
Epoch 338, Training Loss: 3.8747257897868426e-13, Validation Loss: 3.212040822122425e-13
Epoch 339, Training Loss: 3.1812020465787905e-13, Validation Loss: 2.5427565868846314e-13
Epoch 340, Training Loss: 2.6362901662038696e-13, Validation Loss: 2.1733644343848585e-13
Epoch 341, Training Loss: 2.0105880122692904e-13, Validation Loss: 1.5653728584631016e-13
Epoch 342, Training Loss: 1.703238244887828e-13, Validation Loss: 1.1186991816843767e-13
Epoch 343, Training Loss: 1.2452273370419653e-13, Validation Loss: 8.811668842506615e-14
Epoch 344, Training Loss: 9.830939502134678e-14, Validation Loss: 6.301631037732708e-14
Epoch 345, Training Loss: 6.632015899996069e-14, Validation Loss: 4.7400654907235606e-14
Epoch 346, Training Loss: 5.023733436627237e-14, Validation Loss: 3.948257397564346e-14
Epoch 347, Training Loss: 3.826860974377039e-14, Validation Loss: 2.525004368732122e-14
Epoch 348, Training Loss: 2.681836754080992e-14, Validation Loss: 2.31518871727978e-14
Epoch 349, Training Loss: 2.3827636505590125e-14, Validation Loss: 2.373048352060595e-14
Epoch 350, Training Loss: 1.3286122588663119e-14, Validation Loss: 1.9111316397696712e-14
Epoch 351, Training Loss: 1.7508640275999167e-14, Validation Loss: 1.7802533603642097e-14
Epoch 352, Training Loss: 1.4082427579739307e-14, Validation Loss: 1.3633859259664163e-14
Epoch 353, Training Loss: 1.2829823398878386e-14, Validation Loss: 1.6433077839575656e-14
Epoch 354, Training Loss: 1.3363317783344087e-14, Validation Loss: 1.5701891894451432e-14
Epoch 355, Training Loss: 1.515401912570609e-14, Validation Loss: 1.5640275329736365e-14
Epoch 356, Training Loss: 1.4463533113697434e-14, Validation Loss: 1.5785992101718417e-14
Epoch 357, Training Loss: 1.3524580151007097e-14, Validation Loss: 1.6255693893827555e-14
Epoch 358, Training Loss: 1.0960925668891761e-14, Validation Loss: 1.6435437673366707e-14
Epoch 359, Training Loss: 1.2819881773176462e-14, Validation Loss: 1.706123916732534e-14
Epoch 360, Training Loss: 9.042388420064246e-15, Validation Loss: 1.8858680350848644e-14
Epoch 361, Training Loss: 1.0722734921926168e-14, Validation Loss: 1.093553077410013e-14
Epoch 362, Training Loss: 1.0861512800004313e-14, Validation Loss: 1.115664110168434e-14
Epoch 363, Training Loss: 1.0645405896039534e-14, Validation Loss: 1.211194010619079e-14
Epoch 364, Training Loss: 9.426029123633505e-15, Validation Loss: 1.3039616519254331e-14
Epoch 365, Training Loss: 9.468196117813719e-15, Validation Loss: 1.6511197994235026e-14
Epoch 366, Training Loss: 8.571410996336543e-15, Validation Loss: 1.4585388967555332e-14
Epoch 367, Training Loss: 9.553598214720634e-15, Validation Loss: 1.2506522781372681e-14
Epoch 368, Training Loss: 1.0120718960159383e-14, Validation Loss: 1.1625149424370797e-14
Epoch 369, Training Loss: 1.0391335822411765e-14, Validation Loss: 1.0457814356244072e-14
Epoch 370, Training Loss: 1.0910418788312882e-14, Validation Loss: 8.505049353050957e-15
Epoch 371, Training Loss: 1.1021174275397012e-14, Validation Loss: 7.120339372637414e-15
Epoch 372, Training Loss: 1.0897875077396993e-14, Validation Loss: 8.123810834920111e-15
Epoch 373, Training Loss: 9.259228854561347e-15, Validation Loss: 7.731629498143686e-15
Epoch 374, Training Loss: 8.181698760601364e-15, Validation Loss: 8.773131045692207e-15
Epoch 375, Training Loss: 7.517165838096581e-15, Validation Loss: 7.98329823336599e-15
Epoch 376, Training Loss: 6.992945617370367e-15, Validation Loss: 8.134618975327076e-15
Epoch 377, Training Loss: 8.710388774190239e-15, Validation Loss: 7.711213463016016e-15
Epoch 378, Training Loss: 8.790920431650442e-15, Validation Loss: 6.3234342587180966e-15
Epoch 379, Training Loss: 7.942173089710899e-15, Validation Loss: 6.600322976428423e-15
Epoch 380, Training Loss: 6.658210902109676e-15, Validation Loss: 7.616070487215677e-15
Epoch 381, Training Loss: 6.0136942151814594e-15, Validation Loss: 6.924315619852035e-15
Epoch 382, Training Loss: 5.0132928238160856e-15, Validation Loss: 6.1685102385993906e-15
Epoch 383, Training Loss: 4.976863630820573e-15, Validation Loss: 5.571631955174176e-15
Epoch 384, Training Loss: 5.3526980787479365e-15, Validation Loss: 6.1027241542014644e-15
Epoch 385, Training Loss: 6.368111858553972e-15, Validation Loss: 5.125808021848137e-15
Epoch 386, Training Loss: 6.117110585294105e-15, Validation Loss: 5.233227046153033e-15
Epoch 387, Training Loss: 4.528437612280568e-15, Validation Loss: 4.873472248179871e-15
Epoch 388, Training Loss: 4.998347350978257e-15, Validation Loss: 5.789406243495625e-15
Epoch 389, Training Loss: 5.5721405984590026e-15, Validation Loss: 4.96100929163034e-15
Epoch 390, Training Loss: 5.174755514771121e-15, Validation Loss: 4.5562846674545e-15
Epoch 391, Training Loss: 5.1821611238289655e-15, Validation Loss: 5.049079542321106e-15
Epoch 392, Training Loss: 4.8371514754016066e-15, Validation Loss: 4.369334755116583e-15
Epoch 393, Training Loss: 3.9301579128441216e-15, Validation Loss: 4.541473025822338e-15
Epoch 394, Training Loss: 4.1019624525686586e-15, Validation Loss: 5.129143637594424e-15
Epoch 395, Training Loss: 4.683695363380492e-15, Validation Loss: 5.03840438608686e-15
Epoch 396, Training Loss: 4.287844679876562e-15, Validation Loss: 4.403228778500964e-15
Epoch 397, Training Loss: 4.490607003273823e-15, Validation Loss: 4.239497733313181e-15
Epoch 398, Training Loss: 2.9813308753294044e-15, Validation Loss: 5.220150127996847e-15
Epoch 399, Training Loss: 2.298984002910916e-15, Validation Loss: 4.866266538897579e-15
Epoch 400, Training Loss: 2.5899506199628455e-15, Validation Loss: 4.705337478699313e-15
Epoch 401, Training Loss: 3.044982013183776e-15, Validation Loss: 5.170910832223534e-15
Epoch 402, Training Loss: 3.080610548285897e-15, Validation Loss: 4.285534397512926e-15
Epoch 403, Training Loss: 3.1060308540659456e-15, Validation Loss: 4.285534397512926e-15
Epoch 404, Training Loss: 2.2245243011331057e-15, Validation Loss: 4.2811310967366244e-15
Epoch 405, Training Loss: 2.373977547203733e-15, Validation Loss: 4.310487564622564e-15
Epoch 406, Training Loss: 2.3740442510483293e-15, Validation Loss: 4.291138791008434e-15
Epoch 407, Training Loss: 2.3773802903110904e-15, Validation Loss: 4.523591736789326e-15
Epoch 408, Training Loss: 2.3773802903110904e-15, Validation Loss: 4.183052304741102e-15
Epoch 409, Training Loss: 2.3179325534574682e-15, Validation Loss: 5.32530122158547e-15
Epoch 410, Training Loss: 2.1898298316135696e-15, Validation Loss: 5.32530122158547e-15
Epoch 411, Training Loss: 2.320201119448452e-15, Validation Loss: 5.32530122158547e-15
Epoch 412, Training Loss: 8.955260070010827e-16, Validation Loss: 6.176649801706031e-15
Epoch 413, Training Loss: 8.741755886534724e-16, Validation Loss: 6.8649347986012455e-15
Epoch 414, Training Loss: 9.542396839267906e-16, Validation Loss: 6.898562006607241e-15
Epoch 415, Training Loss: 9.76123944789408e-16, Validation Loss: 4.5993859389755355e-15
Epoch 416, Training Loss: 1.4578433344750717e-15, Validation Loss: 4.655831367547615e-15
Epoch 417, Training Loss: 3.655604464969375e-15, Validation Loss: 4.3708026632141746e-15
Epoch 418, Training Loss: 3.775300384811775e-15, Validation Loss: 4.514918119409442e-15
Epoch 419, Training Loss: 1.4494365324735727e-15, Validation Loss: 4.259246729994889e-15
Epoch 420, Training Loss: 1.267424081064319e-15, Validation Loss: 4.281798135182587e-15
Epoch 421, Training Loss: 1.1286462029861744e-15, Validation Loss: 4.1803833039243034e-15
Epoch 422, Training Loss: 1.1339837811032974e-15, Validation Loss: 4.3298367617531676e-15
Epoch 423, Training Loss: 1.041109371293942e-15, Validation Loss: 4.1951953690729394e-15
Epoch 424, Training Loss: 1.1848912023871097e-15, Validation Loss: 5.121270889866169e-15
Epoch 425, Training Loss: 1.2669570482730266e-15, Validation Loss: 4.5469440116286536e-15
Epoch 426, Training Loss: 1.3613659641454516e-15, Validation Loss: 4.317426458526471e-15
Epoch 427, Training Loss: 1.3851850600178346e-15, Validation Loss: 4.3708026632141746e-15
Epoch 428, Training Loss: 1.4552412492611065e-15, Validation Loss: 4.751908197172302e-15
Epoch 429, Training Loss: 1.5192926101830558e-15, Validation Loss: 4.758580275697824e-15
Epoch 430, Training Loss: 1.5132877818617332e-15, Validation Loss: 4.6251399757368025e-15
Epoch 431, Training Loss: 1.492604507839204e-15, Validation Loss: 3.675987465812103e-15
Epoch 432, Training Loss: 1.4349583041852734e-15, Validation Loss: 3.7140179745944e-15
Epoch 433, Training Loss: 1.5762715636327869e-15, Validation Loss: 3.147956020339718e-15
Epoch 434, Training Loss: 1.2900421900966137e-15, Validation Loss: 4.366532770127066e-15
Epoch 435, Training Loss: 1.2236556652182027e-15, Validation Loss: 4.348518073404861e-15
Epoch 436, Training Loss: 1.1405890499051048e-15, Validation Loss: 4.117132812653983e-15
Epoch 437, Training Loss: 1.154800462815019e-15, Validation Loss: 5.681928350400895e-15
Epoch 438, Training Loss: 1.2432713600898362e-15, Validation Loss: 5.5602308917041335e-15
Epoch 439, Training Loss: 1.391790328819642e-15, Validation Loss: 5.55622781399541e-15
Epoch 440, Training Loss: 1.9053351815533732e-15, Validation Loss: 5.55622781399541e-15
Epoch 441, Training Loss: 1.766423895786036e-15, Validation Loss: 5.56903791677321e-15
Epoch 442, Training Loss: 2.6557367043607717e-15, Validation Loss: 5.882288911876216e-15
Epoch 443, Training Loss: 3.6895649804401156e-15, Validation Loss: 5.9096442644242676e-15
Epoch 444, Training Loss: 3.6836937715662224e-15, Validation Loss: 5.798221738894174e-15
Epoch 445, Training Loss: 3.0004795374097455e-15, Validation Loss: 5.532942454758915e-15
Epoch 446, Training Loss: 2.7836391029126446e-15, Validation Loss: 5.816636658683956e-15
Epoch 447, Training Loss: 1.5110192158707494e-15, Validation Loss: 6.7679321619652094e-15
Epoch 448, Training Loss: 1.2330631307677642e-15, Validation Loss: 4.785534981661824e-15
Epoch 449, Training Loss: 1.4542404798339255e-15, Validation Loss: 4.717747358409536e-15
Epoch 450, Training Loss: 1.354093551018563e-15, Validation Loss: 4.788203982478622e-15
Epoch 451, Training Loss: 1.285772085251268e-15, Validation Loss: 4.930718122887106e-15
Epoch 452, Training Loss: 9.20812905091939e-16, Validation Loss: 4.541606433511531e-15
Epoch 453, Training Loss: 1.3833836326972615e-15, Validation Loss: 4.833173385164827e-15
Epoch 454, Training Loss: 1.5417772056470396e-15, Validation Loss: 4.781932127020678e-15
Epoch 455, Training Loss: 1.6694128946996459e-15, Validation Loss: 4.7072056098644826e-15
Epoch 456, Training Loss: 1.560525644659803e-15, Validation Loss: 4.579102888020584e-15
Epoch 457, Training Loss: 9.741890039005239e-16, Validation Loss: 4.579102888020584e-15
Epoch 458, Training Loss: 1.4879340740471623e-15, Validation Loss: 4.451000166176685e-15
Epoch 459, Training Loss: 9.741890039005239e-16, Validation Loss: 4.451000166176685e-15
Epoch 460, Training Loss: 9.63513847666278e-16, Validation Loss: 4.363596953931882e-15
Epoch 461, Training Loss: 9.55507374611475e-16, Validation Loss: 5.1001873927760625e-15
Epoch 462, Training Loss: 9.55507374611475e-16, Validation Loss: 5.1001873927760625e-15
Epoch 463, Training Loss: 6.533986214735663e-16, Validation Loss: 4.750573696763903e-15
Epoch 464, Training Loss: 6.960995111083461e-16, Validation Loss: 4.934054162149867e-15
Epoch 465, Training Loss: 1.1938317410244972e-15, Validation Loss: 4.462743007440945e-15
Epoch 466, Training Loss: 5.941511549724106e-16, Validation Loss: 4.505444055894403e-15
Epoch 467, Training Loss: 1.0645281382196288e-15, Validation Loss: 4.281264504425817e-15
Epoch 468, Training Loss: 1.0535860607278793e-15, Validation Loss: 3.870268448308506e-15
Epoch 469, Training Loss: 1.0535860607278793e-15, Validation Loss: 3.739496725647809e-15
Epoch 470, Training Loss: 1.1055609552834689e-15, Validation Loss: 3.739496725647809e-15
Epoch 471, Training Loss: 1.1182378621303135e-15, Validation Loss: 4.116007105867082e-15
Epoch 472, Training Loss: 1.1166365463435293e-15, Validation Loss: 5.427324646016356e-15
Epoch 473, Training Loss: 1.241069603822567e-15, Validation Loss: 5.490041506529906e-15
Epoch 474, Training Loss: 1.2210535800042375e-15, Validation Loss: 5.239840679405194e-15
Epoch 475, Training Loss: 1.4075363536717443e-15, Validation Loss: 5.354599667714522e-15
Epoch 476, Training Loss: 1.429754133757343e-15, Validation Loss: 5.7870125283866845e-15
Epoch 477, Training Loss: 1.429754133757343e-15, Validation Loss: 5.7870125283866845e-15
Epoch 478, Training Loss: 9.433643102796374e-16, Validation Loss: 5.735771693759009e-15
Epoch 479, Training Loss: 9.400283768959948e-16, Validation Loss: 5.735771693759009e-15
Epoch 480, Training Loss: 9.400283768959948e-16, Validation Loss: 5.760458045490262e-15
Epoch 481, Training Loss: 9.400283768959948e-16, Validation Loss: 5.8245094064122115e-15
Epoch 482, Training Loss: 6.692780010753019e-16, Validation Loss: 5.681728450625343e-15
Epoch 483, Training Loss: 5.355041289517397e-16, Validation Loss: 5.6106712801966534e-15
Epoch 484, Training Loss: 5.541858111803477e-16, Validation Loss: 5.461218245884263e-15
Epoch 485, Training Loss: 6.006230160850255e-16, Validation Loss: 5.5839833896110386e-15
Epoch 486, Training Loss: 5.707323880467237e-16, Validation Loss: 4.307827457651712e-15
Epoch 487, Training Loss: 5.827419917498096e-16, Validation Loss: 4.387291006565427e-15
Epoch 488, Training Loss: 5.747355716345659e-16, Validation Loss: 3.775600657991577e-15
Epoch 489, Training Loss: 7.714265746241447e-16, Validation Loss: 3.798285470868468e-15
Epoch 490, Training Loss: 9.252164176264772e-16, Validation Loss: 4.1537703757545206e-15
Epoch 491, Training Loss: 8.945252375739017e-16, Validation Loss: 4.16690616270054e-15
Epoch 492, Training Loss: 9.970073303457259e-16, Validation Loss: 4.295675922990402e-15
Epoch 493, Training Loss: 9.980749094966215e-16, Validation Loss: 4.26365003077119e-15
Epoch 494, Training Loss: 1.510151854132761e-15, Validation Loss: 4.151560466795134e-15
Epoch 495, Training Loss: 1.539842370637274e-15, Validation Loss: 4.151560466795134e-15
Epoch 496, Training Loss: 1.539842370637274e-15, Validation Loss: 4.108859418341677e-15
Epoch 497, Training Loss: 1.3973948281942685e-15, Validation Loss: 4.531072731779476e-15
Epoch 498, Training Loss: 1.4901358303144314e-15, Validation Loss: 4.5254018461976086e-15
Epoch 499, Training Loss: 1.4900024226252389e-15, Validation Loss: 4.8635395163238934e-15
Epoch 500, Training Loss: 1.2376001568706134e-15, Validation Loss: 4.908375087804432e-15
