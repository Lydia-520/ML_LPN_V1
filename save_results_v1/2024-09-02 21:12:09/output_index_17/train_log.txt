Epoch 1, Training Loss: 0.45107290148735046, Validation Loss: 0.44974419474601746
Epoch 2, Training Loss: 0.44974425435066223, Validation Loss: 0.4484301507472992
Epoch 3, Training Loss: 0.4484301507472992, Validation Loss: 0.4471386671066284
Epoch 4, Training Loss: 0.4471386671066284, Validation Loss: 0.4458495080471039
Epoch 5, Training Loss: 0.4458495080471039, Validation Loss: 0.4445662200450897
Epoch 6, Training Loss: 0.4445662200450897, Validation Loss: 0.4433152973651886
Epoch 7, Training Loss: 0.4433152973651886, Validation Loss: 0.4420875310897827
Epoch 8, Training Loss: 0.4420875310897827, Validation Loss: 0.44085270166397095
Epoch 9, Training Loss: 0.44085270166397095, Validation Loss: 0.4396057426929474
Epoch 10, Training Loss: 0.4396057426929474, Validation Loss: 0.4383556544780731
Epoch 11, Training Loss: 0.4383556842803955, Validation Loss: 0.43713584542274475
Epoch 12, Training Loss: 0.4371359050273895, Validation Loss: 0.4359305500984192
Epoch 13, Training Loss: 0.4359305500984192, Validation Loss: 0.43470141291618347
Epoch 14, Training Loss: 0.4347013533115387, Validation Loss: 0.433467835187912
Epoch 15, Training Loss: 0.43346789479255676, Validation Loss: 0.4322183132171631
Epoch 16, Training Loss: 0.4322182834148407, Validation Loss: 0.43092942237854004
Epoch 17, Training Loss: 0.43092942237854004, Validation Loss: 0.42960578203201294
Epoch 18, Training Loss: 0.42960578203201294, Validation Loss: 0.4282512962818146
Epoch 19, Training Loss: 0.4282512962818146, Validation Loss: 0.42684102058410645
Epoch 20, Training Loss: 0.42684102058410645, Validation Loss: 0.4253796935081482
Epoch 21, Training Loss: 0.4253796935081482, Validation Loss: 0.42387527227401733
Epoch 22, Training Loss: 0.42387527227401733, Validation Loss: 0.42236465215682983
Epoch 23, Training Loss: 0.42236465215682983, Validation Loss: 0.4208391010761261
Epoch 24, Training Loss: 0.4208391010761261, Validation Loss: 0.41925328969955444
Epoch 25, Training Loss: 0.41925325989723206, Validation Loss: 0.41760313510894775
Epoch 26, Training Loss: 0.41760313510894775, Validation Loss: 0.41588205099105835
Epoch 27, Training Loss: 0.41588205099105835, Validation Loss: 0.4140671491622925
Epoch 28, Training Loss: 0.4140671491622925, Validation Loss: 0.41221028566360474
Epoch 29, Training Loss: 0.41221028566360474, Validation Loss: 0.4102751910686493
Epoch 30, Training Loss: 0.4102751910686493, Validation Loss: 0.4082229435443878
Epoch 31, Training Loss: 0.4082229435443878, Validation Loss: 0.4060475528240204
Epoch 32, Training Loss: 0.4060474932193756, Validation Loss: 0.4037473499774933
Epoch 33, Training Loss: 0.4037473499774933, Validation Loss: 0.40129271149635315
Epoch 34, Training Loss: 0.40129271149635315, Validation Loss: 0.3986852765083313
Epoch 35, Training Loss: 0.3986852467060089, Validation Loss: 0.39590984582901
Epoch 36, Training Loss: 0.3959098756313324, Validation Loss: 0.39294520020484924
Epoch 37, Training Loss: 0.39294520020484924, Validation Loss: 0.38981711864471436
Epoch 38, Training Loss: 0.38981711864471436, Validation Loss: 0.3865257799625397
Epoch 39, Training Loss: 0.3865257799625397, Validation Loss: 0.3830017149448395
Epoch 40, Training Loss: 0.3830017149448395, Validation Loss: 0.3792283833026886
Epoch 41, Training Loss: 0.3792283535003662, Validation Loss: 0.3751694858074188
Epoch 42, Training Loss: 0.3751695156097412, Validation Loss: 0.3708031475543976
Epoch 43, Training Loss: 0.3708031177520752, Validation Loss: 0.366136372089386
Epoch 44, Training Loss: 0.3661363422870636, Validation Loss: 0.3611788749694824
Epoch 45, Training Loss: 0.36117884516716003, Validation Loss: 0.3558596670627594
Epoch 46, Training Loss: 0.3558596670627594, Validation Loss: 0.35018083453178406
Epoch 47, Training Loss: 0.35018083453178406, Validation Loss: 0.3440759479999542
Epoch 48, Training Loss: 0.3440759479999542, Validation Loss: 0.3375313878059387
Epoch 49, Training Loss: 0.3375313878059387, Validation Loss: 0.3305639326572418
Epoch 50, Training Loss: 0.3305639326572418, Validation Loss: 0.32315248250961304
Epoch 51, Training Loss: 0.32315248250961304, Validation Loss: 0.31530070304870605
Epoch 52, Training Loss: 0.31530073285102844, Validation Loss: 0.30697599053382874
Epoch 53, Training Loss: 0.30697599053382874, Validation Loss: 0.298175573348999
Epoch 54, Training Loss: 0.298175573348999, Validation Loss: 0.28891071677207947
Epoch 55, Training Loss: 0.28891071677207947, Validation Loss: 0.2791401445865631
Epoch 56, Training Loss: 0.2791401445865631, Validation Loss: 0.2689089775085449
Epoch 57, Training Loss: 0.2689089775085449, Validation Loss: 0.2582314908504486
Epoch 58, Training Loss: 0.2582314610481262, Validation Loss: 0.2472020387649536
Epoch 59, Training Loss: 0.2472020387649536, Validation Loss: 0.23582300543785095
Epoch 60, Training Loss: 0.23582297563552856, Validation Loss: 0.2242184430360794
Epoch 61, Training Loss: 0.2242184430360794, Validation Loss: 0.21251459419727325
Epoch 62, Training Loss: 0.21251459419727325, Validation Loss: 0.20072472095489502
Epoch 63, Training Loss: 0.20072472095489502, Validation Loss: 0.18902871012687683
Epoch 64, Training Loss: 0.18902871012687683, Validation Loss: 0.17764469981193542
Epoch 65, Training Loss: 0.17764469981193542, Validation Loss: 0.166708841919899
Epoch 66, Training Loss: 0.166708841919899, Validation Loss: 0.15625371038913727
Epoch 67, Training Loss: 0.15625371038913727, Validation Loss: 0.14652076363563538
Epoch 68, Training Loss: 0.14652079343795776, Validation Loss: 0.13765539228916168
Epoch 69, Training Loss: 0.13765539228916168, Validation Loss: 0.12964265048503876
Epoch 70, Training Loss: 0.12964265048503876, Validation Loss: 0.12251810729503632
Epoch 71, Training Loss: 0.12251812219619751, Validation Loss: 0.11603431403636932
Epoch 72, Training Loss: 0.11603431403636932, Validation Loss: 0.11006799340248108
Epoch 73, Training Loss: 0.11006797850131989, Validation Loss: 0.10436995327472687
Epoch 74, Training Loss: 0.10436995327472687, Validation Loss: 0.09883679449558258
Epoch 75, Training Loss: 0.09883677959442139, Validation Loss: 0.09341631084680557
Epoch 76, Training Loss: 0.09341632574796677, Validation Loss: 0.08804221451282501
Epoch 77, Training Loss: 0.08804220706224442, Validation Loss: 0.08266249299049377
Epoch 78, Training Loss: 0.08266249299049377, Validation Loss: 0.07713188976049423
Epoch 79, Training Loss: 0.07713188976049423, Validation Loss: 0.0716395303606987
Epoch 80, Training Loss: 0.0716395303606987, Validation Loss: 0.06612947583198547
Epoch 81, Training Loss: 0.06612947583198547, Validation Loss: 0.06060158461332321
Epoch 82, Training Loss: 0.06060158088803291, Validation Loss: 0.055198702961206436
Epoch 83, Training Loss: 0.05519869923591614, Validation Loss: 0.05005297064781189
Epoch 84, Training Loss: 0.05005296692252159, Validation Loss: 0.04522364214062691
Epoch 85, Training Loss: 0.04522363096475601, Validation Loss: 0.04067564755678177
Epoch 86, Training Loss: 0.04067564755678177, Validation Loss: 0.03643815964460373
Epoch 87, Training Loss: 0.03643816336989403, Validation Loss: 0.032545238733291626
Epoch 88, Training Loss: 0.032545238733291626, Validation Loss: 0.02895962819457054
Epoch 89, Training Loss: 0.028959624469280243, Validation Loss: 0.025689028203487396
Epoch 90, Training Loss: 0.025689030066132545, Validation Loss: 0.022721117362380028
Epoch 91, Training Loss: 0.022721121087670326, Validation Loss: 0.02004246972501278
Epoch 92, Training Loss: 0.02004246599972248, Validation Loss: 0.017641158774495125
Epoch 93, Training Loss: 0.017641158774495125, Validation Loss: 0.015508866868913174
Epoch 94, Training Loss: 0.015508866868913174, Validation Loss: 0.013657310977578163
Epoch 95, Training Loss: 0.013657309114933014, Validation Loss: 0.012013472616672516
Epoch 96, Training Loss: 0.012013469822704792, Validation Loss: 0.010541602969169617
Epoch 97, Training Loss: 0.010541604831814766, Validation Loss: 0.009226785972714424
Epoch 98, Training Loss: 0.009226786904036999, Validation Loss: 0.008055363781750202
Epoch 99, Training Loss: 0.008055363781750202, Validation Loss: 0.0070084473118186
Epoch 100, Training Loss: 0.0070084473118186, Validation Loss: 0.006081716623157263
Epoch 101, Training Loss: 0.006081716623157263, Validation Loss: 0.005239858292043209
Epoch 102, Training Loss: 0.005239856895059347, Validation Loss: 0.004513675346970558
Epoch 103, Training Loss: 0.004513672553002834, Validation Loss: 0.003875585738569498
Epoch 104, Training Loss: 0.003875585738569498, Validation Loss: 0.0033040111884474754
Epoch 105, Training Loss: 0.00330400955863297, Validation Loss: 0.002808407647535205
Epoch 106, Training Loss: 0.0028084067162126303, Validation Loss: 0.0023887173738330603
Epoch 107, Training Loss: 0.002388716908171773, Validation Loss: 0.0020348408725112677
Epoch 108, Training Loss: 0.002034839941188693, Validation Loss: 0.0017377149779349566
Epoch 109, Training Loss: 0.0017377155600115657, Validation Loss: 0.0014906792202964425
Epoch 110, Training Loss: 0.0014906798023730516, Validation Loss: 0.0012853422667831182
Epoch 111, Training Loss: 0.0012853421503677964, Validation Loss: 0.0011133666848763824
Epoch 112, Training Loss: 0.0011133657535538077, Validation Loss: 0.0009684307151474059
Epoch 113, Training Loss: 0.0009684300748631358, Validation Loss: 0.000845039205159992
Epoch 114, Training Loss: 0.0008450387394987047, Validation Loss: 0.0007392200059257448
Epoch 115, Training Loss: 0.0007392194238491356, Validation Loss: 0.0006475815898738801
Epoch 116, Training Loss: 0.0006475827540270984, Validation Loss: 0.000568337389267981
Epoch 117, Training Loss: 0.0005683375056833029, Validation Loss: 0.000500727619510144
Epoch 118, Training Loss: 0.0005007275613024831, Validation Loss: 0.0004444354271981865
Epoch 119, Training Loss: 0.00044443580554798245, Validation Loss: 0.0003982334164902568
Epoch 120, Training Loss: 0.0003982333291787654, Validation Loss: 0.0003605608071666211
Epoch 121, Training Loss: 0.0003605607198551297, Validation Loss: 0.00032999139511957765
Epoch 122, Training Loss: 0.000329991162288934, Validation Loss: 0.0003039331641048193
Epoch 123, Training Loss: 0.0003039333096239716, Validation Loss: 0.0002816616033669561
Epoch 124, Training Loss: 0.0002816621563397348, Validation Loss: 0.0002616241981741041
Epoch 125, Training Loss: 0.0002616246056277305, Validation Loss: 0.0002424611011520028
Epoch 126, Training Loss: 0.00024246107204817235, Validation Loss: 0.0002236012660432607
Epoch 127, Training Loss: 0.00022360107686836272, Validation Loss: 0.00020492490148171782
Epoch 128, Training Loss: 0.0002049248432740569, Validation Loss: 0.0001868137187557295
Epoch 129, Training Loss: 0.00018681328219827265, Validation Loss: 0.0001694869133643806
Epoch 130, Training Loss: 0.00016948695702012628, Validation Loss: 0.00015335161879193038
Epoch 131, Training Loss: 0.00015335172065533698, Validation Loss: 0.00013871747069060802
Epoch 132, Training Loss: 0.00013871749979443848, Validation Loss: 0.00012550433166325092
Epoch 133, Training Loss: 0.00012550392420962453, Validation Loss: 0.00011386688856873661
Epoch 134, Training Loss: 0.00011386663391022012, Validation Loss: 0.00010369281517341733
Epoch 135, Training Loss: 0.00010369272786192596, Validation Loss: 9.468558710068464e-05
Epoch 136, Training Loss: 9.468550706515089e-05, Validation Loss: 8.651147072669119e-05
Epoch 137, Training Loss: 8.651116513647139e-05, Validation Loss: 7.888157415436581e-05
Epoch 138, Training Loss: 7.888163963798434e-05, Validation Loss: 7.161193207139149e-05
Epoch 139, Training Loss: 7.161180110415444e-05, Validation Loss: 6.464379112003371e-05
Epoch 140, Training Loss: 6.464387115556747e-05, Validation Loss: 5.803096792078577e-05
Epoch 141, Training Loss: 5.803106614621356e-05, Validation Loss: 5.1898896344937384e-05
Epoch 142, Training Loss: 5.189879084355198e-05, Validation Loss: 4.6389479393837973e-05
Epoch 143, Training Loss: 4.638944665202871e-05, Validation Loss: 4.160931712249294e-05
Epoch 144, Training Loss: 4.160936441621743e-05, Validation Loss: 3.7591355066979304e-05
Epoch 145, Training Loss: 3.759163882932626e-05, Validation Loss: 3.4281219996046275e-05
Epoch 146, Training Loss: 3.428131094551645e-05, Validation Loss: 3.1546511308988556e-05
Epoch 147, Training Loss: 3.154660589643754e-05, Validation Loss: 2.9207234547357075e-05
Epoch 148, Training Loss: 2.9207219995441847e-05, Validation Loss: 2.7073831006418914e-05
Epoch 149, Training Loss: 2.707398743950762e-05, Validation Loss: 2.4987228243844584e-05
Epoch 150, Training Loss: 2.498710819054395e-05, Validation Loss: 2.2844562408863567e-05
Epoch 151, Training Loss: 2.2844662453280762e-05, Validation Loss: 2.0612567823263817e-05
Epoch 152, Training Loss: 2.0612587832147256e-05, Validation Loss: 1.8321346942684613e-05
Epoch 153, Training Loss: 1.8321296010981314e-05, Validation Loss: 1.6042733477661386e-05
Epoch 154, Training Loss: 1.6042753486544825e-05, Validation Loss: 1.3863073945685755e-05
Epoch 155, Training Loss: 1.38630966830533e-05, Validation Loss: 1.1883774277521297e-05
Epoch 156, Training Loss: 1.1883676052093506e-05, Validation Loss: 1.0162759281229228e-05
Epoch 157, Training Loss: 1.016282749333186e-05, Validation Loss: 8.721233825781383e-06
Epoch 158, Training Loss: 8.721210178919137e-06, Validation Loss: 7.543086667283205e-06
Epoch 159, Training Loss: 7.543151241407031e-06, Validation Loss: 6.586638846783899e-06
Epoch 160, Training Loss: 6.586577455891529e-06, Validation Loss: 5.796237928734627e-06
Epoch 161, Training Loss: 5.796317964268383e-06, Validation Loss: 5.118898116052151e-06
Epoch 162, Training Loss: 5.118842182127992e-06, Validation Loss: 4.512880423135357e-06
Epoch 163, Training Loss: 4.512897703534691e-06, Validation Loss: 3.9546330299344845e-06
Epoch 164, Training Loss: 3.9546494008391164e-06, Validation Loss: 3.4382539979560534e-06
Epoch 165, Training Loss: 3.4383401725790463e-06, Validation Loss: 2.970736659335671e-06
Epoch 166, Training Loss: 2.970760760945268e-06, Validation Loss: 2.5648307655501412e-06
Epoch 167, Training Loss: 2.5648187147453427e-06, Validation Loss: 2.2321430606098147e-06
Epoch 168, Training Loss: 2.2321721644402714e-06, Validation Loss: 1.9777260149567155e-06
Epoch 169, Training Loss: 1.9777614852500847e-06, Validation Loss: 1.7972953401113045e-06
Epoch 170, Training Loss: 1.7973154626815813e-06, Validation Loss: 1.678321837061958e-06
Epoch 171, Training Loss: 1.6783660612418316e-06, Validation Loss: 1.602761017238663e-06
Epoch 172, Training Loss: 1.6027639730964438e-06, Validation Loss: 1.5511782294197474e-06
Epoch 173, Training Loss: 1.5512031268372084e-06, Validation Loss: 1.5068396805872908e-06
Epoch 174, Training Loss: 1.5068019365571672e-06, Validation Loss: 1.4581273717340082e-06
Epoch 175, Training Loss: 1.4581030427507358e-06, Validation Loss: 1.4000032706462662e-06
Epoch 176, Training Loss: 1.399966549797682e-06, Validation Loss: 1.3327309034139034e-06
Epoch 177, Training Loss: 1.3327422720976756e-06, Validation Loss: 1.2602206425071927e-06
Epoch 178, Training Loss: 1.2602367860381491e-06, Validation Loss: 1.1874253686983138e-06
Epoch 179, Training Loss: 1.1874276424350683e-06, Validation Loss: 1.1183327615071903e-06
Epoch 180, Training Loss: 1.1182665957676363e-06, Validation Loss: 1.0542973996052751e-06
Epoch 181, Training Loss: 1.0542805739532923e-06, Validation Loss: 9.944427574737347e-07
Epoch 182, Training Loss: 9.944553767127218e-07, Validation Loss: 9.356179475616955e-07
Epoch 183, Training Loss: 9.356341479360708e-07, Validation Loss: 8.741099577491696e-07
Epoch 184, Training Loss: 8.741249075683299e-07, Validation Loss: 8.066577379395312e-07
Epoch 185, Training Loss: 8.066579084697878e-07, Validation Loss: 7.31689624444698e-07
Epoch 186, Training Loss: 7.316676828850177e-07, Validation Loss: 6.497855906673067e-07
Epoch 187, Training Loss: 6.497537583527446e-07, Validation Loss: 5.634665285469964e-07
Epoch 188, Training Loss: 5.63426681310375e-07, Validation Loss: 4.765916798987746e-07
Epoch 189, Training Loss: 4.765941241657856e-07, Validation Loss: 3.935537336019479e-07
Epoch 190, Training Loss: 3.935611232463998e-07, Validation Loss: 3.1822011692383967e-07
Epoch 191, Training Loss: 3.18238363661294e-07, Validation Loss: 2.5324391117464984e-07
Epoch 192, Training Loss: 2.532621863338136e-07, Validation Loss: 1.9990508803857665e-07
Epoch 193, Training Loss: 1.9989938948583585e-07, Validation Loss: 1.5797672858752776e-07
Epoch 194, Training Loss: 1.579841608645438e-07, Validation Loss: 1.263060624978607e-07
Epoch 195, Training Loss: 1.2628404988390685e-07, Validation Loss: 1.0299893205001354e-07
Epoch 196, Training Loss: 1.0298754915538666e-07, Validation Loss: 8.613444890670507e-08
Epoch 197, Training Loss: 8.613194069084784e-08, Validation Loss: 7.409933289181936e-08
Epoch 198, Training Loss: 7.409165903027315e-08, Validation Loss: 6.558403242706845e-08
Epoch 199, Training Loss: 6.557523590799974e-08, Validation Loss: 5.981109296726572e-08
Epoch 200, Training Loss: 5.979814687862017e-08, Validation Loss: 5.623845922286819e-08
Epoch 201, Training Loss: 5.6238668832975236e-08, Validation Loss: 5.4526914539110294e-08
Epoch 202, Training Loss: 5.4517251157903956e-08, Validation Loss: 5.426446847422994e-08
Epoch 203, Training Loss: 5.42529292602012e-08, Validation Loss: 5.497274813137665e-08
Epoch 204, Training Loss: 5.497185640024327e-08, Validation Loss: 5.611333619981451e-08
Epoch 205, Training Loss: 5.612304931901235e-08, Validation Loss: 5.7099295958096263e-08
Epoch 206, Training Loss: 5.710648309786848e-08, Validation Loss: 5.742181130585777e-08
Epoch 207, Training Loss: 5.7427168798085404e-08, Validation Loss: 5.672880831752991e-08
Epoch 208, Training Loss: 5.6744696053101507e-08, Validation Loss: 5.491993704254128e-08
Epoch 209, Training Loss: 5.4921724057521715e-08, Validation Loss: 5.203573039125331e-08
Epoch 210, Training Loss: 5.2028870101139546e-08, Validation Loss: 4.832705258195347e-08
Epoch 211, Training Loss: 4.831946043282187e-08, Validation Loss: 4.411005249949085e-08
Epoch 212, Training Loss: 4.410307852253936e-08, Validation Loss: 3.971438999883503e-08
Epoch 213, Training Loss: 3.971676321157247e-08, Validation Loss: 3.542169579873189e-08
Epoch 214, Training Loss: 3.541861204325869e-08, Validation Loss: 3.1401171440847975e-08
Epoch 215, Training Loss: 3.139114213013272e-08, Validation Loss: 2.7723402240553696e-08
Epoch 216, Training Loss: 2.7732314222816967e-08, Validation Loss: 2.4406871190763013e-08
Epoch 217, Training Loss: 2.441140800613084e-08, Validation Loss: 2.1416775908278396e-08
Epoch 218, Training Loss: 2.141151789203377e-08, Validation Loss: 1.867472931849079e-08
Epoch 219, Training Loss: 1.8676026058983553e-08, Validation Loss: 1.6154842796822777e-08
Epoch 220, Training Loss: 1.6155892623714863e-08, Validation Loss: 1.384851699981482e-08
Epoch 221, Training Loss: 1.3848111102277016e-08, Validation Loss: 1.176619868203943e-08
Epoch 222, Training Loss: 1.1765628471493983e-08, Validation Loss: 9.927379807095349e-09
Epoch 223, Training Loss: 9.92927340348615e-09, Validation Loss: 8.361065617634722e-09
Epoch 224, Training Loss: 8.358385095164067e-09, Validation Loss: 7.067043394926031e-09
Epoch 225, Training Loss: 7.0683756625555816e-09, Validation Loss: 6.042955025264973e-09
Epoch 226, Training Loss: 6.042112588033888e-09, Validation Loss: 5.258741886393636e-09
Epoch 227, Training Loss: 5.261264313105585e-09, Validation Loss: 4.673744946614988e-09
Epoch 228, Training Loss: 4.675344555948868e-09, Validation Loss: 4.2386809617767085e-09
Epoch 229, Training Loss: 4.238988271509925e-09, Validation Loss: 3.909693901960054e-09
Epoch 230, Training Loss: 3.90813514883348e-09, Validation Loss: 3.643511270468025e-09
Epoch 231, Training Loss: 3.6425975569187585e-09, Validation Loss: 3.4131890647159935e-09
Epoch 232, Training Loss: 3.4132632276140384e-09, Validation Loss: 3.2042855035996354e-09
Epoch 233, Training Loss: 3.2022862139768904e-09, Validation Loss: 3.0008877605069983e-09
Epoch 234, Training Loss: 2.999153370097929e-09, Validation Loss: 2.7988755757490935e-09
Epoch 235, Training Loss: 2.8026456710961156e-09, Validation Loss: 2.604116033921855e-09
Epoch 236, Training Loss: 2.6043485146232115e-09, Validation Loss: 2.4114268359909374e-09
Epoch 237, Training Loss: 2.41121145272416e-09, Validation Loss: 2.2188573201020745e-09
Epoch 238, Training Loss: 2.2178769931713305e-09, Validation Loss: 2.0333050798626573e-09
Epoch 239, Training Loss: 2.033836654646848e-09, Validation Loss: 1.8542369861762609e-09
Epoch 240, Training Loss: 1.853081466052231e-09, Validation Loss: 1.6790644430386692e-09
Epoch 241, Training Loss: 1.6808436864579335e-09, Validation Loss: 1.5169918654578396e-09
Epoch 242, Training Loss: 1.5171350842280162e-09, Validation Loss: 1.3628213002547795e-09
Epoch 243, Training Loss: 1.3626358930096671e-09, Validation Loss: 1.2190101150721944e-09
Epoch 244, Training Loss: 1.2182604924859675e-09, Validation Loss: 1.0850397247352817e-09
Epoch 245, Training Loss: 1.0862276633716306e-09, Validation Loss: 9.63720436786275e-10
Epoch 246, Training Loss: 9.642384668495652e-10, Validation Loss: 8.568051823587552e-10
Epoch 247, Training Loss: 8.564006725997331e-10, Validation Loss: 7.616129393817062e-10
Epoch 248, Training Loss: 7.619334607689154e-10, Validation Loss: 6.793957063599976e-10
Epoch 249, Training Loss: 6.788177242533777e-10, Validation Loss: 6.086552373218979e-10
Epoch 250, Training Loss: 6.085031922786754e-10, Validation Loss: 5.496607613508786e-10
Epoch 251, Training Loss: 5.493508981047057e-10, Validation Loss: 5.007352865682435e-10
Epoch 252, Training Loss: 5.006178804833894e-10, Validation Loss: 4.5787038049915907e-10
Epoch 253, Training Loss: 4.5910136803328783e-10, Validation Loss: 4.222480975979437e-10
Epoch 254, Training Loss: 4.224756655624162e-10, Validation Loss: 3.8877551178373437e-10
Epoch 255, Training Loss: 3.888566968424101e-10, Validation Loss: 3.5799302411376743e-10
Epoch 256, Training Loss: 3.566988926451131e-10, Validation Loss: 3.2624031254258057e-10
Epoch 257, Training Loss: 3.259704728364454e-10, Validation Loss: 2.965139245247883e-10
Epoch 258, Training Loss: 2.968429668737116e-10, Validation Loss: 2.6920096707350183e-10
Epoch 259, Training Loss: 2.690995482002023e-10, Validation Loss: 2.4323898450973047e-10
Epoch 260, Training Loss: 2.436057189303398e-10, Validation Loss: 2.196334364379382e-10
Epoch 261, Training Loss: 2.193430853614231e-10, Validation Loss: 1.9796848882425166e-10
Epoch 262, Training Loss: 1.982138064793304e-10, Validation Loss: 1.7852973266396788e-10
Epoch 263, Training Loss: 1.7858436951456724e-10, Validation Loss: 1.5964388144773523e-10
Epoch 264, Training Loss: 1.6003554037524736e-10, Validation Loss: 1.4238540901878594e-10
Epoch 265, Training Loss: 1.4222127642238291e-10, Validation Loss: 1.249114561785447e-10
Epoch 266, Training Loss: 1.2469292265393506e-10, Validation Loss: 1.0757469914857154e-10
Epoch 267, Training Loss: 1.0735082961454978e-10, Validation Loss: 9.021226821115391e-11
Epoch 268, Training Loss: 9.057713606930307e-11, Validation Loss: 7.489285580586369e-11
Epoch 269, Training Loss: 7.466979118353478e-11, Validation Loss: 6.057584295282581e-11
Epoch 270, Training Loss: 6.059990009799066e-11, Validation Loss: 4.888396631930192e-11
Epoch 271, Training Loss: 4.8755100651165506e-11, Validation Loss: 3.950981902756112e-11
Epoch 272, Training Loss: 3.9624192815779224e-11, Validation Loss: 3.291262054561095e-11
Epoch 273, Training Loss: 3.295414288673193e-11, Validation Loss: 2.8601006979434018e-11
Epoch 274, Training Loss: 2.8544248562023533e-11, Validation Loss: 2.6180587212043527e-11
Epoch 275, Training Loss: 2.6229088345708362e-11, Validation Loss: 2.5277915177701615e-11
Epoch 276, Training Loss: 2.5233804629154477e-11, Validation Loss: 2.5054576469063505e-11
Epoch 277, Training Loss: 2.5117132332330705e-11, Validation Loss: 2.5547826007499275e-11
Epoch 278, Training Loss: 2.5642194964592413e-11, Validation Loss: 2.5944982273706785e-11
Epoch 279, Training Loss: 2.6012150766696607e-11, Validation Loss: 2.6390022112021683e-11
Epoch 280, Training Loss: 2.6392730015367682e-11, Validation Loss: 2.6911948364238825e-11
Epoch 281, Training Loss: 2.673603352598697e-11, Validation Loss: 2.6935771321734414e-11
Epoch 282, Training Loss: 2.6963568530713466e-11, Validation Loss: 2.6527537111409316e-11
Epoch 283, Training Loss: 2.6591088705951726e-11, Validation Loss: 2.600076230707682e-11
Epoch 284, Training Loss: 2.5977957632261628e-11, Validation Loss: 2.4944249790714856e-11
Epoch 285, Training Loss: 2.4765942768789628e-11, Validation Loss: 2.3339162200097796e-11
Epoch 286, Training Loss: 2.3226158843425715e-11, Validation Loss: 2.1173538616858778e-11
Epoch 287, Training Loss: 2.1414474360437197e-11, Validation Loss: 1.8874492246911956e-11
Epoch 288, Training Loss: 1.9003461998456928e-11, Validation Loss: 1.6233084321193303e-11
Epoch 289, Training Loss: 1.6436912594897102e-11, Validation Loss: 1.3634284673491592e-11
Epoch 290, Training Loss: 1.368109878857604e-11, Validation Loss: 1.0936171239428472e-11
Epoch 291, Training Loss: 1.0914846283738289e-11, Validation Loss: 8.349678587427078e-12
Epoch 292, Training Loss: 8.438776587238461e-12, Validation Loss: 6.228562804411197e-12
Epoch 293, Training Loss: 6.193488864131291e-12, Validation Loss: 4.428608955248103e-12
Epoch 294, Training Loss: 4.420985712932923e-12, Validation Loss: 2.9708191202210132e-12
Epoch 295, Training Loss: 2.9658445838132153e-12, Validation Loss: 2.0294638365669915e-12
Epoch 296, Training Loss: 2.0082488189770986e-12, Validation Loss: 1.4137513859244222e-12
Epoch 297, Training Loss: 1.4237521751836457e-12, Validation Loss: 1.1529795130790776e-12
Epoch 298, Training Loss: 1.133298749983469e-12, Validation Loss: 1.0623983246957347e-12
Epoch 299, Training Loss: 1.0819724022975707e-12, Validation Loss: 1.1497908744897978e-12
Epoch 300, Training Loss: 1.1533440218494673e-12, Validation Loss: 1.3058222038397904e-12
Epoch 301, Training Loss: 1.270099043299e-12, Validation Loss: 1.504851581887734e-12
Epoch 302, Training Loss: 1.4998376889410747e-12, Validation Loss: 1.641261454000953e-12
Epoch 303, Training Loss: 1.6870118583339755e-12, Validation Loss: 1.7380065485753105e-12
Epoch 304, Training Loss: 1.7755419530474104e-12, Validation Loss: 1.8080060018577093e-12
Epoch 305, Training Loss: 1.7843808028383812e-12, Validation Loss: 1.831103628099906e-12
Epoch 306, Training Loss: 1.820196987925571e-12, Validation Loss: 1.8306705977522153e-12
Epoch 307, Training Loss: 1.8206488833910628e-12, Validation Loss: 1.755022884832036e-12
Epoch 308, Training Loss: 1.7672204845331496e-12, Validation Loss: 1.6456227656599931e-12
Epoch 309, Training Loss: 1.657604934389434e-12, Validation Loss: 1.519077290172699e-12
Epoch 310, Training Loss: 1.5745011631290717e-12, Validation Loss: 1.406755354566025e-12
Epoch 311, Training Loss: 1.4077417617025523e-12, Validation Loss: 1.315954289982102e-12
Epoch 312, Training Loss: 1.3326165258092937e-12, Validation Loss: 1.194928270914497e-12
Epoch 313, Training Loss: 1.1820581406057906e-12, Validation Loss: 1.0191650041263545e-12
Epoch 314, Training Loss: 1.0373975983801742e-12, Validation Loss: 8.757196899057684e-13
Epoch 315, Training Loss: 8.754814906884734e-13, Validation Loss: 7.853565887894209e-13
Epoch 316, Training Loss: 7.787172599457715e-13, Validation Loss: 6.664121836828796e-13
Epoch 317, Training Loss: 6.514951880927378e-13, Validation Loss: 5.719278132684802e-13
Epoch 318, Training Loss: 5.527781466070636e-13, Validation Loss: 4.731085315179406e-13
Epoch 319, Training Loss: 4.665692745348116e-13, Validation Loss: 3.8065652518091964e-13
Epoch 320, Training Loss: 3.932254641261096e-13, Validation Loss: 3.2019143738314104e-13
Epoch 321, Training Loss: 3.3319866505655826e-13, Validation Loss: 2.691203922038088e-13
Epoch 322, Training Loss: 2.64406904574091e-13, Validation Loss: 2.1326394968566864e-13
Epoch 323, Training Loss: 2.2774775229779387e-13, Validation Loss: 1.834765114361661e-13
Epoch 324, Training Loss: 1.9532652947330809e-13, Validation Loss: 1.7342297574125115e-13
Epoch 325, Training Loss: 1.6486572035952912e-13, Validation Loss: 1.3783500165884255e-13
Epoch 326, Training Loss: 1.371912159613478e-13, Validation Loss: 1.424637317837263e-13
Epoch 327, Training Loss: 1.1613010086983927e-13, Validation Loss: 1.223902435561891e-13
Epoch 328, Training Loss: 1.1540031083501212e-13, Validation Loss: 1.1199071861924328e-13
Epoch 329, Training Loss: 1.1450339103529633e-13, Validation Loss: 1.0072494325153586e-13
Epoch 330, Training Loss: 9.534220472579708e-14, Validation Loss: 8.433541137577855e-14
Epoch 331, Training Loss: 8.992132938864111e-14, Validation Loss: 7.834371037107254e-14
Epoch 332, Training Loss: 7.889773090494906e-14, Validation Loss: 6.519363906143036e-14
Epoch 333, Training Loss: 6.865508324609831e-14, Validation Loss: 6.446592256325809e-14
Epoch 334, Training Loss: 6.400836214141489e-14, Validation Loss: 5.916056896758046e-14
Epoch 335, Training Loss: 4.925756796805153e-14, Validation Loss: 4.978789190819566e-14
Epoch 336, Training Loss: 5.3416699638845697e-14, Validation Loss: 4.022132561905256e-14
Epoch 337, Training Loss: 4.752140792419618e-14, Validation Loss: 3.367337807788466e-14
Epoch 338, Training Loss: 3.7763256334911316e-14, Validation Loss: 3.2936855825192735e-14
Epoch 339, Training Loss: 3.7170648368089684e-14, Validation Loss: 3.5091914319046805e-14
Epoch 340, Training Loss: 3.281835930400365e-14, Validation Loss: 3.1059552987270506e-14
Epoch 341, Training Loss: 2.9297504228415275e-14, Validation Loss: 3.026131252590984e-14
Epoch 342, Training Loss: 2.6797867649420472e-14, Validation Loss: 2.9453463322795526e-14
Epoch 343, Training Loss: 2.6030184748664954e-14, Validation Loss: 2.894599233156832e-14
Epoch 344, Training Loss: 2.444388346790373e-14, Validation Loss: 2.8119128932854037e-14
Epoch 345, Training Loss: 2.446549974871766e-14, Validation Loss: 3.046647745826199e-14
Epoch 346, Training Loss: 2.238530033267603e-14, Validation Loss: 2.278775617910265e-14
Epoch 347, Training Loss: 2.2274743898334504e-14, Validation Loss: 2.2626193114743363e-14
Epoch 348, Training Loss: 1.9666988645820373e-14, Validation Loss: 1.8682231529474312e-14
Epoch 349, Training Loss: 1.8320141885182044e-14, Validation Loss: 2.1897942985814323e-14
Epoch 350, Training Loss: 1.7782879051134008e-14, Validation Loss: 1.9574147058537723e-14
Epoch 351, Training Loss: 1.946659420302716e-14, Validation Loss: 1.910123501155849e-14
Epoch 352, Training Loss: 1.757928112973428e-14, Validation Loss: 1.5920351855943683e-14
Epoch 353, Training Loss: 1.4041780162666467e-14, Validation Loss: 1.2578207179698812e-14
Epoch 354, Training Loss: 1.2181523015774784e-14, Validation Loss: 1.641488187780274e-14
Epoch 355, Training Loss: 1.2341484340830811e-14, Validation Loss: 1.6713422028194307e-14
Epoch 356, Training Loss: 9.217814025638295e-15, Validation Loss: 1.3795749278741089e-14
Epoch 357, Training Loss: 7.361726821945944e-15, Validation Loss: 9.382913452552367e-15
Epoch 358, Training Loss: 8.233826015208341e-15, Validation Loss: 1.0617735870751578e-14
Epoch 359, Training Loss: 6.667470242772587e-15, Validation Loss: 9.341946704058413e-15
Epoch 360, Training Loss: 7.711674248939322e-15, Validation Loss: 7.421507866264311e-15
Epoch 361, Training Loss: 6.618531220179075e-15, Validation Loss: 7.408697339970037e-15
Epoch 362, Training Loss: 5.254471479503118e-15, Validation Loss: 7.463041279799978e-15
Epoch 363, Training Loss: 5.022619080081829e-15, Validation Loss: 5.270050532985493e-15
Epoch 364, Training Loss: 5.070924098514321e-15, Validation Loss: 5.850015262519933e-15
Epoch 365, Training Loss: 5.7155741931317304e-15, Validation Loss: 5.428644323348178e-15
Epoch 366, Training Loss: 5.677276868971048e-15, Validation Loss: 4.0480043362461915e-15
Epoch 367, Training Loss: 3.6009462759160026e-15, Validation Loss: 3.9706092417896716e-15
Epoch 368, Training Loss: 3.7598733737434324e-15, Validation Loss: 4.929677542911404e-15
Epoch 369, Training Loss: 4.43828408405603e-15, Validation Loss: 3.7437606895042875e-15
Epoch 370, Training Loss: 2.826692305313923e-15, Validation Loss: 3.7677130871867446e-15
Epoch 371, Training Loss: 2.4124938293812806e-15, Validation Loss: 3.612922474757231e-15
Epoch 372, Training Loss: 2.7265787284208587e-15, Validation Loss: 3.369794372742093e-15
Epoch 373, Training Loss: 2.60261291549135e-15, Validation Loss: 2.7885283888424333e-15
Epoch 374, Training Loss: 3.2612405360461132e-15, Validation Loss: 1.2813206094760914e-15
Epoch 375, Training Loss: 1.7894278283258052e-15, Validation Loss: 1.787726350893008e-15
Epoch 376, Training Loss: 2.4518253807705604e-15, Validation Loss: 2.372862004812199e-15
Epoch 377, Training Loss: 3.0549753078954823e-15, Validation Loss: 2.3882077007176053e-15
Epoch 378, Training Loss: 2.9962949828920725e-15, Validation Loss: 2.9050218888695013e-15
Epoch 379, Training Loss: 1.6409754575614772e-15, Validation Loss: 3.3756990394174027e-15
Epoch 380, Training Loss: 1.3201851280740789e-15, Validation Loss: 2.4676380035881405e-15
Epoch 381, Training Loss: 1.3292589685215406e-15, Validation Loss: 2.9407171278162184e-15
Epoch 382, Training Loss: 1.2896606017538757e-15, Validation Loss: 2.6973219986644583e-15
Epoch 383, Training Loss: 1.2943977393905137e-15, Validation Loss: 2.442184240006675e-15
Epoch 384, Training Loss: 1.3095098659607145e-15, Validation Loss: 2.3494432378865122e-15
Epoch 385, Training Loss: 8.324609100670926e-16, Validation Loss: 2.2549675122903725e-15
Epoch 386, Training Loss: 1.3736946345718564e-15, Validation Loss: 2.4471215950562205e-15
Epoch 387, Training Loss: 1.3736946345718564e-15, Validation Loss: 2.976078847539954e-15
Epoch 388, Training Loss: 1.3231207325110255e-15, Validation Loss: 3.782858459800125e-15
Epoch 389, Training Loss: 1.1341025774741498e-15, Validation Loss: 3.701193048740023e-15
Epoch 390, Training Loss: 8.234536675851088e-16, Validation Loss: 4.021449853349769e-15
Epoch 391, Training Loss: 1.2606039835312641e-15, Validation Loss: 3.925373023725082e-15
Epoch 392, Training Loss: 1.3022373469547075e-15, Validation Loss: 4.002234487424832e-15
Epoch 393, Training Loss: 1.3375990666784432e-15, Validation Loss: 3.5154444408795485e-15
Epoch 394, Training Loss: 1.3456054338541277e-15, Validation Loss: 3.887342514942785e-15
Epoch 395, Training Loss: 2.257269324324536e-15, Validation Loss: 3.8232911540208355e-15
Epoch 396, Training Loss: 1.3530447124716254e-15, Validation Loss: 4.231618209321348e-15
Epoch 397, Training Loss: 1.3274241892786694e-15, Validation Loss: 4.73385411341805e-15
Epoch 398, Training Loss: 1.4026845489498716e-15, Validation Loss: 3.731584167371033e-15
Epoch 399, Training Loss: 1.9070887515124264e-15, Validation Loss: 3.67820796268333e-15
Epoch 400, Training Loss: 1.9157623688923105e-15, Validation Loss: 3.669201037838701e-15
Epoch 401, Training Loss: 1.8757303212556514e-15, Validation Loss: 3.724912088845511e-15
Epoch 402, Training Loss: 9.683364297514703e-16, Validation Loss: 3.724912088845511e-15
Epoch 403, Training Loss: 9.971595845179948e-16, Validation Loss: 3.750733041209611e-15
Epoch 404, Training Loss: 1.0308531787312316e-15, Validation Loss: 3.731384267595481e-15
Epoch 405, Training Loss: 1.0185100028656051e-15, Validation Loss: 2.7405901356761025e-15
Epoch 406, Training Loss: 1.0761562065195358e-15, Validation Loss: 3.099277460377487e-15
Epoch 407, Training Loss: 7.879251882498823e-16, Validation Loss: 3.099277460377487e-15
Epoch 408, Training Loss: 9.36377453135092e-16, Validation Loss: 3.291431543143335e-15
Epoch 409, Training Loss: 1.304672672557182e-15, Validation Loss: 3.291431543143335e-15
Epoch 410, Training Loss: 1.2859910432681332e-15, Validation Loss: 3.3672255335713075e-15
Epoch 411, Training Loss: 7.8745815545859e-16, Validation Loss: 3.228447655493163e-15
Epoch 412, Training Loss: 1.5220468436901715e-15, Validation Loss: 3.228447655493163e-15
Epoch 413, Training Loss: 1.4820147960535124e-15, Validation Loss: 4.03069055928784e-15
Epoch 414, Training Loss: 1.4179634351315631e-15, Validation Loss: 4.03069055928784e-15
Epoch 415, Training Loss: 1.5819281555336695e-15, Validation Loss: 4.051807514179363e-15
Epoch 416, Training Loss: 2.1317688994528395e-15, Validation Loss: 4.049639109834392e-15
Epoch 417, Training Loss: 2.053639639189287e-15, Validation Loss: 4.0652516211181836e-15
Epoch 418, Training Loss: 1.6052802186147601e-15, Validation Loss: 4.0652516211181836e-15
Epoch 419, Training Loss: 1.9382803162785924e-15, Validation Loss: 4.0652516211181836e-15
Epoch 420, Training Loss: 1.1318341173622844e-15, Validation Loss: 4.988691598896032e-15
Epoch 421, Training Loss: 8.559463808373757e-16, Validation Loss: 4.535728871890533e-15
Epoch 422, Training Loss: 7.730465780753277e-16, Validation Loss: 4.414631536036901e-15
Epoch 423, Training Loss: 7.25008110323425e-16, Validation Loss: 4.4358154065312575e-15
Epoch 424, Training Loss: 1.1145535864471126e-15, Validation Loss: 4.1641308592488616e-15
Epoch 425, Training Loss: 1.0761228545972377e-15, Validation Loss: 4.258539881000405e-15
Epoch 426, Training Loss: 5.077339949573299e-16, Validation Loss: 4.258539881000405e-15
Epoch 427, Training Loss: 5.104027840158913e-16, Validation Loss: 3.786227956864303e-15
Epoch 428, Training Loss: 5.104027840158913e-16, Validation Loss: 3.786227956864303e-15
Epoch 429, Training Loss: 5.104027840158913e-16, Validation Loss: 3.786227956864303e-15
Epoch 430, Training Loss: 5.104027840158913e-16, Validation Loss: 4.298638844239897e-15
Epoch 431, Training Loss: 5.050651529592092e-16, Validation Loss: 4.298638844239897e-15
Epoch 432, Training Loss: 5.386921492069681e-16, Validation Loss: 4.248598678814955e-15
Epoch 433, Training Loss: 4.693031572283366e-16, Validation Loss: 4.248598678814955e-15
Epoch 434, Training Loss: 7.151669109653101e-16, Validation Loss: 4.201227090690337e-15
Epoch 435, Training Loss: 7.151669109653101e-16, Validation Loss: 4.6111558852941076e-15
Epoch 436, Training Loss: 7.151669109653101e-16, Validation Loss: 4.246063085687349e-15
Epoch 437, Training Loss: 6.863438091383447e-16, Validation Loss: 4.2652784516122866e-15
Epoch 438, Training Loss: 6.863438091383447e-16, Validation Loss: 4.2652784516122866e-15
Epoch 439, Training Loss: 3.021692365842986e-16, Validation Loss: 4.2652784516122866e-15
Epoch 440, Training Loss: 2.9683163199739604e-16, Validation Loss: 4.2652784516122866e-15
Epoch 441, Training Loss: 2.9683163199739604e-16, Validation Loss: 4.302641921948621e-15
Epoch 442, Training Loss: 3.586812101822966e-16, Validation Loss: 4.272217345516194e-15
Epoch 443, Training Loss: 3.346619498365656e-16, Validation Loss: 4.20666504221171e-15
Epoch 444, Training Loss: 3.346619498365656e-16, Validation Loss: 4.20666504221171e-15
Epoch 445, Training Loss: 4.371440690781694e-16, Validation Loss: 4.20666504221171e-15
Epoch 446, Training Loss: 3.5441110533695086e-16, Validation Loss: 4.77031676421498e-15
Epoch 447, Training Loss: 3.4160084374047284e-16, Validation Loss: 4.77031676421498e-15
Epoch 448, Training Loss: 3.736264977316679e-16, Validation Loss: 4.827962861989792e-15
Epoch 449, Training Loss: 3.736264977316679e-16, Validation Loss: 4.822792149363278e-15
Epoch 450, Training Loss: 2.908268301458531e-16, Validation Loss: 4.822792149363278e-15
Epoch 451, Training Loss: 2.7998480842099805e-16, Validation Loss: 4.822792149363278e-15
Epoch 452, Training Loss: 3.2268567158599826e-16, Validation Loss: 4.822792149363278e-15
Epoch 453, Training Loss: 2.906600175948032e-16, Validation Loss: 4.677075377381226e-15
Epoch 454, Training Loss: 2.842548867965642e-16, Validation Loss: 3.3095794357964952e-15
Epoch 455, Training Loss: 2.511617065940327e-16, Validation Loss: 3.3095794357964952e-15
Epoch 456, Training Loss: 5.05031801036911e-16, Validation Loss: 3.3095794357964952e-15
Epoch 457, Training Loss: 4.631649212178215e-16, Validation Loss: 3.3095794357964952e-15
Epoch 458, Training Loss: 4.631649212178215e-16, Validation Loss: 3.3095794357964952e-15
Epoch 459, Training Loss: 4.631649212178215e-16, Validation Loss: 2.8355994920290124e-15
Epoch 460, Training Loss: 4.631649212178215e-16, Validation Loss: 2.8355994920290124e-15
Epoch 461, Training Loss: 2.5766691962894573e-16, Validation Loss: 2.8772328554524558e-15
Epoch 462, Training Loss: 6.675954230651404e-16, Validation Loss: 3.1834450067637788e-15
Epoch 463, Training Loss: 6.889458943523099e-16, Validation Loss: 3.1834450067637788e-15
Epoch 464, Training Loss: 6.816066715017066e-16, Validation Loss: 3.189850058152679e-15
Epoch 465, Training Loss: 6.302321644870428e-16, Validation Loss: 3.639810688634872e-15
Epoch 466, Training Loss: 6.094154827753211e-16, Validation Loss: 3.687849315205452e-15
Epoch 467, Training Loss: 6.094154827753211e-16, Validation Loss: 3.687849315205452e-15
Epoch 468, Training Loss: 7.476929761398752e-16, Validation Loss: 3.085433130371089e-15
Epoch 469, Training Loss: 1.0743547791989628e-15, Validation Loss: 3.0710549578496843e-15
Epoch 470, Training Loss: 1.4522575757044032e-15, Validation Loss: 3.487388592084118e-15
Epoch 471, Training Loss: 3.1214389657116526e-16, Validation Loss: 3.8973171749296515e-15
Epoch 472, Training Loss: 2.4168743132075654e-16, Validation Loss: 3.8973171749296515e-15
Epoch 473, Training Loss: 2.4168743132075654e-16, Validation Loss: 3.8973171749296515e-15
Epoch 474, Training Loss: 2.4102023405611617e-16, Validation Loss: 3.899818886739367e-15
Epoch 475, Training Loss: 2.4102023405611617e-16, Validation Loss: 3.216604864341127e-15
Epoch 476, Training Loss: 2.30345024882311e-16, Validation Loss: 3.2169051375209286e-15
Epoch 477, Training Loss: 1.0437635490341633e-15, Validation Loss: 3.2706148614316134e-15
Epoch 478, Training Loss: 1.0437635490341633e-15, Validation Loss: 3.2690802494894254e-15
Epoch 479, Training Loss: 1.0437635490341633e-15, Validation Loss: 3.2690802494894254e-15
Epoch 480, Training Loss: 3.6321815687580705e-16, Validation Loss: 2.916797976176941e-15
Epoch 481, Training Loss: 4.519559224685685e-16, Validation Loss: 2.916797976176941e-15
Epoch 482, Training Loss: 3.238532800340087e-16, Validation Loss: 2.923203027565841e-15
Epoch 483, Training Loss: 3.3666354163048673e-16, Validation Loss: 2.923203027565841e-15
Epoch 484, Training Loss: 5.042645480053762e-16, Validation Loss: 2.4006510382292446e-15
Epoch 485, Training Loss: 5.042645480053762e-16, Validation Loss: 2.4006510382292446e-15
Epoch 486, Training Loss: 9.077878677037727e-16, Validation Loss: 2.4166637725806135e-15
Epoch 487, Training Loss: 7.956980919694798e-16, Validation Loss: 2.4166637725806135e-15
Epoch 488, Training Loss: 7.876916718542362e-16, Validation Loss: 2.4166637725806135e-15
Epoch 489, Training Loss: 8.120445043625078e-16, Validation Loss: 2.9444868479479736e-15
Epoch 490, Training Loss: 5.085345999111628e-16, Validation Loss: 2.5089378477886025e-15
Epoch 491, Training Loss: 5.277500187756594e-16, Validation Loss: 2.5089378477886025e-15
Epoch 492, Training Loss: 5.277500187756594e-16, Validation Loss: 2.5264851940821594e-15
Epoch 493, Training Loss: 6.398398474495115e-16, Validation Loss: 3.0372610961113163e-15
Epoch 494, Training Loss: 5.472656578803985e-16, Validation Loss: 2.973209735189367e-15
Epoch 495, Training Loss: 5.259152395327882e-16, Validation Loss: 2.601712095951945e-15
Epoch 496, Training Loss: 5.045647682456187e-16, Validation Loss: 2.6097184631276296e-15
Epoch 497, Training Loss: 5.045647682456187e-16, Validation Loss: 2.5856993616005762e-15
Epoch 498, Training Loss: 5.73953707284691e-16, Validation Loss: 2.7144691218904376e-15
Epoch 499, Training Loss: 4.810792974753355e-16, Validation Loss: 2.7144691218904376e-15
Epoch 500, Training Loss: 4.723055713889979e-16, Validation Loss: 2.7144691218904376e-15
