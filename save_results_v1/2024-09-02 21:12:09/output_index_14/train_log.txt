Epoch 1, Training Loss: 0.4373689889907837, Validation Loss: 0.4362335801124573
Epoch 2, Training Loss: 0.4362335801124573, Validation Loss: 0.43514421582221985
Epoch 3, Training Loss: 0.43514421582221985, Validation Loss: 0.4340752363204956
Epoch 4, Training Loss: 0.434075266122818, Validation Loss: 0.43304771184921265
Epoch 5, Training Loss: 0.43304771184921265, Validation Loss: 0.4320230782032013
Epoch 6, Training Loss: 0.4320230782032013, Validation Loss: 0.43101340532302856
Epoch 7, Training Loss: 0.4310133755207062, Validation Loss: 0.42999938130378723
Epoch 8, Training Loss: 0.42999938130378723, Validation Loss: 0.42897745966911316
Epoch 9, Training Loss: 0.42897745966911316, Validation Loss: 0.427959680557251
Epoch 10, Training Loss: 0.427959680557251, Validation Loss: 0.4269639551639557
Epoch 11, Training Loss: 0.4269639551639557, Validation Loss: 0.4259701669216156
Epoch 12, Training Loss: 0.4259701669216156, Validation Loss: 0.424954354763031
Epoch 13, Training Loss: 0.4249543845653534, Validation Loss: 0.42392563819885254
Epoch 14, Training Loss: 0.42392563819885254, Validation Loss: 0.4228890538215637
Epoch 15, Training Loss: 0.4228890538215637, Validation Loss: 0.4218280017375946
Epoch 16, Training Loss: 0.42182791233062744, Validation Loss: 0.42076241970062256
Epoch 17, Training Loss: 0.42076244950294495, Validation Loss: 0.4196942448616028
Epoch 18, Training Loss: 0.4196942448616028, Validation Loss: 0.418619304895401
Epoch 19, Training Loss: 0.418619304895401, Validation Loss: 0.4175228774547577
Epoch 20, Training Loss: 0.41752293705940247, Validation Loss: 0.4164541959762573
Epoch 21, Training Loss: 0.4164542257785797, Validation Loss: 0.4153415262699127
Epoch 22, Training Loss: 0.4153415262699127, Validation Loss: 0.4142053723335266
Epoch 23, Training Loss: 0.4142053723335266, Validation Loss: 0.4130304455757141
Epoch 24, Training Loss: 0.4130305051803589, Validation Loss: 0.41183337569236755
Epoch 25, Training Loss: 0.41183334589004517, Validation Loss: 0.41059425473213196
Epoch 26, Training Loss: 0.41059425473213196, Validation Loss: 0.4092930853366852
Epoch 27, Training Loss: 0.4092930853366852, Validation Loss: 0.40793362259864807
Epoch 28, Training Loss: 0.40793362259864807, Validation Loss: 0.4065037667751312
Epoch 29, Training Loss: 0.40650373697280884, Validation Loss: 0.40500408411026
Epoch 30, Training Loss: 0.40500408411026, Validation Loss: 0.40342727303504944
Epoch 31, Training Loss: 0.40342727303504944, Validation Loss: 0.40176019072532654
Epoch 32, Training Loss: 0.4017602205276489, Validation Loss: 0.39997154474258423
Epoch 33, Training Loss: 0.39997154474258423, Validation Loss: 0.3980848789215088
Epoch 34, Training Loss: 0.3980849087238312, Validation Loss: 0.3960961103439331
Epoch 35, Training Loss: 0.3960961103439331, Validation Loss: 0.39398011565208435
Epoch 36, Training Loss: 0.39398014545440674, Validation Loss: 0.39170098304748535
Epoch 37, Training Loss: 0.39170098304748535, Validation Loss: 0.38929077982902527
Epoch 38, Training Loss: 0.3892907500267029, Validation Loss: 0.3867134749889374
Epoch 39, Training Loss: 0.386713445186615, Validation Loss: 0.38402074575424194
Epoch 40, Training Loss: 0.38402074575424194, Validation Loss: 0.3811434507369995
Epoch 41, Training Loss: 0.3811434507369995, Validation Loss: 0.3781013488769531
Epoch 42, Training Loss: 0.3781013488769531, Validation Loss: 0.37484800815582275
Epoch 43, Training Loss: 0.37484800815582275, Validation Loss: 0.3713403344154358
Epoch 44, Training Loss: 0.3713403344154358, Validation Loss: 0.3675956428050995
Epoch 45, Training Loss: 0.3675956130027771, Validation Loss: 0.363563597202301
Epoch 46, Training Loss: 0.363563597202301, Validation Loss: 0.35918039083480835
Epoch 47, Training Loss: 0.35918036103248596, Validation Loss: 0.35445207357406616
Epoch 48, Training Loss: 0.35445207357406616, Validation Loss: 0.3493579924106598
Epoch 49, Training Loss: 0.3493579924106598, Validation Loss: 0.34390494227409363
Epoch 50, Training Loss: 0.34390494227409363, Validation Loss: 0.3380562961101532
Epoch 51, Training Loss: 0.3380562961101532, Validation Loss: 0.33178484439849854
Epoch 52, Training Loss: 0.33178481459617615, Validation Loss: 0.3251197934150696
Epoch 53, Training Loss: 0.3251197636127472, Validation Loss: 0.3180663287639618
Epoch 54, Training Loss: 0.3180663287639618, Validation Loss: 0.31049877405166626
Epoch 55, Training Loss: 0.31049877405166626, Validation Loss: 0.30237630009651184
Epoch 56, Training Loss: 0.30237632989883423, Validation Loss: 0.2937335968017578
Epoch 57, Training Loss: 0.2937335968017578, Validation Loss: 0.28451964259147644
Epoch 58, Training Loss: 0.28451964259147644, Validation Loss: 0.2748003900051117
Epoch 59, Training Loss: 0.2748003900051117, Validation Loss: 0.26448458433151245
Epoch 60, Training Loss: 0.26448458433151245, Validation Loss: 0.25361576676368713
Epoch 61, Training Loss: 0.25361576676368713, Validation Loss: 0.24223878979682922
Epoch 62, Training Loss: 0.24223878979682922, Validation Loss: 0.23036101460456848
Epoch 63, Training Loss: 0.23036101460456848, Validation Loss: 0.21802964806556702
Epoch 64, Training Loss: 0.2180296778678894, Validation Loss: 0.20533102750778198
Epoch 65, Training Loss: 0.20533104240894318, Validation Loss: 0.1923418790102005
Epoch 66, Training Loss: 0.1923418790102005, Validation Loss: 0.1791502982378006
Epoch 67, Training Loss: 0.1791503131389618, Validation Loss: 0.1659948080778122
Epoch 68, Training Loss: 0.165994793176651, Validation Loss: 0.1530608832836151
Epoch 69, Training Loss: 0.1530608832836151, Validation Loss: 0.14050929248332977
Epoch 70, Training Loss: 0.14050927758216858, Validation Loss: 0.1284629851579666
Epoch 71, Training Loss: 0.1284629851579666, Validation Loss: 0.11708462983369827
Epoch 72, Training Loss: 0.11708463728427887, Validation Loss: 0.10649281740188599
Epoch 73, Training Loss: 0.1064927950501442, Validation Loss: 0.09687640517950058
Epoch 74, Training Loss: 0.09687640517950058, Validation Loss: 0.08828101307153702
Epoch 75, Training Loss: 0.08828102052211761, Validation Loss: 0.0806853249669075
Epoch 76, Training Loss: 0.0806853249669075, Validation Loss: 0.07387471199035645
Epoch 77, Training Loss: 0.07387471199035645, Validation Loss: 0.06762894243001938
Epoch 78, Training Loss: 0.06762894988059998, Validation Loss: 0.06175272539258003
Epoch 79, Training Loss: 0.06175272911787033, Validation Loss: 0.05614243820309639
Epoch 80, Training Loss: 0.05614244192838669, Validation Loss: 0.0506243035197258
Epoch 81, Training Loss: 0.0506242997944355, Validation Loss: 0.045245617628097534
Epoch 82, Training Loss: 0.04524562135338783, Validation Loss: 0.03994041308760643
Epoch 83, Training Loss: 0.03994041681289673, Validation Loss: 0.03483915328979492
Epoch 84, Training Loss: 0.03483914956450462, Validation Loss: 0.03012474626302719
Epoch 85, Training Loss: 0.03012475185096264, Validation Loss: 0.025904234498739243
Epoch 86, Training Loss: 0.025904234498739243, Validation Loss: 0.02214623987674713
Epoch 87, Training Loss: 0.022146238014101982, Validation Loss: 0.01891518011689186
Epoch 88, Training Loss: 0.01891518197953701, Validation Loss: 0.01614881306886673
Epoch 89, Training Loss: 0.01614881306886673, Validation Loss: 0.013814669102430344
Epoch 90, Training Loss: 0.013814671896398067, Validation Loss: 0.011868055909872055
Epoch 91, Training Loss: 0.011868059635162354, Validation Loss: 0.010240970179438591
Epoch 92, Training Loss: 0.010240970179438591, Validation Loss: 0.008886171504855156
Epoch 93, Training Loss: 0.008886168710887432, Validation Loss: 0.007759748958051205
Epoch 94, Training Loss: 0.007759749423712492, Validation Loss: 0.006775625515729189
Epoch 95, Training Loss: 0.006775624584406614, Validation Loss: 0.005914105102419853
Epoch 96, Training Loss: 0.00591410044580698, Validation Loss: 0.005148613825440407
Epoch 97, Training Loss: 0.005148612894117832, Validation Loss: 0.004464245866984129
Epoch 98, Training Loss: 0.004464247729629278, Validation Loss: 0.0038389305118471384
Epoch 99, Training Loss: 0.0038389298133552074, Validation Loss: 0.0032595351804047823
Epoch 100, Training Loss: 0.003259534016251564, Validation Loss: 0.0027262226212769747
Epoch 101, Training Loss: 0.0027262207586318254, Validation Loss: 0.002241541398689151
Epoch 102, Training Loss: 0.0022415423300117254, Validation Loss: 0.0018139136955142021
Epoch 103, Training Loss: 0.001813913811929524, Validation Loss: 0.0014501564437523484
Epoch 104, Training Loss: 0.001450155396014452, Validation Loss: 0.0011435514315962791
Epoch 105, Training Loss: 0.0011435510823503137, Validation Loss: 0.0008945605950430036
Epoch 106, Training Loss: 0.0008945610607042909, Validation Loss: 0.0007038876647129655
Epoch 107, Training Loss: 0.000703888013958931, Validation Loss: 0.0005710490513592958
Epoch 108, Training Loss: 0.000571048934943974, Validation Loss: 0.0004897376638837159
Epoch 109, Training Loss: 0.0004897369653917849, Validation Loss: 0.0004507111734710634
Epoch 110, Training Loss: 0.0004507110279519111, Validation Loss: 0.0004451654094737023
Epoch 111, Training Loss: 0.0004451659042388201, Validation Loss: 0.0004631089395843446
Epoch 112, Training Loss: 0.0004631082701962441, Validation Loss: 0.0004938766360282898
Epoch 113, Training Loss: 0.000493877858389169, Validation Loss: 0.0005276993615552783
Epoch 114, Training Loss: 0.0005276990123093128, Validation Loss: 0.0005566991167142987
Epoch 115, Training Loss: 0.000556699582375586, Validation Loss: 0.0005751065327785909
Epoch 116, Training Loss: 0.0005751076969318092, Validation Loss: 0.0005796869518235326
Epoch 117, Training Loss: 0.0005796871264465153, Validation Loss: 0.0005690798279829323
Epoch 118, Training Loss: 0.0005690804682672024, Validation Loss: 0.0005434255581349134
Epoch 119, Training Loss: 0.0005434260820038617, Validation Loss: 0.0005058999522589147
Epoch 120, Training Loss: 0.000505899079144001, Validation Loss: 0.0004598005616571754
Epoch 121, Training Loss: 0.0004598018422257155, Validation Loss: 0.0004086835542693734
Epoch 122, Training Loss: 0.00040868320502340794, Validation Loss: 0.00035590853076428175
Epoch 123, Training Loss: 0.00035590847255662084, Validation Loss: 0.0003046878264285624
Epoch 124, Training Loss: 0.00030468805925920606, Validation Loss: 0.000257428822806105
Epoch 125, Training Loss: 0.00025742914294824004, Validation Loss: 0.00021519635629374534
Epoch 126, Training Loss: 0.00021519631263799965, Validation Loss: 0.00017900933744385839
Epoch 127, Training Loss: 0.00017900904640555382, Validation Loss: 0.00014919988461770117
Epoch 128, Training Loss: 0.0001492001028964296, Validation Loss: 0.00012556588626466691
Epoch 129, Training Loss: 0.00012556579895317554, Validation Loss: 0.00010764745820779353
Epoch 130, Training Loss: 0.0001076475964509882, Validation Loss: 9.445083560422063e-05
Epoch 131, Training Loss: 9.445049363421276e-05, Validation Loss: 8.482706471113488e-05
Epoch 132, Training Loss: 8.482713747071102e-05, Validation Loss: 7.770966476527974e-05
Epoch 133, Training Loss: 7.770955562591553e-05, Validation Loss: 7.214664947241545e-05
Epoch 134, Training Loss: 7.214674405986443e-05, Validation Loss: 6.736994691891596e-05
Epoch 135, Training Loss: 6.737029616488144e-05, Validation Loss: 6.28265188424848e-05
Epoch 136, Training Loss: 6.282639515120536e-05, Validation Loss: 5.8176439779344946e-05
Epoch 137, Training Loss: 5.817652345285751e-05, Validation Loss: 5.3271294746082276e-05
Epoch 138, Training Loss: 5.327085455064662e-05, Validation Loss: 4.811561302631162e-05
Epoch 139, Training Loss: 4.8115834943018854e-05, Validation Loss: 4.282341251382604e-05
Epoch 140, Training Loss: 4.2823470721486956e-05, Validation Loss: 3.7569676351267844e-05
Epoch 141, Training Loss: 3.7569840060314164e-05, Validation Loss: 3.255109550082125e-05
Epoch 142, Training Loss: 3.255108094890602e-05, Validation Loss: 2.7947586204390973e-05
Epoch 143, Training Loss: 2.7947571652475744e-05, Validation Loss: 2.3898634026409127e-05
Epoch 144, Training Loss: 2.3898901417851448e-05, Validation Loss: 2.0490368115133606e-05
Epoch 145, Training Loss: 2.0490402675932273e-05, Validation Loss: 1.774621159711387e-05
Epoch 146, Training Loss: 1.7746238881954923e-05, Validation Loss: 1.559033989906311e-05
Epoch 147, Training Loss: 1.5590347175020725e-05, Validation Loss: 1.3933867194282357e-05
Epoch 148, Training Loss: 1.3933835361967795e-05, Validation Loss: 1.2707771929854061e-05
Epoch 149, Training Loss: 1.2707660062005743e-05, Validation Loss: 1.1811749573098496e-05
Epoch 150, Training Loss: 1.1811729564215057e-05, Validation Loss: 1.114005772251403e-05
Epoch 151, Training Loss: 1.1140095011796802e-05, Validation Loss: 1.0594418199616484e-05
Epoch 152, Training Loss: 1.0594503692118451e-05, Validation Loss: 1.0094663593918085e-05
Epoch 153, Training Loss: 1.0094719073094893e-05, Validation Loss: 9.584206964063924e-06
Epoch 154, Training Loss: 9.584155122865923e-06, Validation Loss: 9.031824447447434e-06
Epoch 155, Training Loss: 9.031843546836171e-06, Validation Loss: 8.42949975776719e-06
Epoch 156, Training Loss: 8.429481567873154e-06, Validation Loss: 7.786984497215599e-06
Epoch 157, Training Loss: 7.786986316205002e-06, Validation Loss: 7.124530839064391e-06
Epoch 158, Training Loss: 7.124483545339899e-06, Validation Loss: 6.4665323407098185e-06
Epoch 159, Training Loss: 6.4666510297684e-06, Validation Loss: 5.835709544044221e-06
Epoch 160, Training Loss: 5.835729098180309e-06, Validation Loss: 5.248600700724637e-06
Epoch 161, Training Loss: 5.248554316494847e-06, Validation Loss: 4.713921953225508e-06
Epoch 162, Training Loss: 4.7138569243543316e-06, Validation Loss: 4.232920218782965e-06
Epoch 163, Training Loss: 4.232887476973701e-06, Validation Loss: 3.8013183711882448e-06
Epoch 164, Training Loss: 3.801358388955123e-06, Validation Loss: 3.4114907521143323e-06
Epoch 165, Training Loss: 3.411490069993306e-06, Validation Loss: 3.055176421185024e-06
Epoch 166, Training Loss: 3.0552239422831917e-06, Validation Loss: 2.7259179660177324e-06
Epoch 167, Training Loss: 2.725907506828662e-06, Validation Loss: 2.419672455289401e-06
Epoch 168, Training Loss: 2.419574457235285e-06, Validation Loss: 2.1353171177906916e-06
Epoch 169, Training Loss: 2.135265049219015e-06, Validation Loss: 1.874041458904685e-06
Epoch 170, Training Loss: 1.87398632078839e-06, Validation Loss: 1.6377551901314291e-06
Epoch 171, Training Loss: 1.637743366700306e-06, Validation Loss: 1.428472842235351e-06
Epoch 172, Training Loss: 1.4284738654168905e-06, Validation Loss: 1.246876649929618e-06
Epoch 173, Training Loss: 1.246879492100561e-06, Validation Loss: 1.0919329724856652e-06
Epoch 174, Training Loss: 1.0919687838395475e-06, Validation Loss: 9.61246087172185e-07
Epoch 175, Training Loss: 9.61231421570119e-07, Validation Loss: 8.510583029419649e-07
Epoch 176, Training Loss: 8.510538123118749e-07, Validation Loss: 7.572766662633512e-07
Epoch 177, Training Loss: 7.572366484964732e-07, Validation Loss: 6.76119952913723e-07
Epoch 178, Training Loss: 6.760908490832662e-07, Validation Loss: 6.047266651876271e-07
Epoch 179, Training Loss: 6.04742638188327e-07, Validation Loss: 5.411901611296344e-07
Epoch 180, Training Loss: 5.411928896137397e-07, Validation Loss: 4.846386900680955e-07
Epoch 181, Training Loss: 4.846330057262094e-07, Validation Loss: 4.3488529399837716e-07
Epoch 182, Training Loss: 4.34874124266571e-07, Validation Loss: 3.919911080174643e-07
Epoch 183, Training Loss: 3.919827236131823e-07, Validation Loss: 3.5589809499469993e-07
Epoch 184, Training Loss: 3.55923390316093e-07, Validation Loss: 3.2619470857753186e-07
Epoch 185, Training Loss: 3.261921506236831e-07, Validation Loss: 3.019066241449764e-07
Epoch 186, Training Loss: 3.019093526290817e-07, Validation Loss: 2.818070186094701e-07
Epoch 187, Training Loss: 2.818091502376774e-07, Validation Loss: 2.644746928126551e-07
Epoch 188, Training Loss: 2.644501080339978e-07, Validation Loss: 2.485726895429252e-07
Epoch 189, Training Loss: 2.485862466983235e-07, Validation Loss: 2.3324251685608033e-07
Epoch 190, Training Loss: 2.3326597897721513e-07, Validation Loss: 2.179535414370548e-07
Epoch 191, Training Loss: 2.1795058557927405e-07, Validation Loss: 2.0259901134522806e-07
Epoch 192, Training Loss: 2.0262002919935185e-07, Validation Loss: 1.8744056262676168e-07
Epoch 193, Training Loss: 1.8744032104223152e-07, Validation Loss: 1.7274004449063796e-07
Epoch 194, Training Loss: 1.7274712149628613e-07, Validation Loss: 1.5880138448665093e-07
Epoch 195, Training Loss: 1.588108062833271e-07, Validation Loss: 1.4574378326415172e-07
Epoch 196, Training Loss: 1.4574280271517637e-07, Validation Loss: 1.3343958471523365e-07
Epoch 197, Training Loss: 1.334357051518964e-07, Validation Loss: 1.216652378843719e-07
Epoch 198, Training Loss: 1.2165163809640944e-07, Validation Loss: 1.1008803824097413e-07
Epoch 199, Training Loss: 1.1008368971943128e-07, Validation Loss: 9.84666570502668e-08
Epoch 200, Training Loss: 9.846713311389976e-08, Validation Loss: 8.671711526631043e-08
Epoch 201, Training Loss: 8.672299145473517e-08, Validation Loss: 7.493180476103589e-08
Epoch 202, Training Loss: 7.49213455719655e-08, Validation Loss: 6.338920144344229e-08
Epoch 203, Training Loss: 6.340367519896972e-08, Validation Loss: 5.254048218716889e-08
Epoch 204, Training Loss: 5.253989243669821e-08, Validation Loss: 4.280224885633288e-08
Epoch 205, Training Loss: 4.279191045952757e-08, Validation Loss: 3.4504502366417e-08
Epoch 206, Training Loss: 3.450337615618082e-08, Validation Loss: 2.7876298602791394e-08
Epoch 207, Training Loss: 2.7876113861680096e-08, Validation Loss: 2.2923318354628464e-08
Epoch 208, Training Loss: 2.2914525388273432e-08, Validation Loss: 1.9469737821964372e-08
Epoch 209, Training Loss: 1.947015704217847e-08, Validation Loss: 1.724816911519156e-08
Epoch 210, Training Loss: 1.724345466413979e-08, Validation Loss: 1.589647702360253e-08
Epoch 211, Training Loss: 1.5893226290586426e-08, Validation Loss: 1.50792711650638e-08
Epoch 212, Training Loss: 1.508111147074942e-08, Validation Loss: 1.4538783510431585e-08
Epoch 213, Training Loss: 1.4540269432927744e-08, Validation Loss: 1.4087620847647031e-08
Epoch 214, Training Loss: 1.4091011912853446e-08, Validation Loss: 1.36392905858429e-08
Epoch 215, Training Loss: 1.3635669482425783e-08, Validation Loss: 1.316110509463897e-08
Epoch 216, Training Loss: 1.316631781378419e-08, Validation Loss: 1.2673813110097853e-08
Epoch 217, Training Loss: 1.2674900240483566e-08, Validation Loss: 1.2191862630572814e-08
Epoch 218, Training Loss: 1.2194522724939816e-08, Validation Loss: 1.1724799797718788e-08
Epoch 219, Training Loss: 1.1722145032422304e-08, Validation Loss: 1.1253759701901345e-08
Epoch 220, Training Loss: 1.1254776666191901e-08, Validation Loss: 1.0759675816984782e-08
Epoch 221, Training Loss: 1.0756856738680654e-08, Validation Loss: 1.0195336130891519e-08
Epoch 222, Training Loss: 1.0197775068832016e-08, Validation Loss: 9.548990931307344e-09
Epoch 223, Training Loss: 9.549521173823905e-09, Validation Loss: 8.807454321413388e-09
Epoch 224, Training Loss: 8.807808704602849e-09, Validation Loss: 7.986760586220498e-09
Epoch 225, Training Loss: 7.989486405790558e-09, Validation Loss: 7.132115786845361e-09
Epoch 226, Training Loss: 7.129878909495346e-09, Validation Loss: 6.2716494220182994e-09
Epoch 227, Training Loss: 6.270413521747287e-09, Validation Loss: 5.453403506550103e-09
Epoch 228, Training Loss: 5.452442941589197e-09, Validation Loss: 4.707961132055516e-09
Epoch 229, Training Loss: 4.7076809117641005e-09, Validation Loss: 4.04203959192273e-09
Epoch 230, Training Loss: 4.045847656897195e-09, Validation Loss: 3.4692091421817395e-09
Epoch 231, Training Loss: 3.466088749348728e-09, Validation Loss: 2.9577607030262243e-09
Epoch 232, Training Loss: 2.956526357067446e-09, Validation Loss: 2.5030035821771435e-09
Epoch 233, Training Loss: 2.5052633301214655e-09, Validation Loss: 2.096049556143953e-09
Epoch 234, Training Loss: 2.096579576615909e-09, Validation Loss: 1.7267050012037544e-09
Epoch 235, Training Loss: 1.727689102892782e-09, Validation Loss: 1.398555715681482e-09
Epoch 236, Training Loss: 1.399096505316777e-09, Validation Loss: 1.1161240820456442e-09
Epoch 237, Training Loss: 1.1167730074035376e-09, Validation Loss: 8.89153417560351e-10
Epoch 238, Training Loss: 8.892907521484972e-10, Validation Loss: 7.231227838744303e-10
Epoch 239, Training Loss: 7.227118903330165e-10, Validation Loss: 6.177228728532214e-10
Epoch 240, Training Loss: 6.175246425321745e-10, Validation Loss: 5.663525759480592e-10
Epoch 241, Training Loss: 5.664262392457431e-10, Validation Loss: 5.556147764096409e-10
Epoch 242, Training Loss: 5.554992021927774e-10, Validation Loss: 5.72126457321076e-10
Epoch 243, Training Loss: 5.720024454092254e-10, Validation Loss: 5.991506735192331e-10
Epoch 244, Training Loss: 5.986039997019077e-10, Validation Loss: 6.24694018735994e-10
Epoch 245, Training Loss: 6.245622907741222e-10, Validation Loss: 6.400189822564073e-10
Epoch 246, Training Loss: 6.395608487252957e-10, Validation Loss: 6.405902475137282e-10
Epoch 247, Training Loss: 6.41555641944791e-10, Validation Loss: 6.290806209285904e-10
Epoch 248, Training Loss: 6.290865051106209e-10, Validation Loss: 6.04151395577901e-10
Epoch 249, Training Loss: 6.044791334147703e-10, Validation Loss: 5.727658902721089e-10
Epoch 250, Training Loss: 5.709037687040563e-10, Validation Loss: 5.326282748185918e-10
Epoch 251, Training Loss: 5.328776309099226e-10, Validation Loss: 4.90657792173721e-10
Epoch 252, Training Loss: 4.912167894666197e-10, Validation Loss: 4.4536116461380004e-10
Epoch 253, Training Loss: 4.453934165926654e-10, Validation Loss: 3.9793796036136087e-10
Epoch 254, Training Loss: 3.98461763584379e-10, Validation Loss: 3.502717005332556e-10
Epoch 255, Training Loss: 3.5012537313861003e-10, Validation Loss: 3.0163568864871593e-10
Epoch 256, Training Loss: 3.017759375723017e-10, Validation Loss: 2.5535101810802985e-10
Epoch 257, Training Loss: 2.5585664142901976e-10, Validation Loss: 2.1313771580988572e-10
Epoch 258, Training Loss: 2.1314615350487287e-10, Validation Loss: 1.762450740905308e-10
Epoch 259, Training Loss: 1.7598483781355867e-10, Validation Loss: 1.4521020497149095e-10
Epoch 260, Training Loss: 1.4542662907235382e-10, Validation Loss: 1.2154935391528454e-10
Epoch 261, Training Loss: 1.218009304526646e-10, Validation Loss: 1.0412540968340878e-10
Epoch 262, Training Loss: 1.0416804224755438e-10, Validation Loss: 9.164475428535823e-11
Epoch 263, Training Loss: 9.19267162391435e-11, Validation Loss: 8.196640588487014e-11
Epoch 264, Training Loss: 8.223593334077961e-11, Validation Loss: 7.44419595410939e-11
Epoch 265, Training Loss: 7.423594378108689e-11, Validation Loss: 6.704486271713606e-11
Epoch 266, Training Loss: 6.712860128876841e-11, Validation Loss: 5.9688941289604e-11
Epoch 267, Training Loss: 5.97530497303822e-11, Validation Loss: 5.202541869531174e-11
Epoch 268, Training Loss: 5.1860047506346874e-11, Validation Loss: 4.4747736765993196e-11
Epoch 269, Training Loss: 4.4532370846450675e-11, Validation Loss: 3.777625434686627e-11
Epoch 270, Training Loss: 3.769437192935321e-11, Validation Loss: 3.233915912836949e-11
Epoch 271, Training Loss: 3.243156784793477e-11, Validation Loss: 2.8136090679531378e-11
Epoch 272, Training Loss: 2.8226317116963884e-11, Validation Loss: 2.5467303613191383e-11
Epoch 273, Training Loss: 2.5691946833883428e-11, Validation Loss: 2.4471270496095876e-11
Epoch 274, Training Loss: 2.450067579373716e-11, Validation Loss: 2.4225968453528424e-11
Epoch 275, Training Loss: 2.4339686516272607e-11, Validation Loss: 2.4590954272873944e-11
Epoch 276, Training Loss: 2.453343604658098e-11, Validation Loss: 2.4835697734482132e-11
Epoch 277, Training Loss: 2.5074152823489904e-11, Validation Loss: 2.522288107542625e-11
Epoch 278, Training Loss: 2.5142951956547144e-11, Validation Loss: 2.493232183209404e-11
Epoch 279, Training Loss: 2.5117062943391666e-11, Validation Loss: 2.4275321336419964e-11
Epoch 280, Training Loss: 2.4121902392204575e-11, Validation Loss: 2.304875214298452e-11
Epoch 281, Training Loss: 2.3016069952697116e-11, Validation Loss: 2.137187649076111e-11
Epoch 282, Training Loss: 2.158423266507281e-11, Validation Loss: 1.9445512908222717e-11
Epoch 283, Training Loss: 1.9679275570227972e-11, Validation Loss: 1.741285240997037e-11
Epoch 284, Training Loss: 1.7663625770381053e-11, Validation Loss: 1.5467229927401682e-11
Epoch 285, Training Loss: 1.5502201952677375e-11, Validation Loss: 1.3495321180001518e-11
Epoch 286, Training Loss: 1.3408558985350538e-11, Validation Loss: 1.1639053436318658e-11
Epoch 287, Training Loss: 1.1512489746234866e-11, Validation Loss: 9.745252348147826e-12
Epoch 288, Training Loss: 9.732166461606795e-12, Validation Loss: 8.106354996983978e-12
Epoch 289, Training Loss: 8.201815962505243e-12, Validation Loss: 6.649977877387636e-12
Epoch 290, Training Loss: 6.618632725219342e-12, Validation Loss: 5.5053570209573355e-12
Epoch 291, Training Loss: 5.426995658419642e-12, Validation Loss: 4.457742768665396e-12
Epoch 292, Training Loss: 4.475443019652525e-12, Validation Loss: 3.672062653947705e-12
Epoch 293, Training Loss: 3.72325477740465e-12, Validation Loss: 3.0922801212002193e-12
Epoch 294, Training Loss: 3.1583650625388593e-12, Validation Loss: 2.690766012780621e-12
Epoch 295, Training Loss: 2.6809414063744264e-12, Validation Loss: 2.3341456805575644e-12
Epoch 296, Training Loss: 2.3031411847118655e-12, Validation Loss: 2.018255571348271e-12
Epoch 297, Training Loss: 2.0398181841546625e-12, Validation Loss: 1.7923992368454322e-12
Epoch 298, Training Loss: 1.822927225836324e-12, Validation Loss: 1.6331663669003071e-12
Epoch 299, Training Loss: 1.6437196655866293e-12, Validation Loss: 1.516118502443986e-12
Epoch 300, Training Loss: 1.5102014690876464e-12, Validation Loss: 1.4165026573573214e-12
Epoch 301, Training Loss: 1.3619333525533017e-12, Validation Loss: 1.2702886702589677e-12
Epoch 302, Training Loss: 1.2460863504232256e-12, Validation Loss: 1.2081443701364436e-12
Epoch 303, Training Loss: 1.2097400988939078e-12, Validation Loss: 1.1176190181649837e-12
Epoch 304, Training Loss: 1.1559108704928267e-12, Validation Loss: 1.1000072380751291e-12
Epoch 305, Training Loss: 1.0787145916096863e-12, Validation Loss: 1.0910110705489307e-12
Epoch 306, Training Loss: 1.1063138252720428e-12, Validation Loss: 1.1084553414031362e-12
Epoch 307, Training Loss: 1.1042561179688826e-12, Validation Loss: 1.0610269173677578e-12
Epoch 308, Training Loss: 1.0801280659819557e-12, Validation Loss: 1.0446043986409026e-12
Epoch 309, Training Loss: 1.03070210786399e-12, Validation Loss: 9.898216144291205e-13
Epoch 310, Training Loss: 1.0114629403132347e-12, Validation Loss: 9.77777646175848e-13
Epoch 311, Training Loss: 9.3464038591895e-13, Validation Loss: 9.141235945281379e-13
Epoch 312, Training Loss: 8.938510738867866e-13, Validation Loss: 8.603693929173928e-13
Epoch 313, Training Loss: 8.216962266854866e-13, Validation Loss: 7.478022107793025e-13
Epoch 314, Training Loss: 7.750133000639092e-13, Validation Loss: 6.808735433100344e-13
Epoch 315, Training Loss: 6.615429775161386e-13, Validation Loss: 5.799997526527434e-13
Epoch 316, Training Loss: 5.565651563753382e-13, Validation Loss: 5.059195792335436e-13
Epoch 317, Training Loss: 4.870931674498535e-13, Validation Loss: 4.193503454642117e-13
Epoch 318, Training Loss: 4.13998615120606e-13, Validation Loss: 3.5308526393461326e-13
Epoch 319, Training Loss: 3.4085448764702153e-13, Validation Loss: 2.8674941110820584e-13
Epoch 320, Training Loss: 2.9206967248375515e-13, Validation Loss: 2.598959459101935e-13
Epoch 321, Training Loss: 2.4692617742183565e-13, Validation Loss: 2.0475919679414922e-13
Epoch 322, Training Loss: 1.9296051572987444e-13, Validation Loss: 1.7525287861544503e-13
Epoch 323, Training Loss: 1.5789657721500955e-13, Validation Loss: 1.514874380451059e-13
Epoch 324, Training Loss: 1.5206043889326448e-13, Validation Loss: 1.1775251455327373e-13
Epoch 325, Training Loss: 1.237449677232369e-13, Validation Loss: 1.075543801698671e-13
Epoch 326, Training Loss: 1.0509539609014282e-13, Validation Loss: 1.0426127192500467e-13
Epoch 327, Training Loss: 1.0192479591450768e-13, Validation Loss: 9.748537426520348e-14
Epoch 328, Training Loss: 9.292493532465917e-14, Validation Loss: 8.578012432314264e-14
Epoch 329, Training Loss: 8.269021589419473e-14, Validation Loss: 7.570286492944098e-14
Epoch 330, Training Loss: 6.852708640337282e-14, Validation Loss: 6.017909559346765e-14
Epoch 331, Training Loss: 6.742035315449035e-14, Validation Loss: 6.042185523615073e-14
Epoch 332, Training Loss: 5.4687767443890867e-14, Validation Loss: 5.3392406733918443e-14
Epoch 333, Training Loss: 5.080615087167152e-14, Validation Loss: 4.6078636376347196e-14
Epoch 334, Training Loss: 4.7084393133521585e-14, Validation Loss: 4.4757376786979525e-14
Epoch 335, Training Loss: 3.29285379616507e-14, Validation Loss: 3.9900113784794786e-14
Epoch 336, Training Loss: 3.270812643624797e-14, Validation Loss: 3.725898374009294e-14
Epoch 337, Training Loss: 3.6453689188347543e-14, Validation Loss: 2.686606396606981e-14
Epoch 338, Training Loss: 2.9046284420655016e-14, Validation Loss: 3.013155724278585e-14
Epoch 339, Training Loss: 2.6439262698673208e-14, Validation Loss: 2.383039275080049e-14
Epoch 340, Training Loss: 2.4646559817456844e-14, Validation Loss: 2.3677554125797924e-14
Epoch 341, Training Loss: 2.409098074295738e-14, Validation Loss: 2.444141182576364e-14
Epoch 342, Training Loss: 2.0840108948976845e-14, Validation Loss: 1.9067363858063686e-14
Epoch 343, Training Loss: 2.0783932029849045e-14, Validation Loss: 2.132286351880317e-14
Epoch 344, Training Loss: 1.763120424940097e-14, Validation Loss: 1.832127860339726e-14
Epoch 345, Training Loss: 1.6432578090136776e-14, Validation Loss: 1.7801149551806283e-14
Epoch 346, Training Loss: 1.3426500511978627e-14, Validation Loss: 1.601781824311834e-14
Epoch 347, Training Loss: 1.3359379927172302e-14, Validation Loss: 1.4393634260824115e-14
Epoch 348, Training Loss: 1.3872858076061437e-14, Validation Loss: 1.1782380762237823e-14
Epoch 349, Training Loss: 1.2812074670501619e-14, Validation Loss: 1.0678821345808717e-14
Epoch 350, Training Loss: 1.2041256900808314e-14, Validation Loss: 9.491316729141972e-15
Epoch 351, Training Loss: 1.0762698783410574e-14, Validation Loss: 1.1272503350407467e-14
Epoch 352, Training Loss: 1.1089894905440701e-14, Validation Loss: 9.357574461935254e-15
Epoch 353, Training Loss: 1.0402210031388616e-14, Validation Loss: 1.0363830968548524e-14
Epoch 354, Training Loss: 6.7043813975150874e-15, Validation Loss: 9.260202095417742e-15
Epoch 355, Training Loss: 5.9877402786446404e-15, Validation Loss: 8.397034864584142e-15
Epoch 356, Training Loss: 4.3492935320680725e-15, Validation Loss: 7.96764506450073e-15
Epoch 357, Training Loss: 4.790914487909836e-15, Validation Loss: 8.951769447235192e-15
Epoch 358, Training Loss: 5.12518248801659e-15, Validation Loss: 8.453805553807966e-15
Epoch 359, Training Loss: 4.093822042429071e-15, Validation Loss: 7.728326069649395e-15
Epoch 360, Training Loss: 3.417413294487309e-15, Validation Loss: 7.042712191153346e-15
Epoch 361, Training Loss: 3.4773946620977013e-15, Validation Loss: 7.022016635153082e-15
Epoch 362, Training Loss: 2.771629022753526e-15, Validation Loss: 6.446935474076036e-15
Epoch 363, Training Loss: 3.566332698042929e-15, Validation Loss: 5.313593108672047e-15
Epoch 364, Training Loss: 2.152065714693184e-15, Validation Loss: 6.3639016812896444e-15
Epoch 365, Training Loss: 2.6983034980920893e-15, Validation Loss: 6.466144487253869e-15
Epoch 366, Training Loss: 2.498476779131775e-15, Validation Loss: 5.5848774328868655e-15
Epoch 367, Training Loss: 3.396796724309376e-15, Validation Loss: 5.446063979424936e-15
Epoch 368, Training Loss: 1.870039953915997e-15, Validation Loss: 5.535873612272889e-15
Epoch 369, Training Loss: 2.1231759619611814e-15, Validation Loss: 5.415702083430606e-15
Epoch 370, Training Loss: 2.954108506954072e-15, Validation Loss: 3.895283448823294e-15
Epoch 371, Training Loss: 2.9308900633204108e-15, Validation Loss: 4.897363659490126e-15
Epoch 372, Training Loss: 2.900332079198791e-15, Validation Loss: 5.333846936990318e-15
Epoch 373, Training Loss: 2.7859737374735143e-15, Validation Loss: 3.2526791505317404e-15
Epoch 374, Training Loss: 2.198302913943191e-15, Validation Loss: 3.204667629015472e-15
Epoch 375, Training Loss: 2.4942066742864293e-15, Validation Loss: 4.156934890845463e-15
Epoch 376, Training Loss: 2.746208716973477e-15, Validation Loss: 3.079844830501579e-15
Epoch 377, Training Loss: 2.627446862713662e-15, Validation Loss: 2.7772689916328187e-15
Epoch 378, Training Loss: 2.451772652969594e-15, Validation Loss: 2.8602312101351675e-15
Epoch 379, Training Loss: 3.3005195713926632e-15, Validation Loss: 4.058658316656756e-15
Epoch 380, Training Loss: 2.5270997164853924e-15, Validation Loss: 3.930982922934747e-15
Epoch 381, Training Loss: 2.846288836065125e-15, Validation Loss: 4.180516288097022e-15
Epoch 382, Training Loss: 2.262687794088122e-15, Validation Loss: 2.5660892783222183e-15
Epoch 383, Training Loss: 2.7213887457947948e-15, Validation Loss: 4.570128573944425e-15
Epoch 384, Training Loss: 2.1678118454244045e-15, Validation Loss: 4.340319641508387e-15
Epoch 385, Training Loss: 1.4007972536642706e-15, Validation Loss: 4.125246964772206e-15
Epoch 386, Training Loss: 1.144258290753492e-15, Validation Loss: 4.463918689171734e-15
Epoch 387, Training Loss: 1.821067261762832e-15, Validation Loss: 4.595993148505308e-15
Epoch 388, Training Loss: 1.6193056019136337e-15, Validation Loss: 4.1332222034870785e-15
Epoch 389, Training Loss: 8.336760317694881e-16, Validation Loss: 6.934171695226286e-15
Epoch 390, Training Loss: 1.4412296302476258e-15, Validation Loss: 6.737670215858655e-15
Epoch 391, Training Loss: 1.0777383581858885e-15, Validation Loss: 5.249944088400044e-15
Epoch 392, Training Loss: 1.058989919173125e-15, Validation Loss: 5.293645906280682e-15
Epoch 393, Training Loss: 2.2295279365107737e-15, Validation Loss: 4.0511836744137105e-15
Epoch 394, Training Loss: 1.4310214009255538e-15, Validation Loss: 6.0340789100900814e-15
Epoch 395, Training Loss: 1.34988972650134e-15, Validation Loss: 4.576375441930425e-15
Epoch 396, Training Loss: 1.291176049575632e-15, Validation Loss: 4.648333008382046e-15
Epoch 397, Training Loss: 2.401865895233844e-15, Validation Loss: 4.910084400291991e-15
Epoch 398, Training Loss: 1.4681845479698626e-15, Validation Loss: 5.170824434862914e-15
Epoch 399, Training Loss: 2.39906369848609e-15, Validation Loss: 4.9372563702069616e-15
Epoch 400, Training Loss: 2.2944466591707114e-15, Validation Loss: 5.116733334367728e-15
Epoch 401, Training Loss: 1.849890310650238e-15, Validation Loss: 5.083373365256591e-15
Epoch 402, Training Loss: 1.8691056765751755e-15, Validation Loss: 5.506612435593515e-15
Epoch 403, Training Loss: 2.480128774944826e-15, Validation Loss: 5.50581198945836e-15
Epoch 404, Training Loss: 1.975858085950582e-15, Validation Loss: 5.544423986358947e-15
Epoch 405, Training Loss: 1.975858085950582e-15, Validation Loss: 5.557853693737664e-15
Epoch 406, Training Loss: 2.009418166595508e-15, Validation Loss: 5.42732168140104e-15
Epoch 407, Training Loss: 1.7580835858708966e-15, Validation Loss: 5.31010926215999e-15
Epoch 408, Training Loss: 1.6994365069106666e-15, Validation Loss: 5.498199280844912e-15
Epoch 409, Training Loss: 1.6994365069106666e-15, Validation Loss: 5.455019235259782e-15
Epoch 410, Training Loss: 1.8915905896765145e-15, Validation Loss: 5.534952040426276e-15
Epoch 411, Training Loss: 1.9364263729152896e-15, Validation Loss: 5.595162530448901e-15
Epoch 412, Training Loss: 1.893725536220069e-15, Validation Loss: 5.584487374214655e-15
Epoch 413, Training Loss: 2.07947435583878e-15, Validation Loss: 5.742743198431386e-15
Epoch 414, Training Loss: 1.0124193065792547e-15, Validation Loss: 5.2777873319257134e-15
Epoch 415, Training Loss: 9.985415187714402e-16, Validation Loss: 4.9664044679878765e-15
Epoch 416, Training Loss: 1.1602711309839794e-15, Validation Loss: 4.9103596859998485e-15
Epoch 417, Training Loss: 1.188960772182193e-15, Validation Loss: 4.9319768138467255e-15
Epoch 418, Training Loss: 2.417144887294654e-15, Validation Loss: 4.9319768138467255e-15
Epoch 419, Training Loss: 2.4545081458727516e-15, Validation Loss: 4.943086074466439e-15
Epoch 420, Training Loss: 2.761954635946461e-15, Validation Loss: 5.194829348588101e-15
Epoch 421, Training Loss: 1.1650749724652137e-15, Validation Loss: 5.0164903731919706e-15
Epoch 422, Training Loss: 9.698518775732266e-16, Validation Loss: 5.3559625437266545e-15
Epoch 423, Training Loss: 1.0316346725041921e-15, Validation Loss: 5.308457971429318e-15
Epoch 424, Training Loss: 7.660885729905481e-16, Validation Loss: 3.976552871980555e-15
Epoch 425, Training Loss: 6.806867937209885e-16, Validation Loss: 4.002740589610816e-15
Epoch 426, Training Loss: 7.337960242116291e-16, Validation Loss: 3.778185802546597e-15
Epoch 427, Training Loss: 6.473267187307331e-16, Validation Loss: 3.854132047146838e-15
Epoch 428, Training Loss: 6.452583701526565e-16, Validation Loss: 3.78687805465132e-15
Epoch 429, Training Loss: 9.259499481587994e-16, Validation Loss: 3.5441167179023434e-15
Epoch 430, Training Loss: 2.719920837697203e-15, Validation Loss: 3.2882117591525846e-15
Epoch 431, Training Loss: 2.2555487886504258e-15, Validation Loss: 3.765994457336766e-15
Epoch 432, Training Loss: 2.8340123640440947e-15, Validation Loss: 3.774001036270687e-15
Epoch 433, Training Loss: 1.471854106455605e-15, Validation Loss: 3.813032314480165e-15
Epoch 434, Training Loss: 7.335958597382811e-16, Validation Loss: 3.7249616402729255e-15
Epoch 435, Training Loss: 7.015701792773064e-16, Validation Loss: 3.706279905104758e-15
Epoch 436, Training Loss: 6.588692896425266e-16, Validation Loss: 4.1514304472377306e-15
Epoch 437, Training Loss: 6.535316585858444e-16, Validation Loss: 4.179453261748218e-15
Epoch 438, Training Loss: 6.108308218906238e-16, Validation Loss: 4.149695723761754e-15
Epoch 439, Training Loss: 6.535316585858444e-16, Validation Loss: 4.1541578933278894e-15
Epoch 440, Training Loss: 6.108308218906238e-16, Validation Loss: 4.461604171643362e-15
Epoch 441, Training Loss: 5.484474806000551e-16, Validation Loss: 4.607460704061711e-15
Epoch 442, Training Loss: 1.7109791307620193e-15, Validation Loss: 4.607460704061711e-15
Epoch 443, Training Loss: 1.7163167088791423e-15, Validation Loss: 4.607460704061711e-15
Epoch 444, Training Loss: 1.7163167088791423e-15, Validation Loss: 4.6005218101578035e-15
Epoch 445, Training Loss: 5.681966361004403e-16, Validation Loss: 4.6005218101578035e-15
Epoch 446, Training Loss: 6.674762031778144e-16, Validation Loss: 4.6005218101578035e-15
Epoch 447, Training Loss: 1.6794871869369333e-15, Validation Loss: 4.6005218101578035e-15
Epoch 448, Training Loss: 9.845303232744332e-16, Validation Loss: 4.660840720397677e-15
Epoch 449, Training Loss: 9.845303232744332e-16, Validation Loss: 4.7602540128015985e-15
Epoch 450, Training Loss: 8.308070782375786e-16, Validation Loss: 4.8954455533810684e-15
Epoch 451, Training Loss: 8.308070782375786e-16, Validation Loss: 4.8954455533810684e-15
Epoch 452, Training Loss: 8.413488797221912e-16, Validation Loss: 4.879833042097277e-15
Epoch 453, Training Loss: 1.5705999368970905e-15, Validation Loss: 5.263874392250588e-15
Epoch 454, Training Loss: 1.6273120749684365e-15, Validation Loss: 5.263874392250588e-15
Epoch 455, Training Loss: 1.6273120749684365e-15, Validation Loss: 4.770662353657459e-15
Epoch 456, Training Loss: 1.1398547782189537e-15, Validation Loss: 4.8372344846304375e-15
Epoch 457, Training Loss: 4.3028611976028415e-16, Validation Loss: 4.826425920706999e-15
Epoch 458, Training Loss: 1.7338641610518176e-15, Validation Loss: 4.807744185538832e-15
Epoch 459, Training Loss: 1.5817422318017472e-15, Validation Loss: 4.6365545917340014e-15
Epoch 460, Training Loss: 1.4548404967979368e-15, Validation Loss: 4.6365545917340014e-15
Epoch 461, Training Loss: 2.0393086887546914e-15, Validation Loss: 4.759622126222947e-15
Epoch 462, Training Loss: 2.128980678748715e-15, Validation Loss: 4.759622126222947e-15
Epoch 463, Training Loss: 2.128980678748715e-15, Validation Loss: 4.214239210826058e-15
Epoch 464, Training Loss: 2.38678722646506e-15, Validation Loss: 4.462444428327038e-15
Epoch 465, Training Loss: 1.2936446212212863e-15, Validation Loss: 4.1460577172532966e-15
Epoch 466, Training Loss: 1.8658365529152475e-15, Validation Loss: 4.179684501742819e-15
Epoch 467, Training Loss: 1.7297274638956644e-15, Validation Loss: 4.22316947918896e-15
Epoch 468, Training Loss: 1.3246028284104837e-15, Validation Loss: 4.22316947918896e-15
Epoch 469, Training Loss: 1.5904158491816312e-15, Validation Loss: 4.290840211894527e-15
Epoch 470, Training Loss: 1.1740822149471975e-15, Validation Loss: 3.943776508570076e-15
Epoch 471, Training Loss: 5.122184520778901e-16, Validation Loss: 4.1489473701528546e-15
Epoch 472, Training Loss: 1.4212136064292963e-15, Validation Loss: 4.165971461843245e-15
Epoch 473, Training Loss: 1.4212136064292963e-15, Validation Loss: 4.350118965675172e-15
Epoch 474, Training Loss: 1.0112850235837628e-15, Validation Loss: 4.1319546186815125e-15
Epoch 475, Training Loss: 1.0112850235837628e-15, Validation Loss: 4.0932570714532525e-15
Epoch 476, Training Loss: 9.72854291733888e-16, Validation Loss: 4.0868518083061155e-15
Epoch 477, Training Loss: 9.515037675071592e-16, Validation Loss: 4.083649176732547e-15
Epoch 478, Training Loss: 9.675166077376465e-16, Validation Loss: 4.1156750689517584e-15
Epoch 479, Training Loss: 9.418960845446905e-16, Validation Loss: 3.82744373304475e-15
Epoch 480, Training Loss: 9.418960845446905e-16, Validation Loss: 4.7843440533379845e-15
Epoch 481, Training Loss: 1.0192914966385656e-15, Validation Loss: 4.74698058300165e-15
Epoch 482, Training Loss: 6.344497003500996e-16, Validation Loss: 4.74698058300165e-15
Epoch 483, Training Loss: 5.768035496357281e-16, Validation Loss: 4.599262272165236e-15
Epoch 484, Training Loss: 6.195044392705079e-16, Validation Loss: 4.571239881171222e-15
Epoch 485, Training Loss: 5.9441765271344045e-16, Validation Loss: 3.878845503932403e-15
Epoch 486, Training Loss: 5.063470843853194e-16, Validation Loss: 3.906867894926417e-15
Epoch 487, Training Loss: 5.928830937108117e-16, Validation Loss: 3.854025744511958e-15
Epoch 488, Training Loss: 4.705850886544468e-16, Validation Loss: 4.316196143170584e-15
Epoch 489, Training Loss: 1.7820359835533537e-15, Validation Loss: 4.2950457304776445e-15
Epoch 490, Training Loss: 1.8265384593273842e-15, Validation Loss: 4.259817630201338e-15
Epoch 491, Training Loss: 1.8364796615128343e-15, Validation Loss: 4.092616714545128e-15
Epoch 492, Training Loss: 1.4025986809848437e-15, Validation Loss: 4.205805303770247e-15
Epoch 493, Training Loss: 1.1944318638676269e-15, Validation Loss: 4.4649465636532274e-15
Epoch 494, Training Loss: 7.748955980596247e-16, Validation Loss: 5.2960125163353106e-15
Epoch 495, Training Loss: 8.070547391493511e-16, Validation Loss: 5.088681720737034e-15
Epoch 496, Training Loss: 8.214662635930541e-16, Validation Loss: 3.980593642655432e-15
Epoch 497, Training Loss: 1.6632075313280609e-15, Validation Loss: 3.951370158942211e-15
Epoch 498, Training Loss: 1.6632075313280609e-15, Validation Loss: 3.930553477230489e-15
Epoch 499, Training Loss: 1.3269379923669454e-15, Validation Loss: 4.126564948038133e-15
Epoch 500, Training Loss: 1.7592844668318664e-15, Validation Loss: 4.725157202632117e-15
