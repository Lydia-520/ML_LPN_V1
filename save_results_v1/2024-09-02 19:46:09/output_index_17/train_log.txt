Epoch 1, Training Loss: 0.4754572808742523, Validation Loss: 0.4739314913749695
Epoch 2, Training Loss: 0.4739314913749695, Validation Loss: 0.4724445641040802
Epoch 3, Training Loss: 0.47244447469711304, Validation Loss: 0.4710295796394348
Epoch 4, Training Loss: 0.4710295796394348, Validation Loss: 0.4696865379810333
Epoch 5, Training Loss: 0.4696865379810333, Validation Loss: 0.46836769580841064
Epoch 6, Training Loss: 0.46836766600608826, Validation Loss: 0.46705523133277893
Epoch 7, Training Loss: 0.46705520153045654, Validation Loss: 0.46574023365974426
Epoch 8, Training Loss: 0.46574023365974426, Validation Loss: 0.4644016921520233
Epoch 9, Training Loss: 0.4644016921520233, Validation Loss: 0.4630679488182068
Epoch 10, Training Loss: 0.4630679488182068, Validation Loss: 0.46176040172576904
Epoch 11, Training Loss: 0.46176040172576904, Validation Loss: 0.4604628086090088
Epoch 12, Training Loss: 0.4604628384113312, Validation Loss: 0.4591551125049591
Epoch 13, Training Loss: 0.4591551125049591, Validation Loss: 0.45783135294914246
Epoch 14, Training Loss: 0.45783132314682007, Validation Loss: 0.45650044083595276
Epoch 15, Training Loss: 0.45650044083595276, Validation Loss: 0.4551715552806854
Epoch 16, Training Loss: 0.45517152547836304, Validation Loss: 0.45384547114372253
Epoch 17, Training Loss: 0.45384547114372253, Validation Loss: 0.4525081217288971
Epoch 18, Training Loss: 0.45250818133354187, Validation Loss: 0.4511633515357971
Epoch 19, Training Loss: 0.4511633515357971, Validation Loss: 0.44982245564460754
Epoch 20, Training Loss: 0.44982245564460754, Validation Loss: 0.4485239088535309
Epoch 21, Training Loss: 0.4485239088535309, Validation Loss: 0.4472053647041321
Epoch 22, Training Loss: 0.44720542430877686, Validation Loss: 0.4459136128425598
Epoch 23, Training Loss: 0.4459136128425598, Validation Loss: 0.4445647597312927
Epoch 24, Training Loss: 0.4445647597312927, Validation Loss: 0.44315093755722046
Epoch 25, Training Loss: 0.44315093755722046, Validation Loss: 0.44169148802757263
Epoch 26, Training Loss: 0.44169148802757263, Validation Loss: 0.4401743710041046
Epoch 27, Training Loss: 0.4401743412017822, Validation Loss: 0.4385848641395569
Epoch 28, Training Loss: 0.4385848939418793, Validation Loss: 0.4369856119155884
Epoch 29, Training Loss: 0.43698570132255554, Validation Loss: 0.43531426787376404
Epoch 30, Training Loss: 0.43531426787376404, Validation Loss: 0.43350690603256226
Epoch 31, Training Loss: 0.43350690603256226, Validation Loss: 0.4315931797027588
Epoch 32, Training Loss: 0.4315931797027588, Validation Loss: 0.42956677079200745
Epoch 33, Training Loss: 0.42956677079200745, Validation Loss: 0.4274214804172516
Epoch 34, Training Loss: 0.4274214804172516, Validation Loss: 0.42514172196388245
Epoch 35, Training Loss: 0.42514172196388245, Validation Loss: 0.42273324728012085
Epoch 36, Training Loss: 0.42273324728012085, Validation Loss: 0.42017513513565063
Epoch 37, Training Loss: 0.420175164937973, Validation Loss: 0.417434424161911
Epoch 38, Training Loss: 0.4174344539642334, Validation Loss: 0.4145091772079468
Epoch 39, Training Loss: 0.4145091772079468, Validation Loss: 0.4113999605178833
Epoch 40, Training Loss: 0.4113999605178833, Validation Loss: 0.40805503726005554
Epoch 41, Training Loss: 0.40805503726005554, Validation Loss: 0.40444955229759216
Epoch 42, Training Loss: 0.40444955229759216, Validation Loss: 0.40060877799987793
Epoch 43, Training Loss: 0.40060874819755554, Validation Loss: 0.39651739597320557
Epoch 44, Training Loss: 0.39651739597320557, Validation Loss: 0.39206963777542114
Epoch 45, Training Loss: 0.39206963777542114, Validation Loss: 0.38725993037223816
Epoch 46, Training Loss: 0.38725993037223816, Validation Loss: 0.3820838928222656
Epoch 47, Training Loss: 0.38208386301994324, Validation Loss: 0.37655919790267944
Epoch 48, Training Loss: 0.37655922770500183, Validation Loss: 0.37066709995269775
Epoch 49, Training Loss: 0.37066709995269775, Validation Loss: 0.36435744166374207
Epoch 50, Training Loss: 0.36435744166374207, Validation Loss: 0.3576611578464508
Epoch 51, Training Loss: 0.3576611578464508, Validation Loss: 0.3505808413028717
Epoch 52, Training Loss: 0.3505808413028717, Validation Loss: 0.34308046102523804
Epoch 53, Training Loss: 0.34308046102523804, Validation Loss: 0.33515432476997375
Epoch 54, Training Loss: 0.33515429496765137, Validation Loss: 0.3268141746520996
Epoch 55, Training Loss: 0.3268142342567444, Validation Loss: 0.31811290979385376
Epoch 56, Training Loss: 0.31811290979385376, Validation Loss: 0.3090944290161133
Epoch 57, Training Loss: 0.3090944290161133, Validation Loss: 0.2998100221157074
Epoch 58, Training Loss: 0.2998100221157074, Validation Loss: 0.29034924507141113
Epoch 59, Training Loss: 0.29034924507141113, Validation Loss: 0.28083187341690063
Epoch 60, Training Loss: 0.28083187341690063, Validation Loss: 0.27134546637535095
Epoch 61, Training Loss: 0.27134549617767334, Validation Loss: 0.2620548903942108
Epoch 62, Training Loss: 0.2620548605918884, Validation Loss: 0.25306448340415955
Epoch 63, Training Loss: 0.25306445360183716, Validation Loss: 0.24451839923858643
Epoch 64, Training Loss: 0.24451839923858643, Validation Loss: 0.23673692345619202
Epoch 65, Training Loss: 0.23673690855503082, Validation Loss: 0.2297753244638443
Epoch 66, Training Loss: 0.2297753244638443, Validation Loss: 0.22362251579761505
Epoch 67, Training Loss: 0.22362251579761505, Validation Loss: 0.21839502453804016
Epoch 68, Training Loss: 0.21839502453804016, Validation Loss: 0.2140132486820221
Epoch 69, Training Loss: 0.2140132486820221, Validation Loss: 0.21019171178340912
Epoch 70, Training Loss: 0.2101917415857315, Validation Loss: 0.20673984289169312
Epoch 71, Training Loss: 0.20673984289169312, Validation Loss: 0.20327810943126678
Epoch 72, Training Loss: 0.20327810943126678, Validation Loss: 0.19978956878185272
Epoch 73, Training Loss: 0.19978956878185272, Validation Loss: 0.19579550623893738
Epoch 74, Training Loss: 0.19579550623893738, Validation Loss: 0.1912732869386673
Epoch 75, Training Loss: 0.19127331674098969, Validation Loss: 0.18617218732833862
Epoch 76, Training Loss: 0.18617215752601624, Validation Loss: 0.18054059147834778
Epoch 77, Training Loss: 0.18054059147834778, Validation Loss: 0.1746196746826172
Epoch 78, Training Loss: 0.1746196746826172, Validation Loss: 0.16853924095630646
Epoch 79, Training Loss: 0.16853924095630646, Validation Loss: 0.16227348148822784
Epoch 80, Training Loss: 0.16227348148822784, Validation Loss: 0.15596595406532288
Epoch 81, Training Loss: 0.15596593916416168, Validation Loss: 0.14976680278778076
Epoch 82, Training Loss: 0.14976680278778076, Validation Loss: 0.14373402297496796
Epoch 83, Training Loss: 0.14373403787612915, Validation Loss: 0.13791130483150482
Epoch 84, Training Loss: 0.13791130483150482, Validation Loss: 0.13203057646751404
Epoch 85, Training Loss: 0.13203057646751404, Validation Loss: 0.12606850266456604
Epoch 86, Training Loss: 0.12606851756572723, Validation Loss: 0.11997100710868835
Epoch 87, Training Loss: 0.11997101455926895, Validation Loss: 0.11381645500659943
Epoch 88, Training Loss: 0.11381646990776062, Validation Loss: 0.10764766484498978
Epoch 89, Training Loss: 0.10764766484498978, Validation Loss: 0.10136090219020844
Epoch 90, Training Loss: 0.10136089473962784, Validation Loss: 0.09502764046192169
Epoch 91, Training Loss: 0.09502764046192169, Validation Loss: 0.08854062855243683
Epoch 92, Training Loss: 0.08854062855243683, Validation Loss: 0.08194442093372345
Epoch 93, Training Loss: 0.08194442838430405, Validation Loss: 0.07548150420188904
Epoch 94, Training Loss: 0.07548151165246964, Validation Loss: 0.0691860094666481
Epoch 95, Training Loss: 0.0691860094666481, Validation Loss: 0.06318606436252594
Epoch 96, Training Loss: 0.06318607181310654, Validation Loss: 0.057513292878866196
Epoch 97, Training Loss: 0.0575132891535759, Validation Loss: 0.05213860049843788
Epoch 98, Training Loss: 0.05213860049843788, Validation Loss: 0.04698770120739937
Epoch 99, Training Loss: 0.04698769748210907, Validation Loss: 0.04201969504356384
Epoch 100, Training Loss: 0.04201969876885414, Validation Loss: 0.03728986531496048
Epoch 101, Training Loss: 0.03728986531496048, Validation Loss: 0.032830674201250076
Epoch 102, Training Loss: 0.032830677926540375, Validation Loss: 0.02863914519548416
Epoch 103, Training Loss: 0.02863914705812931, Validation Loss: 0.024754928424954414
Epoch 104, Training Loss: 0.024754934012889862, Validation Loss: 0.02126043662428856
Epoch 105, Training Loss: 0.02126043662428856, Validation Loss: 0.018178138881921768
Epoch 106, Training Loss: 0.018178138881921768, Validation Loss: 0.01553680282086134
Epoch 107, Training Loss: 0.01553680282086134, Validation Loss: 0.013335737399756908
Epoch 108, Training Loss: 0.013335742056369781, Validation Loss: 0.011543290689587593
Epoch 109, Training Loss: 0.01154328789561987, Validation Loss: 0.010164384730160236
Epoch 110, Training Loss: 0.010164382867515087, Validation Loss: 0.009213278070092201
Epoch 111, Training Loss: 0.0092132817953825, Validation Loss: 0.008456318639218807
Epoch 112, Training Loss: 0.008456316776573658, Validation Loss: 0.0078107621520757675
Epoch 113, Training Loss: 0.007810764946043491, Validation Loss: 0.007210705894976854
Epoch 114, Training Loss: 0.007210704032331705, Validation Loss: 0.006612260825932026
Epoch 115, Training Loss: 0.0066122631542384624, Validation Loss: 0.005980232730507851
Epoch 116, Training Loss: 0.005980234127491713, Validation Loss: 0.005315540358424187
Epoch 117, Training Loss: 0.005315538961440325, Validation Loss: 0.004630170296877623
Epoch 118, Training Loss: 0.004630169365555048, Validation Loss: 0.003947797697037458
Epoch 119, Training Loss: 0.003947797231376171, Validation Loss: 0.003304095705971122
Epoch 120, Training Loss: 0.0033040959388017654, Validation Loss: 0.002726644277572632
Epoch 121, Training Loss: 0.0027266459073871374, Validation Loss: 0.0022115963511168957
Epoch 122, Training Loss: 0.002211596118286252, Validation Loss: 0.0017726796213537455
Epoch 123, Training Loss: 0.0017726816004142165, Validation Loss: 0.0014168386114761233
Epoch 124, Training Loss: 0.0014168376801535487, Validation Loss: 0.0011435982305556536
Epoch 125, Training Loss: 0.0011436000932008028, Validation Loss: 0.0009460760047659278
Epoch 126, Training Loss: 0.0009460742585361004, Validation Loss: 0.0008107633329927921
Epoch 127, Training Loss: 0.000810763391200453, Validation Loss: 0.0007226457237266004
Epoch 128, Training Loss: 0.0007226456655189395, Validation Loss: 0.0006656492478214204
Epoch 129, Training Loss: 0.0006656489567831159, Validation Loss: 0.0006258209468796849
Epoch 130, Training Loss: 0.0006258204230107367, Validation Loss: 0.0005919206305406988
Epoch 131, Training Loss: 0.0005919206887483597, Validation Loss: 0.0005556878750212491
Epoch 132, Training Loss: 0.000555686594452709, Validation Loss: 0.0005142181762494147
Epoch 133, Training Loss: 0.0005142176523804665, Validation Loss: 0.0004674000956583768
Epoch 134, Training Loss: 0.00046739933895878494, Validation Loss: 0.00041691921069286764
Epoch 135, Training Loss: 0.00041691871592774987, Validation Loss: 0.0003657075285445899
Epoch 136, Training Loss: 0.0003657079942058772, Validation Loss: 0.00031666745780967176
Epoch 137, Training Loss: 0.0003166664100717753, Validation Loss: 0.0002728268736973405
Epoch 138, Training Loss: 0.00027282771770842373, Validation Loss: 0.00023582365247420967
Epoch 139, Training Loss: 0.0002358236233703792, Validation Loss: 0.00020579119154717773
Epoch 140, Training Loss: 0.00020579084230121225, Validation Loss: 0.00018270853615831584
Epoch 141, Training Loss: 0.00018270908913109452, Validation Loss: 0.0001657680404605344
Epoch 142, Training Loss: 0.00016576847701799124, Validation Loss: 0.00015356348012574017
Epoch 143, Training Loss: 0.00015356317453552037, Validation Loss: 0.00014440655650105327
Epoch 144, Training Loss: 0.00014440673112403601, Validation Loss: 0.00013704186130780727
Epoch 145, Training Loss: 0.00013704186130780727, Validation Loss: 0.0001300628064200282
Epoch 146, Training Loss: 0.00013006245717406273, Validation Loss: 0.00012246913684066385
Epoch 147, Training Loss: 0.00012246907863300294, Validation Loss: 0.00011397180787753314
Epoch 148, Training Loss: 0.00011397206253604963, Validation Loss: 0.00010470623965375125
Epoch 149, Training Loss: 0.00010470639972481877, Validation Loss: 9.506545029580593e-05
Epoch 150, Training Loss: 9.506559581495821e-05, Validation Loss: 8.552928193239495e-05
Epoch 151, Training Loss: 8.552908548153937e-05, Validation Loss: 7.653074862901121e-05
Epoch 152, Training Loss: 7.653095963178203e-05, Validation Loss: 6.838513945695013e-05
Epoch 153, Training Loss: 6.838520494056866e-05, Validation Loss: 6.126577500253916e-05
Epoch 154, Training Loss: 6.126581138232723e-05, Validation Loss: 5.5217537010321394e-05
Epoch 155, Training Loss: 5.521726779988967e-05, Validation Loss: 5.016981594962999e-05
Epoch 156, Training Loss: 5.0169801397714764e-05, Validation Loss: 4.59661750937812e-05
Epoch 157, Training Loss: 4.596609142026864e-05, Validation Loss: 4.238630936015397e-05
Epoch 158, Training Loss: 4.238604742567986e-05, Validation Loss: 3.9184600609587505e-05
Epoch 159, Training Loss: 3.9184651541290805e-05, Validation Loss: 3.613286025938578e-05
Epoch 160, Training Loss: 3.613298395066522e-05, Validation Loss: 3.3144988265121356e-05
Epoch 161, Training Loss: 3.3145013730973005e-05, Validation Loss: 3.0121982490527444e-05
Epoch 162, Training Loss: 3.0122275347821414e-05, Validation Loss: 2.6964522476191632e-05
Epoch 163, Training Loss: 2.6964493372361176e-05, Validation Loss: 2.375448457314633e-05
Epoch 164, Training Loss: 2.37544190895278e-05, Validation Loss: 2.062480416498147e-05
Epoch 165, Training Loss: 2.0624995158868842e-05, Validation Loss: 1.7718528397381306e-05
Epoch 166, Training Loss: 1.771839743014425e-05, Validation Loss: 1.5152455489442218e-05
Epoch 167, Training Loss: 1.5152417290664744e-05, Validation Loss: 1.2999976206629071e-05
Epoch 168, Training Loss: 1.2999999853491317e-05, Validation Loss: 1.1283830644970294e-05
Epoch 169, Training Loss: 1.1283756066404749e-05, Validation Loss: 9.982830306398682e-06
Epoch 170, Training Loss: 9.982802112062927e-06, Validation Loss: 9.04200533113908e-06
Epoch 171, Training Loss: 9.042014426086098e-06, Validation Loss: 8.384829925489612e-06
Epoch 172, Training Loss: 8.384791726712137e-06, Validation Loss: 7.921537871879991e-06
Epoch 173, Training Loss: 7.921616088424344e-06, Validation Loss: 7.560706762888003e-06
Epoch 174, Training Loss: 7.560767244285671e-06, Validation Loss: 7.2187458499684e-06
Epoch 175, Training Loss: 7.218739938252838e-06, Validation Loss: 6.830983238614863e-06
Epoch 176, Training Loss: 6.831087830505567e-06, Validation Loss: 6.3595384744985495e-06
Epoch 177, Training Loss: 6.35954893368762e-06, Validation Loss: 5.796517598355422e-06
Epoch 178, Training Loss: 5.796571713290177e-06, Validation Loss: 5.160615273780422e-06
Epoch 179, Training Loss: 5.160652108315844e-06, Validation Loss: 4.488211743591819e-06
Epoch 180, Training Loss: 4.488352715270594e-06, Validation Loss: 3.822487087745685e-06
Epoch 181, Training Loss: 3.822488906735089e-06, Validation Loss: 3.202432253601728e-06
Epoch 182, Training Loss: 3.2023463063524105e-06, Validation Loss: 2.656521019162028e-06
Epoch 183, Training Loss: 2.6565685402601957e-06, Validation Loss: 2.200642029492883e-06
Epoch 184, Training Loss: 2.2006920517014805e-06, Validation Loss: 1.838491812122811e-06
Epoch 185, Training Loss: 1.8384577060714946e-06, Validation Loss: 1.564763579153805e-06
Epoch 186, Training Loss: 1.5647797226847615e-06, Validation Loss: 1.3680469237442594e-06
Epoch 187, Training Loss: 1.3680582924280316e-06, Validation Loss: 1.2333447330092895e-06
Epoch 188, Training Loss: 1.233362468155974e-06, Validation Loss: 1.1438773981353734e-06
Epoch 189, Training Loss: 1.1438901310611982e-06, Validation Loss: 1.0830200380951283e-06
Epoch 190, Training Loss: 1.0830668770722696e-06, Validation Loss: 1.0362283546783146e-06
Epoch 191, Training Loss: 1.0362034572608536e-06, Validation Loss: 9.92542823041731e-07
Epoch 192, Training Loss: 9.92559193946363e-07, Validation Loss: 9.456987299927277e-07
Epoch 193, Training Loss: 9.457075407226512e-07, Validation Loss: 8.937154234445188e-07
Epoch 194, Training Loss: 8.93687570169277e-07, Validation Loss: 8.375107540814497e-07
Epoch 195, Training Loss: 8.375134257221362e-07, Validation Loss: 7.796139698257321e-07
Epoch 196, Training Loss: 7.795820806677511e-07, Validation Loss: 7.221560167636198e-07
Epoch 197, Training Loss: 7.221527198453259e-07, Validation Loss: 6.665097771474393e-07
Epoch 198, Training Loss: 6.665028422503383e-07, Validation Loss: 6.128817631179118e-07
Epoch 199, Training Loss: 6.128686322881549e-07, Validation Loss: 5.610467610495107e-07
Epoch 200, Training Loss: 5.610440894088242e-07, Validation Loss: 5.107391416458995e-07
Epoch 201, Training Loss: 5.107542619953165e-07, Validation Loss: 4.618917159859848e-07
Epoch 202, Training Loss: 4.6192346303541854e-07, Validation Loss: 4.1489519730930624e-07
Epoch 203, Training Loss: 4.148795369474101e-07, Validation Loss: 3.7000239672124735e-07
Epoch 204, Training Loss: 3.699743160723301e-07, Validation Loss: 3.2754351764197054e-07
Epoch 205, Training Loss: 3.275011124515004e-07, Validation Loss: 2.877751796859229e-07
Epoch 206, Training Loss: 2.8775988880624936e-07, Validation Loss: 2.5101948608607927e-07
Epoch 207, Training Loss: 2.51002035156489e-07, Validation Loss: 2.1764090263332037e-07
Epoch 208, Training Loss: 2.1764630275811214e-07, Validation Loss: 1.8809880941716983e-07
Epoch 209, Training Loss: 1.88110476528891e-07, Validation Loss: 1.6271494018837984e-07
Epoch 210, Training Loss: 1.627223866762506e-07, Validation Loss: 1.415309043295565e-07
Epoch 211, Training Loss: 1.4153138749861682e-07, Validation Loss: 1.2419006623076712e-07
Epoch 212, Training Loss: 1.2419133099683677e-07, Validation Loss: 1.1008253864019935e-07
Epoch 213, Training Loss: 1.1008059175310336e-07, Validation Loss: 9.839931891519882e-08
Epoch 214, Training Loss: 9.84042145546482e-08, Validation Loss: 8.854657096435403e-08
Epoch 215, Training Loss: 8.85500455183319e-08, Validation Loss: 8.004680296380684e-08
Epoch 216, Training Loss: 8.003958384961152e-08, Validation Loss: 7.270018897997943e-08
Epoch 217, Training Loss: 7.269779445095992e-08, Validation Loss: 6.643644923087777e-08
Epoch 218, Training Loss: 6.643799821404173e-08, Validation Loss: 6.122891704762878e-08
Epoch 219, Training Loss: 6.12231829677512e-08, Validation Loss: 5.699887495325129e-08
Epoch 220, Training Loss: 5.699231664380022e-08, Validation Loss: 5.358254639986626e-08
Epoch 221, Training Loss: 5.3578620651251185e-08, Validation Loss: 5.079667886320749e-08
Epoch 222, Training Loss: 5.079210652070287e-08, Validation Loss: 4.841995959736778e-08
Epoch 223, Training Loss: 4.8423522969187616e-08, Validation Loss: 4.623943539172615e-08
Epoch 224, Training Loss: 4.6237484951916485e-08, Validation Loss: 4.4034624835376235e-08
Epoch 225, Training Loss: 4.404509112987398e-08, Validation Loss: 4.160463262792291e-08
Epoch 226, Training Loss: 4.1601424527470954e-08, Validation Loss: 3.8756557074748343e-08
Epoch 227, Training Loss: 3.875393517205339e-08, Validation Loss: 3.539418003128958e-08
Epoch 228, Training Loss: 3.5393213693168946e-08, Validation Loss: 3.154394789817161e-08
Epoch 229, Training Loss: 3.1542391809580295e-08, Validation Loss: 2.735357362837476e-08
Epoch 230, Training Loss: 2.7349441822366316e-08, Validation Loss: 2.3044931296567484e-08
Epoch 231, Training Loss: 2.3046002439741642e-08, Validation Loss: 1.8900079723493945e-08
Epoch 232, Training Loss: 1.8908146159901662e-08, Validation Loss: 1.518714043413638e-08
Epoch 233, Training Loss: 1.5185795732008955e-08, Validation Loss: 1.2056544207439401e-08
Epoch 234, Training Loss: 1.2052352005298417e-08, Validation Loss: 9.598507766384046e-09
Epoch 235, Training Loss: 9.600074513116397e-09, Validation Loss: 7.814128899497064e-09
Epoch 236, Training Loss: 7.814896285651685e-09, Validation Loss: 6.621347026225521e-09
Epoch 237, Training Loss: 6.6203278414889155e-09, Validation Loss: 5.911743095055044e-09
Epoch 238, Training Loss: 5.9125953022487465e-09, Validation Loss: 5.5336228932389986e-09
Epoch 239, Training Loss: 5.532244440331624e-09, Validation Loss: 5.338895991968684e-09
Epoch 240, Training Loss: 5.339606534704444e-09, Validation Loss: 5.204682906878588e-09
Epoch 241, Training Loss: 5.2052362420340614e-09, Validation Loss: 5.031769667596109e-09
Epoch 242, Training Loss: 5.027751548425385e-09, Validation Loss: 4.759704186341196e-09
Epoch 243, Training Loss: 4.755651872301314e-09, Validation Loss: 4.388330143711983e-09
Epoch 244, Training Loss: 4.387654239934591e-09, Validation Loss: 3.955984873016405e-09
Epoch 245, Training Loss: 3.957876693050366e-09, Validation Loss: 3.51468676385025e-09
Epoch 246, Training Loss: 3.5154021915673184e-09, Validation Loss: 3.1163520652910393e-09
Epoch 247, Training Loss: 3.1161495606113476e-09, Validation Loss: 2.8020297193620536e-09
Epoch 248, Training Loss: 2.8000457508170484e-09, Validation Loss: 2.586164171702876e-09
Epoch 249, Training Loss: 2.5859996366506266e-09, Validation Loss: 2.460979642293637e-09
Epoch 250, Training Loss: 2.462007486769835e-09, Validation Loss: 2.4113135932424257e-09
Epoch 251, Training Loss: 2.4086392880207086e-09, Validation Loss: 2.3979747076907643e-09
Epoch 252, Training Loss: 2.3991646447285575e-09, Validation Loss: 2.3966382212137205e-09
Epoch 253, Training Loss: 2.397732012937581e-09, Validation Loss: 2.3725172937361094e-09
Epoch 254, Training Loss: 2.3734672005559787e-09, Validation Loss: 2.2997481696762634e-09
Epoch 255, Training Loss: 2.299230583702183e-09, Validation Loss: 2.1705883757050515e-09
Epoch 256, Training Loss: 2.1702806218826254e-09, Validation Loss: 1.9814716534227728e-09
Epoch 257, Training Loss: 1.9809904827639002e-09, Validation Loss: 1.7489704129403094e-09
Epoch 258, Training Loss: 1.7480467073838213e-09, Validation Loss: 1.495242152316223e-09
Epoch 259, Training Loss: 1.4952395988032663e-09, Validation Loss: 1.2429250961787375e-09
Epoch 260, Training Loss: 1.244964353830369e-09, Validation Loss: 1.0150822404852988e-09
Epoch 261, Training Loss: 1.0145077000700553e-09, Validation Loss: 8.211213931019756e-10
Epoch 262, Training Loss: 8.211303859084751e-10, Validation Loss: 6.685273445938833e-10
Epoch 263, Training Loss: 6.69608646308717e-10, Validation Loss: 5.560417126737605e-10
Epoch 264, Training Loss: 5.560182869679409e-10, Validation Loss: 4.750978499501457e-10
Epoch 265, Training Loss: 4.7504439271151e-10, Validation Loss: 4.1711709086733606e-10
Epoch 266, Training Loss: 4.1760792046652284e-10, Validation Loss: 3.730997177875395e-10
Epoch 267, Training Loss: 3.74314690354538e-10, Validation Loss: 3.35921956917673e-10
Epoch 268, Training Loss: 3.3526301179698237e-10, Validation Loss: 2.9874863693990505e-10
Epoch 269, Training Loss: 2.983253366561911e-10, Validation Loss: 2.599483683862758e-10
Epoch 270, Training Loss: 2.595403059135748e-10, Validation Loss: 2.1888545143067262e-10
Epoch 271, Training Loss: 2.1871930655503746e-10, Validation Loss: 1.7917640982023642e-10
Epoch 272, Training Loss: 1.796377629981194e-10, Validation Loss: 1.4553666605188198e-10
Epoch 273, Training Loss: 1.4547943405496255e-10, Validation Loss: 1.190241100124112e-10
Epoch 274, Training Loss: 1.189889436981062e-10, Validation Loss: 1.0225977009614695e-10
Epoch 275, Training Loss: 1.0270759936981122e-10, Validation Loss: 9.510225246200932e-11
Epoch 276, Training Loss: 9.51739659305062e-11, Validation Loss: 9.478329926482232e-11
Epoch 277, Training Loss: 9.501709835602057e-11, Validation Loss: 9.899860792250692e-11
Epoch 278, Training Loss: 9.924584765119704e-11, Validation Loss: 1.0503792974292381e-10
Epoch 279, Training Loss: 1.0523794335970393e-10, Validation Loss: 1.1040551806118515e-10
Epoch 280, Training Loss: 1.1067899374772594e-10, Validation Loss: 1.1357707829784403e-10
Epoch 281, Training Loss: 1.1364419127968262e-10, Validation Loss: 1.1347683903650818e-10
Epoch 282, Training Loss: 1.1312564773824363e-10, Validation Loss: 1.0931247573786607e-10
Epoch 283, Training Loss: 1.0919540965881325e-10, Validation Loss: 1.0259427335457261e-10
Epoch 284, Training Loss: 1.026565846218297e-10, Validation Loss: 9.352927460293259e-11
Epoch 285, Training Loss: 9.39947564226884e-11, Validation Loss: 8.47864695119327e-11
Epoch 286, Training Loss: 8.458468647720707e-11, Validation Loss: 7.574368215967908e-11
Epoch 287, Training Loss: 7.559388531808153e-11, Validation Loss: 6.721239537155199e-11
Epoch 288, Training Loss: 6.746304903604283e-11, Validation Loss: 6.016548370624264e-11
Epoch 289, Training Loss: 6.027892768267762e-11, Validation Loss: 5.455645657459485e-11
Epoch 290, Training Loss: 5.4412443301066205e-11, Validation Loss: 4.9197635548781093e-11
Epoch 291, Training Loss: 4.91392170010041e-11, Validation Loss: 4.364678757307061e-11
Epoch 292, Training Loss: 4.3628930329608906e-11, Validation Loss: 3.828283870466187e-11
Epoch 293, Training Loss: 3.8389100925906305e-11, Validation Loss: 3.2874432343010795e-11
Epoch 294, Training Loss: 3.2780483188998844e-11, Validation Loss: 2.7200849211928002e-11
Epoch 295, Training Loss: 2.7266168489692433e-11, Validation Loss: 2.1726717647219118e-11
Epoch 296, Training Loss: 2.167409134112841e-11, Validation Loss: 1.6901211333242294e-11
Epoch 297, Training Loss: 1.678387116788027e-11, Validation Loss: 1.2531752545397179e-11
Epoch 298, Training Loss: 1.2480099419176494e-11, Validation Loss: 9.141663988299076e-12
Epoch 299, Training Loss: 9.149801576124883e-12, Validation Loss: 6.825023185497159e-12
Epoch 300, Training Loss: 6.8846629786012414e-12, Validation Loss: 5.5912882830633226e-12
Epoch 301, Training Loss: 5.650115791899779e-12, Validation Loss: 5.416296317700686e-12
Epoch 302, Training Loss: 5.418525871048185e-12, Validation Loss: 5.720650515794734e-12
Epoch 303, Training Loss: 5.768625160884611e-12, Validation Loss: 6.322460784080608e-12
Epoch 304, Training Loss: 6.340798979626028e-12, Validation Loss: 6.922438317014112e-12
Epoch 305, Training Loss: 6.939960758844954e-12, Validation Loss: 7.330578852271508e-12
Epoch 306, Training Loss: 7.397370042905305e-12, Validation Loss: 7.477266202038368e-12
Epoch 307, Training Loss: 7.543597690951032e-12, Validation Loss: 7.298192432336759e-12
Epoch 308, Training Loss: 7.20200418399819e-12, Validation Loss: 6.7109763926542776e-12
Epoch 309, Training Loss: 6.6268384009415815e-12, Validation Loss: 5.933211821157469e-12
Epoch 310, Training Loss: 6.000535138217522e-12, Validation Loss: 5.194935627506059e-12
Epoch 311, Training Loss: 5.2239818373878144e-12, Validation Loss: 4.457015052167224e-12
Epoch 312, Training Loss: 4.46100057935328e-12, Validation Loss: 3.826235769194275e-12
Epoch 313, Training Loss: 3.811510568968446e-12, Validation Loss: 3.3499529105557313e-12
Epoch 314, Training Loss: 3.3079968885657562e-12, Validation Loss: 2.9616907884499888e-12
Epoch 315, Training Loss: 2.974197060509609e-12, Validation Loss: 2.661552185242999e-12
Epoch 316, Training Loss: 2.6781081692572872e-12, Validation Loss: 2.5049040532770794e-12
Epoch 317, Training Loss: 2.507113223623736e-12, Validation Loss: 2.3154483972526174e-12
Epoch 318, Training Loss: 2.317074049990042e-12, Validation Loss: 2.157821881246247e-12
Epoch 319, Training Loss: 2.1144336281864184e-12, Validation Loss: 1.910916086825254e-12
Epoch 320, Training Loss: 1.990315464522885e-12, Validation Loss: 1.7092794193929173e-12
Epoch 321, Training Loss: 1.7011495294025347e-12, Validation Loss: 1.4472499804477068e-12
Epoch 322, Training Loss: 1.4749725963172922e-12, Validation Loss: 1.2431305984605956e-12
Epoch 323, Training Loss: 1.234516503779981e-12, Validation Loss: 1.0287273420270249e-12
Epoch 324, Training Loss: 1.0094549978897915e-12, Validation Loss: 8.226988968546012e-13
Epoch 325, Training Loss: 8.331558099677894e-13, Validation Loss: 6.999748003444495e-13
Epoch 326, Training Loss: 6.853297768692757e-13, Validation Loss: 6.131404520388906e-13
Epoch 327, Training Loss: 6.023261858896511e-13, Validation Loss: 5.547386009753519e-13
Epoch 328, Training Loss: 5.740800630010812e-13, Validation Loss: 5.259314576726293e-13
Epoch 329, Training Loss: 5.306639459454199e-13, Validation Loss: 5.143179176818335e-13
Epoch 330, Training Loss: 5.273519793590198e-13, Validation Loss: 4.924143775023038e-13
Epoch 331, Training Loss: 5.131682296981299e-13, Validation Loss: 4.943070692348117e-13
Epoch 332, Training Loss: 4.863564520736496e-13, Validation Loss: 4.673721262435371e-13
Epoch 333, Training Loss: 5.119897561467468e-13, Validation Loss: 4.697263628408721e-13
Epoch 334, Training Loss: 4.683413487756305e-13, Validation Loss: 4.171119016588981e-13
Epoch 335, Training Loss: 4.3146110057130926e-13, Validation Loss: 4.162521564411714e-13
Epoch 336, Training Loss: 3.8800072096195626e-13, Validation Loss: 3.6975657995499955e-13
Epoch 337, Training Loss: 3.6640167896256903e-13, Validation Loss: 3.325750861770532e-13
Epoch 338, Training Loss: 3.189081485867329e-13, Validation Loss: 2.6044970216979046e-13
Epoch 339, Training Loss: 2.782407550888655e-13, Validation Loss: 2.2106222288906935e-13
Epoch 340, Training Loss: 2.296531563007742e-13, Validation Loss: 1.9978850930406356e-13
Epoch 341, Training Loss: 1.8873074489941105e-13, Validation Loss: 1.6874656782583236e-13
Epoch 342, Training Loss: 1.5863516283996099e-13, Validation Loss: 1.4262549474786113e-13
Epoch 343, Training Loss: 1.4008108908947214e-13, Validation Loss: 1.2856169850482962e-13
Epoch 344, Training Loss: 1.2838893088864406e-13, Validation Loss: 1.1180920284677848e-13
Epoch 345, Training Loss: 1.161077527525589e-13, Validation Loss: 1.0763839228570757e-13
Epoch 346, Training Loss: 9.262373040861555e-14, Validation Loss: 9.287122665953967e-14
Epoch 347, Training Loss: 8.88453671526665e-14, Validation Loss: 8.683949148961465e-14
Epoch 348, Training Loss: 8.613906300487112e-14, Validation Loss: 7.91471651672565e-14
Epoch 349, Training Loss: 7.399240047707353e-14, Validation Loss: 7.164367975829103e-14
Epoch 350, Training Loss: 7.847812433540644e-14, Validation Loss: 6.430886910230998e-14
Epoch 351, Training Loss: 6.223884255196488e-14, Validation Loss: 5.519903653085356e-14
Epoch 352, Training Loss: 5.776272743538563e-14, Validation Loss: 5.0275091706929176e-14
Epoch 353, Training Loss: 4.7604718696756324e-14, Validation Loss: 4.8484321754898446e-14
Epoch 354, Training Loss: 4.044444426175471e-14, Validation Loss: 3.8315406620040293e-14
Epoch 355, Training Loss: 3.38448886971765e-14, Validation Loss: 3.935927647170934e-14
Epoch 356, Training Loss: 3.4426288724040063e-14, Validation Loss: 2.9721186720500087e-14
Epoch 357, Training Loss: 3.034661890809372e-14, Validation Loss: 2.3409993358419236e-14
Epoch 358, Training Loss: 2.5444024396637822e-14, Validation Loss: 1.9692047268531944e-14
Epoch 359, Training Loss: 2.1448422600706465e-14, Validation Loss: 1.946656709797285e-14
Epoch 360, Training Loss: 1.9226907595876717e-14, Validation Loss: 1.9052201968307834e-14
Epoch 361, Training Loss: 1.7752126672950994e-14, Validation Loss: 1.5507360613719115e-14
Epoch 362, Training Loss: 1.6697414799557095e-14, Validation Loss: 1.3435734018136646e-14
Epoch 363, Training Loss: 1.5374220586937895e-14, Validation Loss: 1.3258258592830242e-14
Epoch 364, Training Loss: 1.4150307106066372e-14, Validation Loss: 1.3398070698136984e-14
Epoch 365, Training Loss: 1.2674457227561213e-14, Validation Loss: 1.2244913267481401e-14
Epoch 366, Training Loss: 1.2964823510011776e-14, Validation Loss: 1.1255420389927242e-14
Epoch 367, Training Loss: 1.2314702006071578e-14, Validation Loss: 1.0009221472213458e-14
Epoch 368, Training Loss: 1.2318972746191634e-14, Validation Loss: 1.0579678680431442e-14
Epoch 369, Training Loss: 1.0238905467289776e-14, Validation Loss: 1.2260391947559526e-14
Epoch 370, Training Loss: 1.030562540551205e-14, Validation Loss: 9.235567836212745e-15
Epoch 371, Training Loss: 9.447871562244352e-15, Validation Loss: 9.974527002693922e-15
Epoch 372, Training Loss: 8.229295235973478e-15, Validation Loss: 7.544179412850415e-15
Epoch 373, Training Loss: 8.37714653098261e-15, Validation Loss: 7.0441784051850434e-15
Epoch 374, Training Loss: 5.207139701927021e-15, Validation Loss: 6.134683130817843e-15
Epoch 375, Training Loss: 5.9255820363598045e-15, Validation Loss: 5.319062823928942e-15
Epoch 376, Training Loss: 7.069965899747727e-15, Validation Loss: 4.5035090091264e-15
Epoch 377, Training Loss: 6.2933434132668876e-15, Validation Loss: 5.635082769736522e-15
Epoch 378, Training Loss: 4.7625168613201884e-15, Validation Loss: 4.889952121201651e-15
Epoch 379, Training Loss: 4.6717771862961506e-15, Validation Loss: 5.136516212367326e-15
Epoch 380, Training Loss: 5.308020478912061e-15, Validation Loss: 5.345517356937588e-15
Epoch 381, Training Loss: 4.3899515370527525e-15, Validation Loss: 2.486793018415586e-15
Epoch 382, Training Loss: 4.345649172812511e-15, Validation Loss: 5.18562252396792e-15
Epoch 383, Training Loss: 4.921577366836811e-15, Validation Loss: 4.637616771049858e-15
Epoch 384, Training Loss: 4.3718034326413555e-15, Validation Loss: 4.555150490338127e-15
Epoch 385, Training Loss: 5.466547353671913e-15, Validation Loss: 3.052713094651603e-15
Epoch 386, Training Loss: 4.265585077539193e-15, Validation Loss: 2.719112344749049e-15
Epoch 387, Training Loss: 2.980288389529571e-15, Validation Loss: 4.3296029806597254e-15
Epoch 388, Training Loss: 3.109458584645247e-15, Validation Loss: 4.40970053373446e-15
Epoch 389, Training Loss: 2.7806617821030458e-15, Validation Loss: 3.783598766596025e-15
Epoch 390, Training Loss: 2.7715877298973473e-15, Validation Loss: 4.947197995908885e-15
Epoch 391, Training Loss: 2.2362254260247134e-15, Validation Loss: 2.994666562050976e-15
Epoch 392, Training Loss: 1.854052418794809e-15, Validation Loss: 4.6438547451899126e-15
Epoch 393, Training Loss: 1.8241618966356255e-15, Validation Loss: 3.702834175075328e-15
Epoch 394, Training Loss: 3.765984716457872e-15, Validation Loss: 3.874705206886224e-15
Epoch 395, Training Loss: 4.352588066716418e-15, Validation Loss: 3.471181887187828e-15
Epoch 396, Training Loss: 2.7224818418132265e-15, Validation Loss: 4.3305707158019634e-15
Epoch 397, Training Loss: 3.4056960759697033e-15, Validation Loss: 3.690023648781054e-15
Epoch 398, Training Loss: 2.8975555051976914e-15, Validation Loss: 2.8984561129788596e-15
Epoch 399, Training Loss: 1.922373884562104e-15, Validation Loss: 3.2155102860150376e-15
Epoch 400, Training Loss: 1.3704650038230941e-15, Validation Loss: 4.45663801747361e-15
Epoch 401, Training Loss: 2.1305407016793208e-15, Validation Loss: 4.326266941396964e-15
Epoch 402, Training Loss: 2.192990746814486e-15, Validation Loss: 4.018820663081492e-15
Epoch 403, Training Loss: 2.192990746814486e-15, Validation Loss: 4.187622471008012e-15
Epoch 404, Training Loss: 2.165769013713864e-15, Validation Loss: 4.033899543608513e-15
Epoch 405, Training Loss: 2.165769013713864e-15, Validation Loss: 4.033899543608513e-15
Epoch 406, Training Loss: 2.4465274014437216e-15, Validation Loss: 4.033899543608513e-15
Epoch 407, Training Loss: 2.1252031235621978e-15, Validation Loss: 4.700733854630986e-15
Epoch 408, Training Loss: 1.4676095184777953e-15, Validation Loss: 4.522691340766395e-15
Epoch 409, Training Loss: 1.4889599368254056e-15, Validation Loss: 3.693526553534424e-15
Epoch 410, Training Loss: 1.3341692185167738e-15, Validation Loss: 4.004709517696709e-15
Epoch 411, Training Loss: 1.6725737040214437e-15, Validation Loss: 3.3289678082009094e-15
Epoch 412, Training Loss: 1.5391335099395405e-15, Validation Loss: 3.462408108161931e-15
Epoch 413, Training Loss: 2.945593920010035e-15, Validation Loss: 3.881944373969933e-15
Epoch 414, Training Loss: 3.391818288161889e-15, Validation Loss: 3.881944373969933e-15
Epoch 415, Training Loss: 3.306416403013211e-15, Validation Loss: 3.846416000513825e-15
Epoch 416, Training Loss: 2.8303015127021736e-15, Validation Loss: 3.582237435693523e-15
Epoch 417, Training Loss: 2.4187718258280927e-15, Validation Loss: 2.964142035730773e-15
Epoch 418, Training Loss: 1.1553591869228517e-15, Validation Loss: 2.1821821828910473e-15
Epoch 419, Training Loss: 1.838573526958447e-15, Validation Loss: 2.1821821828910473e-15
Epoch 420, Training Loss: 1.5989146601370257e-15, Validation Loss: 1.790935335213681e-15
Epoch 421, Training Loss: 1.6789788612894623e-15, Validation Loss: 1.748234392639342e-15
Epoch 422, Training Loss: 2.0483414481042113e-15, Validation Loss: 1.748234392639342e-15
Epoch 423, Training Loss: 1.2663815952644857e-15, Validation Loss: 2.3754037389286725e-15
Epoch 424, Training Loss: 1.1751083953627961e-15, Validation Loss: 2.3407092694091363e-15
Epoch 425, Training Loss: 5.479391020130249e-16, Validation Loss: 2.331635217203438e-15
Epoch 426, Training Loss: 5.105758434349272e-16, Validation Loss: 2.299609536742463e-15
Epoch 427, Training Loss: 1.403558157555846e-15, Validation Loss: 1.6434503819542359e-15
Epoch 428, Training Loss: 1.2354233880752883e-15, Validation Loss: 1.4194374842180224e-15
Epoch 429, Training Loss: 2.001370506563645e-15, Validation Loss: 1.3874119096361662e-15
Epoch 430, Training Loss: 2.850050721142118e-15, Validation Loss: 1.3874119096361662e-15
Epoch 431, Training Loss: 1.2380921771338498e-15, Validation Loss: 1.5608842572338469e-15
Epoch 432, Training Loss: 1.2183430745730237e-15, Validation Loss: 1.5608842572338469e-15
Epoch 433, Training Loss: 1.2183430745730237e-15, Validation Loss: 1.576730231973725e-15
Epoch 434, Training Loss: 1.1382788734205871e-15, Validation Loss: 1.5980806503213354e-15
Epoch 435, Training Loss: 1.1687032380947775e-15, Validation Loss: 2.366696663747372e-15
Epoch 436, Training Loss: 6.055853056669556e-16, Validation Loss: 2.527492104498208e-15
Epoch 437, Training Loss: 1.1099895611690696e-15, Validation Loss: 3.3970224585898193e-15
Epoch 438, Training Loss: 2.086238549197316e-15, Validation Loss: 3.3970224585898193e-15
Epoch 439, Training Loss: 2.0435377125020953e-15, Validation Loss: 3.485092921038822e-15
Epoch 440, Training Loss: 1.9928302968729534e-15, Validation Loss: 3.485092921038822e-15
Epoch 441, Training Loss: 1.3656610564627414e-15, Validation Loss: 3.5623215735212065e-15
Epoch 442, Training Loss: 1.8412423160170084e-15, Validation Loss: 3.653060825028771e-15
Epoch 443, Training Loss: 2.064888236728824e-15, Validation Loss: 3.653060825028771e-15
Epoch 444, Training Loss: 1.4163683662127649e-15, Validation Loss: 3.7491380781699314e-15
Epoch 445, Training Loss: 1.5188505648637074e-15, Validation Loss: 3.834539751560373e-15
Epoch 446, Training Loss: 1.5599501916512622e-15, Validation Loss: 3.834539751560373e-15
Epoch 447, Training Loss: 8.500479080904928e-16, Validation Loss: 3.941291737419306e-15
Epoch 448, Training Loss: 1.5092428819012387e-15, Validation Loss: 3.941291737419306e-15
Epoch 449, Training Loss: 1.4318474698073636e-15, Validation Loss: 4.106757929599539e-15
Epoch 450, Training Loss: 1.4494616258246351e-15, Validation Loss: 4.334140112641693e-15
Epoch 451, Training Loss: 1.4494616258246351e-15, Validation Loss: 4.334140112641693e-15
Epoch 452, Training Loss: 1.4494616258246351e-15, Validation Loss: 4.334140112641693e-15
Epoch 453, Training Loss: 1.5337958259432991e-15, Validation Loss: 4.4537026247949e-15
Epoch 454, Training Loss: 1.516181775805146e-15, Validation Loss: 4.427014310692812e-15
Epoch 455, Training Loss: 8.356363307072305e-16, Validation Loss: 4.427014310692812e-15
Epoch 456, Training Loss: 1.4975001465160971e-15, Validation Loss: 4.427014310692812e-15
Epoch 457, Training Loss: 1.5743617160949653e-15, Validation Loss: 4.427014310692812e-15
Epoch 458, Training Loss: 1.5743617160949653e-15, Validation Loss: 4.427014310692812e-15
Epoch 459, Training Loss: 1.5743617160949653e-15, Validation Loss: 4.427014310692812e-15
Epoch 460, Training Loss: 1.598380923501137e-15, Validation Loss: 2.9785204200104146e-15
Epoch 461, Training Loss: 1.9650747212573245e-15, Validation Loss: 2.9806888243553856e-15
Epoch 462, Training Loss: 4.2037022268413327e-16, Validation Loss: 2.9806888243553856e-15
Epoch 463, Training Loss: 4.2037022268413327e-16, Validation Loss: 3.837208328860697e-15
Epoch 464, Training Loss: 1.14361645153771e-15, Validation Loss: 4.496570115222493e-15
Epoch 465, Training Loss: 1.14361645153771e-15, Validation Loss: 3.507244103158943e-15
Epoch 466, Training Loss: 1.14361645153771e-15, Validation Loss: 3.507244103158943e-15
Epoch 467, Training Loss: 1.14361645153771e-15, Validation Loss: 3.98923041410211e-15
Epoch 468, Training Loss: 4.972317922630014e-16, Validation Loss: 3.98923041410211e-15
Epoch 469, Training Loss: 4.972317922630014e-16, Validation Loss: 3.959039618763125e-15
Epoch 470, Training Loss: 5.132446324934887e-16, Validation Loss: 3.959039618763125e-15
Epoch 471, Training Loss: 4.1716764405012397e-16, Validation Loss: 3.959039618763125e-15
Epoch 472, Training Loss: 4.1716764405012397e-16, Validation Loss: 3.87257026034267e-15
Epoch 473, Training Loss: 4.0435738245364595e-16, Validation Loss: 3.9494317240424195e-15
Epoch 474, Training Loss: 4.390518519731821e-16, Validation Loss: 3.9494317240424195e-15
Epoch 475, Training Loss: 1.0929091417876866e-15, Validation Loss: 3.724851949506256e-15
Epoch 476, Training Loss: 9.91494628166758e-16, Validation Loss: 3.812388569440252e-15
Epoch 477, Training Loss: 8.452440666092585e-16, Validation Loss: 3.812388569440252e-15
Epoch 478, Training Loss: 8.452440666092585e-16, Validation Loss: 3.812388569440252e-15
Epoch 479, Training Loss: 8.724658526494396e-16, Validation Loss: 3.662935535127861e-15
Epoch 480, Training Loss: 8.724658526494396e-16, Validation Loss: 3.3266659961667458e-15
Epoch 481, Training Loss: 1.451596678247308e-15, Validation Loss: 3.294640315705771e-15
Epoch 482, Training Loss: 1.451596678247308e-15, Validation Loss: 3.4174054594325468e-15
Epoch 483, Training Loss: 7.283503435146128e-16, Validation Loss: 3.4174054594325468e-15
Epoch 484, Training Loss: 7.641123392454854e-16, Validation Loss: 3.283965159471525e-15
Epoch 485, Training Loss: 7.641123392454854e-16, Validation Loss: 3.283965159471525e-15
Epoch 486, Training Loss: 6.557588787810904e-16, Validation Loss: 2.8227955302400796e-15
Epoch 487, Training Loss: 6.237331983201158e-16, Validation Loss: 2.8227955302400796e-15
Epoch 488, Training Loss: 2.2650484749121196e-15, Validation Loss: 4.039103714036443e-15
Epoch 489, Training Loss: 2.2650484749121196e-15, Validation Loss: 4.113963638881831e-15
Epoch 490, Training Loss: 1.1655007124003274e-15, Validation Loss: 4.113963638881831e-15
Epoch 491, Training Loss: 4.764151105512797e-16, Validation Loss: 4.113963638881831e-15
Epoch 492, Training Loss: 1.3010760647840219e-15, Validation Loss: 4.113963638881831e-15
Epoch 493, Training Loss: 1.3010760647840219e-15, Validation Loss: 3.943159868584475e-15
Epoch 494, Training Loss: 1.2663815952644857e-15, Validation Loss: 2.967745102130156e-15
Epoch 495, Training Loss: 1.1356100843620256e-15, Validation Loss: 2.2376598763208886e-15
Epoch 496, Training Loss: 1.5834356624215454e-15, Validation Loss: 2.2376598763208886e-15
Epoch 497, Training Loss: 1.4761496222893684e-15, Validation Loss: 2.2483352443133714e-15
Epoch 498, Training Loss: 1.4393201003471594e-15, Validation Loss: 1.7774577704734442e-15
Epoch 499, Training Loss: 2.1011838102769076e-15, Validation Loss: 2.2838636177694794e-15
Epoch 500, Training Loss: 1.5407347198472063e-15, Validation Loss: 2.3908493847218546e-15
