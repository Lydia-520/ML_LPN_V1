Epoch 1, Training Loss: 0.5096995234489441, Validation Loss: 0.5083083510398865
Epoch 2, Training Loss: 0.5083083510398865, Validation Loss: 0.506946325302124
Epoch 3, Training Loss: 0.5069462656974792, Validation Loss: 0.5056018829345703
Epoch 4, Training Loss: 0.5056018829345703, Validation Loss: 0.5042828321456909
Epoch 5, Training Loss: 0.5042828321456909, Validation Loss: 0.5029741525650024
Epoch 6, Training Loss: 0.5029742121696472, Validation Loss: 0.5016688108444214
Epoch 7, Training Loss: 0.5016688704490662, Validation Loss: 0.5003682374954224
Epoch 8, Training Loss: 0.5003682374954224, Validation Loss: 0.49905160069465637
Epoch 9, Training Loss: 0.49905163049697876, Validation Loss: 0.497761607170105
Epoch 10, Training Loss: 0.497761607170105, Validation Loss: 0.4964633285999298
Epoch 11, Training Loss: 0.49646326899528503, Validation Loss: 0.4951494038105011
Epoch 12, Training Loss: 0.4951494038105011, Validation Loss: 0.49381616711616516
Epoch 13, Training Loss: 0.49381616711616516, Validation Loss: 0.4924714267253876
Epoch 14, Training Loss: 0.49247145652770996, Validation Loss: 0.49110910296440125
Epoch 15, Training Loss: 0.49110913276672363, Validation Loss: 0.4897169768810272
Epoch 16, Training Loss: 0.48971694707870483, Validation Loss: 0.48831117153167725
Epoch 17, Training Loss: 0.48831120133399963, Validation Loss: 0.48686400055885315
Epoch 18, Training Loss: 0.48686397075653076, Validation Loss: 0.48540017008781433
Epoch 19, Training Loss: 0.48540017008781433, Validation Loss: 0.4839123487472534
Epoch 20, Training Loss: 0.4839123487472534, Validation Loss: 0.48238569498062134
Epoch 21, Training Loss: 0.4823857247829437, Validation Loss: 0.4808345437049866
Epoch 22, Training Loss: 0.4808345437049866, Validation Loss: 0.4792669415473938
Epoch 23, Training Loss: 0.4792669117450714, Validation Loss: 0.4776386022567749
Epoch 24, Training Loss: 0.4776385426521301, Validation Loss: 0.47593098878860474
Epoch 25, Training Loss: 0.4759310483932495, Validation Loss: 0.47416460514068604
Epoch 26, Training Loss: 0.47416460514068604, Validation Loss: 0.47231125831604004
Epoch 27, Training Loss: 0.47231125831604004, Validation Loss: 0.47037309408187866
Epoch 28, Training Loss: 0.4703730642795563, Validation Loss: 0.46836739778518677
Epoch 29, Training Loss: 0.46836739778518677, Validation Loss: 0.4662649631500244
Epoch 30, Training Loss: 0.4662649631500244, Validation Loss: 0.46404215693473816
Epoch 31, Training Loss: 0.46404215693473816, Validation Loss: 0.4617542326450348
Epoch 32, Training Loss: 0.4617542326450348, Validation Loss: 0.4593455493450165
Epoch 33, Training Loss: 0.4593455493450165, Validation Loss: 0.45677149295806885
Epoch 34, Training Loss: 0.45677149295806885, Validation Loss: 0.4540679454803467
Epoch 35, Training Loss: 0.4540679454803467, Validation Loss: 0.4512077569961548
Epoch 36, Training Loss: 0.4512077569961548, Validation Loss: 0.4481631815433502
Epoch 37, Training Loss: 0.4481631815433502, Validation Loss: 0.44494444131851196
Epoch 38, Training Loss: 0.44494444131851196, Validation Loss: 0.4415702223777771
Epoch 39, Training Loss: 0.4415701925754547, Validation Loss: 0.4379614591598511
Epoch 40, Training Loss: 0.4379614591598511, Validation Loss: 0.43414202332496643
Epoch 41, Training Loss: 0.43414199352264404, Validation Loss: 0.43007028102874756
Epoch 42, Training Loss: 0.4300702214241028, Validation Loss: 0.4257762134075165
Epoch 43, Training Loss: 0.4257762134075165, Validation Loss: 0.42119765281677246
Epoch 44, Training Loss: 0.42119765281677246, Validation Loss: 0.4163806140422821
Epoch 45, Training Loss: 0.4163806438446045, Validation Loss: 0.41133156418800354
Epoch 46, Training Loss: 0.4113315939903259, Validation Loss: 0.4060267210006714
Epoch 47, Training Loss: 0.4060267508029938, Validation Loss: 0.4004250168800354
Epoch 48, Training Loss: 0.400424987077713, Validation Loss: 0.3944884240627289
Epoch 49, Training Loss: 0.39448845386505127, Validation Loss: 0.3881852626800537
Epoch 50, Training Loss: 0.3881852626800537, Validation Loss: 0.3815717101097107
Epoch 51, Training Loss: 0.3815717101097107, Validation Loss: 0.3746650218963623
Epoch 52, Training Loss: 0.3746650218963623, Validation Loss: 0.36748167872428894
Epoch 53, Training Loss: 0.36748167872428894, Validation Loss: 0.359976202249527
Epoch 54, Training Loss: 0.35997623205184937, Validation Loss: 0.3522719740867615
Epoch 55, Training Loss: 0.3522719144821167, Validation Loss: 0.34438857436180115
Epoch 56, Training Loss: 0.34438860416412354, Validation Loss: 0.33632969856262207
Epoch 57, Training Loss: 0.33632969856262207, Validation Loss: 0.3282059133052826
Epoch 58, Training Loss: 0.3282058835029602, Validation Loss: 0.32011234760284424
Epoch 59, Training Loss: 0.32011234760284424, Validation Loss: 0.3121192455291748
Epoch 60, Training Loss: 0.3121192157268524, Validation Loss: 0.3043023943901062
Epoch 61, Training Loss: 0.3043023943901062, Validation Loss: 0.29681822657585144
Epoch 62, Training Loss: 0.29681822657585144, Validation Loss: 0.28972458839416504
Epoch 63, Training Loss: 0.28972458839416504, Validation Loss: 0.2829808294773102
Epoch 64, Training Loss: 0.2829808294773102, Validation Loss: 0.2766273617744446
Epoch 65, Training Loss: 0.2766273617744446, Validation Loss: 0.2706063389778137
Epoch 66, Training Loss: 0.2706063389778137, Validation Loss: 0.2649095952510834
Epoch 67, Training Loss: 0.2649095952510834, Validation Loss: 0.2592780590057373
Epoch 68, Training Loss: 0.2592780590057373, Validation Loss: 0.2536446452140808
Epoch 69, Training Loss: 0.2536446452140808, Validation Loss: 0.24782797694206238
Epoch 70, Training Loss: 0.24782797694206238, Validation Loss: 0.24189335107803345
Epoch 71, Training Loss: 0.24189335107803345, Validation Loss: 0.2357187718153
Epoch 72, Training Loss: 0.2357187718153, Validation Loss: 0.22921212017536163
Epoch 73, Training Loss: 0.22921212017536163, Validation Loss: 0.2225113958120346
Epoch 74, Training Loss: 0.2225113958120346, Validation Loss: 0.21554365754127502
Epoch 75, Training Loss: 0.21554365754127502, Validation Loss: 0.20831313729286194
Epoch 76, Training Loss: 0.20831312239170074, Validation Loss: 0.2008505016565323
Epoch 77, Training Loss: 0.2008505016565323, Validation Loss: 0.19329357147216797
Epoch 78, Training Loss: 0.19329357147216797, Validation Loss: 0.18567480146884918
Epoch 79, Training Loss: 0.185674786567688, Validation Loss: 0.17805072665214539
Epoch 80, Training Loss: 0.17805074155330658, Validation Loss: 0.1703926920890808
Epoch 81, Training Loss: 0.1703926920890808, Validation Loss: 0.16267886757850647
Epoch 82, Training Loss: 0.16267886757850647, Validation Loss: 0.15498550236225128
Epoch 83, Training Loss: 0.15498550236225128, Validation Loss: 0.14747844636440277
Epoch 84, Training Loss: 0.14747844636440277, Validation Loss: 0.13987651467323303
Epoch 85, Training Loss: 0.13987651467323303, Validation Loss: 0.13219943642616272
Epoch 86, Training Loss: 0.1321994513273239, Validation Loss: 0.12443619966506958
Epoch 87, Training Loss: 0.12443619966506958, Validation Loss: 0.11676350235939026
Epoch 88, Training Loss: 0.11676350235939026, Validation Loss: 0.1090555414557457
Epoch 89, Training Loss: 0.1090555414557457, Validation Loss: 0.10143973678350449
Epoch 90, Training Loss: 0.10143974423408508, Validation Loss: 0.09402516484260559
Epoch 91, Training Loss: 0.09402516484260559, Validation Loss: 0.08679681271314621
Epoch 92, Training Loss: 0.08679681271314621, Validation Loss: 0.07971294224262238
Epoch 93, Training Loss: 0.07971294224262238, Validation Loss: 0.07288511842489243
Epoch 94, Training Loss: 0.07288510352373123, Validation Loss: 0.06645190715789795
Epoch 95, Training Loss: 0.06645190715789795, Validation Loss: 0.06039789691567421
Epoch 96, Training Loss: 0.06039790064096451, Validation Loss: 0.054661888629198074
Epoch 97, Training Loss: 0.054661888629198074, Validation Loss: 0.0493040457367897
Epoch 98, Training Loss: 0.0493040457367897, Validation Loss: 0.044374678283929825
Epoch 99, Training Loss: 0.04437468945980072, Validation Loss: 0.03990190103650093
Epoch 100, Training Loss: 0.03990190103650093, Validation Loss: 0.03590433672070503
Epoch 101, Training Loss: 0.03590433672070503, Validation Loss: 0.032269783318042755
Epoch 102, Training Loss: 0.03226977959275246, Validation Loss: 0.0290379635989666
Epoch 103, Training Loss: 0.0290379635989666, Validation Loss: 0.02615773305296898
Epoch 104, Training Loss: 0.026157734915614128, Validation Loss: 0.023616859689354897
Epoch 105, Training Loss: 0.023616865277290344, Validation Loss: 0.02135033905506134
Epoch 106, Training Loss: 0.02135034278035164, Validation Loss: 0.019281718879938126
Epoch 107, Training Loss: 0.019281718879938126, Validation Loss: 0.017393851652741432
Epoch 108, Training Loss: 0.01739385537803173, Validation Loss: 0.015658913180232048
Epoch 109, Training Loss: 0.015658915042877197, Validation Loss: 0.014046779833734035
Epoch 110, Training Loss: 0.014046781696379185, Validation Loss: 0.01255347952246666
Epoch 111, Training Loss: 0.012553474865853786, Validation Loss: 0.011240776628255844
Epoch 112, Training Loss: 0.011240771971642971, Validation Loss: 0.010022927075624466
Epoch 113, Training Loss: 0.010022927075624466, Validation Loss: 0.008974221535027027
Epoch 114, Training Loss: 0.008974219672381878, Validation Loss: 0.007995146326720715
Epoch 115, Training Loss: 0.007995148189365864, Validation Loss: 0.007093449123203754
Epoch 116, Training Loss: 0.007093446794897318, Validation Loss: 0.006274981889873743
Epoch 117, Training Loss: 0.006274981424212456, Validation Loss: 0.005526695400476456
Epoch 118, Training Loss: 0.005526697263121605, Validation Loss: 0.004847157746553421
Epoch 119, Training Loss: 0.004847155883908272, Validation Loss: 0.00424252450466156
Epoch 120, Training Loss: 0.004242523107677698, Validation Loss: 0.0037120289634913206
Epoch 121, Training Loss: 0.0037120275665074587, Validation Loss: 0.0032529665622860193
Epoch 122, Training Loss: 0.0032529684249311686, Validation Loss: 0.002858948428183794
Epoch 123, Training Loss: 0.0028589472640305758, Validation Loss: 0.0025207989383488894
Epoch 124, Training Loss: 0.002520799171179533, Validation Loss: 0.002227895660325885
Epoch 125, Training Loss: 0.002227894263342023, Validation Loss: 0.001967133954167366
Epoch 126, Training Loss: 0.0019671344198286533, Validation Loss: 0.0017311286646872759
Epoch 127, Training Loss: 0.001731131342239678, Validation Loss: 0.001512382528744638
Epoch 128, Training Loss: 0.0015123849734663963, Validation Loss: 0.0013121562078595161
Epoch 129, Training Loss: 0.0013121567899361253, Validation Loss: 0.0011258121812716126
Epoch 130, Training Loss: 0.0011258127633482218, Validation Loss: 0.0009516006102785468
Epoch 131, Training Loss: 0.0009516010177321732, Validation Loss: 0.0007921242504380643
Epoch 132, Training Loss: 0.0007921239011920989, Validation Loss: 0.0006501522730104625
Epoch 133, Training Loss: 0.000650151283480227, Validation Loss: 0.0005276638548821211
Epoch 134, Training Loss: 0.0005276637966744602, Validation Loss: 0.00042552323429845273
Epoch 135, Training Loss: 0.00042552381637506187, Validation Loss: 0.00034216578933410347
Epoch 136, Training Loss: 0.0003421659639570862, Validation Loss: 0.00027583693736232817
Epoch 137, Training Loss: 0.000275836733635515, Validation Loss: 0.0002241055917693302
Epoch 138, Training Loss: 0.00022410583915188909, Validation Loss: 0.00018440012354403734
Epoch 139, Training Loss: 0.00018439975974615663, Validation Loss: 0.00015450388309545815
Epoch 140, Training Loss: 0.0001545040140626952, Validation Loss: 0.00013236187805887312
Epoch 141, Training Loss: 0.00013236231461632997, Validation Loss: 0.0001159702442237176
Epoch 142, Training Loss: 0.00011597009870456532, Validation Loss: 0.00010392443800810724
Epoch 143, Training Loss: 0.00010392448166385293, Validation Loss: 9.528243390377611e-05
Epoch 144, Training Loss: 9.5282171969302e-05, Validation Loss: 8.912422345019877e-05
Epoch 145, Training Loss: 8.91241361387074e-05, Validation Loss: 8.474455535179004e-05
Epoch 146, Training Loss: 8.474432252114639e-05, Validation Loss: 8.149569475790486e-05
Epoch 147, Training Loss: 8.149613859131932e-05, Validation Loss: 7.890677079558372e-05
Epoch 148, Training Loss: 7.890687265899032e-05, Validation Loss: 7.655088847968727e-05
Epoch 149, Training Loss: 7.655129593331367e-05, Validation Loss: 7.423338684020564e-05
Epoch 150, Training Loss: 7.423345959978178e-05, Validation Loss: 7.183216803241521e-05
Epoch 151, Training Loss: 7.183225534390658e-05, Validation Loss: 6.931791722308844e-05
Epoch 152, Training Loss: 6.931773532414809e-05, Validation Loss: 6.671248411294073e-05
Epoch 153, Training Loss: 6.67126732878387e-05, Validation Loss: 6.404662417480722e-05
Epoch 154, Training Loss: 6.404663145076483e-05, Validation Loss: 6.132526323199272e-05
Epoch 155, Training Loss: 6.132520502433181e-05, Validation Loss: 5.8513945987215266e-05
Epoch 156, Training Loss: 5.851438254467212e-05, Validation Loss: 5.554397284868173e-05
Epoch 157, Training Loss: 5.554405288421549e-05, Validation Loss: 5.236434662947431e-05
Epoch 158, Training Loss: 5.2364168368512765e-05, Validation Loss: 4.8939637053990737e-05
Epoch 159, Training Loss: 4.89396188640967e-05, Validation Loss: 4.53244756499771e-05
Epoch 160, Training Loss: 4.532479215413332e-05, Validation Loss: 4.164324127486907e-05
Epoch 161, Training Loss: 4.164343772572465e-05, Validation Loss: 3.783749707508832e-05
Epoch 162, Training Loss: 3.783757711062208e-05, Validation Loss: 3.4045573556795716e-05
Epoch 163, Training Loss: 3.404548260732554e-05, Validation Loss: 3.0412986234296113e-05
Epoch 164, Training Loss: 3.0412926207645796e-05, Validation Loss: 2.7065547328675166e-05
Epoch 165, Training Loss: 2.7065711037721485e-05, Validation Loss: 2.4084592951112427e-05
Epoch 166, Training Loss: 2.408462569292169e-05, Validation Loss: 2.149653846572619e-05
Epoch 167, Training Loss: 2.14963383768918e-05, Validation Loss: 1.9377985154278576e-05
Epoch 168, Training Loss: 1.937787965289317e-05, Validation Loss: 1.758616963343229e-05
Epoch 169, Training Loss: 1.7586109606781974e-05, Validation Loss: 1.6026215234887786e-05
Epoch 170, Training Loss: 1.6026086086640134e-05, Validation Loss: 1.4608961464546155e-05
Epoch 171, Training Loss: 1.4608940546168014e-05, Validation Loss: 1.3263805158203468e-05
Epoch 172, Training Loss: 1.3263831533549819e-05, Validation Loss: 1.194707328977529e-05
Epoch 173, Training Loss: 1.1947064194828272e-05, Validation Loss: 1.0642605047905818e-05
Epoch 174, Training Loss: 1.06425450212555e-05, Validation Loss: 9.363743629364762e-06
Epoch 175, Training Loss: 9.363754543301184e-06, Validation Loss: 8.155725481628906e-06
Epoch 176, Training Loss: 8.155807336152066e-06, Validation Loss: 7.006524811004056e-06
Epoch 177, Training Loss: 7.006452960922616e-06, Validation Loss: 5.933675765845692e-06
Epoch 178, Training Loss: 5.933682587055955e-06, Validation Loss: 4.950757556798635e-06
Epoch 179, Training Loss: 4.950712991558248e-06, Validation Loss: 4.067267127538798e-06
Epoch 180, Training Loss: 4.067171630595112e-06, Validation Loss: 3.2897230539674638e-06
Epoch 181, Training Loss: 3.289680535090156e-06, Validation Loss: 2.6229286049783695e-06
Epoch 182, Training Loss: 2.6228915430692723e-06, Validation Loss: 2.0691948066087207e-06
Epoch 183, Training Loss: 2.069199126708554e-06, Validation Loss: 1.6276745782306534e-06
Epoch 184, Training Loss: 1.627644564905495e-06, Validation Loss: 1.2925372629979393e-06
Epoch 185, Training Loss: 1.2925493138027377e-06, Validation Loss: 1.052710103977006e-06
Epoch 186, Training Loss: 1.0526925962039968e-06, Validation Loss: 8.919603260437725e-07
Epoch 187, Training Loss: 8.919550396058185e-07, Validation Loss: 7.911307875474449e-07
Epoch 188, Training Loss: 7.911166335361486e-07, Validation Loss: 7.30879776256188e-07
Epoch 189, Training Loss: 7.309088232432259e-07, Validation Loss: 6.946181656530825e-07
Epoch 190, Training Loss: 6.946083885850385e-07, Validation Loss: 6.702532573399367e-07
Epoch 191, Training Loss: 6.702930477331392e-07, Validation Loss: 6.512709660455585e-07
Epoch 192, Training Loss: 6.512606205433258e-07, Validation Loss: 6.356667086038215e-07
Epoch 193, Training Loss: 6.356696076181834e-07, Validation Loss: 6.242704557735124e-07
Epoch 194, Training Loss: 6.242388508326258e-07, Validation Loss: 6.186897394400148e-07
Epoch 195, Training Loss: 6.186812697706046e-07, Validation Loss: 6.194524644342891e-07
Epoch 196, Training Loss: 6.194422326188942e-07, Validation Loss: 6.251959234759852e-07
Epoch 197, Training Loss: 6.251871695894806e-07, Validation Loss: 6.326801553768746e-07
Epoch 198, Training Loss: 6.326674792944686e-07, Validation Loss: 6.375827297233627e-07
Epoch 199, Training Loss: 6.3761081037228e-07, Validation Loss: 6.358019959407102e-07
Epoch 200, Training Loss: 6.357890356412099e-07, Validation Loss: 6.242922836463549e-07
Epoch 201, Training Loss: 6.242717063287273e-07, Validation Loss: 6.018678391228605e-07
Epoch 202, Training Loss: 6.018552767272922e-07, Validation Loss: 5.691609885616344e-07
Epoch 203, Training Loss: 5.691996989298787e-07, Validation Loss: 5.283308723846858e-07
Epoch 204, Training Loss: 5.283298492031463e-07, Validation Loss: 4.820417416340206e-07
Epoch 205, Training Loss: 4.820398089577793e-07, Validation Loss: 4.332339074153424e-07
Epoch 206, Training Loss: 4.332366358994477e-07, Validation Loss: 3.844236289296532e-07
Epoch 207, Training Loss: 3.844282048248715e-07, Validation Loss: 3.3752525041563786e-07
Epoch 208, Training Loss: 3.3752189665392507e-07, Validation Loss: 2.9380618116192636e-07
Epoch 209, Training Loss: 2.9380353794294933e-07, Validation Loss: 2.5412236936972477e-07
Epoch 210, Training Loss: 2.541174524139933e-07, Validation Loss: 2.1895989732456655e-07
Epoch 211, Training Loss: 2.1895272084293538e-07, Validation Loss: 1.885128995127161e-07
Epoch 212, Training Loss: 1.8851667960007035e-07, Validation Loss: 1.6270426783648873e-07
Epoch 213, Training Loss: 1.627166881235098e-07, Validation Loss: 1.4119738978024543e-07
Epoch 214, Training Loss: 1.4119787294930575e-07, Validation Loss: 1.2332660048741673e-07
Epoch 215, Training Loss: 1.2332708365647704e-07, Validation Loss: 1.0827073282371202e-07
Epoch 216, Training Loss: 1.0826578744627113e-07, Validation Loss: 9.507204623560028e-08
Epoch 217, Training Loss: 9.507013487564109e-08, Validation Loss: 8.299028309011192e-08
Epoch 218, Training Loss: 8.299385001464543e-08, Validation Loss: 7.14832424364431e-08
Epoch 219, Training Loss: 7.147207981006432e-08, Validation Loss: 6.036026434230735e-08
Epoch 220, Training Loss: 6.038403199681852e-08, Validation Loss: 4.9823405845472735e-08
Epoch 221, Training Loss: 4.9823817960259476e-08, Validation Loss: 4.018599852884108e-08
Epoch 222, Training Loss: 4.0187231320487626e-08, Validation Loss: 3.1891506324654983e-08
Epoch 223, Training Loss: 3.188704411627441e-08, Validation Loss: 2.522401842952604e-08
Epoch 224, Training Loss: 2.5220098009981484e-08, Validation Loss: 2.030996171242805e-08
Epoch 225, Training Loss: 2.031247170464212e-08, Validation Loss: 1.701412344345954e-08
Epoch 226, Training Loss: 1.701524254826836e-08, Validation Loss: 1.503526547708134e-08
Epoch 227, Training Loss: 1.502963620225728e-08, Validation Loss: 1.3975871127058781e-08
Epoch 228, Training Loss: 1.3977249579966156e-08, Validation Loss: 1.3450459412922555e-08
Epoch 229, Training Loss: 1.3450635272249656e-08, Validation Loss: 1.3147415600656132e-08
Epoch 230, Training Loss: 1.3150069477774196e-08, Validation Loss: 1.289104467616653e-08
Epoch 231, Training Loss: 1.2888730971383211e-08, Validation Loss: 1.25813235385408e-08
Epoch 232, Training Loss: 1.2579923769351353e-08, Validation Loss: 1.2226919032798378e-08
Epoch 233, Training Loss: 1.22260228607729e-08, Validation Loss: 1.1847228975625512e-08
Epoch 234, Training Loss: 1.1848499070765683e-08, Validation Loss: 1.1486500639534825e-08
Epoch 235, Training Loss: 1.1485339790340277e-08, Validation Loss: 1.115298076115323e-08
Epoch 236, Training Loss: 1.115221159864177e-08, Validation Loss: 1.084420997443658e-08
Epoch 237, Training Loss: 1.0846564535427206e-08, Validation Loss: 1.0555289975400228e-08
Epoch 238, Training Loss: 1.0557196006288905e-08, Validation Loss: 1.0272249717502291e-08
Epoch 239, Training Loss: 1.0270785999466625e-08, Validation Loss: 9.975662962347087e-09
Epoch 240, Training Loss: 9.970847258955473e-09, Validation Loss: 9.652925569980653e-09
Epoch 241, Training Loss: 9.654411492476811e-09, Validation Loss: 9.290238800474526e-09
Epoch 242, Training Loss: 9.288217306391289e-09, Validation Loss: 8.862869549375318e-09
Epoch 243, Training Loss: 8.862532929754252e-09, Validation Loss: 8.350672153767391e-09
Epoch 244, Training Loss: 8.349563707099605e-09, Validation Loss: 7.734057838604258e-09
Epoch 245, Training Loss: 7.73292541111914e-09, Validation Loss: 7.0102141869199386e-09
Epoch 246, Training Loss: 7.010287017550354e-09, Validation Loss: 6.198557667147497e-09
Epoch 247, Training Loss: 6.19884543695548e-09, Validation Loss: 5.336928676769048e-09
Epoch 248, Training Loss: 5.335481834123357e-09, Validation Loss: 4.47352110910515e-09
Epoch 249, Training Loss: 4.476238935069432e-09, Validation Loss: 3.662321557129644e-09
Epoch 250, Training Loss: 3.663110259566338e-09, Validation Loss: 2.9486286745594725e-09
Epoch 251, Training Loss: 2.947860178181827e-09, Validation Loss: 2.355571071532836e-09
Epoch 252, Training Loss: 2.3544801663888393e-09, Validation Loss: 1.8891750386273998e-09
Epoch 253, Training Loss: 1.8900432330326566e-09, Validation Loss: 1.5420650312236717e-09
Epoch 254, Training Loss: 1.5415666521079174e-09, Validation Loss: 1.2862853004946828e-09
Epoch 255, Training Loss: 1.2863758946934922e-09, Validation Loss: 1.0968468355798677e-09
Epoch 256, Training Loss: 1.096714163928425e-09, Validation Loss: 9.49513911940869e-10
Epoch 257, Training Loss: 9.488966279391775e-10, Validation Loss: 8.270683582445315e-10
Epoch 258, Training Loss: 8.275105600752397e-10, Validation Loss: 7.234217669349619e-10
Epoch 259, Training Loss: 7.226055864784087e-10, Validation Loss: 6.340943881077976e-10
Epoch 260, Training Loss: 6.338267133365605e-10, Validation Loss: 5.630028665493114e-10
Epoch 261, Training Loss: 5.623121412945409e-10, Validation Loss: 5.071846831405935e-10
Epoch 262, Training Loss: 5.081594589562144e-10, Validation Loss: 4.700615452435386e-10
Epoch 263, Training Loss: 4.708931022889828e-10, Validation Loss: 4.4713671654150744e-10
Epoch 264, Training Loss: 4.4675224630807975e-10, Validation Loss: 4.325794722426224e-10
Epoch 265, Training Loss: 4.3244760550287253e-10, Validation Loss: 4.2424472268542956e-10
Epoch 266, Training Loss: 4.243987106189451e-10, Validation Loss: 4.1833181363415406e-10
Epoch 267, Training Loss: 4.1827374896996616e-10, Validation Loss: 4.107670315001144e-10
Epoch 268, Training Loss: 4.105737694271028e-10, Validation Loss: 4.0088665720361405e-10
Epoch 269, Training Loss: 4.0058673045351156e-10, Validation Loss: 3.8545633351816377e-10
Epoch 270, Training Loss: 3.8576883354402014e-10, Validation Loss: 3.646313251337574e-10
Epoch 271, Training Loss: 3.642489643240765e-10, Validation Loss: 3.369027834487781e-10
Epoch 272, Training Loss: 3.3685718103804163e-10, Validation Loss: 3.05833053326765e-10
Epoch 273, Training Loss: 3.052754160570714e-10, Validation Loss: 2.703564594419561e-10
Epoch 274, Training Loss: 2.7002855507163304e-10, Validation Loss: 2.3470869692232554e-10
Epoch 275, Training Loss: 2.340844185155788e-10, Validation Loss: 2.0136579903518026e-10
Epoch 276, Training Loss: 2.0125853761321366e-10, Validation Loss: 1.7225183779334685e-10
Epoch 277, Training Loss: 1.721013470623589e-10, Validation Loss: 1.4921663904488014e-10
Epoch 278, Training Loss: 1.4880210952306072e-10, Validation Loss: 1.322003062576016e-10
Epoch 279, Training Loss: 1.322170151141222e-10, Validation Loss: 1.2134579452371952e-10
Epoch 280, Training Loss: 1.2089922118985186e-10, Validation Loss: 1.1329510246627095e-10
Epoch 281, Training Loss: 1.1292505819326948e-10, Validation Loss: 1.0708612468990353e-10
Epoch 282, Training Loss: 1.0741202371988834e-10, Validation Loss: 1.0183567183963405e-10
Epoch 283, Training Loss: 1.0202813593984672e-10, Validation Loss: 9.548827006877758e-11
Epoch 284, Training Loss: 9.536898354367551e-11, Validation Loss: 8.858246081100418e-11
Epoch 285, Training Loss: 8.838702686420064e-11, Validation Loss: 8.029223813599273e-11
Epoch 286, Training Loss: 8.058581579817314e-11, Validation Loss: 7.195129214654372e-11
Epoch 287, Training Loss: 7.228683623905496e-11, Validation Loss: 6.425502491191892e-11
Epoch 288, Training Loss: 6.412141650979919e-11, Validation Loss: 5.6774977080786826e-11
Epoch 289, Training Loss: 5.650753129304853e-11, Validation Loss: 5.0018874458990226e-11
Epoch 290, Training Loss: 4.985335408380642e-11, Validation Loss: 4.386624050112253e-11
Epoch 291, Training Loss: 4.3911582703337615e-11, Validation Loss: 3.85090570542701e-11
Epoch 292, Training Loss: 3.846675408758493e-11, Validation Loss: 3.327613185000189e-11
Epoch 293, Training Loss: 3.327858474899692e-11, Validation Loss: 2.8699258247666393e-11
Epoch 294, Training Loss: 2.878931641692173e-11, Validation Loss: 2.4389013378312008e-11
Epoch 295, Training Loss: 2.4212423732627997e-11, Validation Loss: 2.0563044322852164e-11
Epoch 296, Training Loss: 2.06153653176111e-11, Validation Loss: 1.740255509141697e-11
Epoch 297, Training Loss: 1.7321638914880033e-11, Validation Loss: 1.4496773573235977e-11
Epoch 298, Training Loss: 1.4551365321024967e-11, Validation Loss: 1.2186794975943549e-11
Epoch 299, Training Loss: 1.2232765148056934e-11, Validation Loss: 1.023001388461564e-11
Epoch 300, Training Loss: 1.0325260611787623e-11, Validation Loss: 8.816872579253676e-12
Epoch 301, Training Loss: 8.942664317390658e-12, Validation Loss: 7.84601116715633e-12
Epoch 302, Training Loss: 7.800262172286132e-12, Validation Loss: 7.252608669877647e-12
Epoch 303, Training Loss: 7.214537994792991e-12, Validation Loss: 6.977914340094982e-12
Epoch 304, Training Loss: 6.875540935202817e-12, Validation Loss: 6.991265205646968e-12
Epoch 305, Training Loss: 6.860977497941123e-12, Validation Loss: 6.9745611196159185e-12
Epoch 306, Training Loss: 6.83928174510795e-12, Validation Loss: 6.949898555957956e-12
Epoch 307, Training Loss: 6.83001138285233e-12, Validation Loss: 6.855752510831481e-12
Epoch 308, Training Loss: 6.8204140252214884e-12, Validation Loss: 6.688512157321247e-12
Epoch 309, Training Loss: 6.523516969669796e-12, Validation Loss: 6.265624304113704e-12
Epoch 310, Training Loss: 6.286618794981713e-12, Validation Loss: 5.92051321163245e-12
Epoch 311, Training Loss: 5.805898730532055e-12, Validation Loss: 5.350482643745602e-12
Epoch 312, Training Loss: 5.332173938499274e-12, Validation Loss: 4.740475807035738e-12
Epoch 313, Training Loss: 4.82371000781745e-12, Validation Loss: 4.195801258516374e-12
Epoch 314, Training Loss: 4.165815262191508e-12, Validation Loss: 3.616502063097382e-12
Epoch 315, Training Loss: 3.5983492661234573e-12, Validation Loss: 3.1161111017918852e-12
Epoch 316, Training Loss: 3.2033570674522283e-12, Validation Loss: 2.7113792981647844e-12
Epoch 317, Training Loss: 2.735565680228591e-12, Validation Loss: 2.4059562935691003e-12
Epoch 318, Training Loss: 2.394385687984335e-12, Validation Loss: 2.0935015873635443e-12
Epoch 319, Training Loss: 2.065958298533288e-12, Validation Loss: 1.882760006927109e-12
Epoch 320, Training Loss: 1.8762786463399905e-12, Validation Loss: 1.673702409304978e-12
Epoch 321, Training Loss: 1.6172436653749678e-12, Validation Loss: 1.4466394662043802e-12
Epoch 322, Training Loss: 1.4998111259878488e-12, Validation Loss: 1.3448083792388932e-12
Epoch 323, Training Loss: 1.3553927945275657e-12, Validation Loss: 1.2277838251292805e-12
Epoch 324, Training Loss: 1.2305970045062287e-12, Validation Loss: 1.1018601395879069e-12
Epoch 325, Training Loss: 1.0862518566925883e-12, Validation Loss: 1.0308811096426673e-12
Epoch 326, Training Loss: 9.818009035975073e-13, Validation Loss: 9.320178092839249e-13
Epoch 327, Training Loss: 9.18388520614044e-13, Validation Loss: 8.211383504576342e-13
Epoch 328, Training Loss: 8.014663151895141e-13, Validation Loss: 7.724617386711818e-13
Epoch 329, Training Loss: 7.757071352441913e-13, Validation Loss: 6.829146081098469e-13
Epoch 330, Training Loss: 6.709736932730692e-13, Validation Loss: 5.880831303699263e-13
Epoch 331, Training Loss: 6.105217243215777e-13, Validation Loss: 5.432207960363866e-13
Epoch 332, Training Loss: 5.470480839153691e-13, Validation Loss: 5.124173654835751e-13
Epoch 333, Training Loss: 4.782418493338991e-13, Validation Loss: 4.485856402048488e-13
Epoch 334, Training Loss: 4.1206624158858507e-13, Validation Loss: 3.687567287115334e-13
Epoch 335, Training Loss: 3.794355509043751e-13, Validation Loss: 3.392353401226317e-13
Epoch 336, Training Loss: 3.210989417065657e-13, Validation Loss: 2.910726672709918e-13
Epoch 337, Training Loss: 2.935838150277398e-13, Validation Loss: 2.58723083105053e-13
Epoch 338, Training Loss: 2.542322092864008e-13, Validation Loss: 2.2362648299974197e-13
Epoch 339, Training Loss: 2.371589795206741e-13, Validation Loss: 1.8752995033580189e-13
Epoch 340, Training Loss: 1.9211443145952106e-13, Validation Loss: 1.5666802707578475e-13
Epoch 341, Training Loss: 1.6312339391581776e-13, Validation Loss: 1.3491439139912825e-13
Epoch 342, Training Loss: 1.41538893778069e-13, Validation Loss: 1.1029839422447424e-13
Epoch 343, Training Loss: 1.306327550472386e-13, Validation Loss: 9.752148497381083e-14
Epoch 344, Training Loss: 1.1649829592761535e-13, Validation Loss: 9.724486434202831e-14
Epoch 345, Training Loss: 9.14187955479602e-14, Validation Loss: 9.19205304320686e-14
Epoch 346, Training Loss: 8.614023529847012e-14, Validation Loss: 8.568499913503419e-14
Epoch 347, Training Loss: 6.5604910826772e-14, Validation Loss: 6.814140858556542e-14
Epoch 348, Training Loss: 6.265994667575825e-14, Validation Loss: 5.5974258024839643e-14
Epoch 349, Training Loss: 5.821858701507074e-14, Validation Loss: 5.839512901006927e-14
Epoch 350, Training Loss: 5.289172217066464e-14, Validation Loss: 5.260075280075563e-14
Epoch 351, Training Loss: 5.881413249215345e-14, Validation Loss: 4.5137105045365417e-14
Epoch 352, Training Loss: 4.477548296326003e-14, Validation Loss: 3.638082063796115e-14
Epoch 353, Training Loss: 4.4755066081099415e-14, Validation Loss: 3.288061622562684e-14
Epoch 354, Training Loss: 3.443312936212209e-14, Validation Loss: 3.54754982714086e-14
Epoch 355, Training Loss: 3.700405392802371e-14, Validation Loss: 2.780902000646887e-14
Epoch 356, Training Loss: 3.378794436619849e-14, Validation Loss: 2.7483559454947667e-14
Epoch 357, Training Loss: 2.410932070033133e-14, Validation Loss: 2.4185782364479977e-14
Epoch 358, Training Loss: 2.557476223798063e-14, Validation Loss: 2.1191715713513894e-14
Epoch 359, Training Loss: 2.1441983456241438e-14, Validation Loss: 2.1853246751253608e-14
Epoch 360, Training Loss: 2.042236585191818e-14, Validation Loss: 2.0447053474198854e-14
Epoch 361, Training Loss: 1.988220108299285e-14, Validation Loss: 2.2148949341271873e-14
Epoch 362, Training Loss: 1.730440030362542e-14, Validation Loss: 1.5742883206900857e-14
Epoch 363, Training Loss: 1.4400273305064694e-14, Validation Loss: 1.7480676330278513e-14
Epoch 364, Training Loss: 1.768503996946256e-14, Validation Loss: 1.6138799958974673e-14
Epoch 365, Training Loss: 1.2069339431141583e-14, Validation Loss: 1.5797259333982794e-14
Epoch 366, Training Loss: 1.2231735975920966e-14, Validation Loss: 1.6755494154684428e-14
Epoch 367, Training Loss: 1.2191970320146218e-14, Validation Loss: 1.6136531604741926e-14
Epoch 368, Training Loss: 1.2567871683676415e-14, Validation Loss: 1.4936770421328412e-14
Epoch 369, Training Loss: 1.1943904863081535e-14, Validation Loss: 1.1092489367358141e-14
Epoch 370, Training Loss: 1.1378651825291481e-14, Validation Loss: 1.0130185400377897e-14
Epoch 371, Training Loss: 1.2369112861504352e-14, Validation Loss: 9.257218845377512e-15
Epoch 372, Training Loss: 1.3026039428142792e-14, Validation Loss: 8.241004619436321e-15
Epoch 373, Training Loss: 1.1040714478457222e-14, Validation Loss: 1.2167684191482543e-14
Epoch 374, Training Loss: 1.1737072969889191e-14, Validation Loss: 6.796780410082796e-15
Epoch 375, Training Loss: 1.0304591178283452e-14, Validation Loss: 1.1188966420050406e-14
Epoch 376, Training Loss: 9.172884857017085e-15, Validation Loss: 6.442229359021091e-15
Epoch 377, Training Loss: 7.336346326714416e-15, Validation Loss: 6.188159285393322e-15
Epoch 378, Training Loss: 7.118037984119724e-15, Validation Loss: 8.749344666467412e-15
Epoch 379, Training Loss: 6.7605511168628354e-15, Validation Loss: 7.246874236495945e-15
Epoch 380, Training Loss: 7.216650406872017e-15, Validation Loss: 6.624108508620271e-15
Epoch 381, Training Loss: 7.32113361498173e-15, Validation Loss: 6.010950675465303e-15
Epoch 382, Training Loss: 5.9418285518046156e-15, Validation Loss: 5.3281366643764035e-15
Epoch 383, Training Loss: 5.638652166576252e-15, Validation Loss: 6.2725601893565824e-15
Epoch 384, Training Loss: 3.2646828779437547e-15, Validation Loss: 5.85249029279181e-15
Epoch 385, Training Loss: 3.1812827434076754e-15, Validation Loss: 8.372709772404893e-15
Epoch 386, Training Loss: 5.044375968365003e-15, Validation Loss: 5.258214094580561e-15
Epoch 387, Training Loss: 3.721982625397432e-15, Validation Loss: 5.508748229170017e-15
Epoch 388, Training Loss: 3.233457855376172e-15, Validation Loss: 5.4152730612428215e-15
Epoch 389, Training Loss: 2.1517910642600366e-15, Validation Loss: 5.455171701190288e-15
Epoch 390, Training Loss: 2.731455732372912e-15, Validation Loss: 7.400797910703943e-15
Epoch 391, Training Loss: 3.1943598733220977e-15, Validation Loss: 5.183487577424366e-15
Epoch 392, Training Loss: 2.412400020482372e-15, Validation Loss: 4.917140608259093e-15
Epoch 393, Training Loss: 1.6828819891104101e-15, Validation Loss: 5.7825008073931344e-15
Epoch 394, Training Loss: 3.160332654006761e-15, Validation Loss: 6.990602300721788e-15
Epoch 395, Training Loss: 2.366229525076961e-15, Validation Loss: 6.097219710593732e-15
Epoch 396, Training Loss: 2.5647886592317093e-15, Validation Loss: 4.613096861292741e-15
Epoch 397, Training Loss: 2.184483994925211e-15, Validation Loss: 9.257151929774679e-15
Epoch 398, Training Loss: 2.4300140706205254e-15, Validation Loss: 5.732727457346577e-15
Epoch 399, Training Loss: 3.4731834260421897e-15, Validation Loss: 9.487069705944439e-15
Epoch 400, Training Loss: 3.099884147725958e-15, Validation Loss: 6.4670495419580105e-15
Epoch 401, Training Loss: 2.4526988834974164e-15, Validation Loss: 6.73806662727797e-15
Epoch 402, Training Loss: 2.599349721062053e-15, Validation Loss: 7.483464091191227e-15
Epoch 403, Training Loss: 2.4167368291723142e-15, Validation Loss: 7.526298547333877e-15
Epoch 404, Training Loss: 3.60915910737258e-15, Validation Loss: 6.5650614183507e-15
Epoch 405, Training Loss: 3.100217878707176e-15, Validation Loss: 6.226523101640364e-15
Epoch 406, Training Loss: 3.024957519035974e-15, Validation Loss: 9.797985854728339e-15
Epoch 407, Training Loss: 3.905663414075422e-15, Validation Loss: 8.42355038396499e-15
Epoch 408, Training Loss: 3.1223688490690602e-15, Validation Loss: 7.875444681159152e-15
Epoch 409, Training Loss: 2.663067562761021e-15, Validation Loss: 8.731997431707644e-15
Epoch 410, Training Loss: 1.6503892758581431e-15, Validation Loss: 7.119438976614482e-15
Epoch 411, Training Loss: 1.8660288293942742e-15, Validation Loss: 7.246340605739175e-15
Epoch 412, Training Loss: 1.4531645362326757e-15, Validation Loss: 6.583542830226842e-15
Epoch 413, Training Loss: 1.5467061962462308e-15, Validation Loss: 6.537839473491841e-15
Epoch 414, Training Loss: 2.193624539217269e-15, Validation Loss: 6.5661286798642405e-15
Epoch 415, Training Loss: 2.138380415122633e-15, Validation Loss: 6.348487799231984e-15
Epoch 416, Training Loss: 2.1820153174004382e-15, Validation Loss: 6.3199313539647264e-15
Epoch 417, Training Loss: 2.1219672459454495e-15, Validation Loss: 6.49767401816599e-15
Epoch 418, Training Loss: 1.873367946365759e-15, Validation Loss: 6.203838288763473e-15
Epoch 419, Training Loss: 1.4260762108212464e-15, Validation Loss: 6.859363862907154e-15
Epoch 420, Training Loss: 1.1358435478181126e-15, Validation Loss: 6.801450526237483e-15
Epoch 421, Training Loss: 1.043102651577068e-15, Validation Loss: 6.0643933722393656e-15
Epoch 422, Training Loss: 1.0525768209712258e-15, Validation Loss: 5.955105793252827e-15
Epoch 423, Training Loss: 1.1996280933616768e-15, Validation Loss: 6.919345230517546e-15
Epoch 424, Training Loss: 1.0258888245064926e-15, Validation Loss: 7.294379232309755e-15
Epoch 425, Training Loss: 1.1938900804187393e-15, Validation Loss: 6.048780860955574e-15
Epoch 426, Training Loss: 1.0209515753360657e-15, Validation Loss: 7.102625372611485e-15
Epoch 427, Training Loss: 1.57059199596321e-15, Validation Loss: 6.6046263273169484e-15
Epoch 428, Training Loss: 1.2063000660080805e-15, Validation Loss: 6.118570023062224e-15
Epoch 429, Training Loss: 1.0328277184103998e-15, Validation Loss: 5.97979214498408e-15
Epoch 430, Training Loss: 1.876437170250135e-15, Validation Loss: 5.491400994410249e-15
Epoch 431, Training Loss: 1.1932229360936582e-15, Validation Loss: 9.323805799427067e-15
Epoch 432, Training Loss: 1.5729939696433864e-15, Validation Loss: 6.6744824050264315e-15
Epoch 433, Training Loss: 1.4614378246658637e-15, Validation Loss: 9.393861353395629e-15
Epoch 434, Training Loss: 1.5548460769902262e-15, Validation Loss: 9.589952021783841e-15
Epoch 435, Training Loss: 1.829733044087954e-15, Validation Loss: 7.67468347309978e-15
Epoch 436, Training Loss: 2.339741746025135e-15, Validation Loss: 7.884651929295806e-15
Epoch 437, Training Loss: 2.547641747763967e-15, Validation Loss: 8.005949588441464e-15
Epoch 438, Training Loss: 2.5052077264471314e-15, Validation Loss: 7.250810398601835e-15
Epoch 439, Training Loss: 2.8370735411154717e-15, Validation Loss: 4.6456563842687225e-15
Epoch 440, Training Loss: 2.737794079917216e-15, Validation Loss: 5.35342356246726e-15
Epoch 441, Training Loss: 1.8997892333312257e-15, Validation Loss: 9.86570613886132e-15
Epoch 442, Training Loss: 2.0161491139108643e-15, Validation Loss: 6.9560412388914444e-15
Epoch 443, Training Loss: 1.4783847304789357e-15, Validation Loss: 1.0010756295913883e-14
Epoch 444, Training Loss: 1.6644004713551501e-15, Validation Loss: 9.707245756187827e-15
Epoch 445, Training Loss: 1.5380325788663467e-15, Validation Loss: 9.693568715188512e-15
Epoch 446, Training Loss: 1.5005359125990565e-15, Validation Loss: 7.504614503884167e-15
Epoch 447, Training Loss: 1.5352303821185927e-15, Validation Loss: 6.192963232753675e-15
Epoch 448, Training Loss: 1.4946644919669265e-15, Validation Loss: 4.852888924045118e-15
Epoch 449, Training Loss: 1.5106773321974139e-15, Validation Loss: 5.629511410525957e-15
Epoch 450, Training Loss: 1.9667761986901216e-15, Validation Loss: 5.629511410525957e-15
Epoch 451, Training Loss: 7.359230827608623e-16, Validation Loss: 5.0070124980286686e-15
Epoch 452, Training Loss: 5.384314748174506e-16, Validation Loss: 5.724921201704682e-15
Epoch 453, Training Loss: 1.3881791097281417e-15, Validation Loss: 4.858093094473048e-15
Epoch 454, Training Loss: 1.0716587792069707e-15, Validation Loss: 5.184354939162354e-15
Epoch 455, Training Loss: 1.395518332578745e-15, Validation Loss: 5.109627998489685e-15
Epoch 456, Training Loss: 1.319457420893269e-15, Validation Loss: 5.145990699398839e-15
Epoch 457, Training Loss: 9.83454803189657e-16, Validation Loss: 5.1107625991225324e-15
Epoch 458, Training Loss: 1.6119584381291499e-15, Validation Loss: 6.964647940668495e-15
Epoch 459, Training Loss: 1.1106233535718526e-15, Validation Loss: 7.105160542222617e-15
Epoch 460, Training Loss: 9.021897210762506e-16, Validation Loss: 6.533035526131489e-15
Epoch 461, Training Loss: 1.5409682891824117e-15, Validation Loss: 5.689559693739183e-15
Epoch 462, Training Loss: 1.4982673466080727e-15, Validation Loss: 5.567128280993625e-15
Epoch 463, Training Loss: 2.190822342469515e-15, Validation Loss: 6.071131942851247e-15
Epoch 464, Training Loss: 2.5004037790867786e-15, Validation Loss: 6.3973933640240795e-15
Epoch 465, Training Loss: 2.542304169646844e-15, Validation Loss: 7.78330443715683e-15
Epoch 466, Training Loss: 6.3797796315232815e-16, Validation Loss: 7.786106422146347e-15
Epoch 467, Training Loss: 7.447301607694981e-16, Validation Loss: 4.3515538394878206e-15
Epoch 468, Training Loss: 7.447301607694981e-16, Validation Loss: 4.340878683253575e-15
Epoch 469, Training Loss: 8.016424103746329e-16, Validation Loss: 5.266220249998009e-15
Epoch 470, Training Loss: 7.816263865563034e-16, Validation Loss: 5.266220249998009e-15
Epoch 471, Training Loss: 8.728995335184338e-16, Validation Loss: 5.323866347772821e-15
Epoch 472, Training Loss: 8.724992045717377e-16, Validation Loss: 7.296780570715221e-15
Epoch 473, Training Loss: 8.071135020600668e-16, Validation Loss: 1.066995121678507e-14
Epoch 474, Training Loss: 1.4386863079443764e-15, Validation Loss: 9.696103884799644e-15
Epoch 475, Training Loss: 9.097290554606428e-16, Validation Loss: 4.855224193880698e-15
Epoch 476, Training Loss: 2.0106112125017157e-15, Validation Loss: 5.828070756438942e-15
Epoch 477, Training Loss: 1.6967597769182246e-15, Validation Loss: 7.637187018590726e-15
Epoch 478, Training Loss: 1.6967597769182246e-15, Validation Loss: 7.604160356944334e-15
Epoch 479, Training Loss: 3.591077918564016e-15, Validation Loss: 6.710778190332752e-15
Epoch 480, Training Loss: 1.391315037457114e-15, Validation Loss: 7.626578777959313e-15
Epoch 481, Training Loss: 1.303511284507378e-15, Validation Loss: 5.691360909301519e-15
Epoch 482, Training Loss: 1.6924229682282826e-15, Validation Loss: 7.85175909885508e-15
Epoch 483, Training Loss: 2.3350045025093786e-15, Validation Loss: 4.559120533761908e-15
Epoch 484, Training Loss: 2.3568888692511144e-15, Validation Loss: 5.987598400625975e-15
Epoch 485, Training Loss: 1.8866451878139703e-15, Validation Loss: 5.3505546618749095e-15
Epoch 486, Training Loss: 1.2351231148954867e-15, Validation Loss: 7.045846636574661e-15
Epoch 487, Training Loss: 1.113292142630414e-15, Validation Loss: 5.844483713857889e-15
Epoch 488, Training Loss: 1.113292142630414e-15, Validation Loss: 4.297644004043347e-15
Epoch 489, Training Loss: 9.418214397662137e-16, Validation Loss: 4.304849713325639e-15
Epoch 490, Training Loss: 1.8267972278927704e-15, Validation Loss: 4.627642111062992e-15
Epoch 491, Training Loss: 1.954366318979899e-15, Validation Loss: 5.297979326838835e-15
Epoch 492, Training Loss: 1.8919162738447338e-15, Validation Loss: 4.974319567363494e-15
Epoch 493, Training Loss: 1.960771370368799e-15, Validation Loss: 4.856759017581123e-15
Epoch 494, Training Loss: 2.1824157522262527e-15, Validation Loss: 4.906799183006065e-15
Epoch 495, Training Loss: 9.061929046640929e-16, Validation Loss: 7.240535888951641e-15
Epoch 496, Training Loss: 1.3214590656267493e-15, Validation Loss: 7.71218077464178e-15
Epoch 497, Training Loss: 1.208568526119946e-15, Validation Loss: 5.207773706088041e-15
Epoch 498, Training Loss: 1.4871918614271307e-15, Validation Loss: 5.341747636805833e-15
Epoch 499, Training Loss: 1.359089139583232e-15, Validation Loss: 4.846817391879199e-15
Epoch 500, Training Loss: 1.5537784978393305e-15, Validation Loss: 5.251808831433424e-15
