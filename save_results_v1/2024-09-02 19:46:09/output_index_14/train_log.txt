Epoch 1, Training Loss: 0.5226267576217651, Validation Loss: 0.5213466882705688
Epoch 2, Training Loss: 0.5213466882705688, Validation Loss: 0.520102858543396
Epoch 3, Training Loss: 0.5201027989387512, Validation Loss: 0.5188887715339661
Epoch 4, Training Loss: 0.5188887715339661, Validation Loss: 0.5177274942398071
Epoch 5, Training Loss: 0.5177274942398071, Validation Loss: 0.5165635943412781
Epoch 6, Training Loss: 0.5165635943412781, Validation Loss: 0.5154241323471069
Epoch 7, Training Loss: 0.5154242515563965, Validation Loss: 0.514348566532135
Epoch 8, Training Loss: 0.5143486261367798, Validation Loss: 0.5132761001586914
Epoch 9, Training Loss: 0.5132761597633362, Validation Loss: 0.5121853947639465
Epoch 10, Training Loss: 0.5121853947639465, Validation Loss: 0.5110796689987183
Epoch 11, Training Loss: 0.5110796689987183, Validation Loss: 0.5099632740020752
Epoch 12, Training Loss: 0.5099632740020752, Validation Loss: 0.5088490843772888
Epoch 13, Training Loss: 0.5088490843772888, Validation Loss: 0.507743239402771
Epoch 14, Training Loss: 0.5077432990074158, Validation Loss: 0.506618320941925
Epoch 15, Training Loss: 0.506618320941925, Validation Loss: 0.5054918527603149
Epoch 16, Training Loss: 0.5054917931556702, Validation Loss: 0.5043531656265259
Epoch 17, Training Loss: 0.5043531656265259, Validation Loss: 0.503227174282074
Epoch 18, Training Loss: 0.503227174282074, Validation Loss: 0.5021130442619324
Epoch 19, Training Loss: 0.5021130442619324, Validation Loss: 0.5009828805923462
Epoch 20, Training Loss: 0.5009828805923462, Validation Loss: 0.4998270273208618
Epoch 21, Training Loss: 0.4998270869255066, Validation Loss: 0.4986281096935272
Epoch 22, Training Loss: 0.4986281096935272, Validation Loss: 0.49736568331718445
Epoch 23, Training Loss: 0.49736568331718445, Validation Loss: 0.496057391166687
Epoch 24, Training Loss: 0.496057391166687, Validation Loss: 0.494730681180954
Epoch 25, Training Loss: 0.494730681180954, Validation Loss: 0.4933435916900635
Epoch 26, Training Loss: 0.4933435916900635, Validation Loss: 0.4919046461582184
Epoch 27, Training Loss: 0.4919046461582184, Validation Loss: 0.4904181659221649
Epoch 28, Training Loss: 0.49041813611984253, Validation Loss: 0.4889068007469177
Epoch 29, Training Loss: 0.4889068007469177, Validation Loss: 0.48732826113700867
Epoch 30, Training Loss: 0.48732826113700867, Validation Loss: 0.48569005727767944
Epoch 31, Training Loss: 0.48569005727767944, Validation Loss: 0.4839550256729126
Epoch 32, Training Loss: 0.4839550256729126, Validation Loss: 0.4821024239063263
Epoch 33, Training Loss: 0.4821024239063263, Validation Loss: 0.48012858629226685
Epoch 34, Training Loss: 0.4801286458969116, Validation Loss: 0.47807812690734863
Epoch 35, Training Loss: 0.47807812690734863, Validation Loss: 0.4759587049484253
Epoch 36, Training Loss: 0.4759587049484253, Validation Loss: 0.473749041557312
Epoch 37, Training Loss: 0.473749041557312, Validation Loss: 0.4714578688144684
Epoch 38, Training Loss: 0.4714578688144684, Validation Loss: 0.4689636528491974
Epoch 39, Training Loss: 0.4689636528491974, Validation Loss: 0.46627533435821533
Epoch 40, Training Loss: 0.46627533435821533, Validation Loss: 0.4634062945842743
Epoch 41, Training Loss: 0.4634062945842743, Validation Loss: 0.4603252708911896
Epoch 42, Training Loss: 0.4603252708911896, Validation Loss: 0.45707717537879944
Epoch 43, Training Loss: 0.4570772349834442, Validation Loss: 0.4535907506942749
Epoch 44, Training Loss: 0.4535906910896301, Validation Loss: 0.4498872458934784
Epoch 45, Training Loss: 0.4498872458934784, Validation Loss: 0.4458874464035034
Epoch 46, Training Loss: 0.44588735699653625, Validation Loss: 0.44159838557243347
Epoch 47, Training Loss: 0.44159844517707825, Validation Loss: 0.43695613741874695
Epoch 48, Training Loss: 0.43695613741874695, Validation Loss: 0.43193861842155457
Epoch 49, Training Loss: 0.43193861842155457, Validation Loss: 0.4265301525592804
Epoch 50, Training Loss: 0.4265301823616028, Validation Loss: 0.4206569790840149
Epoch 51, Training Loss: 0.4206569492816925, Validation Loss: 0.4143259525299072
Epoch 52, Training Loss: 0.4143259823322296, Validation Loss: 0.40748682618141174
Epoch 53, Training Loss: 0.40748685598373413, Validation Loss: 0.40016037225723267
Epoch 54, Training Loss: 0.40016037225723267, Validation Loss: 0.3923425078392029
Epoch 55, Training Loss: 0.39234253764152527, Validation Loss: 0.3839648365974426
Epoch 56, Training Loss: 0.3839648365974426, Validation Loss: 0.37499314546585083
Epoch 57, Training Loss: 0.37499314546585083, Validation Loss: 0.3654787540435791
Epoch 58, Training Loss: 0.3654787838459015, Validation Loss: 0.3553326725959778
Epoch 59, Training Loss: 0.3553326725959778, Validation Loss: 0.3445664346218109
Epoch 60, Training Loss: 0.3445664346218109, Validation Loss: 0.3331422209739685
Epoch 61, Training Loss: 0.3331421911716461, Validation Loss: 0.32109758257865906
Epoch 62, Training Loss: 0.32109758257865906, Validation Loss: 0.3084673583507538
Epoch 63, Training Loss: 0.3084673583507538, Validation Loss: 0.2953425347805023
Epoch 64, Training Loss: 0.2953425347805023, Validation Loss: 0.2817545533180237
Epoch 65, Training Loss: 0.2817545533180237, Validation Loss: 0.26781874895095825
Epoch 66, Training Loss: 0.26781877875328064, Validation Loss: 0.253429114818573
Epoch 67, Training Loss: 0.2534290850162506, Validation Loss: 0.23866389691829681
Epoch 68, Training Loss: 0.23866389691829681, Validation Loss: 0.22391045093536377
Epoch 69, Training Loss: 0.22391045093536377, Validation Loss: 0.20916235446929932
Epoch 70, Training Loss: 0.20916235446929932, Validation Loss: 0.1946675330400467
Epoch 71, Training Loss: 0.19466754794120789, Validation Loss: 0.18062858283519745
Epoch 72, Training Loss: 0.18062856793403625, Validation Loss: 0.16724149882793427
Epoch 73, Training Loss: 0.16724149882793427, Validation Loss: 0.1545843780040741
Epoch 74, Training Loss: 0.1545843929052353, Validation Loss: 0.1428592950105667
Epoch 75, Training Loss: 0.1428592950105667, Validation Loss: 0.13193181157112122
Epoch 76, Training Loss: 0.1319318264722824, Validation Loss: 0.12180985510349274
Epoch 77, Training Loss: 0.12180984765291214, Validation Loss: 0.11258450150489807
Epoch 78, Training Loss: 0.11258449405431747, Validation Loss: 0.10389997810125351
Epoch 79, Training Loss: 0.10389996320009232, Validation Loss: 0.09558023512363434
Epoch 80, Training Loss: 0.09558023512363434, Validation Loss: 0.08746271580457687
Epoch 81, Training Loss: 0.08746271580457687, Validation Loss: 0.07963206619024277
Epoch 82, Training Loss: 0.07963206619024277, Validation Loss: 0.07187770307064056
Epoch 83, Training Loss: 0.07187769562005997, Validation Loss: 0.06410056352615356
Epoch 84, Training Loss: 0.06410056352615356, Validation Loss: 0.05659553408622742
Epoch 85, Training Loss: 0.056595537811517715, Validation Loss: 0.04937981069087982
Epoch 86, Training Loss: 0.04937981441617012, Validation Loss: 0.04260841757059097
Epoch 87, Training Loss: 0.04260843247175217, Validation Loss: 0.03642535209655762
Epoch 88, Training Loss: 0.03642534837126732, Validation Loss: 0.030969299376010895
Epoch 89, Training Loss: 0.030969304963946342, Validation Loss: 0.026246773079037666
Epoch 90, Training Loss: 0.026246778666973114, Validation Loss: 0.022188203409314156
Epoch 91, Training Loss: 0.022188201546669006, Validation Loss: 0.018795469775795937
Epoch 92, Training Loss: 0.018795469775795937, Validation Loss: 0.016003258526325226
Epoch 93, Training Loss: 0.016003258526325226, Validation Loss: 0.013737985864281654
Epoch 94, Training Loss: 0.013737985864281654, Validation Loss: 0.011943972669541836
Epoch 95, Training Loss: 0.011943970806896687, Validation Loss: 0.010527236387133598
Epoch 96, Training Loss: 0.010527231730520725, Validation Loss: 0.009374774061143398
Epoch 97, Training Loss: 0.009374774992465973, Validation Loss: 0.008408675901591778
Epoch 98, Training Loss: 0.008408674038946629, Validation Loss: 0.007573356851935387
Epoch 99, Training Loss: 0.007573364302515984, Validation Loss: 0.006825530901551247
Epoch 100, Training Loss: 0.0068255322985351086, Validation Loss: 0.006127193570137024
Epoch 101, Training Loss: 0.006127191707491875, Validation Loss: 0.005456046666949987
Epoch 102, Training Loss: 0.005456046666949987, Validation Loss: 0.00480858888477087
Epoch 103, Training Loss: 0.004808585625141859, Validation Loss: 0.00418464932590723
Epoch 104, Training Loss: 0.004184649791568518, Validation Loss: 0.0035868065897375345
Epoch 105, Training Loss: 0.003586803562939167, Validation Loss: 0.0030317003838717937
Epoch 106, Training Loss: 0.0030316999182105064, Validation Loss: 0.002531047211959958
Epoch 107, Training Loss: 0.0025310511700809, Validation Loss: 0.0020897099748253822
Epoch 108, Training Loss: 0.002089710207656026, Validation Loss: 0.001714294427074492
Epoch 109, Training Loss: 0.0017142950091511011, Validation Loss: 0.0014066736912354827
Epoch 110, Training Loss: 0.0014066732255741954, Validation Loss: 0.0011657070135697722
Epoch 111, Training Loss: 0.0011657060822471976, Validation Loss: 0.0009863335872069001
Epoch 112, Training Loss: 0.0009863345185294747, Validation Loss: 0.0008597030537202954
Epoch 113, Training Loss: 0.0008597015985287726, Validation Loss: 0.0007737010600976646
Epoch 114, Training Loss: 0.0007737019332125783, Validation Loss: 0.0007196883670985699
Epoch 115, Training Loss: 0.0007196899969130754, Validation Loss: 0.0006867420161142945
Epoch 116, Training Loss: 0.0006867412594147027, Validation Loss: 0.0006658604834228754
Epoch 117, Training Loss: 0.0006658606580458581, Validation Loss: 0.0006501015741378069
Epoch 118, Training Loss: 0.0006501025636680424, Validation Loss: 0.0006343027926050127
Epoch 119, Training Loss: 0.0006343022105284035, Validation Loss: 0.0006146207451820374
Epoch 120, Training Loss: 0.0006146204541437328, Validation Loss: 0.0005914721987210214
Epoch 121, Training Loss: 0.0005914731882512569, Validation Loss: 0.0005634691333398223
Epoch 122, Training Loss: 0.0005634702392853796, Validation Loss: 0.0005290855187922716
Epoch 123, Training Loss: 0.0005290853441692889, Validation Loss: 0.0004895403399132192
Epoch 124, Training Loss: 0.0004895381280221045, Validation Loss: 0.00044646396418102086
Epoch 125, Training Loss: 0.00044646431342698634, Validation Loss: 0.0004019835323560983
Epoch 126, Training Loss: 0.00040198356145992875, Validation Loss: 0.0003582137287594378
Epoch 127, Training Loss: 0.0003582148056011647, Validation Loss: 0.0003170047129970044
Epoch 128, Training Loss: 0.0003170044510625303, Validation Loss: 0.00027972061070613563
Epoch 129, Training Loss: 0.00027972093084827065, Validation Loss: 0.0002471648040227592
Epoch 130, Training Loss: 0.00024716489133425057, Validation Loss: 0.00021929427748546004
Epoch 131, Training Loss: 0.00021929443755652755, Validation Loss: 0.00019577880448196083
Epoch 132, Training Loss: 0.00019577897910494357, Validation Loss: 0.00017613402451388538
Epoch 133, Training Loss: 0.0001761338789947331, Validation Loss: 0.00015969107334967703
Epoch 134, Training Loss: 0.00015969084051903337, Validation Loss: 0.00014572011423297226
Epoch 135, Training Loss: 0.00014571954670827836, Validation Loss: 0.0001335235865553841
Epoch 136, Training Loss: 0.00013352367386687547, Validation Loss: 0.00012248626444488764
Epoch 137, Training Loss: 0.000122486351756379, Validation Loss: 0.00011216120765311643
Epoch 138, Training Loss: 0.00011216130951652303, Validation Loss: 0.00010226404992863536
Epoch 139, Training Loss: 0.00010226424637949094, Validation Loss: 9.265587868867442e-05
Epoch 140, Training Loss: 9.265564585803077e-05, Validation Loss: 8.326692477567121e-05
Epoch 141, Training Loss: 8.326675742864609e-05, Validation Loss: 7.411956175928935e-05
Epoch 142, Training Loss: 7.411932165268809e-05, Validation Loss: 6.529799429699779e-05
Epoch 143, Training Loss: 6.529770325869322e-05, Validation Loss: 5.691079786629416e-05
Epoch 144, Training Loss: 5.691119804396294e-05, Validation Loss: 4.907753100269474e-05
Epoch 145, Training Loss: 4.9077574658440426e-05, Validation Loss: 4.190971594653092e-05
Epoch 146, Training Loss: 4.190966865280643e-05, Validation Loss: 3.550266774254851e-05
Epoch 147, Training Loss: 3.550261681084521e-05, Validation Loss: 2.9927787181804888e-05
Epoch 148, Training Loss: 2.9927579817012884e-05, Validation Loss: 2.5223187549272552e-05
Epoch 149, Training Loss: 2.522325848985929e-05, Validation Loss: 2.139076968887821e-05
Epoch 150, Training Loss: 2.1390858819358982e-05, Validation Loss: 1.8390233890386298e-05
Epoch 151, Training Loss: 1.839019387261942e-05, Validation Loss: 1.6140493244165555e-05
Epoch 152, Training Loss: 1.6140416846610606e-05, Validation Loss: 1.452623382647289e-05
Epoch 153, Training Loss: 1.4526212908094749e-05, Validation Loss: 1.340635117230704e-05
Epoch 154, Training Loss: 1.340626386081567e-05, Validation Loss: 1.2629885532078333e-05
Epoch 155, Training Loss: 1.262995556317037e-05, Validation Loss: 1.2050636541971471e-05
Epoch 156, Training Loss: 1.2050716577505227e-05, Validation Loss: 1.1542756510607433e-05
Epoch 157, Training Loss: 1.1542819265741855e-05, Validation Loss: 1.1011752576450817e-05
Epoch 158, Training Loss: 1.1011684364348184e-05, Validation Loss: 1.0400917744846083e-05
Epoch 159, Training Loss: 1.0401057807030156e-05, Validation Loss: 9.693098036223091e-06
Epoch 160, Training Loss: 9.693091669760179e-06, Validation Loss: 8.903747584554367e-06
Epoch 161, Training Loss: 8.903542948246468e-06, Validation Loss: 8.07131982583087e-06
Epoch 162, Training Loss: 8.071328920777887e-06, Validation Loss: 7.246546829264844e-06
Epoch 163, Training Loss: 7.2466482379240915e-06, Validation Loss: 6.478601335402345e-06
Epoch 164, Training Loss: 6.478697741840733e-06, Validation Loss: 5.8063678807229735e-06
Epoch 165, Training Loss: 5.806452918477589e-06, Validation Loss: 5.251692982710665e-06
Epoch 166, Training Loss: 5.2517393669404555e-06, Validation Loss: 4.817443823412759e-06
Epoch 167, Training Loss: 4.817552962776972e-06, Validation Loss: 4.489504135563038e-06
Epoch 168, Training Loss: 4.489405910135247e-06, Validation Loss: 4.2409169509483036e-06
Epoch 169, Training Loss: 4.240933776600286e-06, Validation Loss: 4.039082796225557e-06
Epoch 170, Training Loss: 4.039067334815627e-06, Validation Loss: 3.851378551189555e-06
Epoch 171, Training Loss: 3.8513799154316075e-06, Validation Loss: 3.650883172667818e-06
Epoch 172, Training Loss: 3.650821554401773e-06, Validation Loss: 3.4197578315797728e-06
Epoch 173, Training Loss: 3.419754420974641e-06, Validation Loss: 3.150417569486308e-06
Epoch 174, Training Loss: 3.150409838781343e-06, Validation Loss: 2.845161816367181e-06
Epoch 175, Training Loss: 2.8451308935473207e-06, Validation Loss: 2.513936806280981e-06
Epoch 176, Training Loss: 2.5139290755760157e-06, Validation Loss: 2.171337428080733e-06
Epoch 177, Training Loss: 2.1713203750550747e-06, Validation Loss: 1.8338043901167111e-06
Epoch 178, Training Loss: 1.8337907476961846e-06, Validation Loss: 1.51665665271139e-06
Epoch 179, Training Loss: 1.5166315279202536e-06, Validation Loss: 1.232569047715515e-06
Epoch 180, Training Loss: 1.2325177749517024e-06, Validation Loss: 9.89851173471834e-07
Epoch 181, Training Loss: 9.898913049255498e-07, Validation Loss: 7.927980050226324e-07
Epoch 182, Training Loss: 7.927967544674175e-07, Validation Loss: 6.412925017684756e-07
Epoch 183, Training Loss: 6.41302563053614e-07, Validation Loss: 5.319940896697517e-07
Epoch 184, Training Loss: 5.320099489836139e-07, Validation Loss: 4.590856690356304e-07
Epoch 185, Training Loss: 4.5907384560450737e-07, Validation Loss: 4.150978156758356e-07
Epoch 186, Training Loss: 4.1511262338644883e-07, Validation Loss: 3.921755364899582e-07
Epoch 187, Training Loss: 3.9214810954035784e-07, Validation Loss: 3.8247620182119135e-07
Epoch 188, Training Loss: 3.824574434929673e-07, Validation Loss: 3.7905070371380134e-07
Epoch 189, Training Loss: 3.790415803450742e-07, Validation Loss: 3.7624846527251066e-07
Epoch 190, Training Loss: 3.762488063330238e-07, Validation Loss: 3.6998667951593234e-07
Epoch 191, Training Loss: 3.700056936395413e-07, Validation Loss: 3.5788383456747397e-07
Epoch 192, Training Loss: 3.578703058337851e-07, Validation Loss: 3.3907272722899506e-07
Epoch 193, Training Loss: 3.3906664498317696e-07, Validation Loss: 3.141144020446518e-07
Epoch 194, Training Loss: 3.141399247397203e-07, Validation Loss: 2.84610194967172e-07
Epoch 195, Training Loss: 2.846048516857991e-07, Validation Loss: 2.526543880776444e-07
Epoch 196, Training Loss: 2.5263602765335236e-07, Validation Loss: 2.2057560045141145e-07
Epoch 197, Training Loss: 2.205687223977293e-07, Validation Loss: 1.9045556598484836e-07
Epoch 198, Training Loss: 1.9047675436922873e-07, Validation Loss: 1.6400694846652186e-07
Epoch 199, Training Loss: 1.640082984977198e-07, Validation Loss: 1.4210687027116364e-07
Epoch 200, Training Loss: 1.4209631160611025e-07, Validation Loss: 1.250670749186611e-07
Epoch 201, Training Loss: 1.2506458801908593e-07, Validation Loss: 1.1258054399831963e-07
Epoch 202, Training Loss: 1.1257248644369611e-07, Validation Loss: 1.0387404358880303e-07
Epoch 203, Training Loss: 1.038664905195219e-07, Validation Loss: 9.79239516141206e-08
Epoch 204, Training Loss: 9.791615696030931e-08, Validation Loss: 9.365184183707242e-08
Epoch 205, Training Loss: 9.367052200559556e-08, Validation Loss: 9.008881107774869e-08
Epoch 206, Training Loss: 9.007284518247616e-08, Validation Loss: 8.637503157160609e-08
Epoch 207, Training Loss: 8.637674397959927e-08, Validation Loss: 8.205777390912772e-08
Epoch 208, Training Loss: 8.20556991243393e-08, Validation Loss: 7.684544556241235e-08
Epoch 209, Training Loss: 7.685645186938928e-08, Validation Loss: 7.069072438525836e-08
Epoch 210, Training Loss: 7.070214991244939e-08, Validation Loss: 6.379895722830042e-08
Epoch 211, Training Loss: 6.38028652133471e-08, Validation Loss: 5.644275802296761e-08
Epoch 212, Training Loss: 5.644196576781724e-08, Validation Loss: 4.896623906347486e-08
Epoch 213, Training Loss: 4.89679585768954e-08, Validation Loss: 4.173134371399101e-08
Epoch 214, Training Loss: 4.171759115934037e-08, Validation Loss: 3.5033352219215885e-08
Epoch 215, Training Loss: 3.503537371329912e-08, Validation Loss: 2.913946772764575e-08
Epoch 216, Training Loss: 2.913758123668231e-08, Validation Loss: 2.4174864776682625e-08
Epoch 217, Training Loss: 2.4179632518439576e-08, Validation Loss: 2.0190993765822896e-08
Epoch 218, Training Loss: 2.019346645454334e-08, Validation Loss: 1.712619202010046e-08
Epoch 219, Training Loss: 1.712500719008858e-08, Validation Loss: 1.486338785383623e-08
Epoch 220, Training Loss: 1.4865102038186251e-08, Validation Loss: 1.3224610739825948e-08
Epoch 221, Training Loss: 1.3223992567645837e-08, Validation Loss: 1.2014957917472202e-08
Epoch 222, Training Loss: 1.2009324201756044e-08, Validation Loss: 1.1052937232136628e-08
Epoch 223, Training Loss: 1.1050341086615845e-08, Validation Loss: 1.0193848432038521e-08
Epoch 224, Training Loss: 1.0194836974619648e-08, Validation Loss: 9.358567254480477e-09
Epoch 225, Training Loss: 9.360237918087932e-09, Validation Loss: 8.494814629500524e-09
Epoch 226, Training Loss: 8.498819425994952e-09, Validation Loss: 7.61972529517152e-09
Epoch 227, Training Loss: 7.620341690994792e-09, Validation Loss: 6.766063709306991e-09
Epoch 228, Training Loss: 6.76757672124495e-09, Validation Loss: 5.989492013469544e-09
Epoch 229, Training Loss: 5.989449380905398e-09, Validation Loss: 5.337331021593172e-09
Epoch 230, Training Loss: 5.332025487803094e-09, Validation Loss: 4.832367395124493e-09
Epoch 231, Training Loss: 4.829781019566326e-09, Validation Loss: 4.480792181738025e-09
Epoch 232, Training Loss: 4.480472437506933e-09, Validation Loss: 4.269602893458568e-09
Epoch 233, Training Loss: 4.269789410926705e-09, Validation Loss: 4.155353838797282e-09
Epoch 234, Training Loss: 4.158236865947629e-09, Validation Loss: 4.10053635491181e-09
Epoch 235, Training Loss: 4.100560779818352e-09, Validation Loss: 4.057273628177427e-09
Epoch 236, Training Loss: 4.0536733969531724e-09, Validation Loss: 3.9819938457696935e-09
Epoch 237, Training Loss: 3.980855201035638e-09, Validation Loss: 3.855708197164631e-09
Epoch 238, Training Loss: 3.85473342134901e-09, Validation Loss: 3.666974501825848e-09
Epoch 239, Training Loss: 3.6672467285114863e-09, Validation Loss: 3.417921057291551e-09
Epoch 240, Training Loss: 3.4147107363935447e-09, Validation Loss: 3.1176277115463336e-09
Epoch 241, Training Loss: 3.11685344200896e-09, Validation Loss: 2.780528252088743e-09
Epoch 242, Training Loss: 2.78317324742261e-09, Validation Loss: 2.431139289882367e-09
Epoch 243, Training Loss: 2.431526979762566e-09, Validation Loss: 2.078719640863369e-09
Epoch 244, Training Loss: 2.0770365427580373e-09, Validation Loss: 1.7412534747407449e-09
Epoch 245, Training Loss: 1.742061495058067e-09, Validation Loss: 1.4304970541445527e-09
Epoch 246, Training Loss: 1.4307823814618814e-09, Validation Loss: 1.1572183211683296e-09
Epoch 247, Training Loss: 1.1569557534230057e-09, Validation Loss: 9.245323395745686e-10
Epoch 248, Training Loss: 9.245409993141607e-10, Validation Loss: 7.369695964598577e-10
Epoch 249, Training Loss: 7.361913301195955e-10, Validation Loss: 5.921769741235039e-10
Epoch 250, Training Loss: 5.940489211653244e-10, Validation Loss: 4.906359207801358e-10
Epoch 251, Training Loss: 4.914305073988601e-10, Validation Loss: 4.2324418969563737e-10
Epoch 252, Training Loss: 4.2327039095901853e-10, Validation Loss: 3.8094336018978936e-10
Epoch 253, Training Loss: 3.811556625876733e-10, Validation Loss: 3.577258489428914e-10
Epoch 254, Training Loss: 3.570437001609861e-10, Validation Loss: 3.428536343719202e-10
Epoch 255, Training Loss: 3.4269531656860863e-10, Validation Loss: 3.3090505335842124e-10
Epoch 256, Training Loss: 3.3122612985714284e-10, Validation Loss: 3.163815875950604e-10
Epoch 257, Training Loss: 3.1610031259177163e-10, Validation Loss: 2.980228841487076e-10
Epoch 258, Training Loss: 2.971565771225926e-10, Validation Loss: 2.7479940545305226e-10
Epoch 259, Training Loss: 2.756798400671556e-10, Validation Loss: 2.5015686744289667e-10
Epoch 260, Training Loss: 2.5033392025974877e-10, Validation Loss: 2.2560846246744148e-10
Epoch 261, Training Loss: 2.2633366014712664e-10, Validation Loss: 2.054223874337069e-10
Epoch 262, Training Loss: 2.046637165298293e-10, Validation Loss: 1.888584566511753e-10
Epoch 263, Training Loss: 1.8856274874856638e-10, Validation Loss: 1.7813407693356709e-10
Epoch 264, Training Loss: 1.7835173615754485e-10, Validation Loss: 1.7257953399685277e-10
Epoch 265, Training Loss: 1.7249969508359442e-10, Validation Loss: 1.7024454068703676e-10
Epoch 266, Training Loss: 1.7043502720248682e-10, Validation Loss: 1.703217011872482e-10
Epoch 267, Training Loss: 1.7015497344452513e-10, Validation Loss: 1.696766893655166e-10
Epoch 268, Training Loss: 1.6956966386594274e-10, Validation Loss: 1.6646074796344834e-10
Epoch 269, Training Loss: 1.6668494362548358e-10, Validation Loss: 1.6064302665874663e-10
Epoch 270, Training Loss: 1.6003869063307974e-10, Validation Loss: 1.4943318804583328e-10
Epoch 271, Training Loss: 1.494449286543187e-10, Validation Loss: 1.3503419216132073e-10
Epoch 272, Training Loss: 1.3472331583663788e-10, Validation Loss: 1.179683434271439e-10
Epoch 273, Training Loss: 1.1762003870874338e-10, Validation Loss: 9.930330169272139e-11
Epoch 274, Training Loss: 9.897552916138252e-11, Validation Loss: 7.978902261118748e-11
Epoch 275, Training Loss: 7.975885230049329e-11, Validation Loss: 6.15058767805543e-11
Epoch 276, Training Loss: 6.13336187393898e-11, Validation Loss: 4.5384397628911444e-11
Epoch 277, Training Loss: 4.523200217154688e-11, Validation Loss: 3.2578571784736e-11
Epoch 278, Training Loss: 3.2217360723674204e-11, Validation Loss: 2.2710043914853095e-11
Epoch 279, Training Loss: 2.2309242994622558e-11, Validation Loss: 1.6199822733264924e-11
Epoch 280, Training Loss: 1.6009459383181657e-11, Validation Loss: 1.2398860584073024e-11
Epoch 281, Training Loss: 1.2436714852404052e-11, Validation Loss: 1.1279194592206387e-11
Epoch 282, Training Loss: 1.1179529524341092e-11, Validation Loss: 1.1318157348838565e-11
Epoch 283, Training Loss: 1.1312159542420375e-11, Validation Loss: 1.2403465407540004e-11
Epoch 284, Training Loss: 1.2479353488081824e-11, Validation Loss: 1.3768640741429472e-11
Epoch 285, Training Loss: 1.367683917508078e-11, Validation Loss: 1.472189557760739e-11
Epoch 286, Training Loss: 1.4874454098978696e-11, Validation Loss: 1.5472477465916512e-11
Epoch 287, Training Loss: 1.5390227287026548e-11, Validation Loss: 1.552421559358752e-11
Epoch 288, Training Loss: 1.5443141557214268e-11, Validation Loss: 1.4991391808494292e-11
Epoch 289, Training Loss: 1.5007819639811792e-11, Validation Loss: 1.4163320689875025e-11
Epoch 290, Training Loss: 1.4082953553318234e-11, Validation Loss: 1.2907909116566252e-11
Epoch 291, Training Loss: 1.2885568480280885e-11, Validation Loss: 1.1679752651150288e-11
Epoch 292, Training Loss: 1.1851699309450847e-11, Validation Loss: 1.0563603811131195e-11
Epoch 293, Training Loss: 1.0613328792208332e-11, Validation Loss: 9.606556002073052e-12
Epoch 294, Training Loss: 9.626660579797885e-12, Validation Loss: 8.575368713736875e-12
Epoch 295, Training Loss: 8.657327459082875e-12, Validation Loss: 8.077978390363949e-12
Epoch 296, Training Loss: 7.948171634741819e-12, Validation Loss: 7.375332115866495e-12
Epoch 297, Training Loss: 7.319385549042767e-12, Validation Loss: 6.833787875859532e-12
Epoch 298, Training Loss: 6.79049785151653e-12, Validation Loss: 6.268607594811515e-12
Epoch 299, Training Loss: 6.4067141349044565e-12, Validation Loss: 5.8434286055730755e-12
Epoch 300, Training Loss: 5.921725783342158e-12, Validation Loss: 5.46008984553259e-12
Epoch 301, Training Loss: 5.385574798622006e-12, Validation Loss: 4.9710201233121865e-12
Epoch 302, Training Loss: 4.929597962471943e-12, Validation Loss: 4.454129339664936e-12
Epoch 303, Training Loss: 4.448338399021257e-12, Validation Loss: 3.734366548630019e-12
Epoch 304, Training Loss: 3.770635279704004e-12, Validation Loss: 3.197978557314962e-12
Epoch 305, Training Loss: 3.174054118496028e-12, Validation Loss: 2.5574783176635085e-12
Epoch 306, Training Loss: 2.541397214200769e-12, Validation Loss: 2.0464335521303e-12
Epoch 307, Training Loss: 1.9989021288885356e-12, Validation Loss: 1.4482325928766304e-12
Epoch 308, Training Loss: 1.4355408138252979e-12, Validation Loss: 1.0169145256769263e-12
Epoch 309, Training Loss: 1.0394370910868367e-12, Validation Loss: 7.395466617571289e-13
Epoch 310, Training Loss: 7.371174525795665e-13, Validation Loss: 5.574002088885865e-13
Epoch 311, Training Loss: 5.374339211508539e-13, Validation Loss: 4.43550767946152e-13
Epoch 312, Training Loss: 4.3687598569146224e-13, Validation Loss: 3.9624054905262884e-13
Epoch 313, Training Loss: 3.743151893043778e-13, Validation Loss: 4.016801810873688e-13
Epoch 314, Training Loss: 4.085536162851122e-13, Validation Loss: 4.60606921527662e-13
Epoch 315, Training Loss: 4.674840159077376e-13, Validation Loss: 4.986981422434866e-13
Epoch 316, Training Loss: 4.972988709196768e-13, Validation Loss: 4.898430294199285e-13
Epoch 317, Training Loss: 5.186642131407848e-13, Validation Loss: 5.661653329318284e-13
Epoch 318, Training Loss: 5.172009738887984e-13, Validation Loss: 5.353842911538786e-13
Epoch 319, Training Loss: 5.400651171931503e-13, Validation Loss: 5.373044132013505e-13
Epoch 320, Training Loss: 5.315243145793958e-13, Validation Loss: 5.258573524541399e-13
Epoch 321, Training Loss: 4.879421519610183e-13, Validation Loss: 4.566959874510723e-13
Epoch 322, Training Loss: 4.798343796949545e-13, Validation Loss: 4.654912523147092e-13
Epoch 323, Training Loss: 4.33850221373544e-13, Validation Loss: 4.4601830367051176e-13
Epoch 324, Training Loss: 4.162735423290237e-13, Validation Loss: 4.2306083766416314e-13
Epoch 325, Training Loss: 4.0700616162937797e-13, Validation Loss: 3.780479618589738e-13
Epoch 326, Training Loss: 3.685260104892285e-13, Validation Loss: 3.5660244288721055e-13
Epoch 327, Training Loss: 3.601226576058908e-13, Validation Loss: 3.1848978207342504e-13
Epoch 328, Training Loss: 3.0345558422843755e-13, Validation Loss: 3.0085130350507305e-13
Epoch 329, Training Loss: 2.653488865266007e-13, Validation Loss: 2.278103649732549e-13
Epoch 330, Training Loss: 2.309592946579675e-13, Validation Loss: 1.9918843050664714e-13
Epoch 331, Training Loss: 2.0816565159988143e-13, Validation Loss: 1.7551648882115772e-13
Epoch 332, Training Loss: 1.6637266651159388e-13, Validation Loss: 1.5547154221581122e-13
Epoch 333, Training Loss: 1.4481697904657892e-13, Validation Loss: 1.2839139744858646e-13
Epoch 334, Training Loss: 1.3032427242411215e-13, Validation Loss: 1.2074209362368526e-13
Epoch 335, Training Loss: 1.1772896026107649e-13, Validation Loss: 9.81419061144885e-14
Epoch 336, Training Loss: 1.0318688855844374e-13, Validation Loss: 1.0684491214951047e-13
Epoch 337, Training Loss: 9.109925406267441e-14, Validation Loss: 9.587594390278453e-14
Epoch 338, Training Loss: 9.110264897072701e-14, Validation Loss: 8.691840785524443e-14
Epoch 339, Training Loss: 7.696998556095194e-14, Validation Loss: 7.826732155175736e-14
Epoch 340, Training Loss: 7.655751439695699e-14, Validation Loss: 6.849208700199227e-14
Epoch 341, Training Loss: 6.58181124077277e-14, Validation Loss: 6.299805512324785e-14
Epoch 342, Training Loss: 6.102227284674605e-14, Validation Loss: 4.36336012351983e-14
Epoch 343, Training Loss: 5.0632210961886956e-14, Validation Loss: 4.014170452201066e-14
Epoch 344, Training Loss: 4.5310479137141216e-14, Validation Loss: 3.840704542053784e-14
Epoch 345, Training Loss: 3.7887062058613794e-14, Validation Loss: 2.9832239516148704e-14
Epoch 346, Training Loss: 3.345497571463282e-14, Validation Loss: 3.0491834236570994e-14
Epoch 347, Training Loss: 3.2296044907408755e-14, Validation Loss: 2.1095504629167067e-14
Epoch 348, Training Loss: 2.0595069093599754e-14, Validation Loss: 1.8971601701178904e-14
Epoch 349, Training Loss: 2.3348209081180613e-14, Validation Loss: 1.769224313764601e-14
Epoch 350, Training Loss: 1.9916392414941718e-14, Validation Loss: 1.2903038385740206e-14
Epoch 351, Training Loss: 1.756237265804119e-14, Validation Loss: 1.3010758106741377e-14
Epoch 352, Training Loss: 1.4601867146511217e-14, Validation Loss: 1.2348293638693789e-14
Epoch 353, Training Loss: 1.3986839911641659e-14, Validation Loss: 9.609065320238634e-15
Epoch 354, Training Loss: 1.4509125509116344e-14, Validation Loss: 8.798082095219477e-15
Epoch 355, Training Loss: 1.4871682715595497e-14, Validation Loss: 8.447734868674995e-15
Epoch 356, Training Loss: 1.3223962228795915e-14, Validation Loss: 7.4989741114884e-15
Epoch 357, Training Loss: 1.4190070220742278e-14, Validation Loss: 5.6131962854124185e-15
Epoch 358, Training Loss: 1.2392895852597358e-14, Validation Loss: 9.432524172273051e-15
Epoch 359, Training Loss: 1.2241974910187376e-14, Validation Loss: 8.236064723287934e-15
Epoch 360, Training Loss: 1.204208191089894e-14, Validation Loss: 8.063359787540466e-15
Epoch 361, Training Loss: 1.0698071016568018e-14, Validation Loss: 8.153298592912875e-15
Epoch 362, Training Loss: 1.0743574473527466e-14, Validation Loss: 1.0499445178568673e-14
Epoch 363, Training Loss: 9.426251893298633e-15, Validation Loss: 1.0633686348181324e-14
Epoch 364, Training Loss: 6.65336333255254e-15, Validation Loss: 6.311022261425506e-15
Epoch 365, Training Loss: 6.3912866799908496e-15, Validation Loss: 1.0461081362321632e-14
Epoch 366, Training Loss: 7.06102334940709e-15, Validation Loss: 8.796614187121885e-15
Epoch 367, Training Loss: 5.904096198619752e-15, Validation Loss: 1.1568034839770387e-14
Epoch 368, Training Loss: 5.860994927098717e-15, Validation Loss: 1.1596291011857843e-14
Epoch 369, Training Loss: 4.089708850437204e-15, Validation Loss: 1.2281173053887463e-14
Epoch 370, Training Loss: 4.746501585869978e-15, Validation Loss: 9.296981960053418e-15
Epoch 371, Training Loss: 2.9334487380958292e-15, Validation Loss: 1.139146065751986e-14
Epoch 372, Training Loss: 3.7047336464595456e-15, Validation Loss: 1.2194236980313071e-14
Epoch 373, Training Loss: 3.8882141118455095e-15, Validation Loss: 9.387721211560982e-15
Epoch 374, Training Loss: 3.185917707695051e-15, Validation Loss: 7.79804704560379e-15
Epoch 375, Training Loss: 3.955868327408605e-15, Validation Loss: 7.991402644605319e-15
Epoch 376, Training Loss: 3.0179165576619225e-15, Validation Loss: 8.274829186119027e-15
Epoch 377, Training Loss: 4.296007536389252e-15, Validation Loss: 8.241602624697083e-15
Epoch 378, Training Loss: 3.492563539875368e-15, Validation Loss: 6.851822305061275e-15
Epoch 379, Training Loss: 3.4712130156486394e-15, Validation Loss: 9.084144603265041e-15
Epoch 380, Training Loss: 2.9177028191228454e-15, Validation Loss: 9.886920926058251e-15
Epoch 381, Training Loss: 3.3573885164383697e-15, Validation Loss: 9.558725305150364e-15
Epoch 382, Training Loss: 3.0971799950418486e-15, Validation Loss: 9.69483418241171e-15
Epoch 383, Training Loss: 4.089842258126397e-15, Validation Loss: 9.178420217327392e-15
Epoch 384, Training Loss: 3.1442843442716075e-15, Validation Loss: 6.462410342505899e-15
Epoch 385, Training Loss: 4.5331305983248305e-15, Validation Loss: 4.198729614045358e-15
Epoch 386, Training Loss: 4.9650767438430554e-15, Validation Loss: 3.5152151067090794e-15
Epoch 387, Training Loss: 3.799609383365026e-15, Validation Loss: 3.6166295144508896e-15
Epoch 388, Training Loss: 3.1404146742520763e-15, Validation Loss: 3.620098961402843e-15
Epoch 389, Training Loss: 2.8800727451663627e-15, Validation Loss: 4.439088765355922e-15
Epoch 390, Training Loss: 2.2673149233207353e-15, Validation Loss: 6.690493021795432e-15
Epoch 391, Training Loss: 2.2742538172246425e-15, Validation Loss: 6.458306891392925e-15
Epoch 392, Training Loss: 1.9964312456899683e-15, Validation Loss: 4.142184235585503e-15
Epoch 393, Training Loss: 3.4391873351876647e-15, Validation Loss: 5.068926794824695e-15
Epoch 394, Training Loss: 2.6824476765941992e-15, Validation Loss: 4.991064561697765e-15
Epoch 395, Training Loss: 2.655092324046148e-15, Validation Loss: 4.82476446558096e-15
Epoch 396, Training Loss: 3.4874927771366302e-15, Validation Loss: 3.5648215912650275e-15
Epoch 397, Training Loss: 2.9909616399396858e-15, Validation Loss: 4.806616784686036e-15
Epoch 398, Training Loss: 2.202996747020401e-15, Validation Loss: 4.5877743878181e-15
Epoch 399, Training Loss: 2.835503565547736e-15, Validation Loss: 4.867999144791187e-15
Epoch 400, Training Loss: 2.4151668536045784e-15, Validation Loss: 4.1158965680674654e-15
Epoch 401, Training Loss: 2.457867690299799e-15, Validation Loss: 3.3212595966226584e-15
Epoch 402, Training Loss: 2.6193303812548346e-15, Validation Loss: 4.637114056995663e-15
Epoch 403, Training Loss: 3.1218663467731016e-15, Validation Loss: 4.653727337706635e-15
Epoch 404, Training Loss: 3.0410015936063912e-15, Validation Loss: 4.641417407884188e-15
Epoch 405, Training Loss: 1.7992064001853825e-15, Validation Loss: 4.6299083477133705e-15
Epoch 406, Training Loss: 1.74276118337154e-15, Validation Loss: 4.680915824764077e-15
Epoch 407, Training Loss: 1.2215434826851057e-15, Validation Loss: 4.588341476376287e-15
Epoch 408, Training Loss: 1.68911826918457e-15, Validation Loss: 3.7143080833788346e-15
Epoch 409, Training Loss: 1.7483656827461664e-15, Validation Loss: 3.7463335520815724e-15
Epoch 410, Training Loss: 1.7047307804683612e-15, Validation Loss: 3.726417689909256e-15
Epoch 411, Training Loss: 2.125067598290637e-15, Validation Loss: 4.518052141314283e-15
Epoch 412, Training Loss: 2.090373128771101e-15, Validation Loss: 4.526058296731731e-15
Epoch 413, Training Loss: 1.6752404813767554e-15, Validation Loss: 4.5622206743488585e-15
Epoch 414, Training Loss: 1.6817790463339666e-15, Validation Loss: 4.485492618338301e-15
Epoch 415, Training Loss: 1.6524221549315534e-15, Validation Loss: 5.730090220265301e-15
Epoch 416, Training Loss: 1.2424936779651384e-15, Validation Loss: 5.730090220265301e-15
Epoch 417, Training Loss: 1.8894120209361764e-15, Validation Loss: 5.730090220265301e-15
Epoch 418, Training Loss: 1.4026219743908932e-15, Validation Loss: 5.661234911982999e-15
Epoch 419, Training Loss: 1.4026219743908932e-15, Validation Loss: 5.676046553615161e-15
Epoch 420, Training Loss: 1.818955608625327e-15, Validation Loss: 5.607024803358724e-15
Epoch 421, Training Loss: 2.0963779570924235e-15, Validation Loss: 5.663069585346752e-15
Epoch 422, Training Loss: 1.9222383592905432e-15, Validation Loss: 5.807185041542019e-15
Epoch 423, Training Loss: 1.9195695702319817e-15, Validation Loss: 6.4975050350930125e-15
Epoch 424, Training Loss: 1.9411869098370955e-15, Validation Loss: 6.508713822084029e-15
Epoch 425, Training Loss: 1.94919327701278e-15, Validation Loss: 6.508713822084029e-15
Epoch 426, Training Loss: 4.513915232399893e-15, Validation Loss: 6.613898373474068e-15
Epoch 427, Training Loss: 1.7617097339180923e-15, Validation Loss: 5.7925068075990495e-15
Epoch 428, Training Loss: 1.539264800046365e-15, Validation Loss: 5.68508735977768e-15
Epoch 429, Training Loss: 1.539264800046365e-15, Validation Loss: 5.68508735977768e-15
Epoch 430, Training Loss: 1.1497526758449754e-15, Validation Loss: 5.7219167758407706e-15
Epoch 431, Training Loss: 7.302164629765324e-16, Validation Loss: 5.441692018867683e-15
Epoch 432, Training Loss: 7.654446691319572e-16, Validation Loss: 5.441692018867683e-15
Epoch 433, Training Loss: 7.654446691319572e-16, Validation Loss: 5.4215762569198144e-15
Epoch 434, Training Loss: 7.670459849187415e-16, Validation Loss: 5.4215762569198144e-15
Epoch 435, Training Loss: 7.383562907809687e-16, Validation Loss: 5.437989214338761e-15
Epoch 436, Training Loss: 8.811374053865147e-16, Validation Loss: 5.465611382265197e-15
Epoch 437, Training Loss: 8.4911172492554e-16, Validation Loss: 5.492299272850812e-15
Epoch 438, Training Loss: 8.4911172492554e-16, Validation Loss: 5.51091451593262e-15
Epoch 439, Training Loss: 8.884765752975587e-16, Validation Loss: 5.574965876854569e-15
Epoch 440, Training Loss: 1.2270145743705396e-15, Validation Loss: 5.4335189979596264e-15
Epoch 441, Training Loss: 1.192987355055203e-15, Validation Loss: 5.791672903662478e-15
Epoch 442, Training Loss: 1.197524275278934e-15, Validation Loss: 5.767386774998802e-15
Epoch 443, Training Loss: 1.2081995373922983e-15, Validation Loss: 3.960605359166125e-15
Epoch 444, Training Loss: 1.2168731547721823e-15, Validation Loss: 4.060685690016009e-15
Epoch 445, Training Loss: 4.749170586686776e-15, Validation Loss: 4.060685690016009e-15
Epoch 446, Training Loss: 4.720347326041133e-15, Validation Loss: 4.060685690016009e-15
Epoch 447, Training Loss: 4.720347326041133e-15, Validation Loss: 4.060685690016009e-15
Epoch 448, Training Loss: 1.409694275983993e-15, Validation Loss: 4.505041715244457e-15
Epoch 449, Training Loss: 1.409694275983993e-15, Validation Loss: 4.067357345025058e-15
Epoch 450, Training Loss: 1.4652054272152508e-15, Validation Loss: 4.067357345025058e-15
Epoch 451, Training Loss: 1.0432672936061906e-15, Validation Loss: 4.144219232241281e-15
Epoch 452, Training Loss: 1.0432672936061906e-15, Validation Loss: 4.144219232241281e-15
Epoch 453, Training Loss: 1.0772946188006456e-15, Validation Loss: 4.144219232241281e-15
Epoch 454, Training Loss: 1.0772946188006456e-15, Validation Loss: 4.144219232241281e-15
Epoch 455, Training Loss: 1.0772946188006456e-15, Validation Loss: 4.105788500391406e-15
Epoch 456, Training Loss: 1.0672866068914808e-15, Validation Loss: 4.0833705028929e-15
Epoch 457, Training Loss: 1.0672866068914808e-15, Validation Loss: 4.0833705028929e-15
Epoch 458, Training Loss: 1.037262465284868e-15, Validation Loss: 4.13621265330736e-15
Epoch 459, Training Loss: 1.028588847904984e-15, Validation Loss: 3.715609125985817e-15
Epoch 460, Training Loss: 6.138565294573346e-16, Validation Loss: 3.655560842772592e-15
Epoch 461, Training Loss: 5.945077029036454e-16, Validation Loss: 3.697727836952805e-15
Epoch 462, Training Loss: 1.119328311170785e-15, Validation Loss: 3.684384103418235e-15
Epoch 463, Training Loss: 1.5152455926401931e-15, Validation Loss: 3.684384103418235e-15
Epoch 464, Training Loss: 1.5893049654713072e-15, Validation Loss: 2.899755038003474e-15
Epoch 465, Training Loss: 1.5519416010140912e-15, Validation Loss: 2.899755038003474e-15
Epoch 466, Training Loss: 1.519916026432235e-15, Validation Loss: 3.0464727911709436e-15
Epoch 467, Training Loss: 1.5412664447798452e-15, Validation Loss: 3.04353697497576e-15
Epoch 468, Training Loss: 1.5412664447798452e-15, Validation Loss: 3.04353697497576e-15
Epoch 469, Training Loss: 1.4585334545688471e-15, Validation Loss: 3.3331023877746944e-15
Epoch 470, Training Loss: 1.3568519138112967e-15, Validation Loss: 3.1536586696571077e-15
Epoch 471, Training Loss: 9.916259182735825e-16, Validation Loss: 3.1221666199529033e-15
Epoch 472, Training Loss: 9.869554844815407e-16, Validation Loss: 3.1221666199529033e-15
Epoch 473, Training Loss: 5.385962227256915e-16, Validation Loss: 3.5980146948855554e-15
Epoch 474, Training Loss: 1.158159371967356e-15, Validation Loss: 3.583603276320971e-15
Epoch 475, Training Loss: 6.340060139044159e-16, Validation Loss: 3.583603276320971e-15
Epoch 476, Training Loss: 6.340060139044159e-16, Validation Loss: 3.572827746682475e-15
Epoch 477, Training Loss: 6.320044221104948e-16, Validation Loss: 3.0961792256146677e-15
Epoch 478, Training Loss: 6.827117318605183e-16, Validation Loss: 3.0849702268654147e-15
Epoch 479, Training Loss: 1.201260643488391e-15, Validation Loss: 3.1093897632182826e-15
Epoch 480, Training Loss: 1.190051644739138e-15, Validation Loss: 3.0581487168323705e-15
Epoch 481, Training Loss: 1.2327524814343587e-15, Validation Loss: 3.0528111387152475e-15
Epoch 482, Training Loss: 1.2053972347654258e-15, Validation Loss: 3.072827162533577e-15
Epoch 483, Training Loss: 6.912518886116506e-16, Validation Loss: 3.099581968722025e-15
Epoch 484, Training Loss: 9.427868455678468e-16, Validation Loss: 3.0367314887610455e-15
Epoch 485, Training Loss: 9.427868455678468e-16, Validation Loss: 2.8659279302219263e-15
Epoch 486, Training Loss: 9.427868455678468e-16, Validation Loss: 2.7110039101032202e-15
Epoch 487, Training Loss: 1.2758537529553938e-15, Validation Loss: 2.932381264824052e-15
Epoch 488, Training Loss: 1.2758537529553938e-15, Validation Loss: 2.932381264824052e-15
Epoch 489, Training Loss: 2.019249466256052e-15, Validation Loss: 2.879338791117567e-15
Epoch 490, Training Loss: 1.336035232099575e-15, Validation Loss: 3.2892673739631003e-15
Epoch 491, Training Loss: 1.3440417051543778e-15, Validation Loss: 3.28226156445636e-15
Epoch 492, Training Loss: 9.539957384379814e-16, Validation Loss: 3.28226156445636e-15
Epoch 493, Training Loss: 9.539957384379814e-16, Validation Loss: 3.28226156445636e-15
Epoch 494, Training Loss: 9.523945285303155e-16, Validation Loss: 3.2809272758061976e-15
Epoch 495, Training Loss: 9.523945285303155e-16, Validation Loss: 3.276023378558069e-15
Epoch 496, Training Loss: 5.8636782215965e-16, Validation Loss: 2.9237411052455845e-15
Epoch 497, Training Loss: 6.003790705962162e-16, Validation Loss: 3.4494957261557496e-15
Epoch 498, Training Loss: 6.003790705962162e-16, Validation Loss: 3.4494957261557496e-15
Epoch 499, Training Loss: 7.05129676419465e-16, Validation Loss: 3.4494957261557496e-15
Epoch 500, Training Loss: 7.05129676419465e-16, Validation Loss: 3.4494957261557496e-15
