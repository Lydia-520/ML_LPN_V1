Epoch 1, Training Loss: 0.5108106732368469, Validation Loss: 0.509442150592804
Epoch 2, Training Loss: 0.509442150592804, Validation Loss: 0.5081082582473755
Epoch 3, Training Loss: 0.5081082582473755, Validation Loss: 0.5067704916000366
Epoch 4, Training Loss: 0.5067704916000366, Validation Loss: 0.5054348111152649
Epoch 5, Training Loss: 0.5054348707199097, Validation Loss: 0.5041042566299438
Epoch 6, Training Loss: 0.5041042566299438, Validation Loss: 0.5027985572814941
Epoch 7, Training Loss: 0.5027985572814941, Validation Loss: 0.5014895796775818
Epoch 8, Training Loss: 0.5014895796775818, Validation Loss: 0.5001646876335144
Epoch 9, Training Loss: 0.5001646876335144, Validation Loss: 0.49882790446281433
Epoch 10, Training Loss: 0.49882787466049194, Validation Loss: 0.49751967191696167
Epoch 11, Training Loss: 0.49751967191696167, Validation Loss: 0.49621158838272095
Epoch 12, Training Loss: 0.49621158838272095, Validation Loss: 0.49486735463142395
Epoch 13, Training Loss: 0.49486735463142395, Validation Loss: 0.4934864938259125
Epoch 14, Training Loss: 0.4934864938259125, Validation Loss: 0.4920474886894226
Epoch 15, Training Loss: 0.49204742908477783, Validation Loss: 0.49056121706962585
Epoch 16, Training Loss: 0.49056121706962585, Validation Loss: 0.4890478849411011
Epoch 17, Training Loss: 0.4890478849411011, Validation Loss: 0.4874780476093292
Epoch 18, Training Loss: 0.4874780476093292, Validation Loss: 0.48591652512550354
Epoch 19, Training Loss: 0.48591652512550354, Validation Loss: 0.4843098819255829
Epoch 20, Training Loss: 0.4843098521232605, Validation Loss: 0.4826345145702362
Epoch 21, Training Loss: 0.482634574174881, Validation Loss: 0.48088544607162476
Epoch 22, Training Loss: 0.48088544607162476, Validation Loss: 0.4790553152561188
Epoch 23, Training Loss: 0.4790552854537964, Validation Loss: 0.4771536588668823
Epoch 24, Training Loss: 0.4771536588668823, Validation Loss: 0.47516465187072754
Epoch 25, Training Loss: 0.47516462206840515, Validation Loss: 0.4730689823627472
Epoch 26, Training Loss: 0.4730689823627472, Validation Loss: 0.47088170051574707
Epoch 27, Training Loss: 0.47088170051574707, Validation Loss: 0.4686283767223358
Epoch 28, Training Loss: 0.4686283767223358, Validation Loss: 0.466257780790329
Epoch 29, Training Loss: 0.466257780790329, Validation Loss: 0.46375980973243713
Epoch 30, Training Loss: 0.46375980973243713, Validation Loss: 0.46109920740127563
Epoch 31, Training Loss: 0.46109920740127563, Validation Loss: 0.4583583474159241
Epoch 32, Training Loss: 0.45835837721824646, Validation Loss: 0.455487996339798
Epoch 33, Training Loss: 0.4554879665374756, Validation Loss: 0.4524856209754944
Epoch 34, Training Loss: 0.4524856209754944, Validation Loss: 0.4492246210575104
Epoch 35, Training Loss: 0.4492246210575104, Validation Loss: 0.4457416832447052
Epoch 36, Training Loss: 0.4457416832447052, Validation Loss: 0.44202569127082825
Epoch 37, Training Loss: 0.44202563166618347, Validation Loss: 0.4380553960800171
Epoch 38, Training Loss: 0.4380553364753723, Validation Loss: 0.43379297852516174
Epoch 39, Training Loss: 0.43379297852516174, Validation Loss: 0.4292108118534088
Epoch 40, Training Loss: 0.4292108118534088, Validation Loss: 0.42433544993400574
Epoch 41, Training Loss: 0.4243355095386505, Validation Loss: 0.4190400242805481
Epoch 42, Training Loss: 0.41904008388519287, Validation Loss: 0.41331160068511963
Epoch 43, Training Loss: 0.41331160068511963, Validation Loss: 0.4071410298347473
Epoch 44, Training Loss: 0.4071410298347473, Validation Loss: 0.40048959851264954
Epoch 45, Training Loss: 0.40048959851264954, Validation Loss: 0.3933543860912323
Epoch 46, Training Loss: 0.3933543860912323, Validation Loss: 0.38570889830589294
Epoch 47, Training Loss: 0.38570886850357056, Validation Loss: 0.37754493951797485
Epoch 48, Training Loss: 0.37754493951797485, Validation Loss: 0.36889103055000305
Epoch 49, Training Loss: 0.36889100074768066, Validation Loss: 0.35975557565689087
Epoch 50, Training Loss: 0.35975557565689087, Validation Loss: 0.35003626346588135
Epoch 51, Training Loss: 0.35003629326820374, Validation Loss: 0.3397454023361206
Epoch 52, Training Loss: 0.3397454023361206, Validation Loss: 0.32890447974205017
Epoch 53, Training Loss: 0.32890453934669495, Validation Loss: 0.3176921010017395
Epoch 54, Training Loss: 0.3176921010017395, Validation Loss: 0.30615201592445374
Epoch 55, Training Loss: 0.30615198612213135, Validation Loss: 0.29434654116630554
Epoch 56, Training Loss: 0.29434651136398315, Validation Loss: 0.2823677957057953
Epoch 57, Training Loss: 0.2823677957057953, Validation Loss: 0.27029648423194885
Epoch 58, Training Loss: 0.27029648423194885, Validation Loss: 0.25840115547180176
Epoch 59, Training Loss: 0.25840115547180176, Validation Loss: 0.2469603717327118
Epoch 60, Training Loss: 0.24696038663387299, Validation Loss: 0.2361271232366562
Epoch 61, Training Loss: 0.2361271232366562, Validation Loss: 0.22618551552295685
Epoch 62, Training Loss: 0.22618551552295685, Validation Loss: 0.21738258004188538
Epoch 63, Training Loss: 0.21738258004188538, Validation Loss: 0.20991690456867218
Epoch 64, Training Loss: 0.20991690456867218, Validation Loss: 0.20388036966323853
Epoch 65, Training Loss: 0.20388035476207733, Validation Loss: 0.1991344839334488
Epoch 66, Training Loss: 0.1991344839334488, Validation Loss: 0.19546008110046387
Epoch 67, Training Loss: 0.19546006619930267, Validation Loss: 0.1924867331981659
Epoch 68, Training Loss: 0.1924867331981659, Validation Loss: 0.18974356353282928
Epoch 69, Training Loss: 0.1897435188293457, Validation Loss: 0.18672509491443634
Epoch 70, Training Loss: 0.18672509491443634, Validation Loss: 0.18292100727558136
Epoch 71, Training Loss: 0.18292100727558136, Validation Loss: 0.17820018529891968
Epoch 72, Training Loss: 0.1782001405954361, Validation Loss: 0.17260761559009552
Epoch 73, Training Loss: 0.17260761559009552, Validation Loss: 0.16622979938983917
Epoch 74, Training Loss: 0.16622979938983917, Validation Loss: 0.1594599336385727
Epoch 75, Training Loss: 0.1594599336385727, Validation Loss: 0.15257275104522705
Epoch 76, Training Loss: 0.15257276594638824, Validation Loss: 0.14564192295074463
Epoch 77, Training Loss: 0.14564190804958344, Validation Loss: 0.13888438045978546
Epoch 78, Training Loss: 0.13888436555862427, Validation Loss: 0.13233473896980286
Epoch 79, Training Loss: 0.13233473896980286, Validation Loss: 0.1258457750082016
Epoch 80, Training Loss: 0.1258457601070404, Validation Loss: 0.11956581473350525
Epoch 81, Training Loss: 0.11956579983234406, Validation Loss: 0.11354828625917435
Epoch 82, Training Loss: 0.11354828625917435, Validation Loss: 0.10750657320022583
Epoch 83, Training Loss: 0.10750658065080643, Validation Loss: 0.1013404056429863
Epoch 84, Training Loss: 0.1013404056429863, Validation Loss: 0.09498543292284012
Epoch 85, Training Loss: 0.09498543292284012, Validation Loss: 0.08844399452209473
Epoch 86, Training Loss: 0.08844399452209473, Validation Loss: 0.08176051825284958
Epoch 87, Training Loss: 0.08176052570343018, Validation Loss: 0.07499388605356216
Epoch 88, Training Loss: 0.07499388605356216, Validation Loss: 0.0683133527636528
Epoch 89, Training Loss: 0.0683133602142334, Validation Loss: 0.06169735640287399
Epoch 90, Training Loss: 0.06169736757874489, Validation Loss: 0.05521370470523834
Epoch 91, Training Loss: 0.05521370470523834, Validation Loss: 0.048997193574905396
Epoch 92, Training Loss: 0.0489971898496151, Validation Loss: 0.04322265833616257
Epoch 93, Training Loss: 0.04322265088558197, Validation Loss: 0.037829507142305374
Epoch 94, Training Loss: 0.037829507142305374, Validation Loss: 0.032922156155109406
Epoch 95, Training Loss: 0.032922156155109406, Validation Loss: 0.028474872931838036
Epoch 96, Training Loss: 0.028474869206547737, Validation Loss: 0.024673491716384888
Epoch 97, Training Loss: 0.024673499166965485, Validation Loss: 0.0213826484978199
Epoch 98, Training Loss: 0.021382639184594154, Validation Loss: 0.018568534404039383
Epoch 99, Training Loss: 0.01856853812932968, Validation Loss: 0.016183843836188316
Epoch 100, Training Loss: 0.016183841973543167, Validation Loss: 0.014179364778101444
Epoch 101, Training Loss: 0.014179367572069168, Validation Loss: 0.012589622288942337
Epoch 102, Training Loss: 0.012589623220264912, Validation Loss: 0.011342355981469154
Epoch 103, Training Loss: 0.011342357844114304, Validation Loss: 0.010392742231488228
Epoch 104, Training Loss: 0.010392745025455952, Validation Loss: 0.00959190633147955
Epoch 105, Training Loss: 0.0095919044688344, Validation Loss: 0.008891044184565544
Epoch 106, Training Loss: 0.008891042321920395, Validation Loss: 0.008231882005929947
Epoch 107, Training Loss: 0.008231881074607372, Validation Loss: 0.007591335102915764
Epoch 108, Training Loss: 0.0075913360342383385, Validation Loss: 0.00696587422862649
Epoch 109, Training Loss: 0.006965876091271639, Validation Loss: 0.00635030260309577
Epoch 110, Training Loss: 0.00635030260309577, Validation Loss: 0.005741664208471775
Epoch 111, Training Loss: 0.005741664674133062, Validation Loss: 0.005154219921678305
Epoch 112, Training Loss: 0.005154219921678305, Validation Loss: 0.004591680131852627
Epoch 113, Training Loss: 0.0045916796661913395, Validation Loss: 0.004034898243844509
Epoch 114, Training Loss: 0.004034900572150946, Validation Loss: 0.003506670007482171
Epoch 115, Training Loss: 0.0035066725686192513, Validation Loss: 0.0030259222257882357
Epoch 116, Training Loss: 0.003025922691449523, Validation Loss: 0.002598937600851059
Epoch 117, Training Loss: 0.0025989373680204153, Validation Loss: 0.0022259599063545465
Epoch 118, Training Loss: 0.002225959673523903, Validation Loss: 0.0019058533944189548
Epoch 119, Training Loss: 0.0019058517646044493, Validation Loss: 0.0016377801075577736
Epoch 120, Training Loss: 0.0016377794090658426, Validation Loss: 0.0014146605972200632
Epoch 121, Training Loss: 0.001414660131558776, Validation Loss: 0.0012262767413631082
Epoch 122, Training Loss: 0.0012262772070243955, Validation Loss: 0.0010647692251950502
Epoch 123, Training Loss: 0.001064769341610372, Validation Loss: 0.0009239097125828266
Epoch 124, Training Loss: 0.0009239100618287921, Validation Loss: 0.0008000282687135041
Epoch 125, Training Loss: 0.0008000282105058432, Validation Loss: 0.0006905892514623702
Epoch 126, Training Loss: 0.0006905894842930138, Validation Loss: 0.000594641431234777
Epoch 127, Training Loss: 0.0005946420133113861, Validation Loss: 0.0005113130901008844
Epoch 128, Training Loss: 0.0005113150109536946, Validation Loss: 0.0004394284915179014
Epoch 129, Training Loss: 0.0004394281713757664, Validation Loss: 0.00037753081414848566
Epoch 130, Training Loss: 0.0003775301738642156, Validation Loss: 0.00032336957519873977
Epoch 131, Training Loss: 0.0003233696916140616, Validation Loss: 0.0002748881815932691
Epoch 132, Training Loss: 0.000274889258434996, Validation Loss: 0.00023028352006804198
Epoch 133, Training Loss: 0.00023028359282761812, Validation Loss: 0.00018977373838424683
Epoch 134, Training Loss: 0.00018977369472850114, Validation Loss: 0.00015425961464643478
Epoch 135, Training Loss: 0.00015426010941155255, Validation Loss: 0.00012516083370428532
Epoch 136, Training Loss: 0.00012516019342001528, Validation Loss: 0.00010323546302970499
Epoch 137, Training Loss: 0.00010323537571821362, Validation Loss: 8.885518036549911e-05
Epoch 138, Training Loss: 8.885495481081307e-05, Validation Loss: 8.14173836261034e-05
Epoch 139, Training Loss: 8.141771104419604e-05, Validation Loss: 7.738525164313614e-05
Epoch 140, Training Loss: 7.738506246823817e-05, Validation Loss: 7.599233504151925e-05
Epoch 141, Training Loss: 7.599249511258677e-05, Validation Loss: 7.577882934128866e-05
Epoch 142, Training Loss: 7.5778596510645e-05, Validation Loss: 7.529590220656246e-05
Epoch 143, Training Loss: 7.529586582677439e-05, Validation Loss: 7.376981375273317e-05
Epoch 144, Training Loss: 7.376997382380068e-05, Validation Loss: 7.107241981429979e-05
Epoch 145, Training Loss: 7.107236888259649e-05, Validation Loss: 6.78749056532979e-05
Epoch 146, Training Loss: 6.787503662053496e-05, Validation Loss: 6.442485027946532e-05
Epoch 147, Training Loss: 6.442485027946532e-05, Validation Loss: 6.103120176703669e-05
Epoch 148, Training Loss: 6.103176565375179e-05, Validation Loss: 5.800652434118092e-05
Epoch 149, Training Loss: 5.800654616905376e-05, Validation Loss: 5.5581160268047825e-05
Epoch 150, Training Loss: 5.558077828027308e-05, Validation Loss: 5.38332351425197e-05
Epoch 151, Training Loss: 5.3833311540074646e-05, Validation Loss: 5.252769551589154e-05
Epoch 152, Training Loss: 5.2527535444824025e-05, Validation Loss: 5.115720705362037e-05
Epoch 153, Training Loss: 5.115685416967608e-05, Validation Loss: 4.944820102537051e-05
Epoch 154, Training Loss: 4.944809916196391e-05, Validation Loss: 4.7213732614181936e-05
Epoch 155, Training Loss: 4.721383811556734e-05, Validation Loss: 4.440619159140624e-05
Epoch 156, Training Loss: 4.440628981683403e-05, Validation Loss: 4.1093149775406346e-05
Epoch 157, Training Loss: 4.109310975763947e-05, Validation Loss: 3.740828833542764e-05
Epoch 158, Training Loss: 3.7408161006169394e-05, Validation Loss: 3.352236308273859e-05
Epoch 159, Training Loss: 3.3522523153806105e-05, Validation Loss: 2.9606489988509566e-05
Epoch 160, Training Loss: 2.9606480893562548e-05, Validation Loss: 2.580957516329363e-05
Epoch 161, Training Loss: 2.5809726139414124e-05, Validation Loss: 2.2252610506257042e-05
Epoch 162, Training Loss: 2.225256321253255e-05, Validation Loss: 1.9027344023925252e-05
Epoch 163, Training Loss: 1.902712756418623e-05, Validation Loss: 1.6193460396607406e-05
Epoch 164, Training Loss: 1.6193351257243194e-05, Validation Loss: 1.3777582353213802e-05
Epoch 165, Training Loss: 1.3777393178315833e-05, Validation Loss: 1.1768956028390676e-05
Epoch 166, Training Loss: 1.1768969670811202e-05, Validation Loss: 1.0123507308890112e-05
Epoch 167, Training Loss: 1.0123488209501375e-05, Validation Loss: 8.768894986133091e-06
Epoch 168, Training Loss: 8.768918632995337e-06, Validation Loss: 7.616178663738538e-06
Epoch 169, Training Loss: 7.616236871399451e-06, Validation Loss: 6.599730568268569e-06
Epoch 170, Training Loss: 6.599737844226183e-06, Validation Loss: 5.6575263442937285e-06
Epoch 171, Training Loss: 5.657605925080134e-06, Validation Loss: 4.7622015699744225e-06
Epoch 172, Training Loss: 4.762190656038001e-06, Validation Loss: 3.9273445509024896e-06
Epoch 173, Training Loss: 3.927265424863435e-06, Validation Loss: 3.1769893666933058e-06
Epoch 174, Training Loss: 3.1769927772984374e-06, Validation Loss: 2.539204160711961e-06
Epoch 175, Training Loss: 2.5391732378921006e-06, Validation Loss: 2.032268412222038e-06
Epoch 176, Training Loss: 2.0322654563642573e-06, Validation Loss: 1.6570799061810249e-06
Epoch 177, Training Loss: 1.6570792240599985e-06, Validation Loss: 1.396204538650636e-06
Epoch 178, Training Loss: 1.3962268212708295e-06, Validation Loss: 1.220211402142013e-06
Epoch 179, Training Loss: 1.2202357311252854e-06, Validation Loss: 1.0969458799081622e-06
Epoch 180, Training Loss: 1.0969314416797715e-06, Validation Loss: 1.0004088153436896e-06
Epoch 181, Training Loss: 1.0004167734223302e-06, Validation Loss: 9.163587719740462e-07
Epoch 182, Training Loss: 9.163912295662158e-07, Validation Loss: 8.4246062215243e-07
Epoch 183, Training Loss: 8.425033684034133e-07, Validation Loss: 7.845142704354657e-07
Epoch 184, Training Loss: 7.845176810405974e-07, Validation Loss: 7.497696401514986e-07
Epoch 185, Training Loss: 7.497650926779897e-07, Validation Loss: 7.4206332101312e-07
Epoch 186, Training Loss: 7.420847509820305e-07, Validation Loss: 7.58128237521305e-07
Epoch 187, Training Loss: 7.581707563986129e-07, Validation Loss: 7.881108672336268e-07
Epoch 188, Training Loss: 7.881209285187651e-07, Validation Loss: 8.183012596418848e-07
Epoch 189, Training Loss: 8.18344062736287e-07, Validation Loss: 8.358604759450827e-07
Epoch 190, Training Loss: 8.358458103430166e-07, Validation Loss: 8.320159281538508e-07
Epoch 191, Training Loss: 8.320351412294258e-07, Validation Loss: 8.044483479352493e-07
Epoch 192, Training Loss: 8.044642072491115e-07, Validation Loss: 7.56682140945486e-07
Epoch 193, Training Loss: 7.567019224552496e-07, Validation Loss: 6.961765279811516e-07
Epoch 194, Training Loss: 6.961828376006451e-07, Validation Loss: 6.315054292826972e-07
Epoch 195, Training Loss: 6.315044629445765e-07, Validation Loss: 5.699144480786345e-07
Epoch 196, Training Loss: 5.698884706362151e-07, Validation Loss: 5.154671498530661e-07
Epoch 197, Training Loss: 5.154905693416367e-07, Validation Loss: 4.694269648553018e-07
Epoch 198, Training Loss: 4.6943031861701456e-07, Validation Loss: 4.305515801661386e-07
Epoch 199, Training Loss: 4.3056547838205006e-07, Validation Loss: 3.9661770756538317e-07
Epoch 200, Training Loss: 3.9659491335442e-07, Validation Loss: 3.6526660096569685e-07
Epoch 201, Training Loss: 3.6523894664242107e-07, Validation Loss: 3.349010171405098e-07
Epoch 202, Training Loss: 3.3489968132016656e-07, Validation Loss: 3.047199186312355e-07
Epoch 203, Training Loss: 3.047173038339679e-07, Validation Loss: 2.745520077951369e-07
Epoch 204, Training Loss: 2.7455749318505696e-07, Validation Loss: 2.446140001666208e-07
Epoch 205, Training Loss: 2.445911775339482e-07, Validation Loss: 2.150826645674897e-07
Epoch 206, Training Loss: 2.150755591401321e-07, Validation Loss: 1.8625144093675772e-07
Epoch 207, Training Loss: 1.8626350595241092e-07, Validation Loss: 1.5854504908929812e-07
Epoch 208, Training Loss: 1.585370767998029e-07, Validation Loss: 1.3244260799183394e-07
Epoch 209, Training Loss: 1.324387284284967e-07, Validation Loss: 1.086942731376439e-07
Epoch 210, Training Loss: 1.0869834454751981e-07, Validation Loss: 8.802323492318465e-08
Epoch 211, Training Loss: 8.80095001321024e-08, Validation Loss: 7.097860077465157e-08
Epoch 212, Training Loss: 7.097756338225736e-08, Validation Loss: 5.776103861876436e-08
Epoch 213, Training Loss: 5.7760932037353996e-08, Validation Loss: 4.8077971825932764e-08
Epoch 214, Training Loss: 4.80823061366209e-08, Validation Loss: 4.128593289465243e-08
Epoch 215, Training Loss: 4.1290306285191036e-08, Validation Loss: 3.648955981816471e-08
Epoch 216, Training Loss: 3.648643698284104e-08, Validation Loss: 3.284887029053607e-08
Epoch 217, Training Loss: 3.284850791374083e-08, Validation Loss: 2.9706017201647228e-08
Epoch 218, Training Loss: 2.9705816473324376e-08, Validation Loss: 2.6700801569745636e-08
Epoch 219, Training Loss: 2.6707317246632556e-08, Validation Loss: 2.3755376332701417e-08
Epoch 220, Training Loss: 2.374926033610336e-08, Validation Loss: 2.0923643262449332e-08
Epoch 221, Training Loss: 2.0933368816145048e-08, Validation Loss: 1.833660512318147e-08
Epoch 222, Training Loss: 1.833693197283992e-08, Validation Loss: 1.607163824246527e-08
Epoch 223, Training Loss: 1.6072519315457612e-08, Validation Loss: 1.4138007209396619e-08
Epoch 224, Training Loss: 1.4134547754451887e-08, Validation Loss: 1.2495854129213058e-08
Epoch 225, Training Loss: 1.2496220058721974e-08, Validation Loss: 1.113044501011018e-08
Epoch 226, Training Loss: 1.1125992571692223e-08, Validation Loss: 1.0044613141246828e-08
Epoch 227, Training Loss: 1.0044334253223042e-08, Validation Loss: 9.29674559557725e-09
Epoch 228, Training Loss: 9.296081238119314e-09, Validation Loss: 8.937378837003962e-09
Epoch 229, Training Loss: 8.936886786159448e-09, Validation Loss: 8.974214260604185e-09
Epoch 230, Training Loss: 8.974105902836982e-09, Validation Loss: 9.327076000431589e-09
Epoch 231, Training Loss: 9.325635375034835e-09, Validation Loss: 9.845864568092111e-09
Epoch 232, Training Loss: 9.842101356127841e-09, Validation Loss: 1.0324007426731896e-08
Epoch 233, Training Loss: 1.032366903075399e-08, Validation Loss: 1.0561393537500408e-08
Epoch 234, Training Loss: 1.0566179042825752e-08, Validation Loss: 1.0452067655819519e-08
Epoch 235, Training Loss: 1.0449480392082933e-08, Validation Loss: 9.944441714537788e-09
Epoch 236, Training Loss: 9.945250845078135e-09, Validation Loss: 9.120697974651648e-09
Epoch 237, Training Loss: 9.122302024877627e-09, Validation Loss: 8.118210992336117e-09
Epoch 238, Training Loss: 8.11900058295123e-09, Validation Loss: 7.088803322119475e-09
Epoch 239, Training Loss: 7.089270503968237e-09, Validation Loss: 6.165401078561672e-09
Epoch 240, Training Loss: 6.165647548073139e-09, Validation Loss: 5.410334846800424e-09
Epoch 241, Training Loss: 5.406759484571921e-09, Validation Loss: 4.829343591694624e-09
Epoch 242, Training Loss: 4.831024913443116e-09, Validation Loss: 4.391709218509732e-09
Epoch 243, Training Loss: 4.3879424538317835e-09, Validation Loss: 4.020317412312124e-09
Epoch 244, Training Loss: 4.020150434769221e-09, Validation Loss: 3.6763099231507113e-09
Epoch 245, Training Loss: 3.677975701776859e-09, Validation Loss: 3.31593263958041e-09
Epoch 246, Training Loss: 3.3159734957877163e-09, Validation Loss: 2.9289801695142614e-09
Epoch 247, Training Loss: 2.9257396505499855e-09, Validation Loss: 2.5219468735571127e-09
Epoch 248, Training Loss: 2.5207100851076802e-09, Validation Loss: 2.1162538388352914e-09
Epoch 249, Training Loss: 2.116590014367148e-09, Validation Loss: 1.7311410083209466e-09
Epoch 250, Training Loss: 1.730821819201367e-09, Validation Loss: 1.383595682469263e-09
Epoch 251, Training Loss: 1.3844925206285552e-09, Validation Loss: 1.0821532558935587e-09
Epoch 252, Training Loss: 1.0832046370978787e-09, Validation Loss: 8.314234301032286e-10
Epoch 253, Training Loss: 8.324645417445709e-10, Validation Loss: 6.367187332934066e-10
Epoch 254, Training Loss: 6.367173455146258e-10, Validation Loss: 4.929749941595674e-10
Epoch 255, Training Loss: 4.925359009533281e-10, Validation Loss: 3.9567599197098957e-10
Epoch 256, Training Loss: 3.955808736133548e-10, Validation Loss: 3.351613153679267e-10
Epoch 257, Training Loss: 3.3621769257585754e-10, Validation Loss: 3.0259597605386546e-10
Epoch 258, Training Loss: 3.0221133928698407e-10, Validation Loss: 2.846030355829754e-10
Epoch 259, Training Loss: 2.8435043208929756e-10, Validation Loss: 2.722576331048998e-10
Epoch 260, Training Loss: 2.7106858424552627e-10, Validation Loss: 2.5891577770664753e-10
Epoch 261, Training Loss: 2.5856936036738887e-10, Validation Loss: 2.438117485681346e-10
Epoch 262, Training Loss: 2.441049584689381e-10, Validation Loss: 2.309774177478019e-10
Epoch 263, Training Loss: 2.31041893949957e-10, Validation Loss: 2.2066927451991347e-10
Epoch 264, Training Loss: 2.2108191666259103e-10, Validation Loss: 2.160874673640123e-10
Epoch 265, Training Loss: 2.1574610153951568e-10, Validation Loss: 2.1632566571394563e-10
Epoch 266, Training Loss: 2.1643506431523463e-10, Validation Loss: 2.1990093079793382e-10
Epoch 267, Training Loss: 2.1939268457504824e-10, Validation Loss: 2.228158491046628e-10
Epoch 268, Training Loss: 2.2366765384251863e-10, Validation Loss: 2.2316895553764482e-10
Epoch 269, Training Loss: 2.2334725735539962e-10, Validation Loss: 2.2030050006449642e-10
Epoch 270, Training Loss: 2.2081553252562003e-10, Validation Loss: 2.1381564574429746e-10
Epoch 271, Training Loss: 2.1459155286063236e-10, Validation Loss: 2.0464768768491126e-10
Epoch 272, Training Loss: 2.0480808715639398e-10, Validation Loss: 1.9394814920747905e-10
Epoch 273, Training Loss: 1.937621452174909e-10, Validation Loss: 1.812977129533877e-10
Epoch 274, Training Loss: 1.8117857214505761e-10, Validation Loss: 1.694854256939493e-10
Epoch 275, Training Loss: 1.6896439802849272e-10, Validation Loss: 1.558423251557528e-10
Epoch 276, Training Loss: 1.5580248202695657e-10, Validation Loss: 1.4124507119461782e-10
Epoch 277, Training Loss: 1.4140781601224006e-10, Validation Loss: 1.2527007209328644e-10
Epoch 278, Training Loss: 1.258572968065863e-10, Validation Loss: 1.098369728502746e-10
Epoch 279, Training Loss: 1.0952239809514097e-10, Validation Loss: 9.415439955473559e-11
Epoch 280, Training Loss: 9.389278937677048e-11, Validation Loss: 7.947214414327775e-11
Epoch 281, Training Loss: 7.961518944110679e-11, Validation Loss: 6.731390445047225e-11
Epoch 282, Training Loss: 6.733395091496064e-11, Validation Loss: 5.750664180959042e-11
Epoch 283, Training Loss: 5.754919457645613e-11, Validation Loss: 5.016874762842072e-11
Epoch 284, Training Loss: 5.0180887223305604e-11, Validation Loss: 4.394200975310625e-11
Epoch 285, Training Loss: 4.3971486174410046e-11, Validation Loss: 3.8366174820447796e-11
Epoch 286, Training Loss: 3.826330918776932e-11, Validation Loss: 3.2973741792563516e-11
Epoch 287, Training Loss: 3.30542503090836e-11, Validation Loss: 2.744118994535416e-11
Epoch 288, Training Loss: 2.744306171198474e-11, Validation Loss: 2.2430250365412796e-11
Epoch 289, Training Loss: 2.2453587600335112e-11, Validation Loss: 1.7979871064222053e-11
Epoch 290, Training Loss: 1.783822048406769e-11, Validation Loss: 1.3792713499105602e-11
Epoch 291, Training Loss: 1.369771657211416e-11, Validation Loss: 1.0671255545879887e-11
Epoch 292, Training Loss: 1.0600076372213607e-11, Validation Loss: 8.371584675481714e-12
Epoch 293, Training Loss: 8.410066913711045e-12, Validation Loss: 6.929120038162706e-12
Epoch 294, Training Loss: 6.987309602440872e-12, Validation Loss: 6.120909768619898e-12
Epoch 295, Training Loss: 6.047183153529145e-12, Validation Loss: 5.848685685067023e-12
Epoch 296, Training Loss: 5.951002711446218e-12, Validation Loss: 5.898943226251285e-12
Epoch 297, Training Loss: 5.8640752843841515e-12, Validation Loss: 5.8301198070653815e-12
Epoch 298, Training Loss: 5.854521294840209e-12, Validation Loss: 6.0202528726072124e-12
Epoch 299, Training Loss: 5.872195524975199e-12, Validation Loss: 5.9596646194426395e-12
Epoch 300, Training Loss: 5.922686820147849e-12, Validation Loss: 5.896800409077585e-12
Epoch 301, Training Loss: 5.916823888479916e-12, Validation Loss: 5.885413250500404e-12
Epoch 302, Training Loss: 5.921640348210966e-12, Validation Loss: 5.7849432709422555e-12
Epoch 303, Training Loss: 5.843976778191484e-12, Validation Loss: 5.723798605222763e-12
Epoch 304, Training Loss: 5.650038163024229e-12, Validation Loss: 5.298628289601703e-12
Epoch 305, Training Loss: 5.298124352431932e-12, Validation Loss: 5.02304057722891e-12
Epoch 306, Training Loss: 5.101824778613873e-12, Validation Loss: 4.635832950156127e-12
Epoch 307, Training Loss: 4.645927306062836e-12, Validation Loss: 4.251371390345815e-12
Epoch 308, Training Loss: 4.2192894143811e-12, Validation Loss: 3.8709248480206515e-12
Epoch 309, Training Loss: 3.892728587390204e-12, Validation Loss: 3.5016685731581454e-12
Epoch 310, Training Loss: 3.5411953317604494e-12, Validation Loss: 3.137401146172114e-12
Epoch 311, Training Loss: 3.170500754295924e-12, Validation Loss: 2.8159044106884634e-12
Epoch 312, Training Loss: 2.8989321793765344e-12, Validation Loss: 2.6867056756446628e-12
Epoch 313, Training Loss: 2.649927152709175e-12, Validation Loss: 2.4868358240726085e-12
Epoch 314, Training Loss: 2.4802159024478465e-12, Validation Loss: 2.3282643174526996e-12
Epoch 315, Training Loss: 2.3337126502098737e-12, Validation Loss: 2.140016679488821e-12
Epoch 316, Training Loss: 2.188500249078462e-12, Validation Loss: 1.8997117247343542e-12
Epoch 317, Training Loss: 1.979535459162296e-12, Validation Loss: 1.8284245645316943e-12
Epoch 318, Training Loss: 1.836811518857173e-12, Validation Loss: 1.6597176107427392e-12
Epoch 319, Training Loss: 1.6370933471690496e-12, Validation Loss: 1.465855323408427e-12
Epoch 320, Training Loss: 1.4811048438048702e-12, Validation Loss: 1.3075590957201122e-12
Epoch 321, Training Loss: 1.2878389760856424e-12, Validation Loss: 1.0934918335397947e-12
Epoch 322, Training Loss: 1.0739243695712108e-12, Validation Loss: 9.139646504896515e-13
Epoch 323, Training Loss: 9.259951746359851e-13, Validation Loss: 7.660589827415687e-13
Epoch 324, Training Loss: 7.307906992222446e-13, Validation Loss: 5.972573781029555e-13
Epoch 325, Training Loss: 6.043058848465011e-13, Validation Loss: 4.802579774837445e-13
Epoch 326, Training Loss: 4.710377053684933e-13, Validation Loss: 3.535645355049605e-13
Epoch 327, Training Loss: 3.482034539176171e-13, Validation Loss: 2.6718701578477833e-13
Epoch 328, Training Loss: 2.805710579232429e-13, Validation Loss: 2.1593011124802775e-13
Epoch 329, Training Loss: 2.158312184573699e-13, Validation Loss: 1.5291991306044805e-13
Epoch 330, Training Loss: 1.6673853053469911e-13, Validation Loss: 1.1042947426712774e-13
Epoch 331, Training Loss: 1.1844052214687872e-13, Validation Loss: 1.0752125101723409e-13
Epoch 332, Training Loss: 1.0833213259829957e-13, Validation Loss: 1.1279380072093045e-13
Epoch 333, Training Loss: 1.0398913717971081e-13, Validation Loss: 9.894065818374931e-14
Epoch 334, Training Loss: 1.0403983040753809e-13, Validation Loss: 1.0039851030619121e-13
Epoch 335, Training Loss: 9.03567110997934e-14, Validation Loss: 9.383221603138578e-14
Epoch 336, Training Loss: 8.480152344225722e-14, Validation Loss: 8.636766703293969e-14
Epoch 337, Training Loss: 8.012407875851099e-14, Validation Loss: 7.870152419304707e-14
Epoch 338, Training Loss: 7.930965996785777e-14, Validation Loss: 7.201091258663903e-14
Epoch 339, Training Loss: 7.14924945416015e-14, Validation Loss: 7.670464740802685e-14
Epoch 340, Training Loss: 6.661238536676342e-14, Validation Loss: 5.98757087205519e-14
Epoch 341, Training Loss: 6.326777751870793e-14, Validation Loss: 5.660932944737303e-14
Epoch 342, Training Loss: 5.838069556864806e-14, Validation Loss: 5.413550873854464e-14
Epoch 343, Training Loss: 5.824254788308267e-14, Validation Loss: 5.443953935650031e-14
Epoch 344, Training Loss: 4.986690652964733e-14, Validation Loss: 4.6618884154501355e-14
Epoch 345, Training Loss: 4.92406103684475e-14, Validation Loss: 4.7208192080960484e-14
Epoch 346, Training Loss: 3.9674579404127067e-14, Validation Loss: 4.3435215954555975e-14
Epoch 347, Training Loss: 4.07166332171572e-14, Validation Loss: 3.5363747520611444e-14
Epoch 348, Training Loss: 3.495396653325697e-14, Validation Loss: 4.2032935969717536e-14
Epoch 349, Training Loss: 3.476905246460778e-14, Validation Loss: 4.127858197942001e-14
Epoch 350, Training Loss: 3.1552475340595673e-14, Validation Loss: 3.290701654852686e-14
Epoch 351, Training Loss: 3.176546008111687e-14, Validation Loss: 3.032364398643239e-14
Epoch 352, Training Loss: 2.8615737573565656e-14, Validation Loss: 3.5526432056592894e-14
Epoch 353, Training Loss: 2.7567747753641167e-14, Validation Loss: 3.381678753211839e-14
Epoch 354, Training Loss: 2.663605047517701e-14, Validation Loss: 3.179442521978118e-14
Epoch 355, Training Loss: 2.3375386980326214e-14, Validation Loss: 2.811899510164837e-14
Epoch 356, Training Loss: 2.0050806379275608e-14, Validation Loss: 2.6752234596420094e-14
Epoch 357, Training Loss: 2.2810183917480048e-14, Validation Loss: 1.9556544019827884e-14
Epoch 358, Training Loss: 1.8886390186685122e-14, Validation Loss: 2.388493489634009e-14
Epoch 359, Training Loss: 1.8808376758177106e-14, Validation Loss: 2.0566607092506115e-14
Epoch 360, Training Loss: 1.6217169141320535e-14, Validation Loss: 2.032461655573914e-14
Epoch 361, Training Loss: 1.4483911032342478e-14, Validation Loss: 2.2293978322500754e-14
Epoch 362, Training Loss: 1.3079486360081591e-14, Validation Loss: 1.8204218650086715e-14
Epoch 363, Training Loss: 1.5414375030835432e-14, Validation Loss: 2.3744144467979268e-14
Epoch 364, Training Loss: 1.3208456443663478e-14, Validation Loss: 1.218129262281313e-14
Epoch 365, Training Loss: 1.3530914263386665e-14, Validation Loss: 1.0733879334413193e-14
Epoch 366, Training Loss: 1.3987063528339734e-14, Validation Loss: 1.411983763688774e-14
Epoch 367, Training Loss: 1.1767234119075022e-14, Validation Loss: 1.362128590259512e-14
Epoch 368, Training Loss: 8.390545745175226e-15, Validation Loss: 1.3183000562499644e-14
Epoch 369, Training Loss: 1.0608822543047621e-14, Validation Loss: 1.275167444509881e-14
Epoch 370, Training Loss: 8.919068893273492e-15, Validation Loss: 1.2849401718421222e-14
Epoch 371, Training Loss: 8.723879467941158e-15, Validation Loss: 1.0113136321215563e-14
Epoch 372, Training Loss: 1.1530095387029919e-14, Validation Loss: 9.915600614619335e-15
Epoch 373, Training Loss: 8.762426243304807e-15, Validation Loss: 1.0465662116500383e-14
Epoch 374, Training Loss: 7.831163492742592e-15, Validation Loss: 1.0355290335341358e-14
Epoch 375, Training Loss: 7.797503250451653e-15, Validation Loss: 1.1792817055180944e-14
Epoch 376, Training Loss: 8.85746926921737e-15, Validation Loss: 1.107425783020144e-14
Epoch 377, Training Loss: 7.861204363249913e-15, Validation Loss: 1.2018071067943122e-14
Epoch 378, Training Loss: 9.226114948521387e-15, Validation Loss: 1.1310626609297488e-14
Epoch 379, Training Loss: 6.8248400705264896e-15, Validation Loss: 1.1492599779553813e-14
Epoch 380, Training Loss: 5.8164321002271945e-15, Validation Loss: 1.0464088329284384e-14
Epoch 381, Training Loss: 4.8148961082289735e-15, Validation Loss: 7.419992524321673e-15
Epoch 382, Training Loss: 6.525550295976602e-15, Validation Loss: 1.1863307137051447e-14
Epoch 383, Training Loss: 4.484731559235193e-15, Validation Loss: 8.813675971778429e-15
Epoch 384, Training Loss: 4.054403670162698e-15, Validation Loss: 1.04179944903607e-14
Epoch 385, Training Loss: 4.4592113035673685e-15, Validation Loss: 7.265508114302592e-15
Epoch 386, Training Loss: 4.037406683526619e-15, Validation Loss: 9.837894659071172e-15
Epoch 387, Training Loss: 3.871523751136337e-15, Validation Loss: 8.8155665493167e-15
Epoch 388, Training Loss: 3.779149726040572e-15, Validation Loss: 6.2234886061068254e-15
Epoch 389, Training Loss: 3.57608712946351e-15, Validation Loss: 8.68610095146067e-15
Epoch 390, Training Loss: 5.881984827048152e-15, Validation Loss: 6.9371740035078285e-15
Epoch 391, Training Loss: 3.866486446199016e-15, Validation Loss: 6.366666820345956e-15
Epoch 392, Training Loss: 3.6926469098187e-15, Validation Loss: 7.369547477147943e-15
Epoch 393, Training Loss: 4.916460864318921e-15, Validation Loss: 6.921778332658534e-15
Epoch 394, Training Loss: 4.955792415708201e-15, Validation Loss: 9.198029877089276e-15
Epoch 395, Training Loss: 4.303303031163953e-15, Validation Loss: 8.71128917021317e-15
Epoch 396, Training Loss: 4.044729283355633e-15, Validation Loss: 6.152724509077886e-15
Epoch 397, Training Loss: 5.861051254789709e-15, Validation Loss: 5.7241478606238384e-15
Epoch 398, Training Loss: 4.8771962285324745e-15, Validation Loss: 7.158320329992297e-15
Epoch 399, Training Loss: 4.3063387972469124e-15, Validation Loss: 7.517338632817821e-15
Epoch 400, Training Loss: 4.352042153981913e-15, Validation Loss: 9.988283664790279e-15
Epoch 401, Training Loss: 3.634333773597925e-15, Validation Loss: 1.0225157275522891e-14
Epoch 402, Training Loss: 4.963648646293985e-15, Validation Loss: 1.0844144389420864e-14
Epoch 403, Training Loss: 3.966649786277731e-15, Validation Loss: 9.605681423614353e-15
Epoch 404, Training Loss: 5.5866811895480435e-15, Validation Loss: 9.542218327074272e-15
Epoch 405, Training Loss: 4.5699163921911375e-15, Validation Loss: 9.490816132670145e-15
Epoch 406, Training Loss: 4.611683163303773e-15, Validation Loss: 9.651061213763502e-15
Epoch 407, Training Loss: 5.18407541828976e-15, Validation Loss: 1.0058268915024218e-14
Epoch 408, Training Loss: 5.236767643872556e-15, Validation Loss: 1.0757122765518799e-14
Epoch 409, Training Loss: 2.7731934926071046e-15, Validation Loss: 1.1548575951873113e-14
Epoch 410, Training Loss: 3.4829624214182406e-15, Validation Loss: 8.374505482253072e-15
Epoch 411, Training Loss: 2.4717353137122464e-15, Validation Loss: 7.475507910717667e-15
Epoch 412, Training Loss: 3.7177339081340046e-15, Validation Loss: 8.383112184030123e-15
Epoch 413, Training Loss: 4.432106249255231e-15, Validation Loss: 5.812683132402647e-15
Epoch 414, Training Loss: 4.83544597456231e-15, Validation Loss: 5.4920388102195315e-15
Epoch 415, Training Loss: 2.6600195147003262e-15, Validation Loss: 8.465621663422164e-15
Epoch 416, Training Loss: 2.9253655026801814e-15, Validation Loss: 7.101253602753406e-15
Epoch 417, Training Loss: 2.630178967485031e-15, Validation Loss: 7.617333413340033e-15
Epoch 418, Training Loss: 2.6540981191243082e-15, Validation Loss: 8.224695847069887e-15
Epoch 419, Training Loss: 3.6111149064477904e-15, Validation Loss: 8.687266468796091e-15
Epoch 420, Training Loss: 4.0871800335731765e-15, Validation Loss: 9.387729681890455e-15
Epoch 421, Training Loss: 3.790341995889117e-15, Validation Loss: 9.783611705613433e-15
Epoch 422, Training Loss: 3.0790886418379177e-15, Validation Loss: 8.5046969873449e-15
Epoch 423, Training Loss: 3.8199322448684986e-15, Validation Loss: 8.034611489310655e-15
Epoch 424, Training Loss: 2.5127348847329067e-15, Validation Loss: 8.978691542430722e-15
Epoch 425, Training Loss: 2.5493142143183205e-15, Validation Loss: 8.144336984330924e-15
Epoch 426, Training Loss: 3.0561370135826415e-15, Validation Loss: 9.320640437303178e-15
Epoch 427, Training Loss: 2.977257070369585e-15, Validation Loss: 8.827144642672719e-15
Epoch 428, Training Loss: 2.8745414082625553e-15, Validation Loss: 6.202116270781705e-15
Epoch 429, Training Loss: 2.1094783804128953e-15, Validation Loss: 6.19180787981362e-15
Epoch 430, Training Loss: 2.7238540351877784e-15, Validation Loss: 5.433884069159893e-15
Epoch 431, Training Loss: 2.65878517593794e-15, Validation Loss: 7.95611355795681e-15
Epoch 432, Training Loss: 1.895573550352741e-15, Validation Loss: 8.23473657562664e-15
Epoch 433, Training Loss: 2.2825502931847616e-15, Validation Loss: 6.132499903396295e-15
Epoch 434, Training Loss: 2.4402767218094585e-15, Validation Loss: 6.076988752165037e-15
Epoch 435, Training Loss: 2.5285974824943748e-15, Validation Loss: 8.679284877334114e-15
Epoch 436, Training Loss: 3.3105742759930454e-15, Validation Loss: 8.771508977598215e-15
Epoch 437, Training Loss: 3.0244783101460648e-15, Validation Loss: 8.129247092375589e-15
Epoch 438, Training Loss: 2.0363029923413595e-15, Validation Loss: 9.518028760166584e-15
Epoch 439, Training Loss: 1.6345476421621196e-15, Validation Loss: 7.0579498903579774e-15
Epoch 440, Training Loss: 1.3111719563614643e-15, Validation Loss: 6.345201734913111e-15
Epoch 441, Training Loss: 1.4623931719512481e-15, Validation Loss: 7.021128944624359e-15
Epoch 442, Training Loss: 1.5053274721025557e-15, Validation Loss: 7.012297779116286e-15
Epoch 443, Training Loss: 1.0670930598630332e-15, Validation Loss: 6.522473872312175e-15
Epoch 444, Training Loss: 1.62510682469026e-15, Validation Loss: 6.439642096883703e-15
Epoch 445, Training Loss: 2.1599854727500116e-15, Validation Loss: 5.254727706969662e-15
Epoch 446, Training Loss: 1.8935385536969626e-15, Validation Loss: 5.331611193526041e-15
Epoch 447, Training Loss: 2.4021627802818567e-15, Validation Loss: 9.251727530780463e-15
Epoch 448, Training Loss: 2.4347223032578384e-15, Validation Loss: 9.368020919273742e-15
Epoch 449, Training Loss: 1.6441387021029984e-15, Validation Loss: 8.867949607873748e-15
Epoch 450, Training Loss: 1.8724550566068558e-15, Validation Loss: 1.0983314443753587e-14
Epoch 451, Training Loss: 1.7648187683509892e-15, Validation Loss: 9.406920060343448e-15
Epoch 452, Training Loss: 1.626958226954721e-15, Validation Loss: 7.189818097168895e-15
Epoch 453, Training Loss: 1.5625733468097903e-15, Validation Loss: 7.211934127421705e-15
Epoch 454, Training Loss: 1.5299304969676225e-15, Validation Loss: 6.9239374196410856e-15
Epoch 455, Training Loss: 1.5660928745847504e-15, Validation Loss: 6.880144122202144e-15
Epoch 456, Training Loss: 1.813190914144551e-15, Validation Loss: 8.731687417648949e-15
Epoch 457, Training Loss: 1.7277057021296868e-15, Validation Loss: 8.237635122372144e-15
Epoch 458, Training Loss: 2.2856862209137338e-15, Validation Loss: 7.933391052113766e-15
Epoch 459, Training Loss: 2.990317471383299e-15, Validation Loss: 8.057757511627326e-15
Epoch 460, Training Loss: 2.979642315149053e-15, Validation Loss: 8.079775286058254e-15
Epoch 461, Training Loss: 1.8987761819263095e-15, Validation Loss: 7.991511064822567e-15
Epoch 462, Training Loss: 1.837927240819692e-15, Validation Loss: 7.991511064822567e-15
Epoch 463, Training Loss: 1.8085538322748073e-15, Validation Loss: 7.875276121602649e-15
Epoch 464, Training Loss: 1.6446559215964156e-15, Validation Loss: 7.981423749453716e-15
Epoch 465, Training Loss: 1.6603350308456847e-15, Validation Loss: 7.875769941810898e-15
Epoch 466, Training Loss: 1.5332999940318001e-15, Validation Loss: 6.8733699762064775e-15
Epoch 467, Training Loss: 1.8087874016100127e-15, Validation Loss: 6.897720479374144e-15
Epoch 468, Training Loss: 1.879977767969658e-15, Validation Loss: 6.89371740166542e-15
Epoch 469, Training Loss: 2.33063889469923e-15, Validation Loss: 5.578901191927513e-15
Epoch 470, Training Loss: 1.387032650634033e-15, Validation Loss: 5.590041369249801e-15
Epoch 471, Training Loss: 1.7936085711952156e-15, Validation Loss: 5.569775258953795e-15
Epoch 472, Training Loss: 1.85760974541504e-15, Validation Loss: 5.613485123647432e-15
Epoch 473, Training Loss: 1.7133942334528782e-15, Validation Loss: 7.630795307970745e-15
Epoch 474, Training Loss: 1.8807282391609254e-15, Validation Loss: 7.626692280374246e-15
Epoch 475, Training Loss: 2.4294014540414237e-15, Validation Loss: 7.16866599041006e-15
Epoch 476, Training Loss: 9.647110228581035e-16, Validation Loss: 7.307443021455258e-15
Epoch 477, Training Loss: 1.5512310462504632e-15, Validation Loss: 6.3339230677039466e-15
Epoch 478, Training Loss: 1.4946356928467199e-15, Validation Loss: 6.413423886067341e-15
Epoch 479, Training Loss: 9.382564898494572e-16, Validation Loss: 6.225648540122324e-15
Epoch 480, Training Loss: 1.216162494129436e-15, Validation Loss: 6.387684672382651e-15
Epoch 481, Training Loss: 1.270706227855811e-15, Validation Loss: 6.374373973133023e-15
Epoch 482, Training Loss: 2.586927559374095e-15, Validation Loss: 6.377789209976352e-15
Epoch 483, Training Loss: 2.1238565529343003e-15, Validation Loss: 7.751202735488839e-15
Epoch 484, Training Loss: 2.121721394632509e-15, Validation Loss: 6.172366356091766e-15
Epoch 485, Training Loss: 1.7217008738083643e-15, Validation Loss: 6.228186250832298e-15
Epoch 486, Training Loss: 1.2674703502390627e-15, Validation Loss: 6.259909328772866e-15
Epoch 487, Training Loss: 1.887283638897963e-15, Validation Loss: 6.455947904634822e-15
Epoch 488, Training Loss: 1.2048034646694006e-15, Validation Loss: 6.274168704923418e-15
Epoch 489, Training Loss: 1.5838570613128044e-15, Validation Loss: 6.244964279451511e-15
Epoch 490, Training Loss: 1.7524922155069526e-15, Validation Loss: 6.493327892113628e-15
Epoch 491, Training Loss: 1.277978746861818e-15, Validation Loss: 6.9729204879478545e-15
Epoch 492, Training Loss: 1.8064021568305446e-15, Validation Loss: 5.440158889233153e-15
Epoch 493, Training Loss: 2.4102525802028457e-15, Validation Loss: 2.6043654266592192e-15
Epoch 494, Training Loss: 3.1186203047609863e-15, Validation Loss: 5.204434278693491e-15
Epoch 495, Training Loss: 1.7262545229328034e-15, Validation Loss: 5.284865562749444e-15
Epoch 496, Training Loss: 2.4057990927244194e-15, Validation Loss: 6.424788527120652e-15
Epoch 497, Training Loss: 2.383731343349603e-15, Validation Loss: 7.410958070906259e-15
Epoch 498, Training Loss: 4.1756339901890486e-15, Validation Loss: 8.764784383029963e-15
Epoch 499, Training Loss: 4.928971117433394e-15, Validation Loss: 7.575173195423397e-15
Epoch 500, Training Loss: 4.065295666831441e-15, Validation Loss: 7.457745629813745e-15
