Epoch 1, Training Loss: 0.46010148525238037, Validation Loss: 0.45877957344055176
Epoch 2, Training Loss: 0.45877957344055176, Validation Loss: 0.45749711990356445
Epoch 3, Training Loss: 0.45749711990356445, Validation Loss: 0.4562630355358124
Epoch 4, Training Loss: 0.4562630355358124, Validation Loss: 0.45507869124412537
Epoch 5, Training Loss: 0.45507869124412537, Validation Loss: 0.45388302206993103
Epoch 6, Training Loss: 0.45388302206993103, Validation Loss: 0.45270031690597534
Epoch 7, Training Loss: 0.45270031690597534, Validation Loss: 0.45152902603149414
Epoch 8, Training Loss: 0.45152902603149414, Validation Loss: 0.4503805339336395
Epoch 9, Training Loss: 0.4503805339336395, Validation Loss: 0.4492274224758148
Epoch 10, Training Loss: 0.4492274224758148, Validation Loss: 0.44806382060050964
Epoch 11, Training Loss: 0.44806385040283203, Validation Loss: 0.44688042998313904
Epoch 12, Training Loss: 0.44688042998313904, Validation Loss: 0.4456765651702881
Epoch 13, Training Loss: 0.4456765651702881, Validation Loss: 0.44444459676742554
Epoch 14, Training Loss: 0.44444459676742554, Validation Loss: 0.4431862235069275
Epoch 15, Training Loss: 0.4431862235069275, Validation Loss: 0.4419066309928894
Epoch 16, Training Loss: 0.4419066309928894, Validation Loss: 0.44060835242271423
Epoch 17, Training Loss: 0.44060835242271423, Validation Loss: 0.4392790198326111
Epoch 18, Training Loss: 0.4392790198326111, Validation Loss: 0.43791019916534424
Epoch 19, Training Loss: 0.43791019916534424, Validation Loss: 0.43653935194015503
Epoch 20, Training Loss: 0.43653935194015503, Validation Loss: 0.4351341426372528
Epoch 21, Training Loss: 0.4351341724395752, Validation Loss: 0.4336724281311035
Epoch 22, Training Loss: 0.4336724281311035, Validation Loss: 0.43216437101364136
Epoch 23, Training Loss: 0.43216440081596375, Validation Loss: 0.4306085705757141
Epoch 24, Training Loss: 0.4306085705757141, Validation Loss: 0.429007887840271
Epoch 25, Training Loss: 0.429007887840271, Validation Loss: 0.4273246228694916
Epoch 26, Training Loss: 0.4273246228694916, Validation Loss: 0.42557692527770996
Epoch 27, Training Loss: 0.42557692527770996, Validation Loss: 0.4237402379512787
Epoch 28, Training Loss: 0.4237402379512787, Validation Loss: 0.4217976927757263
Epoch 29, Training Loss: 0.4217976927757263, Validation Loss: 0.41972529888153076
Epoch 30, Training Loss: 0.41972529888153076, Validation Loss: 0.4175283908843994
Epoch 31, Training Loss: 0.4175283908843994, Validation Loss: 0.41519367694854736
Epoch 32, Training Loss: 0.41519367694854736, Validation Loss: 0.4127129018306732
Epoch 33, Training Loss: 0.4127129018306732, Validation Loss: 0.4100852906703949
Epoch 34, Training Loss: 0.4100852906703949, Validation Loss: 0.4073140025138855
Epoch 35, Training Loss: 0.4073140025138855, Validation Loss: 0.4043913781642914
Epoch 36, Training Loss: 0.4043913781642914, Validation Loss: 0.4012553095817566
Epoch 37, Training Loss: 0.4012553095817566, Validation Loss: 0.39787015318870544
Epoch 38, Training Loss: 0.39787015318870544, Validation Loss: 0.394265741109848
Epoch 39, Training Loss: 0.394265741109848, Validation Loss: 0.3904075026512146
Epoch 40, Training Loss: 0.3904075026512146, Validation Loss: 0.38626545667648315
Epoch 41, Training Loss: 0.38626545667648315, Validation Loss: 0.3818381726741791
Epoch 42, Training Loss: 0.3818381726741791, Validation Loss: 0.3771097660064697
Epoch 43, Training Loss: 0.3771097660064697, Validation Loss: 0.3720487952232361
Epoch 44, Training Loss: 0.3720487952232361, Validation Loss: 0.36664217710494995
Epoch 45, Training Loss: 0.36664217710494995, Validation Loss: 0.3608684539794922
Epoch 46, Training Loss: 0.36086851358413696, Validation Loss: 0.35470050573349
Epoch 47, Training Loss: 0.3547004461288452, Validation Loss: 0.34811267256736755
Epoch 48, Training Loss: 0.34811267256736755, Validation Loss: 0.34111642837524414
Epoch 49, Training Loss: 0.34111642837524414, Validation Loss: 0.3337275981903076
Epoch 50, Training Loss: 0.3337275981903076, Validation Loss: 0.3258436322212219
Epoch 51, Training Loss: 0.3258436322212219, Validation Loss: 0.3174740672111511
Epoch 52, Training Loss: 0.3174741268157959, Validation Loss: 0.3086062967777252
Epoch 53, Training Loss: 0.30860626697540283, Validation Loss: 0.29925286769866943
Epoch 54, Training Loss: 0.29925286769866943, Validation Loss: 0.28951284289360046
Epoch 55, Training Loss: 0.2895128130912781, Validation Loss: 0.2794438600540161
Epoch 56, Training Loss: 0.2794438600540161, Validation Loss: 0.26908519864082336
Epoch 57, Training Loss: 0.26908519864082336, Validation Loss: 0.25849103927612305
Epoch 58, Training Loss: 0.25849103927612305, Validation Loss: 0.2478516548871994
Epoch 59, Training Loss: 0.2478516548871994, Validation Loss: 0.23722690343856812
Epoch 60, Training Loss: 0.23722687363624573, Validation Loss: 0.2267550677061081
Epoch 61, Training Loss: 0.2267550677061081, Validation Loss: 0.2165980041027069
Epoch 62, Training Loss: 0.2165980041027069, Validation Loss: 0.20699068903923035
Epoch 63, Training Loss: 0.20699070394039154, Validation Loss: 0.198032408952713
Epoch 64, Training Loss: 0.19803237915039062, Validation Loss: 0.18984317779541016
Epoch 65, Training Loss: 0.18984317779541016, Validation Loss: 0.18239960074424744
Epoch 66, Training Loss: 0.18239957094192505, Validation Loss: 0.1756356656551361
Epoch 67, Training Loss: 0.1756356656551361, Validation Loss: 0.16944603621959686
Epoch 68, Training Loss: 0.16944603621959686, Validation Loss: 0.1635035127401352
Epoch 69, Training Loss: 0.163503497838974, Validation Loss: 0.1575707346200943
Epoch 70, Training Loss: 0.1575707197189331, Validation Loss: 0.1513679027557373
Epoch 71, Training Loss: 0.1513679027557373, Validation Loss: 0.1447451412677765
Epoch 72, Training Loss: 0.1447451412677765, Validation Loss: 0.13775014877319336
Epoch 73, Training Loss: 0.13775014877319336, Validation Loss: 0.13038909435272217
Epoch 74, Training Loss: 0.13038909435272217, Validation Loss: 0.12255321443080902
Epoch 75, Training Loss: 0.12255321443080902, Validation Loss: 0.11450504511594772
Epoch 76, Training Loss: 0.11450503766536713, Validation Loss: 0.10652962327003479
Epoch 77, Training Loss: 0.1065296158194542, Validation Loss: 0.09852689504623413
Epoch 78, Training Loss: 0.09852689504623413, Validation Loss: 0.09088723361492157
Epoch 79, Training Loss: 0.09088723361492157, Validation Loss: 0.08369964361190796
Epoch 80, Training Loss: 0.08369966596364975, Validation Loss: 0.07670470327138901
Epoch 81, Training Loss: 0.07670470327138901, Validation Loss: 0.06998291611671448
Epoch 82, Training Loss: 0.06998291611671448, Validation Loss: 0.06370420753955841
Epoch 83, Training Loss: 0.06370420753955841, Validation Loss: 0.05772494524717331
Epoch 84, Training Loss: 0.0577249601483345, Validation Loss: 0.052212268114089966
Epoch 85, Training Loss: 0.05221227928996086, Validation Loss: 0.047061920166015625
Epoch 86, Training Loss: 0.04706193134188652, Validation Loss: 0.042253635823726654
Epoch 87, Training Loss: 0.04225364327430725, Validation Loss: 0.03782952204346657
Epoch 88, Training Loss: 0.03782953694462776, Validation Loss: 0.033769991248846054
Epoch 89, Training Loss: 0.03376999497413635, Validation Loss: 0.03002016805112362
Epoch 90, Training Loss: 0.03002016805112362, Validation Loss: 0.026632580906152725
Epoch 91, Training Loss: 0.026632577180862427, Validation Loss: 0.023552849888801575
Epoch 92, Training Loss: 0.023552849888801575, Validation Loss: 0.02079598978161812
Epoch 93, Training Loss: 0.02079598605632782, Validation Loss: 0.018356265500187874
Epoch 94, Training Loss: 0.018356263637542725, Validation Loss: 0.016198134049773216
Epoch 95, Training Loss: 0.01619812846183777, Validation Loss: 0.014268982224166393
Epoch 96, Training Loss: 0.014268986880779266, Validation Loss: 0.012534628622233868
Epoch 97, Training Loss: 0.012534628622233868, Validation Loss: 0.01098187081515789
Epoch 98, Training Loss: 0.01098187267780304, Validation Loss: 0.009573133662343025
Epoch 99, Training Loss: 0.009573135524988174, Validation Loss: 0.008249744772911072
Epoch 100, Training Loss: 0.008249741047620773, Validation Loss: 0.007012101821601391
Epoch 101, Training Loss: 0.007012100424617529, Validation Loss: 0.005864541977643967
Epoch 102, Training Loss: 0.005864537786692381, Validation Loss: 0.00483662448823452
Epoch 103, Training Loss: 0.004836625419557095, Validation Loss: 0.00395698007196188
Epoch 104, Training Loss: 0.003956981003284454, Validation Loss: 0.00321866013109684
Epoch 105, Training Loss: 0.0032186596654355526, Validation Loss: 0.0025859109591692686
Epoch 106, Training Loss: 0.0025859130546450615, Validation Loss: 0.002056211233139038
Epoch 107, Training Loss: 0.0020562107674777508, Validation Loss: 0.0016256957314908504
Epoch 108, Training Loss: 0.0016256936360150576, Validation Loss: 0.0012797191739082336
Epoch 109, Training Loss: 0.0012797180097550154, Validation Loss: 0.0010093878954648972
Epoch 110, Training Loss: 0.0010093885939568281, Validation Loss: 0.000801367568783462
Epoch 111, Training Loss: 0.0008013676851987839, Validation Loss: 0.0006384393782354891
Epoch 112, Training Loss: 0.0006384389707818627, Validation Loss: 0.0005155003163963556
Epoch 113, Training Loss: 0.0005154999671503901, Validation Loss: 0.00042561008012853563
Epoch 114, Training Loss: 0.00042560952715575695, Validation Loss: 0.00036380853271111846
Epoch 115, Training Loss: 0.0003638079797383398, Validation Loss: 0.0003266166604589671
Epoch 116, Training Loss: 0.00032661587465554476, Validation Loss: 0.00031001781462691724
Epoch 117, Training Loss: 0.00031001720344647765, Validation Loss: 0.00030947779305279255
Epoch 118, Training Loss: 0.00030947785126045346, Validation Loss: 0.0003197862533852458
Epoch 119, Training Loss: 0.00031978663173504174, Validation Loss: 0.0003355695807840675
Epoch 120, Training Loss: 0.00033556888229213655, Validation Loss: 0.00035214232048019767
Epoch 121, Training Loss: 0.00035214261151850224, Validation Loss: 0.00036538986023515463
Epoch 122, Training Loss: 0.00036539032589644194, Validation Loss: 0.0003726327558979392
Epoch 123, Training Loss: 0.0003726318245753646, Validation Loss: 0.0003725790302269161
Epoch 124, Training Loss: 0.00037257917574606836, Validation Loss: 0.0003652065934147686
Epoch 125, Training Loss: 0.00036520732101053, Validation Loss: 0.0003513287228997797
Epoch 126, Training Loss: 0.0003513285773806274, Validation Loss: 0.00033242598874494433
Epoch 127, Training Loss: 0.0003324260178487748, Validation Loss: 0.000310164294205606
Epoch 128, Training Loss: 0.0003101638285443187, Validation Loss: 0.0002861149550881237
Epoch 129, Training Loss: 0.00028611451853066683, Validation Loss: 0.00026157969841733575
Epoch 130, Training Loss: 0.0002615795820020139, Validation Loss: 0.0002375201293034479
Epoch 131, Training Loss: 0.00023752071138005704, Validation Loss: 0.00021457902039401233
Epoch 132, Training Loss: 0.00021457939874380827, Validation Loss: 0.00019313301891088486
Epoch 133, Training Loss: 0.00019313294615130872, Validation Loss: 0.0001733694225549698
Epoch 134, Training Loss: 0.00017337016470264643, Validation Loss: 0.0001553423353470862
Epoch 135, Training Loss: 0.00015534265548922122, Validation Loss: 0.00013900069461669773
Epoch 136, Training Loss: 0.00013900034537073225, Validation Loss: 0.00012421463907230645
Epoch 137, Training Loss: 0.00012421402789186686, Validation Loss: 0.0001107971984311007
Epoch 138, Training Loss: 0.00011079707473982126, Validation Loss: 9.853288065642118e-05
Epoch 139, Training Loss: 9.853288065642118e-05, Validation Loss: 8.721143240109086e-05
Epoch 140, Training Loss: 8.721166523173451e-05, Validation Loss: 7.666913006687537e-05
Epoch 141, Training Loss: 7.666921010240912e-05, Validation Loss: 6.681499507976696e-05
Epoch 142, Training Loss: 6.681488594040275e-05, Validation Loss: 5.763768422184512e-05
Epoch 143, Training Loss: 5.763759691035375e-05, Validation Loss: 4.919335333397612e-05
Epoch 144, Training Loss: 4.919326966046356e-05, Validation Loss: 4.1571409383323044e-05
Epoch 145, Training Loss: 4.15714384871535e-05, Validation Loss: 3.485882916720584e-05
Epoch 146, Training Loss: 3.485878914943896e-05, Validation Loss: 2.910449984483421e-05
Epoch 147, Training Loss: 2.9104388886480592e-05, Validation Loss: 2.4300941731780767e-05
Epoch 148, Training Loss: 2.4301156372530386e-05, Validation Loss: 2.038142702076584e-05
Epoch 149, Training Loss: 2.038142702076584e-05, Validation Loss: 1.723369314277079e-05
Epoch 150, Training Loss: 1.7233649487025104e-05, Validation Loss: 1.4723969798069447e-05
Epoch 151, Training Loss: 1.4724018910783343e-05, Validation Loss: 1.2720651284325868e-05
Epoch 152, Training Loss: 1.2720620361506008e-05, Validation Loss: 1.111359233618714e-05
Epoch 153, Training Loss: 1.1113514119642787e-05, Validation Loss: 9.8226837508264e-06
Epoch 154, Training Loss: 9.822712854656857e-06, Validation Loss: 8.797369446256198e-06
Epoch 155, Training Loss: 8.79738036019262e-06, Validation Loss: 8.005804374988656e-06
Epoch 156, Training Loss: 8.005848940229043e-06, Validation Loss: 7.422091584885493e-06
Epoch 157, Training Loss: 7.422132966894424e-06, Validation Loss: 7.014803031779593e-06
Epoch 158, Training Loss: 7.014933999016648e-06, Validation Loss: 6.74117245580419e-06
Epoch 159, Training Loss: 6.7411451709631365e-06, Validation Loss: 6.5482163336128e-06
Epoch 160, Training Loss: 6.547983502969146e-06, Validation Loss: 6.379742899298435e-06
Epoch 161, Training Loss: 6.37967877992196e-06, Validation Loss: 6.1880509747425094e-06
Epoch 162, Training Loss: 6.188043698784895e-06, Validation Loss: 5.942260941083077e-06
Epoch 163, Training Loss: 5.942275947745657e-06, Validation Loss: 5.634079570882022e-06
Epoch 164, Training Loss: 5.634064109472092e-06, Validation Loss: 5.276512638374697e-06
Epoch 165, Training Loss: 5.276579031487927e-06, Validation Loss: 4.897718099527992e-06
Epoch 166, Training Loss: 4.897709004580975e-06, Validation Loss: 4.5305860112421215e-06
Epoch 167, Training Loss: 4.530578735284507e-06, Validation Loss: 4.20253309130203e-06
Epoch 168, Training Loss: 4.202454874757677e-06, Validation Loss: 3.927942088921554e-06
Epoch 169, Training Loss: 3.927986654161941e-06, Validation Loss: 3.7056033761473373e-06
Epoch 170, Training Loss: 3.705563131006784e-06, Validation Loss: 3.5202192520955577e-06
Epoch 171, Training Loss: 3.5202544950152515e-06, Validation Loss: 3.349042799527524e-06
Epoch 172, Training Loss: 3.3490655368950684e-06, Validation Loss: 3.168708190059988e-06
Epoch 173, Training Loss: 3.168762759742094e-06, Validation Loss: 2.9621448902616976e-06
Epoch 174, Training Loss: 2.962086682600784e-06, Validation Loss: 2.722063072724268e-06
Epoch 175, Training Loss: 2.722026692936197e-06, Validation Loss: 2.4522710191376973e-06
Epoch 176, Training Loss: 2.4522305466234684e-06, Validation Loss: 2.1645005290338304e-06
Epoch 177, Training Loss: 2.1645050765073393e-06, Validation Loss: 1.8744556200545048e-06
Epoch 178, Training Loss: 1.8744674434856279e-06, Validation Loss: 1.597165805833356e-06
Epoch 179, Training Loss: 1.5971754692145623e-06, Validation Loss: 1.3436942936095875e-06
Epoch 180, Training Loss: 1.3436715562420432e-06, Validation Loss: 1.1194097169209272e-06
Epoch 181, Training Loss: 1.1194076705578482e-06, Validation Loss: 9.247175398741092e-07
Epoch 182, Training Loss: 9.247241905541159e-07, Validation Loss: 7.565413397969678e-07
Epoch 183, Training Loss: 7.565074611193268e-07, Validation Loss: 6.109025889600161e-07
Epoch 184, Training Loss: 6.109105470386567e-07, Validation Loss: 4.847576633437711e-07
Epoch 185, Training Loss: 4.847665309171134e-07, Validation Loss: 3.7697844845752115e-07
Epoch 186, Training Loss: 3.76989731876165e-07, Validation Loss: 2.88168621409568e-07
Epoch 187, Training Loss: 2.8817248676205054e-07, Validation Loss: 2.1965051644201594e-07
Epoch 188, Training Loss: 2.196430841649999e-07, Validation Loss: 1.7216136427578022e-07
Epoch 189, Training Loss: 1.721789288922082e-07, Validation Loss: 1.4487993382772402e-07
Epoch 190, Training Loss: 1.4487932276097126e-07, Validation Loss: 1.347959255326714e-07
Epoch 191, Training Loss: 1.348168723325216e-07, Validation Loss: 1.3723023073453078e-07
Epoch 192, Training Loss: 1.3722686276196328e-07, Validation Loss: 1.465545267365087e-07
Epoch 193, Training Loss: 1.4655584834599722e-07, Validation Loss: 1.5746937265248562e-07
Epoch 194, Training Loss: 1.5747204429317208e-07, Validation Loss: 1.65887797720643e-07
Epoch 195, Training Loss: 1.6591604889981681e-07, Validation Loss: 1.6959874926669727e-07
Epoch 196, Training Loss: 1.695990476946463e-07, Validation Loss: 1.6815462799968373e-07
Epoch 197, Training Loss: 1.6816440506772778e-07, Validation Loss: 1.6259315316347056e-07
Epoch 198, Training Loss: 1.6260014490399044e-07, Validation Loss: 1.5460666702438175e-07
Epoch 199, Training Loss: 1.546151224829373e-07, Validation Loss: 1.4593780406357837e-07
Epoch 200, Training Loss: 1.4593136654639238e-07, Validation Loss: 1.3773114915238693e-07
Epoch 201, Training Loss: 1.3773014018170215e-07, Validation Loss: 1.304315446759574e-07
Epoch 202, Training Loss: 1.3043700164416805e-07, Validation Loss: 1.2386627190608124e-07
Epoch 203, Training Loss: 1.238560400906863e-07, Validation Loss: 1.1743655647933338e-07
Epoch 204, Training Loss: 1.1742429251171416e-07, Validation Loss: 1.1050700265968771e-07
Epoch 205, Training Loss: 1.1049516501770995e-07, Validation Loss: 1.0272930239807465e-07
Epoch 206, Training Loss: 1.0272526651533553e-07, Validation Loss: 9.403579781519511e-08
Epoch 207, Training Loss: 9.402951661741099e-08, Validation Loss: 8.469504564345698e-08
Epoch 208, Training Loss: 8.470620826983577e-08, Validation Loss: 7.517613198615436e-08
Epoch 209, Training Loss: 7.517704858628349e-08, Validation Loss: 6.593405998955859e-08
Epoch 210, Training Loss: 6.59307062278458e-08, Validation Loss: 5.7318885637869244e-08
Epoch 211, Training Loss: 5.730985819241141e-08, Validation Loss: 4.946556231288923e-08
Epoch 212, Training Loss: 4.9465967322248616e-08, Validation Loss: 4.238766138087158e-08
Epoch 213, Training Loss: 4.2390063015318447e-08, Validation Loss: 3.5985785018510796e-08
Epoch 214, Training Loss: 3.598610121002821e-08, Validation Loss: 3.014119442923402e-08
Epoch 215, Training Loss: 3.0145741902742884e-08, Validation Loss: 2.4825101974101926e-08
Epoch 216, Training Loss: 2.482613226106878e-08, Validation Loss: 2.005757515632922e-08
Epoch 217, Training Loss: 2.0060694438939208e-08, Validation Loss: 1.5922633878062697e-08
Epoch 218, Training Loss: 1.592349008205929e-08, Validation Loss: 1.2526959025649376e-08
Epoch 219, Training Loss: 1.2520554371064918e-08, Validation Loss: 9.91016779749998e-09
Epoch 220, Training Loss: 9.908485587573068e-09, Validation Loss: 8.07220423837407e-09
Epoch 221, Training Loss: 8.073792301388494e-09, Validation Loss: 6.916601957840385e-09
Epoch 222, Training Loss: 6.919195438825909e-09, Validation Loss: 6.286253295684219e-09
Epoch 223, Training Loss: 6.2860467942016385e-09, Validation Loss: 5.9957221409945305e-09
Epoch 224, Training Loss: 5.996635188409982e-09, Validation Loss: 5.880354869702842e-09
Epoch 225, Training Loss: 5.882006881563484e-09, Validation Loss: 5.811641834441161e-09
Epoch 226, Training Loss: 5.812875070176915e-09, Validation Loss: 5.707808892196908e-09
Epoch 227, Training Loss: 5.709714478996375e-09, Validation Loss: 5.542912795419852e-09
Epoch 228, Training Loss: 5.544610992558319e-09, Validation Loss: 5.325182961257724e-09
Epoch 229, Training Loss: 5.32190602697824e-09, Validation Loss: 5.064655361763926e-09
Epoch 230, Training Loss: 5.0668713669210774e-09, Validation Loss: 4.799762809426511e-09
Epoch 231, Training Loss: 4.803954567478286e-09, Validation Loss: 4.549094434480594e-09
Epoch 232, Training Loss: 4.549259635666658e-09, Validation Loss: 4.317662227748542e-09
Epoch 233, Training Loss: 4.317107560325439e-09, Validation Loss: 4.105713991009452e-09
Epoch 234, Training Loss: 4.104823148054493e-09, Validation Loss: 3.910195722767185e-09
Epoch 235, Training Loss: 3.9094287807017736e-09, Validation Loss: 3.728710673556179e-09
Epoch 236, Training Loss: 3.7295868615672134e-09, Validation Loss: 3.5478695536994564e-09
Epoch 237, Training Loss: 3.5489526872822807e-09, Validation Loss: 3.364299061558995e-09
Epoch 238, Training Loss: 3.3634002249982586e-09, Validation Loss: 3.1681719470100234e-09
Epoch 239, Training Loss: 3.1685896129118873e-09, Validation Loss: 2.9577387206103367e-09
Epoch 240, Training Loss: 2.954559708001625e-09, Validation Loss: 2.7214617226434257e-09
Epoch 241, Training Loss: 2.721283420825671e-09, Validation Loss: 2.469972226748496e-09
Epoch 242, Training Loss: 2.4696205080942946e-09, Validation Loss: 2.2034434277173887e-09
Epoch 243, Training Loss: 2.204188831456122e-09, Validation Loss: 1.931490301032568e-09
Epoch 244, Training Loss: 1.9304067233605338e-09, Validation Loss: 1.6603229902045769e-09
Epoch 245, Training Loss: 1.6600254504339773e-09, Validation Loss: 1.3994559955321506e-09
Epoch 246, Training Loss: 1.3994965186725494e-09, Validation Loss: 1.1571011926392316e-09
Epoch 247, Training Loss: 1.155711193412401e-09, Validation Loss: 9.405303202925097e-10
Epoch 248, Training Loss: 9.390095367933782e-10, Validation Loss: 7.495807863300286e-10
Epoch 249, Training Loss: 7.497302778602943e-10, Validation Loss: 5.892175636290631e-10
Epoch 250, Training Loss: 5.882939690948774e-10, Validation Loss: 4.5586512342765673e-10
Epoch 251, Training Loss: 4.556271471223283e-10, Validation Loss: 3.513320190329239e-10
Epoch 252, Training Loss: 3.5055375269266165e-10, Validation Loss: 2.7346711006792646e-10
Epoch 253, Training Loss: 2.7366670041217844e-10, Validation Loss: 2.2105377250891678e-10
Epoch 254, Training Loss: 2.2076729333520007e-10, Validation Loss: 1.9013976504389518e-10
Epoch 255, Training Loss: 1.9045345855950302e-10, Validation Loss: 1.7671208940583938e-10
Epoch 256, Training Loss: 1.7716741962381377e-10, Validation Loss: 1.756499390381805e-10
Epoch 257, Training Loss: 1.753562156592281e-10, Validation Loss: 1.7983679823085907e-10
Epoch 258, Training Loss: 1.7987211720082996e-10, Validation Loss: 1.8514775823597063e-10
Epoch 259, Training Loss: 1.8478280017220072e-10, Validation Loss: 1.8762302822494803e-10
Epoch 260, Training Loss: 1.8793859524190992e-10, Validation Loss: 1.876103716824673e-10
Epoch 261, Training Loss: 1.8797716161422784e-10, Validation Loss: 1.8352980246660877e-10
Epoch 262, Training Loss: 1.837829194384355e-10, Validation Loss: 1.7775202143521796e-10
Epoch 263, Training Loss: 1.7762588622183273e-10, Validation Loss: 1.7170879995642707e-10
Epoch 264, Training Loss: 1.7122070428143843e-10, Validation Loss: 1.6587574369619773e-10
Epoch 265, Training Loss: 1.65896449355607e-10, Validation Loss: 1.604417432243821e-10
Epoch 266, Training Loss: 1.604866795013038e-10, Validation Loss: 1.557806939000983e-10
Epoch 267, Training Loss: 1.5598432268060236e-10, Validation Loss: 1.5013379428552298e-10
Epoch 268, Training Loss: 1.5000786723895487e-10, Validation Loss: 1.424737827715461e-10
Epoch 269, Training Loss: 1.4216239296871436e-10, Validation Loss: 1.3227273443217058e-10
Epoch 270, Training Loss: 1.320811515714837e-10, Validation Loss: 1.2048698150302073e-10
Epoch 271, Training Loss: 1.2019343853530984e-10, Validation Loss: 1.0801909366975337e-10
Epoch 272, Training Loss: 1.0798249794330417e-10, Validation Loss: 9.427152114493964e-11
Epoch 273, Training Loss: 9.439642123520997e-11, Validation Loss: 8.186055999725994e-11
Epoch 274, Training Loss: 8.200094769872379e-11, Validation Loss: 6.99407406989927e-11
Epoch 275, Training Loss: 6.989318845906922e-11, Validation Loss: 5.938619734857653e-11
Epoch 276, Training Loss: 5.959270577005071e-11, Validation Loss: 5.0364417497617e-11
Epoch 277, Training Loss: 5.042441464375713e-11, Validation Loss: 4.2389272647547216e-11
Epoch 278, Training Loss: 4.217941967921135e-11, Validation Loss: 3.488837690968083e-11
Epoch 279, Training Loss: 3.478269061663042e-11, Validation Loss: 2.8169012261658466e-11
Epoch 280, Training Loss: 2.8339299656954253e-11, Validation Loss: 2.250166025730138e-11
Epoch 281, Training Loss: 2.2452642176040705e-11, Validation Loss: 1.7678344899074716e-11
Epoch 282, Training Loss: 1.761586536364046e-11, Validation Loss: 1.3654764818848975e-11
Epoch 283, Training Loss: 1.3711750485034813e-11, Validation Loss: 1.0872854699917056e-11
Epoch 284, Training Loss: 1.0859434011745162e-11, Validation Loss: 9.117885266252124e-12
Epoch 285, Training Loss: 9.029871468613226e-12, Validation Loss: 8.07817181203152e-12
Epoch 286, Training Loss: 8.16959087185376e-12, Validation Loss: 7.728379568250343e-12
Epoch 287, Training Loss: 7.715011789144466e-12, Validation Loss: 7.607196123027293e-12
Epoch 288, Training Loss: 7.574166988044695e-12, Validation Loss: 7.558139877850145e-12
Epoch 289, Training Loss: 7.409562546856208e-12, Validation Loss: 7.255407212525267e-12
Epoch 290, Training Loss: 7.379294224285626e-12, Validation Loss: 7.177666013630235e-12
Epoch 291, Training Loss: 7.291083535532206e-12, Validation Loss: 7.159372920895191e-12
Epoch 292, Training Loss: 7.008930762164578e-12, Validation Loss: 6.840040252947821e-12
Epoch 293, Training Loss: 6.971704030050985e-12, Validation Loss: 6.7302738902819126e-12
Epoch 294, Training Loss: 6.750503801777885e-12, Validation Loss: 6.605776255858009e-12
Epoch 295, Training Loss: 6.603975612889945e-12, Validation Loss: 6.598255795908781e-12
Epoch 296, Training Loss: 6.5984192935963915e-12, Validation Loss: 6.419908007981867e-12
Epoch 297, Training Loss: 6.4433623367388115e-12, Validation Loss: 6.358124964023215e-12
Epoch 298, Training Loss: 6.311918869517097e-12, Validation Loss: 6.096801882793379e-12
Epoch 299, Training Loss: 6.133811340791606e-12, Validation Loss: 5.7904028794020235e-12
Epoch 300, Training Loss: 5.7426056097875655e-12, Validation Loss: 5.367927456700894e-12
Epoch 301, Training Loss: 5.363510850731057e-12, Validation Loss: 4.889517176559499e-12
Epoch 302, Training Loss: 4.8686952906773495e-12, Validation Loss: 4.377945922451332e-12
Epoch 303, Training Loss: 4.303035358588225e-12, Validation Loss: 3.852327744996442e-12
Epoch 304, Training Loss: 3.741579528843131e-12, Validation Loss: 3.277261058018399e-12
Epoch 305, Training Loss: 3.2235060974661334e-12, Validation Loss: 2.721064259331163e-12
Epoch 306, Training Loss: 2.6733767109765605e-12, Validation Loss: 2.243337026558434e-12
Epoch 307, Training Loss: 2.2278355375771053e-12, Validation Loss: 1.833619193980507e-12
Epoch 308, Training Loss: 1.7918664598978729e-12, Validation Loss: 1.4669550296719791e-12
Epoch 309, Training Loss: 1.4327018304366446e-12, Validation Loss: 1.1688540760279587e-12
Epoch 310, Training Loss: 1.1740707147808727e-12, Validation Loss: 9.400119571623122e-13
Epoch 311, Training Loss: 9.115237861387349e-13, Validation Loss: 7.141942202568141e-13
Epoch 312, Training Loss: 6.871414786994989e-13, Validation Loss: 5.941622519510525e-13
Epoch 313, Training Loss: 5.536881717005393e-13, Validation Loss: 4.676474051751311e-13
Epoch 314, Training Loss: 4.697964565113233e-13, Validation Loss: 3.544949435992789e-13
Epoch 315, Training Loss: 3.9181087844661344e-13, Validation Loss: 3.2034777933641345e-13
Epoch 316, Training Loss: 3.2322807082783844e-13, Validation Loss: 2.7160082993402113e-13
Epoch 317, Training Loss: 2.9720656816688285e-13, Validation Loss: 2.4465173810439556e-13
Epoch 318, Training Loss: 2.535277489248283e-13, Validation Loss: 2.576011778020193e-13
Epoch 319, Training Loss: 2.4756086937360866e-13, Validation Loss: 2.432093968492838e-13
Epoch 320, Training Loss: 2.4706265137029726e-13, Validation Loss: 2.377315466879637e-13
Epoch 321, Training Loss: 2.4581790596112096e-13, Validation Loss: 2.365070758594129e-13
Epoch 322, Training Loss: 2.42673719660913e-13, Validation Loss: 2.4772810755871455e-13
Epoch 323, Training Loss: 2.4079623386387417e-13, Validation Loss: 2.395464198095415e-13
Epoch 324, Training Loss: 2.400495709327377e-13, Validation Loss: 2.2294912769248165e-13
Epoch 325, Training Loss: 2.2297272264226037e-13, Validation Loss: 2.1418132024886294e-13
Epoch 326, Training Loss: 2.0655493374738265e-13, Validation Loss: 2.0084495590093343e-13
Epoch 327, Training Loss: 2.14924649258319e-13, Validation Loss: 1.8973714201349356e-13
Epoch 328, Training Loss: 1.8866744104506505e-13, Validation Loss: 1.7680938635931953e-13
Epoch 329, Training Loss: 1.7838690052028594e-13, Validation Loss: 1.7989053985572462e-13
Epoch 330, Training Loss: 1.728804138690851e-13, Validation Loss: 1.5555406355366452e-13
Epoch 331, Training Loss: 1.682859445328519e-13, Validation Loss: 1.4863152755003467e-13
Epoch 332, Training Loss: 1.5801508051246221e-13, Validation Loss: 1.3791254921922957e-13
Epoch 333, Training Loss: 1.4777015602904925e-13, Validation Loss: 1.2803511506218057e-13
Epoch 334, Training Loss: 1.3520554034002208e-13, Validation Loss: 1.1915623110599072e-13
Epoch 335, Training Loss: 1.2701203478716894e-13, Validation Loss: 1.1539562166061612e-13
Epoch 336, Training Loss: 1.045222800455034e-13, Validation Loss: 1.0142722165623619e-13
Epoch 337, Training Loss: 9.331022689544263e-14, Validation Loss: 9.83470236129956e-14
Epoch 338, Training Loss: 9.237865328378878e-14, Validation Loss: 9.136479550350685e-14
Epoch 339, Training Loss: 8.448024045723188e-14, Validation Loss: 7.879849930111232e-14
Epoch 340, Training Loss: 6.980002784529732e-14, Validation Loss: 6.90391957470192e-14
Epoch 341, Training Loss: 6.675885430400263e-14, Validation Loss: 6.134627311346619e-14
Epoch 342, Training Loss: 6.119290593990453e-14, Validation Loss: 6.322971524619012e-14
Epoch 343, Training Loss: 5.274315597984802e-14, Validation Loss: 5.1610083394437734e-14
Epoch 344, Training Loss: 4.909809199287428e-14, Validation Loss: 4.6965659443107266e-14
Epoch 345, Training Loss: 3.398321256559492e-14, Validation Loss: 4.4435450056914266e-14
Epoch 346, Training Loss: 3.1975507311376994e-14, Validation Loss: 3.828910794109394e-14
Epoch 347, Training Loss: 3.159043935729161e-14, Validation Loss: 3.0051597332565044e-14
Epoch 348, Training Loss: 2.9737666593521866e-14, Validation Loss: 3.1652997822644025e-14
Epoch 349, Training Loss: 2.802582994777987e-14, Validation Loss: 3.058599041898778e-14
Epoch 350, Training Loss: 2.6927765234079602e-14, Validation Loss: 3.512499603783477e-14
Epoch 351, Training Loss: 2.218333210266682e-14, Validation Loss: 2.21210226650009e-14
Epoch 352, Training Loss: 2.4212778998574866e-14, Validation Loss: 2.4881631789110646e-14
Epoch 353, Training Loss: 2.1309898832512497e-14, Validation Loss: 1.9419482230500877e-14
Epoch 354, Training Loss: 2.014098489497209e-14, Validation Loss: 2.0024236649786135e-14
Epoch 355, Training Loss: 1.5322859897148183e-14, Validation Loss: 1.8082791394900127e-14
Epoch 356, Training Loss: 1.4779711878182625e-14, Validation Loss: 1.2394218071028022e-14
Epoch 357, Training Loss: 1.5468613938579914e-14, Validation Loss: 1.1675924814393956e-14
Epoch 358, Training Loss: 1.179168626619636e-14, Validation Loss: 1.1470396504907436e-14
Epoch 359, Training Loss: 8.302579679536973e-15, Validation Loss: 1.148278774989282e-14
Epoch 360, Training Loss: 1.021478620411671e-14, Validation Loss: 9.348794118404016e-15
Epoch 361, Training Loss: 9.780563234036265e-15, Validation Loss: 8.620729489690424e-15
Epoch 362, Training Loss: 8.583351619793986e-15, Validation Loss: 9.743334441938544e-15
Epoch 363, Training Loss: 8.663762998575679e-15, Validation Loss: 1.0583234524744016e-14
Epoch 364, Training Loss: 6.999223825575416e-15, Validation Loss: 8.89692575796637e-15
Epoch 365, Training Loss: 6.774432292802439e-15, Validation Loss: 7.83590264208248e-15
Epoch 366, Training Loss: 5.700566463372279e-15, Validation Loss: 8.246128321734263e-15
Epoch 367, Training Loss: 5.4042175872152584e-15, Validation Loss: 8.474466381457393e-15
Epoch 368, Training Loss: 5.0960153319943614e-15, Validation Loss: 6.1702835020744674e-15
Epoch 369, Training Loss: 4.9098578189786e-15, Validation Loss: 4.9878568479265126e-15
Epoch 370, Training Loss: 4.760309916976117e-15, Validation Loss: 5.441848719962925e-15
Epoch 371, Training Loss: 4.572164841149624e-15, Validation Loss: 5.717524910009257e-15
Epoch 372, Training Loss: 4.427423851122809e-15, Validation Loss: 5.67838521158253e-15
Epoch 373, Training Loss: 4.031039536862109e-15, Validation Loss: 5.672182812826261e-15
Epoch 374, Training Loss: 4.2864775686996936e-15, Validation Loss: 5.733693074906447e-15
Epoch 375, Training Loss: 4.228472752471719e-15, Validation Loss: 6.769553383026254e-15
Epoch 376, Training Loss: 3.829811613648799e-15, Validation Loss: 6.124837219838959e-15
Epoch 377, Training Loss: 6.087590216532872e-15, Validation Loss: 5.711010803128398e-15
Epoch 378, Training Loss: 5.1277100343311965e-15, Validation Loss: 5.4584641182562656e-15
Epoch 379, Training Loss: 5.516577354701489e-15, Validation Loss: 4.994448034805572e-15
Epoch 380, Training Loss: 4.598402533723773e-15, Validation Loss: 3.163063276470472e-15
Epoch 381, Training Loss: 4.14751884908731e-15, Validation Loss: 4.1724377113625845e-15
Epoch 382, Training Loss: 3.797466390008473e-15, Validation Loss: 4.777675362944251e-15
Epoch 383, Training Loss: 4.050663596184096e-15, Validation Loss: 5.217653498384815e-15
Epoch 384, Training Loss: 2.5955196498328057e-15, Validation Loss: 4.808841516722e-15
Epoch 385, Training Loss: 2.906179782908398e-15, Validation Loss: 5.52907701990412e-15
Epoch 386, Training Loss: 2.5653066198789553e-15, Validation Loss: 5.516116568778182e-15
Epoch 387, Training Loss: 2.3761133407802348e-15, Validation Loss: 4.526994268138447e-15
Epoch 388, Training Loss: 2.129312715664039e-15, Validation Loss: 4.52956458961689e-15
Epoch 389, Training Loss: 1.9788976636818043e-15, Validation Loss: 4.532162439666119e-15
Epoch 390, Training Loss: 1.8661406377433118e-15, Validation Loss: 6.17981516382992e-15
Epoch 391, Training Loss: 2.521721692545038e-15, Validation Loss: 6.070491585943123e-15
Epoch 392, Training Loss: 2.185908069067782e-15, Validation Loss: 4.1919533504673236e-15
Epoch 393, Training Loss: 2.2643320967969793e-15, Validation Loss: 4.5330475890959995e-15
Epoch 394, Training Loss: 4.07422678222729e-15, Validation Loss: 4.240457845158894e-15
Epoch 395, Training Loss: 3.369242530776957e-15, Validation Loss: 4.22278534974738e-15
Epoch 396, Training Loss: 2.804336988253514e-15, Validation Loss: 4.341324646100304e-15
Epoch 397, Training Loss: 2.697000973177449e-15, Validation Loss: 4.308346688848379e-15
Epoch 398, Training Loss: 2.1019186113586507e-15, Validation Loss: 4.2693154106389006e-15
Epoch 399, Training Loss: 2.25229745268239e-15, Validation Loss: 4.280157432363756e-15
Epoch 400, Training Loss: 1.9109543981254582e-15, Validation Loss: 4.086446926557328e-15
Epoch 401, Training Loss: 1.8194477347676817e-15, Validation Loss: 3.9882542086303995e-15
Epoch 402, Training Loss: 1.6442406636940242e-15, Validation Loss: 4.3065353088906754e-15
Epoch 403, Training Loss: 1.1676253886693964e-15, Validation Loss: 4.2076560707599974e-15
Epoch 404, Training Loss: 2.1894859362369843e-15, Validation Loss: 4.1318296813217924e-15
Epoch 405, Training Loss: 2.2568511018068293e-15, Validation Loss: 4.055501848378813e-15
Epoch 406, Training Loss: 2.6159388613340284e-15, Validation Loss: 4.3475181510106275e-15
Epoch 407, Training Loss: 2.647163883901611e-15, Validation Loss: 5.086627665839942e-15
Epoch 408, Training Loss: 2.6370445930390006e-15, Validation Loss: 5.0460065067884675e-15
Epoch 409, Training Loss: 2.702277353164133e-15, Validation Loss: 5.0460065067884675e-15
Epoch 410, Training Loss: 2.2881845445916604e-15, Validation Loss: 4.993603119440686e-15
Epoch 411, Training Loss: 2.304808836730947e-15, Validation Loss: 4.9195614284223456e-15
Epoch 412, Training Loss: 2.2881845445916604e-15, Validation Loss: 4.887902724985769e-15
Epoch 413, Training Loss: 2.2721021417803798e-15, Validation Loss: 6.112834339459892e-15
Epoch 414, Training Loss: 1.5436989116461228e-15, Validation Loss: 6.128938976886038e-15
Epoch 415, Training Loss: 1.5436989116461228e-15, Validation Loss: 4.2348377815538615e-15
Epoch 416, Training Loss: 1.617713815247506e-15, Validation Loss: 4.269893934141875e-15
Epoch 417, Training Loss: 1.802751021311405e-15, Validation Loss: 4.274953261935825e-15
Epoch 418, Training Loss: 2.5051333993060098e-15, Validation Loss: 5.536639330057207e-15
Epoch 419, Training Loss: 2.8867725640209074e-15, Validation Loss: 5.414341325000842e-15
Epoch 420, Training Loss: 2.4565611419786592e-15, Validation Loss: 5.553119203078986e-15
Epoch 421, Training Loss: 2.5420684827292704e-15, Validation Loss: 5.561684400241622e-15
Epoch 422, Training Loss: 2.115326507638976e-15, Validation Loss: 4.180334176013363e-15
Epoch 423, Training Loss: 2.1205306780669063e-15, Validation Loss: 4.397210609410722e-15
Epoch 424, Training Loss: 2.1205306780669063e-15, Validation Loss: 4.375594328596792e-15
Epoch 425, Training Loss: 1.412763499868369e-15, Validation Loss: 5.522680227086456e-15
Epoch 426, Training Loss: 1.202681223620055e-15, Validation Loss: 5.4243795124587525e-15
Epoch 427, Training Loss: 1.1332922845809826e-15, Validation Loss: 5.552915915171645e-15
Epoch 428, Training Loss: 1.1636499454105768e-15, Validation Loss: 4.726320178868697e-15
Epoch 429, Training Loss: 1.192562038636563e-15, Validation Loss: 4.726320178868697e-15
Epoch 430, Training Loss: 1.0780702892220937e-15, Validation Loss: 4.655445120523667e-15
Epoch 431, Training Loss: 1.1960314855885166e-15, Validation Loss: 4.685947200470768e-15
Epoch 432, Training Loss: 1.7025707405737443e-15, Validation Loss: 4.727544564993953e-15
Epoch 433, Training Loss: 1.665274185840243e-15, Validation Loss: 4.754437437552803e-15
Epoch 434, Training Loss: 1.6051370700466742e-15, Validation Loss: 4.754437437552803e-15
Epoch 435, Training Loss: 1.4524814041607151e-15, Validation Loss: 4.736656521924041e-15
Epoch 436, Training Loss: 1.049736401861727e-15, Validation Loss: 5.306332342248183e-15
Epoch 437, Training Loss: 1.6707674062614239e-15, Validation Loss: 5.052629033886575e-15
Epoch 438, Training Loss: 2.2202050683768192e-15, Validation Loss: 5.066940502563384e-15
Epoch 439, Training Loss: 2.146081638679069e-15, Validation Loss: 5.2334739562571574e-15
Epoch 440, Training Loss: 2.5103735686341985e-15, Validation Loss: 4.797660681818243e-15
Epoch 441, Training Loss: 2.5103735686341985e-15, Validation Loss: 4.797863969725584e-15
Epoch 442, Training Loss: 3.278856068491924e-15, Validation Loss: 4.810007034057422e-15
Epoch 443, Training Loss: 1.1833101095119411e-15, Validation Loss: 4.760458994774834e-15
Epoch 444, Training Loss: 1.4169556776825673e-15, Validation Loss: 4.774485860381365e-15
Epoch 445, Training Loss: 1.3846103481631226e-15, Validation Loss: 4.9900616746882155e-15
Epoch 446, Training Loss: 7.269694151127923e-16, Validation Loss: 4.553345039611054e-15
Epoch 447, Training Loss: 7.454008520450459e-16, Validation Loss: 4.886411946998601e-15
Epoch 448, Training Loss: 1.638205236307482e-15, Validation Loss: 4.886411946998601e-15
Epoch 449, Training Loss: 2.2577184635448177e-15, Validation Loss: 4.9465174049357664e-15
Epoch 450, Training Loss: 2.619227466751743e-15, Validation Loss: 5.4668844727849206e-15
Epoch 451, Training Loss: 2.619227466751743e-15, Validation Loss: 5.418579030835955e-15
Epoch 452, Training Loss: 2.1040145943866315e-15, Validation Loss: 5.351358496141854e-15
Epoch 453, Training Loss: 2.0953409770067474e-15, Validation Loss: 5.392991859565297e-15
Epoch 454, Training Loss: 2.090136806578817e-15, Validation Loss: 6.765433414770809e-15
Epoch 455, Training Loss: 1.834698774741232e-15, Validation Loss: 6.765433414770809e-15
Epoch 456, Training Loss: 1.8072324608770906e-15, Validation Loss: 6.559024191019145e-15
Epoch 457, Training Loss: 1.3761535712177356e-15, Validation Loss: 6.559024191019145e-15
Epoch 458, Training Loss: 1.8202428869469166e-15, Validation Loss: 4.9968828310124544e-15
Epoch 459, Training Loss: 2.6563433917092425e-15, Validation Loss: 5.170332732237033e-15
Epoch 460, Training Loss: 2.54358636577075e-15, Validation Loss: 5.170332732237033e-15
Epoch 461, Training Loss: 2.059598515973221e-15, Validation Loss: 5.6144219420870955e-15
Epoch 462, Training Loss: 2.059598515973221e-15, Validation Loss: 5.6144219420870955e-15
Epoch 463, Training Loss: 2.059598515973221e-15, Validation Loss: 7.036827429752297e-15
Epoch 464, Training Loss: 2.0234583729709585e-15, Validation Loss: 6.364405242376787e-15
Epoch 465, Training Loss: 2.1495150867307643e-15, Validation Loss: 4.834089874813756e-15
Epoch 466, Training Loss: 1.2046688923099055e-15, Validation Loss: 4.8986270091309556e-15
Epoch 467, Training Loss: 5.735548077060934e-16, Validation Loss: 4.858714816656333e-15
Epoch 468, Training Loss: 5.692179990161514e-16, Validation Loss: 4.9275616546091625e-15
Epoch 469, Training Loss: 5.807828574823696e-16, Validation Loss: 4.9275616546091625e-15
Epoch 470, Training Loss: 5.102374008329399e-16, Validation Loss: 4.956473853714267e-15
Epoch 471, Training Loss: 5.102374008329399e-16, Validation Loss: 4.956473853714267e-15
Epoch 472, Training Loss: 5.102374008329399e-16, Validation Loss: 4.956473853714267e-15
Epoch 473, Training Loss: 1.7229175307579767e-15, Validation Loss: 4.5123846438642045e-15
Epoch 474, Training Loss: 1.7229175307579767e-15, Validation Loss: 4.5123846438642045e-15
Epoch 475, Training Loss: 9.405572430924367e-16, Validation Loss: 4.5297318786239726e-15
Epoch 476, Training Loss: 9.347748667988868e-16, Validation Loss: 4.9653732053745944e-15
Epoch 477, Training Loss: 9.058627735729005e-16, Validation Loss: 4.654098761654006e-15
Epoch 478, Training Loss: 1.5739120474790916e-15, Validation Loss: 4.654098761654006e-15
Epoch 479, Training Loss: 1.5739120474790916e-15, Validation Loss: 4.849657493351343e-15
Epoch 480, Training Loss: 9.031522681416868e-16, Validation Loss: 4.849657493351343e-15
Epoch 481, Training Loss: 1.4481445954707731e-15, Validation Loss: 4.849657493351343e-15
Epoch 482, Training Loss: 1.6100520846022356e-15, Validation Loss: 4.877123807215484e-15
Epoch 483, Training Loss: 2.192919172530443e-15, Validation Loss: 4.877123807215484e-15
Epoch 484, Training Loss: 2.19985806643435e-15, Validation Loss: 4.877123807215484e-15
Epoch 485, Training Loss: 1.2681309300588027e-15, Validation Loss: 4.7400806526133165e-15
Epoch 486, Training Loss: 1.2681309300588027e-15, Validation Loss: 4.748844479002083e-15
Epoch 487, Training Loss: 8.188374968412504e-16, Validation Loss: 4.748844479002083e-15
Epoch 488, Training Loss: 1.6312663424035748e-15, Validation Loss: 4.866123813845966e-15
Epoch 489, Training Loss: 1.6312663424035748e-15, Validation Loss: 4.79356781861711e-15
Epoch 490, Training Loss: 2.0406611886132197e-15, Validation Loss: 6.154747647272403e-15
Epoch 491, Training Loss: 1.9180739218053675e-15, Validation Loss: 5.957567270997548e-15
Epoch 492, Training Loss: 1.9180739218053675e-15, Validation Loss: 5.935883227547838e-15
Epoch 493, Training Loss: 1.760503241363847e-15, Validation Loss: 5.953592145376083e-15
Epoch 494, Training Loss: 2.5064344419129924e-15, Validation Loss: 5.889045693696464e-15
Epoch 495, Training Loss: 2.051936891207069e-15, Validation Loss: 6.99603898169374e-15
Epoch 496, Training Loss: 2.124433805887854e-15, Validation Loss: 7.149047013285757e-15
Epoch 497, Training Loss: 1.5936084222389511e-15, Validation Loss: 6.108257820445877e-15
Epoch 498, Training Loss: 5.042742888842697e-16, Validation Loss: 6.113068967586281e-15
Epoch 499, Training Loss: 1.3681665799207196e-15, Validation Loss: 6.113068967586281e-15
Epoch 500, Training Loss: 1.3609386360235618e-15, Validation Loss: 6.113068967586281e-15
