Epoch 1, Training Loss: 0.48163214325904846, Validation Loss: 0.48011428117752075
Epoch 2, Training Loss: 0.48011428117752075, Validation Loss: 0.47861042618751526
Epoch 3, Training Loss: 0.47861042618751526, Validation Loss: 0.4771006107330322
Epoch 4, Training Loss: 0.4771006107330322, Validation Loss: 0.47561538219451904
Epoch 5, Training Loss: 0.47561538219451904, Validation Loss: 0.4741659462451935
Epoch 6, Training Loss: 0.4741659462451935, Validation Loss: 0.4727326035499573
Epoch 7, Training Loss: 0.4727325737476349, Validation Loss: 0.47129321098327637
Epoch 8, Training Loss: 0.471293181180954, Validation Loss: 0.4698460102081299
Epoch 9, Training Loss: 0.4698460102081299, Validation Loss: 0.4684006869792938
Epoch 10, Training Loss: 0.4684006869792938, Validation Loss: 0.46695476770401
Epoch 11, Training Loss: 0.4669547379016876, Validation Loss: 0.46547606587409973
Epoch 12, Training Loss: 0.46547600626945496, Validation Loss: 0.46400731801986694
Epoch 13, Training Loss: 0.46400728821754456, Validation Loss: 0.46254241466522217
Epoch 14, Training Loss: 0.46254241466522217, Validation Loss: 0.4610333740711212
Epoch 15, Training Loss: 0.46103331446647644, Validation Loss: 0.4594636559486389
Epoch 16, Training Loss: 0.4594636857509613, Validation Loss: 0.4578993320465088
Epoch 17, Training Loss: 0.4578993320465088, Validation Loss: 0.4563477039337158
Epoch 18, Training Loss: 0.4563477039337158, Validation Loss: 0.45474329590797424
Epoch 19, Training Loss: 0.45474329590797424, Validation Loss: 0.45307469367980957
Epoch 20, Training Loss: 0.45307469367980957, Validation Loss: 0.4513534605503082
Epoch 21, Training Loss: 0.4513534605503082, Validation Loss: 0.4496346116065979
Epoch 22, Training Loss: 0.4496346116065979, Validation Loss: 0.44784343242645264
Epoch 23, Training Loss: 0.4478433430194855, Validation Loss: 0.4459351897239685
Epoch 24, Training Loss: 0.4459351897239685, Validation Loss: 0.44391900300979614
Epoch 25, Training Loss: 0.44391897320747375, Validation Loss: 0.44183850288391113
Epoch 26, Training Loss: 0.44183850288391113, Validation Loss: 0.43964871764183044
Epoch 27, Training Loss: 0.43964871764183044, Validation Loss: 0.43729519844055176
Epoch 28, Training Loss: 0.43729519844055176, Validation Loss: 0.43479517102241516
Epoch 29, Training Loss: 0.43479517102241516, Validation Loss: 0.43213406205177307
Epoch 30, Training Loss: 0.43213406205177307, Validation Loss: 0.4293302595615387
Epoch 31, Training Loss: 0.4293302595615387, Validation Loss: 0.4263702630996704
Epoch 32, Training Loss: 0.4263702630996704, Validation Loss: 0.4232056736946106
Epoch 33, Training Loss: 0.42320573329925537, Validation Loss: 0.4198789894580841
Epoch 34, Training Loss: 0.4198790192604065, Validation Loss: 0.4163293242454529
Epoch 35, Training Loss: 0.4163293242454529, Validation Loss: 0.41255277395248413
Epoch 36, Training Loss: 0.41255277395248413, Validation Loss: 0.4085288643836975
Epoch 37, Training Loss: 0.4085288643836975, Validation Loss: 0.4042254388332367
Epoch 38, Training Loss: 0.4042254388332367, Validation Loss: 0.39962583780288696
Epoch 39, Training Loss: 0.39962583780288696, Validation Loss: 0.39471936225891113
Epoch 40, Training Loss: 0.39471936225891113, Validation Loss: 0.3894813060760498
Epoch 41, Training Loss: 0.3894813060760498, Validation Loss: 0.38390427827835083
Epoch 42, Training Loss: 0.38390427827835083, Validation Loss: 0.3779391646385193
Epoch 43, Training Loss: 0.3779391646385193, Validation Loss: 0.37160831689834595
Epoch 44, Training Loss: 0.37160831689834595, Validation Loss: 0.3648639917373657
Epoch 45, Training Loss: 0.3648639917373657, Validation Loss: 0.35763317346572876
Epoch 46, Training Loss: 0.35763320326805115, Validation Loss: 0.34992799162864685
Epoch 47, Training Loss: 0.34992799162864685, Validation Loss: 0.341778039932251
Epoch 48, Training Loss: 0.341778039932251, Validation Loss: 0.3331848382949829
Epoch 49, Training Loss: 0.3331848382949829, Validation Loss: 0.32419344782829285
Epoch 50, Training Loss: 0.32419347763061523, Validation Loss: 0.3148110508918762
Epoch 51, Training Loss: 0.3148110508918762, Validation Loss: 0.3050557076931
Epoch 52, Training Loss: 0.3050557076931, Validation Loss: 0.29500851035118103
Epoch 53, Training Loss: 0.29500851035118103, Validation Loss: 0.28461432456970215
Epoch 54, Training Loss: 0.28461432456970215, Validation Loss: 0.2739495635032654
Epoch 55, Training Loss: 0.2739495635032654, Validation Loss: 0.2632100582122803
Epoch 56, Training Loss: 0.2632100582122803, Validation Loss: 0.252544641494751
Epoch 57, Training Loss: 0.252544641494751, Validation Loss: 0.24203836917877197
Epoch 58, Training Loss: 0.24203836917877197, Validation Loss: 0.23173417150974274
Epoch 59, Training Loss: 0.23173417150974274, Validation Loss: 0.2217472940683365
Epoch 60, Training Loss: 0.2217472940683365, Validation Loss: 0.21220964193344116
Epoch 61, Training Loss: 0.21220964193344116, Validation Loss: 0.20320937037467957
Epoch 62, Training Loss: 0.20320937037467957, Validation Loss: 0.19485200941562653
Epoch 63, Training Loss: 0.19485200941562653, Validation Loss: 0.1870776265859604
Epoch 64, Training Loss: 0.187077596783638, Validation Loss: 0.1797555834054947
Epoch 65, Training Loss: 0.17975559830665588, Validation Loss: 0.172748863697052
Epoch 66, Training Loss: 0.1727488487958908, Validation Loss: 0.16597235202789307
Epoch 67, Training Loss: 0.16597236692905426, Validation Loss: 0.15942808985710144
Epoch 68, Training Loss: 0.15942807495594025, Validation Loss: 0.1526559442281723
Epoch 69, Training Loss: 0.1526559591293335, Validation Loss: 0.14554959535598755
Epoch 70, Training Loss: 0.14554961025714874, Validation Loss: 0.13806232810020447
Epoch 71, Training Loss: 0.13806231319904327, Validation Loss: 0.13022254407405853
Epoch 72, Training Loss: 0.13022255897521973, Validation Loss: 0.1221509650349617
Epoch 73, Training Loss: 0.1221509650349617, Validation Loss: 0.11392498761415482
Epoch 74, Training Loss: 0.11392496526241302, Validation Loss: 0.10566777735948563
Epoch 75, Training Loss: 0.10566777735948563, Validation Loss: 0.09745027869939804
Epoch 76, Training Loss: 0.09745029360055923, Validation Loss: 0.0898628830909729
Epoch 77, Training Loss: 0.08986286073923111, Validation Loss: 0.08267334848642349
Epoch 78, Training Loss: 0.08267334848642349, Validation Loss: 0.07566170394420624
Epoch 79, Training Loss: 0.07566170394420624, Validation Loss: 0.06893044710159302
Epoch 80, Training Loss: 0.06893044710159302, Validation Loss: 0.062354568392038345
Epoch 81, Training Loss: 0.06235455721616745, Validation Loss: 0.05590205267071724
Epoch 82, Training Loss: 0.055902060121297836, Validation Loss: 0.04966104030609131
Epoch 83, Training Loss: 0.04966104030609131, Validation Loss: 0.043807223439216614
Epoch 84, Training Loss: 0.04380722716450691, Validation Loss: 0.038237571716308594
Epoch 85, Training Loss: 0.038237567991018295, Validation Loss: 0.033029429614543915
Epoch 86, Training Loss: 0.033029429614543915, Validation Loss: 0.028263051062822342
Epoch 87, Training Loss: 0.02826305665075779, Validation Loss: 0.02402929961681366
Epoch 88, Training Loss: 0.024029294028878212, Validation Loss: 0.020416952669620514
Epoch 89, Training Loss: 0.020416952669620514, Validation Loss: 0.017293572425842285
Epoch 90, Training Loss: 0.017293566837906837, Validation Loss: 0.014637116342782974
Epoch 91, Training Loss: 0.0146371154114604, Validation Loss: 0.012460087426006794
Epoch 92, Training Loss: 0.012460087426006794, Validation Loss: 0.010728705674409866
Epoch 93, Training Loss: 0.010728709399700165, Validation Loss: 0.009297325275838375
Epoch 94, Training Loss: 0.009297325275838375, Validation Loss: 0.008099967613816261
Epoch 95, Training Loss: 0.008099963888525963, Validation Loss: 0.007097173947840929
Epoch 96, Training Loss: 0.007097175810486078, Validation Loss: 0.0062477621249854565
Epoch 97, Training Loss: 0.00624776491895318, Validation Loss: 0.005512876436114311
Epoch 98, Training Loss: 0.005512875504791737, Validation Loss: 0.004859923385083675
Epoch 99, Training Loss: 0.004859921056777239, Validation Loss: 0.004272833466529846
Epoch 100, Training Loss: 0.004272833466529846, Validation Loss: 0.0037516173906624317
Epoch 101, Training Loss: 0.0037516173906624317, Validation Loss: 0.0032895563635975122
Epoch 102, Training Loss: 0.0032895575277507305, Validation Loss: 0.002883167704567313
Epoch 103, Training Loss: 0.002883165841922164, Validation Loss: 0.002526649506762624
Epoch 104, Training Loss: 0.0025266502052545547, Validation Loss: 0.002211143495514989
Epoch 105, Training Loss: 0.002211145358160138, Validation Loss: 0.0019262130372226238
Epoch 106, Training Loss: 0.0019262128043919802, Validation Loss: 0.0016639318782836199
Epoch 107, Training Loss: 0.0016639321111142635, Validation Loss: 0.0014204767066985369
Epoch 108, Training Loss: 0.0014204770559445024, Validation Loss: 0.001195017248392105
Epoch 109, Training Loss: 0.0011950184125453234, Validation Loss: 0.0009883088059723377
Epoch 110, Training Loss: 0.0009883083403110504, Validation Loss: 0.0008063082932494581
Epoch 111, Training Loss: 0.000806307652965188, Validation Loss: 0.0006549159297719598
Epoch 112, Training Loss: 0.000654915813356638, Validation Loss: 0.0005383630050346255
Epoch 113, Training Loss: 0.0005383632378652692, Validation Loss: 0.00045798326027579606
Epoch 114, Training Loss: 0.0004579834931064397, Validation Loss: 0.00041101433453150094
Epoch 115, Training Loss: 0.00041101459646597505, Validation Loss: 0.00039108601049520075
Epoch 116, Training Loss: 0.0003910865925718099, Validation Loss: 0.000388837099308148
Epoch 117, Training Loss: 0.0003888380015268922, Validation Loss: 0.00039502742583863437
Epoch 118, Training Loss: 0.0003950268146581948, Validation Loss: 0.0004015522717963904
Epoch 119, Training Loss: 0.0004015534359496087, Validation Loss: 0.00040265233837999403
Epoch 120, Training Loss: 0.00040265260031446815, Validation Loss: 0.0003951566759496927
Epoch 121, Training Loss: 0.0003951566759496927, Validation Loss: 0.000378943863324821
Epoch 122, Training Loss: 0.000378942844690755, Validation Loss: 0.00035586231388151646
Epoch 123, Training Loss: 0.0003558624885044992, Validation Loss: 0.00032851166906766593
Epoch 124, Training Loss: 0.00032851059222593904, Validation Loss: 0.0002994578971993178
Epoch 125, Training Loss: 0.0002994578971993178, Validation Loss: 0.00027065208996646106
Epoch 126, Training Loss: 0.00027065162430517375, Validation Loss: 0.00024314250913448632
Epoch 127, Training Loss: 0.0002431423927191645, Validation Loss: 0.00021729776926804334
Epoch 128, Training Loss: 0.00021729794389102608, Validation Loss: 0.00019298419647384435
Epoch 129, Training Loss: 0.00019298467668704689, Validation Loss: 0.00017022302199620754
Epoch 130, Training Loss: 0.00017022338579408824, Validation Loss: 0.00014864005788695067
Epoch 131, Training Loss: 0.00014863978140056133, Validation Loss: 0.0001284757599933073
Epoch 132, Training Loss: 0.00012847548350691795, Validation Loss: 0.00011024176637874916
Epoch 133, Training Loss: 0.00011024170817108825, Validation Loss: 9.459787543164566e-05
Epoch 134, Training Loss: 9.45979991229251e-05, Validation Loss: 8.187146158888936e-05
Epoch 135, Training Loss: 8.187134517356753e-05, Validation Loss: 7.217795791802928e-05
Epoch 136, Training Loss: 7.217798702185974e-05, Validation Loss: 6.533361738547683e-05
Epoch 137, Training Loss: 6.53336028335616e-05, Validation Loss: 6.073727854527533e-05
Epoch 138, Training Loss: 6.073733311495744e-05, Validation Loss: 5.7561173889553174e-05
Epoch 139, Training Loss: 5.7560911955079064e-05, Validation Loss: 5.494431752595119e-05
Epoch 140, Training Loss: 5.494423385243863e-05, Validation Loss: 5.2176907047396526e-05
Epoch 141, Training Loss: 5.2177132602082565e-05, Validation Loss: 4.8824382247403264e-05
Epoch 142, Training Loss: 4.882436041953042e-05, Validation Loss: 4.476887625060044e-05
Epoch 143, Training Loss: 4.4768923544324934e-05, Validation Loss: 4.0164431993616745e-05
Epoch 144, Training Loss: 4.0164606616599485e-05, Validation Loss: 3.5332701372681186e-05
Epoch 145, Training Loss: 3.5332803236087784e-05, Validation Loss: 3.063751864829101e-05
Epoch 146, Training Loss: 3.0637707823188975e-05, Validation Loss: 2.6377087124274112e-05
Epoch 147, Training Loss: 2.637707075336948e-05, Validation Loss: 2.271923040098045e-05
Epoch 148, Training Loss: 2.271930134156719e-05, Validation Loss: 1.9687604435603134e-05
Epoch 149, Training Loss: 1.9687731764861383e-05, Validation Loss: 1.719351530482527e-05
Epoch 150, Training Loss: 1.7193733583553694e-05, Validation Loss: 1.5092156900209375e-05
Epoch 151, Training Loss: 1.5092166904651094e-05, Validation Loss: 1.3241962733445689e-05
Epoch 152, Training Loss: 1.3242010936664883e-05, Validation Loss: 1.154829533334123e-05
Epoch 153, Training Loss: 1.1548334441613406e-05, Validation Loss: 9.98052109935088e-06
Epoch 154, Training Loss: 9.980588401958812e-06, Validation Loss: 8.563727533328347e-06
Epoch 155, Training Loss: 8.563762094127014e-06, Validation Loss: 7.351644853770267e-06
Epoch 156, Training Loss: 7.3515393523848616e-06, Validation Loss: 6.394079264282482e-06
Epoch 157, Training Loss: 6.394059710146394e-06, Validation Loss: 5.710864570573904e-06
Epoch 158, Training Loss: 5.7108973123831674e-06, Validation Loss: 5.278808657749323e-06
Epoch 159, Training Loss: 5.27882230016985e-06, Validation Loss: 5.035955382481916e-06
Epoch 160, Training Loss: 5.036038601247128e-06, Validation Loss: 4.89781450596638e-06
Epoch 161, Training Loss: 4.897884991805768e-06, Validation Loss: 4.77979074275936e-06
Epoch 162, Training Loss: 4.779737992066657e-06, Validation Loss: 4.617456852429314e-06
Epoch 163, Training Loss: 4.617409558704821e-06, Validation Loss: 4.378826361062238e-06
Epoch 164, Training Loss: 4.3787845243059564e-06, Validation Loss: 4.065118901053211e-06
Epoch 165, Training Loss: 4.065040684508858e-06, Validation Loss: 3.7029255963716423e-06
Epoch 166, Training Loss: 3.702873527799966e-06, Validation Loss: 3.3302630981779657e-06
Epoch 167, Training Loss: 3.330241725052474e-06, Validation Loss: 2.982478463309235e-06
Epoch 168, Training Loss: 2.982544629048789e-06, Validation Loss: 2.6821162464329973e-06
Epoch 169, Training Loss: 2.682115564311971e-06, Validation Loss: 2.4345088149857474e-06
Epoch 170, Training Loss: 2.4345929432456614e-06, Validation Loss: 2.2309286578092724e-06
Epoch 171, Training Loss: 2.2308993266051402e-06, Validation Loss: 2.0540198875096394e-06
Epoch 172, Training Loss: 2.0540544483083067e-06, Validation Loss: 1.886470954559627e-06
Epoch 173, Training Loss: 1.886452196231403e-06, Validation Loss: 1.7160651850645081e-06
Epoch 174, Training Loss: 1.716097472126421e-06, Validation Loss: 1.5397705510622473e-06
Epoch 175, Training Loss: 1.5397411061712774e-06, Validation Loss: 1.3622264987134258e-06
Epoch 176, Training Loss: 1.3622577625937993e-06, Validation Loss: 1.1928889307455393e-06
Epoch 177, Training Loss: 1.192911895486759e-06, Validation Loss: 1.0414299822514295e-06
Epoch 178, Training Loss: 1.0414307780592935e-06, Validation Loss: 9.142508474724309e-07
Epoch 179, Training Loss: 9.142011663243466e-07, Validation Loss: 8.124358146233135e-07
Epoch 180, Training Loss: 8.123744805743627e-07, Validation Loss: 7.320954296119453e-07
Epoch 181, Training Loss: 7.3207922923757e-07, Validation Loss: 6.662298233095498e-07
Epoch 182, Training Loss: 6.662357918685302e-07, Validation Loss: 6.072302198845136e-07
Epoch 183, Training Loss: 6.072432370274328e-07, Validation Loss: 5.495230652741157e-07
Epoch 184, Training Loss: 5.495275559042057e-07, Validation Loss: 4.905425043943978e-07
Epoch 185, Training Loss: 4.905821811007627e-07, Validation Loss: 4.311847305871197e-07
Epoch 186, Training Loss: 4.3122551574015233e-07, Validation Loss: 3.743581658000039e-07
Epoch 187, Training Loss: 3.743543288692308e-07, Validation Loss: 3.2358167345591937e-07
Epoch 188, Training Loss: 3.2354100198972446e-07, Validation Loss: 2.814781510096509e-07
Epoch 189, Training Loss: 2.814853701238462e-07, Validation Loss: 2.4906219664444507e-07
Epoch 190, Training Loss: 2.490607471372641e-07, Validation Loss: 2.2527444798470242e-07
Epoch 191, Training Loss: 2.2529196996856626e-07, Validation Loss: 2.0772233710886212e-07
Epoch 192, Training Loss: 2.0771845754552487e-07, Validation Loss: 1.9349816682279197e-07
Epoch 193, Training Loss: 1.9349496938048105e-07, Validation Loss: 1.8015086311606865e-07
Epoch 194, Training Loss: 1.8015414582350786e-07, Validation Loss: 1.6614055198260758e-07
Epoch 195, Training Loss: 1.6614117726021504e-07, Validation Loss: 1.5107426065696927e-07
Epoch 196, Training Loss: 1.510957048367345e-07, Validation Loss: 1.3544668320264464e-07
Epoch 197, Training Loss: 1.354535612563268e-07, Validation Loss: 1.2016739958653488e-07
Epoch 198, Training Loss: 1.2015298977985367e-07, Validation Loss: 1.0603885414184333e-07
Epoch 199, Training Loss: 1.0602786204572112e-07, Validation Loss: 9.357869146242592e-08
Epoch 200, Training Loss: 9.356611485600297e-08, Validation Loss: 8.28282651355039e-08
Epoch 201, Training Loss: 8.282642482981828e-08, Validation Loss: 7.351203379357685e-08
Epoch 202, Training Loss: 7.352191744303127e-08, Validation Loss: 6.521479178900336e-08
Epoch 203, Training Loss: 6.522662943098112e-08, Validation Loss: 5.7665381802962656e-08
Epoch 204, Training Loss: 5.765793176237821e-08, Validation Loss: 5.07424466889006e-08
Epoch 205, Training Loss: 5.0745214252856385e-08, Validation Loss: 4.462339830979545e-08
Epoch 206, Training Loss: 4.462895830670277e-08, Validation Loss: 3.9542477736631554e-08
Epoch 207, Training Loss: 3.95397883323767e-08, Validation Loss: 3.569687834215074e-08
Epoch 208, Training Loss: 3.570212925296801e-08, Validation Loss: 3.315552987714909e-08
Epoch 209, Training Loss: 3.3152357303833924e-08, Validation Loss: 3.172878493273856e-08
Epoch 210, Training Loss: 3.1722265703137964e-08, Validation Loss: 3.107235357902027e-08
Epoch 211, Training Loss: 3.1072676875965044e-08, Validation Loss: 3.073677845577549e-08
Epoch 212, Training Loss: 3.073506249506863e-08, Validation Loss: 3.031355078064735e-08
Epoch 213, Training Loss: 3.031020057164824e-08, Validation Loss: 2.9479501506557426e-08
Epoch 214, Training Loss: 2.9473916640654352e-08, Validation Loss: 2.8095714199594113e-08
Epoch 215, Training Loss: 2.8096680537714747e-08, Validation Loss: 2.6171642630856695e-08
Epoch 216, Training Loss: 2.6170603462105646e-08, Validation Loss: 2.3831402629070908e-08
Epoch 217, Training Loss: 2.3823680805890035e-08, Validation Loss: 2.122824049877181e-08
Epoch 218, Training Loss: 2.1236608915842226e-08, Validation Loss: 1.855219444735212e-08
Epoch 219, Training Loss: 1.8542293034329305e-08, Validation Loss: 1.5896716831775848e-08
Epoch 220, Training Loss: 1.5889296989257673e-08, Validation Loss: 1.3380615726532596e-08
Epoch 221, Training Loss: 1.3385568209400844e-08, Validation Loss: 1.106436275932765e-08
Epoch 222, Training Loss: 1.1065971250445727e-08, Validation Loss: 8.983358057434998e-09
Epoch 223, Training Loss: 8.987099953117195e-09, Validation Loss: 7.1924324274164064e-09
Epoch 224, Training Loss: 7.193037721009432e-09, Validation Loss: 5.719729134767704e-09
Epoch 225, Training Loss: 5.719924089930828e-09, Validation Loss: 4.582076496006948e-09
Epoch 226, Training Loss: 4.583190271745252e-09, Validation Loss: 3.781297941429784e-09
Epoch 227, Training Loss: 3.780844526346527e-09, Validation Loss: 3.270921533626847e-09
Epoch 228, Training Loss: 3.2694422724688366e-09, Validation Loss: 2.9946767288180354e-09
Epoch 229, Training Loss: 2.9962252678927825e-09, Validation Loss: 2.8705129384576367e-09
Epoch 230, Training Loss: 2.8727293877039983e-09, Validation Loss: 2.826516354303976e-09
Epoch 231, Training Loss: 2.825154110652761e-09, Validation Loss: 2.789197317554226e-09
Epoch 232, Training Loss: 2.788661745967147e-09, Validation Loss: 2.7271989111454786e-09
Epoch 233, Training Loss: 2.7291127135953275e-09, Validation Loss: 2.6246427253795446e-09
Epoch 234, Training Loss: 2.6217197302003115e-09, Validation Loss: 2.482728023167624e-09
Epoch 235, Training Loss: 2.480773142465864e-09, Validation Loss: 2.31127983418844e-09
Epoch 236, Training Loss: 2.3102779689310182e-09, Validation Loss: 2.1292112517556916e-09
Epoch 237, Training Loss: 2.130513543363577e-09, Validation Loss: 1.9478236801262483e-09
Epoch 238, Training Loss: 1.9474968304677986e-09, Validation Loss: 1.770019908420295e-09
Epoch 239, Training Loss: 1.771268354211486e-09, Validation Loss: 1.6023028459599686e-09
Epoch 240, Training Loss: 1.600586885253108e-09, Validation Loss: 1.4412130378005372e-09
Epoch 241, Training Loss: 1.4424426098003096e-09, Validation Loss: 1.2952494632401113e-09
Epoch 242, Training Loss: 1.2961007822553938e-09, Validation Loss: 1.1634480046041062e-09
Epoch 243, Training Loss: 1.164928042918234e-09, Validation Loss: 1.0552370088845464e-09
Epoch 244, Training Loss: 1.0556420182439297e-09, Validation Loss: 9.712738391343123e-10
Epoch 245, Training Loss: 9.71236535640685e-10, Validation Loss: 9.076079887648802e-10
Epoch 246, Training Loss: 9.08029929025389e-10, Validation Loss: 8.569831511096027e-10
Epoch 247, Training Loss: 8.571766074716436e-10, Validation Loss: 8.130736084410728e-10
Epoch 248, Training Loss: 8.130071060818977e-10, Validation Loss: 7.640845733902779e-10
Epoch 249, Training Loss: 7.641652310930169e-10, Validation Loss: 7.073307495275571e-10
Epoch 250, Training Loss: 7.062193607687561e-10, Validation Loss: 6.406402075498363e-10
Epoch 251, Training Loss: 6.389266338224786e-10, Validation Loss: 5.623969623336222e-10
Epoch 252, Training Loss: 5.625779841977874e-10, Validation Loss: 4.83337536660855e-10
Epoch 253, Training Loss: 4.835645772693908e-10, Validation Loss: 4.088266392088258e-10
Epoch 254, Training Loss: 4.0861741767983517e-10, Validation Loss: 3.411046167745013e-10
Epoch 255, Training Loss: 3.403228254761359e-10, Validation Loss: 2.8362814874505204e-10
Epoch 256, Training Loss: 2.8389190998012737e-10, Validation Loss: 2.369224538778525e-10
Epoch 257, Training Loss: 2.370613150226575e-10, Validation Loss: 1.9902143821859397e-10
Epoch 258, Training Loss: 1.9884439927952968e-10, Validation Loss: 1.6660794965872583e-10
Epoch 259, Training Loss: 1.6663566360097803e-10, Validation Loss: 1.4043410878628038e-10
Epoch 260, Training Loss: 1.4039516771369165e-10, Validation Loss: 1.1867398730380785e-10
Epoch 261, Training Loss: 1.1913957320697222e-10, Validation Loss: 1.0261778232711904e-10
Epoch 262, Training Loss: 1.024495210888432e-10, Validation Loss: 9.058474803591565e-11
Epoch 263, Training Loss: 9.083600538417613e-11, Validation Loss: 8.406641355263034e-11
Epoch 264, Training Loss: 8.401310896966052e-11, Validation Loss: 8.067846390957811e-11
Epoch 265, Training Loss: 8.085494773713009e-11, Validation Loss: 7.962644432701893e-11
Epoch 266, Training Loss: 7.94077650856373e-11, Validation Loss: 7.869889462330804e-11
Epoch 267, Training Loss: 7.869267043547623e-11, Validation Loss: 7.607614538329699e-11
Epoch 268, Training Loss: 7.607446617097224e-11, Validation Loss: 7.220146008846129e-11
Epoch 269, Training Loss: 7.206462510067624e-11, Validation Loss: 6.677108171926349e-11
Epoch 270, Training Loss: 6.654513745596446e-11, Validation Loss: 6.030104887644328e-11
Epoch 271, Training Loss: 6.01721519832843e-11, Validation Loss: 5.410951894879723e-11
Epoch 272, Training Loss: 5.417302717525274e-11, Validation Loss: 4.855748442222918e-11
Epoch 273, Training Loss: 4.878791121099013e-11, Validation Loss: 4.4962922274294215e-11
Epoch 274, Training Loss: 4.486955251792324e-11, Validation Loss: 4.195370439941115e-11
Epoch 275, Training Loss: 4.2148739359815224e-11, Validation Loss: 4.020483598821123e-11
Epoch 276, Training Loss: 4.0359299235959156e-11, Validation Loss: 3.820354449457497e-11
Epoch 277, Training Loss: 3.826534228368317e-11, Validation Loss: 3.666143430502977e-11
Epoch 278, Training Loss: 3.654336902525479e-11, Validation Loss: 3.4204413607019646e-11
Epoch 279, Training Loss: 3.435028997356149e-11, Validation Loss: 3.143175650310859e-11
Epoch 280, Training Loss: 3.1600728978009585e-11, Validation Loss: 2.873236544520541e-11
Epoch 281, Training Loss: 2.8372694818590283e-11, Validation Loss: 2.5232852265966166e-11
Epoch 282, Training Loss: 2.5320204266598978e-11, Validation Loss: 2.2401400179283826e-11
Epoch 283, Training Loss: 2.245558947122639e-11, Validation Loss: 1.9591037125898936e-11
Epoch 284, Training Loss: 1.963649902403386e-11, Validation Loss: 1.7110075509196854e-11
Epoch 285, Training Loss: 1.704718484429879e-11, Validation Loss: 1.4721241586856948e-11
Epoch 286, Training Loss: 1.4564328909560942e-11, Validation Loss: 1.2226649380442378e-11
Epoch 287, Training Loss: 1.2314283273640036e-11, Validation Loss: 9.961175113926135e-12
Epoch 288, Training Loss: 9.994439303939728e-12, Validation Loss: 7.856942527140198e-12
Epoch 289, Training Loss: 7.92634881341403e-12, Validation Loss: 5.869937348690346e-12
Epoch 290, Training Loss: 5.928830343338021e-12, Validation Loss: 4.377950259260022e-12
Epoch 291, Training Loss: 4.369338224563535e-12, Validation Loss: 3.286368139426843e-12
Epoch 292, Training Loss: 3.241211335783256e-12, Validation Loss: 2.5462000129844453e-12
Epoch 293, Training Loss: 2.5702771074692654e-12, Validation Loss: 2.2542892032240136e-12
Epoch 294, Training Loss: 2.2602739992161336e-12, Validation Loss: 2.206091212486605e-12
Epoch 295, Training Loss: 2.1663016432776905e-12, Validation Loss: 2.240749903334449e-12
Epoch 296, Training Loss: 2.3539915676440426e-12, Validation Loss: 2.463363497559601e-12
Epoch 297, Training Loss: 2.45317936971301e-12, Validation Loss: 2.6910121266737752e-12
Epoch 298, Training Loss: 2.7398463272459983e-12, Validation Loss: 2.873879086096043e-12
Epoch 299, Training Loss: 2.86893035369995e-12, Validation Loss: 2.937703682745485e-12
Epoch 300, Training Loss: 2.896567751278778e-12, Validation Loss: 2.934024334252938e-12
Epoch 301, Training Loss: 2.8778871646872872e-12, Validation Loss: 2.828845230978816e-12
Epoch 302, Training Loss: 2.8383792712027844e-12, Validation Loss: 2.6714821761003593e-12
Epoch 303, Training Loss: 2.6911443993388184e-12, Validation Loss: 2.4641272095698996e-12
Epoch 304, Training Loss: 2.523363028944514e-12, Validation Loss: 2.3379707458220933e-12
Epoch 305, Training Loss: 2.264283378849985e-12, Validation Loss: 2.0278119461369926e-12
Epoch 306, Training Loss: 2.1225972368643653e-12, Validation Loss: 1.8703300627004316e-12
Epoch 307, Training Loss: 1.8613745527557013e-12, Validation Loss: 1.5827602900184146e-12
Epoch 308, Training Loss: 1.6019011204321254e-12, Validation Loss: 1.4118676930699459e-12
Epoch 309, Training Loss: 1.4153265148406091e-12, Validation Loss: 1.1861267176782597e-12
Epoch 310, Training Loss: 1.2136229521342301e-12, Validation Loss: 9.637346259569468e-13
Epoch 311, Training Loss: 9.950088713031602e-13, Validation Loss: 8.101081654457443e-13
Epoch 312, Training Loss: 8.312988426968648e-13, Validation Loss: 7.089686910460857e-13
Epoch 313, Training Loss: 6.562053418007752e-13, Validation Loss: 5.81391109300694e-13
Epoch 314, Training Loss: 5.802397408036231e-13, Validation Loss: 4.862461345025992e-13
Epoch 315, Training Loss: 4.905695532957111e-13, Validation Loss: 4.248318548078639e-13
Epoch 316, Training Loss: 4.152217578014955e-13, Validation Loss: 3.7246608249920377e-13
Epoch 317, Training Loss: 3.8144975459536434e-13, Validation Loss: 3.646832456242338e-13
Epoch 318, Training Loss: 3.791608682839759e-13, Validation Loss: 3.602102611414276e-13
Epoch 319, Training Loss: 3.3184894177203106e-13, Validation Loss: 3.3115505238164034e-13
Epoch 320, Training Loss: 3.579069549411451e-13, Validation Loss: 3.192096381058468e-13
Epoch 321, Training Loss: 3.323133055625066e-13, Validation Loss: 2.870557524320416e-13
Epoch 322, Training Loss: 2.99890537749925e-13, Validation Loss: 2.837240533661023e-13
Epoch 323, Training Loss: 2.6093675289072527e-13, Validation Loss: 2.410196337215148e-13
Epoch 324, Training Loss: 2.4322495515045894e-13, Validation Loss: 2.4433883735741624e-13
Epoch 325, Training Loss: 2.1053734385219347e-13, Validation Loss: 2.1317423195589547e-13
Epoch 326, Training Loss: 1.80062684055661e-13, Validation Loss: 1.764958757486182e-13
Epoch 327, Training Loss: 1.6610747066020393e-13, Validation Loss: 1.3116330938034437e-13
Epoch 328, Training Loss: 1.2816108580209623e-13, Validation Loss: 1.1248067635725306e-13
Epoch 329, Training Loss: 1.0531154534575496e-13, Validation Loss: 9.392938087483121e-14
Epoch 330, Training Loss: 7.94985415388319e-14, Validation Loss: 8.924820924611707e-14
Epoch 331, Training Loss: 7.481480848248526e-14, Validation Loss: 6.842990123113665e-14
Epoch 332, Training Loss: 6.104884257623552e-14, Validation Loss: 5.6585521045291604e-14
Epoch 333, Training Loss: 5.519952103369939e-14, Validation Loss: 5.235246372699287e-14
Epoch 334, Training Loss: 4.9729090880997265e-14, Validation Loss: 5.10475857548251e-14
Epoch 335, Training Loss: 4.522434943893261e-14, Validation Loss: 4.878244347101407e-14
Epoch 336, Training Loss: 4.134757789517156e-14, Validation Loss: 4.160806085524299e-14
Epoch 337, Training Loss: 4.65458800788434e-14, Validation Loss: 4.387016737297106e-14
Epoch 338, Training Loss: 3.920376122259345e-14, Validation Loss: 4.21507311476263e-14
Epoch 339, Training Loss: 3.464325451941336e-14, Validation Loss: 3.862876137667934e-14
Epoch 340, Training Loss: 3.147752986542261e-14, Validation Loss: 3.38034586216604e-14
Epoch 341, Training Loss: 3.195525983580583e-14, Validation Loss: 3.41846031191341e-14
Epoch 342, Training Loss: 3.0411613440202434e-14, Validation Loss: 3.223004071202691e-14
Epoch 343, Training Loss: 3.016951787135e-14, Validation Loss: 3.082077778757131e-14
Epoch 344, Training Loss: 3.084494194349058e-14, Validation Loss: 2.602437749077858e-14
Epoch 345, Training Loss: 2.5864367884844558e-14, Validation Loss: 2.3724913431944807e-14
Epoch 346, Training Loss: 2.2614422744908318e-14, Validation Loss: 2.2800343088698848e-14
Epoch 347, Training Loss: 2.2485128247707632e-14, Validation Loss: 2.195209380213229e-14
Epoch 348, Training Loss: 2.001443139638872e-14, Validation Loss: 1.4698544098979034e-14
Epoch 349, Training Loss: 1.5928735788055606e-14, Validation Loss: 1.328796996752108e-14
Epoch 350, Training Loss: 1.5221061783481267e-14, Validation Loss: 1.389999531762557e-14
Epoch 351, Training Loss: 1.5871261214452613e-14, Validation Loss: 1.7173208452622886e-14
Epoch 352, Training Loss: 1.422405318258612e-14, Validation Loss: 1.5868660823304542e-14
Epoch 353, Training Loss: 1.1103177229086596e-14, Validation Loss: 1.132988220928742e-14
Epoch 354, Training Loss: 7.463742623080305e-15, Validation Loss: 1.1595765851430545e-14
Epoch 355, Training Loss: 5.933943945615099e-15, Validation Loss: 1.2447299084733607e-14
Epoch 356, Training Loss: 5.924271676390402e-15, Validation Loss: 1.2795410144297338e-14
Epoch 357, Training Loss: 8.917592514846428e-15, Validation Loss: 1.2661456965886754e-14
Epoch 358, Training Loss: 5.735865290899681e-15, Validation Loss: 1.0878558491034859e-14
Epoch 359, Training Loss: 8.089921893733414e-15, Validation Loss: 1.2354269456136668e-14
Epoch 360, Training Loss: 9.411261104198126e-15, Validation Loss: 9.751370243509146e-15
Epoch 361, Training Loss: 8.89981329328356e-15, Validation Loss: 1.3377475092024495e-14
Epoch 362, Training Loss: 7.92726954500396e-15, Validation Loss: 9.187321686570087e-15
Epoch 363, Training Loss: 7.338394452380877e-15, Validation Loss: 7.834648186287596e-15
Epoch 364, Training Loss: 4.81556822887262e-15, Validation Loss: 1.4966240391629283e-14
Epoch 365, Training Loss: 4.760454759610098e-15, Validation Loss: 1.677703250846721e-14
Epoch 366, Training Loss: 5.4474052560969134e-15, Validation Loss: 6.318279216201107e-15
Epoch 367, Training Loss: 5.402824641533499e-15, Validation Loss: 6.224622783223199e-15
Epoch 368, Training Loss: 5.4127095160279564e-15, Validation Loss: 5.218467073530653e-15
Epoch 369, Training Loss: 4.167452498951519e-15, Validation Loss: 5.803550846681825e-15
Epoch 370, Training Loss: 4.298613856767953e-15, Validation Loss: 5.69291860289152e-15
Epoch 371, Training Loss: 3.918836046954647e-15, Validation Loss: 7.41082508673354e-15
Epoch 372, Training Loss: 3.0637437929654588e-15, Validation Loss: 7.36676582094916e-15
Epoch 373, Training Loss: 5.8507983444796696e-15, Validation Loss: 6.830886191703991e-15
Epoch 374, Training Loss: 5.6088344892505325e-15, Validation Loss: 5.37370534287279e-15
Epoch 375, Training Loss: 5.205347803727105e-15, Validation Loss: 4.385438121993308e-15
Epoch 376, Training Loss: 4.993658176582257e-15, Validation Loss: 4.538935738628838e-15
Epoch 377, Training Loss: 4.410315479654167e-15, Validation Loss: 4.094232006375542e-15
Epoch 378, Training Loss: 4.994839787543677e-15, Validation Loss: 4.734821001527341e-15
Epoch 379, Training Loss: 4.163851338376268e-15, Validation Loss: 5.237518115063823e-15
Epoch 380, Training Loss: 3.098926788737324e-15, Validation Loss: 6.051737852974439e-15
Epoch 381, Training Loss: 2.5070705636563804e-15, Validation Loss: 6.62591819451208e-15
Epoch 382, Training Loss: 2.9368540223020283e-15, Validation Loss: 6.466301188349111e-15
Epoch 383, Training Loss: 2.932189200103262e-15, Validation Loss: 7.740549602111221e-15
Epoch 384, Training Loss: 2.2291647711346384e-15, Validation Loss: 5.473635325374537e-15
Epoch 385, Training Loss: 2.407098864781981e-15, Validation Loss: 4.520394610929915e-15
Epoch 386, Training Loss: 2.632175635899946e-15, Validation Loss: 5.326874161768521e-15
Epoch 387, Training Loss: 2.7553602726938494e-15, Validation Loss: 5.946989523552236e-15
Epoch 388, Training Loss: 1.3336417287488711e-15, Validation Loss: 5.332462461638031e-15
Epoch 389, Training Loss: 1.3722659017480752e-15, Validation Loss: 4.416094785453283e-15
Epoch 390, Training Loss: 1.9006121258394832e-15, Validation Loss: 4.5387248274249715e-15
Epoch 391, Training Loss: 1.9005812091369085e-15, Validation Loss: 6.2226445377748865e-15
Epoch 392, Training Loss: 1.9324349419095905e-15, Validation Loss: 5.723581619098599e-15
Epoch 393, Training Loss: 2.2891954784142084e-15, Validation Loss: 5.726229444091716e-15
Epoch 394, Training Loss: 2.1808646231415933e-15, Validation Loss: 5.696867894008093e-15
Epoch 395, Training Loss: 6.881775295900319e-16, Validation Loss: 5.5864211504332364e-15
Epoch 396, Training Loss: 1.3500246164981902e-15, Validation Loss: 4.522913686915049e-15
Epoch 397, Training Loss: 1.3366612953267143e-15, Validation Loss: 3.9357999993057825e-15
Epoch 398, Training Loss: 1.2967444441708818e-15, Validation Loss: 4.524028805790109e-15
Epoch 399, Training Loss: 1.6983815273748613e-15, Validation Loss: 3.8755306404933236e-15
Epoch 400, Training Loss: 1.2292992339875213e-15, Validation Loss: 4.50465673876993e-15
Epoch 401, Training Loss: 1.2623947170608781e-15, Validation Loss: 4.056936298674988e-15
Epoch 402, Training Loss: 1.6009150343210851e-15, Validation Loss: 4.0775738329183655e-15
Epoch 403, Training Loss: 1.4367543316708077e-15, Validation Loss: 7.578171692056677e-15
Epoch 404, Training Loss: 1.3999353976404394e-15, Validation Loss: 7.48070530488202e-15
Epoch 405, Training Loss: 1.4199963142049734e-15, Validation Loss: 6.685966054208832e-15
Epoch 406, Training Loss: 1.5669896707176559e-15, Validation Loss: 7.209077085290616e-15
Epoch 407, Training Loss: 1.1907013190096821e-15, Validation Loss: 6.6283640021472766e-15
Epoch 408, Training Loss: 1.1907118010424044e-15, Validation Loss: 6.912840440999107e-15
Epoch 409, Training Loss: 1.2649119931009995e-15, Validation Loss: 6.912856534625105e-15
Epoch 410, Training Loss: 1.2136767700665998e-15, Validation Loss: 6.912864581438104e-15
Epoch 411, Training Loss: 1.3900876867165425e-15, Validation Loss: 6.651859849071164e-15
Epoch 412, Training Loss: 1.9393526599898164e-15, Validation Loss: 5.481458945191852e-15
Epoch 413, Training Loss: 1.9647064736835057e-15, Validation Loss: 5.357493132262343e-15
Epoch 414, Training Loss: 1.9261423341444383e-15, Validation Loss: 5.222985570787781e-15
Epoch 415, Training Loss: 1.7154620526353627e-15, Validation Loss: 4.7548812828171645e-15
Epoch 416, Training Loss: 1.8255080437470494e-15, Validation Loss: 5.355496252089191e-15
Epoch 417, Training Loss: 1.8255080437470494e-15, Validation Loss: 5.299202018898197e-15
Epoch 418, Training Loss: 1.380883509074322e-15, Validation Loss: 5.207922783886758e-15
Epoch 419, Training Loss: 1.3808803327007698e-15, Validation Loss: 5.1678826894371e-15
Epoch 420, Training Loss: 1.3808759916569152e-15, Validation Loss: 4.793571630265373e-15
Epoch 421, Training Loss: 1.8772678978131547e-15, Validation Loss: 5.219498336143935e-15
Epoch 422, Training Loss: 1.266050828898583e-15, Validation Loss: 4.9762287796266055e-15
Epoch 423, Training Loss: 1.2633854279718104e-15, Validation Loss: 4.976223273912448e-15
Epoch 424, Training Loss: 1.52119430502876e-15, Validation Loss: 6.0653124029871365e-15
Epoch 425, Training Loss: 8.351790917343908e-16, Validation Loss: 5.964965256758867e-15
Epoch 426, Training Loss: 9.02966767926238e-16, Validation Loss: 5.945753278965718e-15
Epoch 427, Training Loss: 9.910361715840567e-16, Validation Loss: 5.945761749295191e-15
Epoch 428, Training Loss: 1.404164844904317e-15, Validation Loss: 5.607140423356024e-15
Epoch 429, Training Loss: 1.4073652530163989e-15, Validation Loss: 5.6071488936854964e-15
Epoch 430, Training Loss: 1.0807002206442e-15, Validation Loss: 5.981990195482205e-15
Epoch 431, Training Loss: 7.03927683727752e-16, Validation Loss: 4.568596714859315e-15
Epoch 432, Training Loss: 6.783100192709929e-16, Validation Loss: 4.139159057414384e-15
Epoch 433, Training Loss: 6.671025028293976e-16, Validation Loss: 4.2694949816237185e-15
Epoch 434, Training Loss: 1.0151443174496902e-15, Validation Loss: 4.564574578909278e-15
Epoch 435, Training Loss: 9.751120580547942e-16, Validation Loss: 4.564571614293963e-15
Epoch 436, Training Loss: 9.590991119451885e-16, Validation Loss: 4.5645673791292266e-15
Epoch 437, Training Loss: 9.590987943078333e-16, Validation Loss: 4.564564414513911e-15
Epoch 438, Training Loss: 9.590985825495965e-16, Validation Loss: 4.578572221879129e-15
Epoch 439, Training Loss: 9.003847997447701e-16, Validation Loss: 5.014117410390238e-15
Epoch 440, Training Loss: 9.003845879865333e-16, Validation Loss: 5.118197430817057e-15
Epoch 441, Training Loss: 9.00384482107415e-16, Validation Loss: 5.118194466201742e-15
Epoch 442, Training Loss: 8.971816387756096e-16, Validation Loss: 4.626906462948301e-15
Epoch 443, Training Loss: 9.0678921585896e-16, Validation Loss: 4.7016308625221284e-15
Epoch 444, Training Loss: 9.06789004100723e-16, Validation Loss: 4.784361417513403e-15
Epoch 445, Training Loss: 6.802953056806794e-16, Validation Loss: 4.7843576058651405e-15
Epoch 446, Training Loss: 5.486827969407141e-16, Validation Loss: 4.1011412541262955e-15
Epoch 447, Training Loss: 4.958415994383203e-16, Validation Loss: 4.10274256991308e-15
Epoch 448, Training Loss: 4.958415994383203e-16, Validation Loss: 4.057375061741666e-15
Epoch 449, Training Loss: 4.958404347680178e-16, Validation Loss: 4.0573788733899285e-15
Epoch 450, Training Loss: 5.374714688508562e-16, Validation Loss: 4.038701796902971e-15
Epoch 451, Training Loss: 5.374692453893697e-16, Validation Loss: 3.8151388854199865e-15
Epoch 452, Training Loss: 5.374658572575807e-16, Validation Loss: 3.8151456616835645e-15
Epoch 453, Training Loss: 6.294018075009376e-16, Validation Loss: 3.8124842841632915e-15
Epoch 454, Training Loss: 1.5854682238576005e-15, Validation Loss: 4.5223940322019086e-15
Epoch 455, Training Loss: 1.5726588622336289e-15, Validation Loss: 4.967556009279669e-15
Epoch 456, Training Loss: 1.4637720357102597e-15, Validation Loss: 5.033213768186086e-15
Epoch 457, Training Loss: 1.4637725651058518e-15, Validation Loss: 4.343064451773964e-15
Epoch 458, Training Loss: 1.4637729886223254e-15, Validation Loss: 4.3174476343501526e-15
Epoch 459, Training Loss: 5.146025321870558e-16, Validation Loss: 4.317449751932521e-15
Epoch 460, Training Loss: 4.676419138605341e-16, Validation Loss: 4.317449751932521e-15
Epoch 461, Training Loss: 4.548315993244969e-16, Validation Loss: 4.317449751932521e-15
Epoch 462, Training Loss: 4.548315993244969e-16, Validation Loss: 4.317449751932521e-15
Epoch 463, Training Loss: 4.548315993244969e-16, Validation Loss: 4.317449751932521e-15
Epoch 464, Training Loss: 4.548315993244969e-16, Validation Loss: 4.317449751932521e-15
Epoch 465, Training Loss: 4.548315993244969e-16, Validation Loss: 4.317449751932521e-15
Epoch 466, Training Loss: 1.2907016052460512e-15, Validation Loss: 4.287066680114509e-15
Epoch 467, Training Loss: 1.2866879396254867e-15, Validation Loss: 4.287065409565088e-15
Epoch 468, Training Loss: 1.2866849750101713e-15, Validation Loss: 4.358054393841524e-15
Epoch 469, Training Loss: 1.2866805280871982e-15, Validation Loss: 4.3580522762591556e-15
Epoch 470, Training Loss: 1.5025808618919652e-15, Validation Loss: 5.87660066211893e-15
Epoch 471, Training Loss: 1.5025750385404529e-15, Validation Loss: 5.774116028248264e-15
Epoch 472, Training Loss: 1.5025677328812828e-15, Validation Loss: 5.786923589927223e-15
Epoch 473, Training Loss: 1.5025587331562182e-15, Validation Loss: 5.762901312026617e-15
Epoch 474, Training Loss: 1.5009487352817246e-15, Validation Loss: 5.079683266221878e-15
Epoch 475, Training Loss: 3.0664784388356693e-16, Validation Loss: 3.660072987282615e-15
Epoch 476, Training Loss: 1.0754308816188901e-16, Validation Loss: 3.660058587722512e-15
Epoch 477, Training Loss: 1.1874024168477022e-16, Validation Loss: 3.76150306513395e-15
Epoch 478, Training Loss: 1.1872843616306787e-16, Validation Loss: 3.761483583376163e-15
Epoch 479, Training Loss: 1.1871516156859762e-16, Validation Loss: 3.76146452513485e-15
Epoch 480, Training Loss: 1.1870186050434776e-16, Validation Loss: 3.7614454668935364e-15
Epoch 481, Training Loss: 5.366235359310955e-16, Validation Loss: 4.3408130382001624e-15
Epoch 482, Training Loss: 5.366088187336369e-16, Validation Loss: 4.379197183237938e-15
Epoch 483, Training Loss: 5.269863656341505e-16, Validation Loss: 4.35713155144549e-15
Epoch 484, Training Loss: 9.19563253562053e-17, Validation Loss: 3.947065961020738e-15
Epoch 485, Training Loss: 8.660401018928908e-17, Validation Loss: 3.9470282680545855e-15
Epoch 486, Training Loss: 8.658781730161774e-17, Validation Loss: 3.946990575088433e-15
Epoch 487, Training Loss: 3.586563815290302e-16, Validation Loss: 3.94695288212228e-15
Epoch 488, Training Loss: 3.586402084936936e-16, Validation Loss: 3.946915189156127e-15
Epoch 489, Training Loss: 3.5862406192813654e-16, Validation Loss: 3.96409132326055e-15
Epoch 490, Training Loss: 3.586078888927999e-16, Validation Loss: 3.9640540538108705e-15
Epoch 491, Training Loss: 3.3991013950797366e-16, Validation Loss: 3.964015937328244e-15
Epoch 492, Training Loss: 6.841803281723796e-16, Validation Loss: 4.084078198920331e-15
Epoch 493, Training Loss: 6.841786870460443e-16, Validation Loss: 4.0840472822177565e-15
Epoch 494, Training Loss: 6.841772047383866e-16, Validation Loss: 3.9959931251529884e-15
Epoch 495, Training Loss: 6.841757753702881e-16, Validation Loss: 3.4329152679714835e-15
Epoch 496, Training Loss: 7.443373492402089e-16, Validation Loss: 3.4136960903982834e-15
Epoch 497, Training Loss: 5.009545020661841e-16, Validation Loss: 3.4136935492994416e-15
Epoch 498, Training Loss: 5.057657550857069e-16, Validation Loss: 4.0969077834559185e-15
Epoch 499, Training Loss: 3.3763093266558995e-16, Validation Loss: 4.096909477521813e-15
Epoch 500, Training Loss: 2.7611320610755586e-16, Validation Loss: 4.479617174299672e-15
