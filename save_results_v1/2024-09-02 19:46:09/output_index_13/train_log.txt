Epoch 1, Training Loss: 0.5072711110115051, Validation Loss: 0.5057260394096375
Epoch 2, Training Loss: 0.5057260394096375, Validation Loss: 0.5042257308959961
Epoch 3, Training Loss: 0.5042257308959961, Validation Loss: 0.5027350783348083
Epoch 4, Training Loss: 0.5027350783348083, Validation Loss: 0.5012362599372864
Epoch 5, Training Loss: 0.5012362599372864, Validation Loss: 0.49972793459892273
Epoch 6, Training Loss: 0.49972793459892273, Validation Loss: 0.4982186257839203
Epoch 7, Training Loss: 0.4982186257839203, Validation Loss: 0.4967325031757355
Epoch 8, Training Loss: 0.4967325031757355, Validation Loss: 0.4952409863471985
Epoch 9, Training Loss: 0.4952409565448761, Validation Loss: 0.4937586486339569
Epoch 10, Training Loss: 0.4937586486339569, Validation Loss: 0.4922569990158081
Epoch 11, Training Loss: 0.4922569990158081, Validation Loss: 0.49072912335395813
Epoch 12, Training Loss: 0.49072912335395813, Validation Loss: 0.48916980624198914
Epoch 13, Training Loss: 0.4891698360443115, Validation Loss: 0.4876425862312317
Epoch 14, Training Loss: 0.48764264583587646, Validation Loss: 0.4861028790473938
Epoch 15, Training Loss: 0.4861029386520386, Validation Loss: 0.4845382571220398
Epoch 16, Training Loss: 0.484538197517395, Validation Loss: 0.48294928669929504
Epoch 17, Training Loss: 0.48294928669929504, Validation Loss: 0.48129522800445557
Epoch 18, Training Loss: 0.48129522800445557, Validation Loss: 0.47959110140800476
Epoch 19, Training Loss: 0.47959110140800476, Validation Loss: 0.4778546094894409
Epoch 20, Training Loss: 0.4778546094894409, Validation Loss: 0.47608381509780884
Epoch 21, Training Loss: 0.47608378529548645, Validation Loss: 0.4742431938648224
Epoch 22, Training Loss: 0.4742431938648224, Validation Loss: 0.4723318815231323
Epoch 23, Training Loss: 0.4723318815231323, Validation Loss: 0.4703349471092224
Epoch 24, Training Loss: 0.4703349173069, Validation Loss: 0.4682515859603882
Epoch 25, Training Loss: 0.4682515263557434, Validation Loss: 0.4660753607749939
Epoch 26, Training Loss: 0.4660753309726715, Validation Loss: 0.4637875258922577
Epoch 27, Training Loss: 0.4637874960899353, Validation Loss: 0.4614008963108063
Epoch 28, Training Loss: 0.4614008665084839, Validation Loss: 0.45890846848487854
Epoch 29, Training Loss: 0.4589084982872009, Validation Loss: 0.4562995731830597
Epoch 30, Training Loss: 0.4562995731830597, Validation Loss: 0.4535365700721741
Epoch 31, Training Loss: 0.4535365700721741, Validation Loss: 0.4506141245365143
Epoch 32, Training Loss: 0.4506141245365143, Validation Loss: 0.44758284091949463
Epoch 33, Training Loss: 0.44758284091949463, Validation Loss: 0.44436970353126526
Epoch 34, Training Loss: 0.44436973333358765, Validation Loss: 0.4409436583518982
Epoch 35, Training Loss: 0.4409436583518982, Validation Loss: 0.4373096525669098
Epoch 36, Training Loss: 0.4373096525669098, Validation Loss: 0.4334900379180908
Epoch 37, Training Loss: 0.4334900379180908, Validation Loss: 0.42939531803131104
Epoch 38, Training Loss: 0.42939531803131104, Validation Loss: 0.42497900128364563
Epoch 39, Training Loss: 0.42497894167900085, Validation Loss: 0.42027291655540466
Epoch 40, Training Loss: 0.42027291655540466, Validation Loss: 0.4152291417121887
Epoch 41, Training Loss: 0.4152292013168335, Validation Loss: 0.4098314344882965
Epoch 42, Training Loss: 0.4098314344882965, Validation Loss: 0.4040585160255432
Epoch 43, Training Loss: 0.4040584862232208, Validation Loss: 0.39789068698883057
Epoch 44, Training Loss: 0.39789068698883057, Validation Loss: 0.391272634267807
Epoch 45, Training Loss: 0.391272634267807, Validation Loss: 0.38417187333106995
Epoch 46, Training Loss: 0.38417190313339233, Validation Loss: 0.3765934109687805
Epoch 47, Training Loss: 0.3765934705734253, Validation Loss: 0.3685174584388733
Epoch 48, Training Loss: 0.3685174584388733, Validation Loss: 0.3598717749118805
Epoch 49, Training Loss: 0.3598718047142029, Validation Loss: 0.3507139980792999
Epoch 50, Training Loss: 0.35071396827697754, Validation Loss: 0.34107303619384766
Epoch 51, Training Loss: 0.34107300639152527, Validation Loss: 0.3309328258037567
Epoch 52, Training Loss: 0.3309328258037567, Validation Loss: 0.3202729821205139
Epoch 53, Training Loss: 0.3202730119228363, Validation Loss: 0.30914047360420227
Epoch 54, Training Loss: 0.30914050340652466, Validation Loss: 0.29769665002822876
Epoch 55, Training Loss: 0.29769667983055115, Validation Loss: 0.28592854738235474
Epoch 56, Training Loss: 0.28592854738235474, Validation Loss: 0.2739141285419464
Epoch 57, Training Loss: 0.2739141285419464, Validation Loss: 0.2617795467376709
Epoch 58, Training Loss: 0.2617795765399933, Validation Loss: 0.24970048666000366
Epoch 59, Training Loss: 0.24970048666000366, Validation Loss: 0.23791921138763428
Epoch 60, Training Loss: 0.23791919648647308, Validation Loss: 0.22660206258296967
Epoch 61, Training Loss: 0.22660209238529205, Validation Loss: 0.21597881615161896
Epoch 62, Training Loss: 0.21597880125045776, Validation Loss: 0.2062591165304184
Epoch 63, Training Loss: 0.2062591165304184, Validation Loss: 0.19767633080482483
Epoch 64, Training Loss: 0.19767633080482483, Validation Loss: 0.19037595391273499
Epoch 65, Training Loss: 0.19037595391273499, Validation Loss: 0.18416465818881989
Epoch 66, Training Loss: 0.18416467308998108, Validation Loss: 0.17885497212409973
Epoch 67, Training Loss: 0.17885497212409973, Validation Loss: 0.17423182725906372
Epoch 68, Training Loss: 0.17423182725906372, Validation Loss: 0.169901043176651
Epoch 69, Training Loss: 0.169901043176651, Validation Loss: 0.1654197722673416
Epoch 70, Training Loss: 0.165419802069664, Validation Loss: 0.16058030724525452
Epoch 71, Training Loss: 0.16058030724525452, Validation Loss: 0.1551636904478073
Epoch 72, Training Loss: 0.1551637202501297, Validation Loss: 0.14935700595378876
Epoch 73, Training Loss: 0.14935699105262756, Validation Loss: 0.143075630068779
Epoch 74, Training Loss: 0.1430756151676178, Validation Loss: 0.13648855686187744
Epoch 75, Training Loss: 0.13648855686187744, Validation Loss: 0.12976861000061035
Epoch 76, Training Loss: 0.12976859509944916, Validation Loss: 0.12312792241573334
Epoch 77, Training Loss: 0.12312794476747513, Validation Loss: 0.11661296337842941
Epoch 78, Training Loss: 0.1166129782795906, Validation Loss: 0.11028821766376495
Epoch 79, Training Loss: 0.11028823256492615, Validation Loss: 0.10417772829532623
Epoch 80, Training Loss: 0.10417772084474564, Validation Loss: 0.09821602702140808
Epoch 81, Training Loss: 0.09821602702140808, Validation Loss: 0.09250544011592865
Epoch 82, Training Loss: 0.09250545501708984, Validation Loss: 0.08700782060623169
Epoch 83, Training Loss: 0.08700782805681229, Validation Loss: 0.08161488175392151
Epoch 84, Training Loss: 0.08161488175392151, Validation Loss: 0.07615873962640762
Epoch 85, Training Loss: 0.07615873962640762, Validation Loss: 0.07072722911834717
Epoch 86, Training Loss: 0.07072722166776657, Validation Loss: 0.06540344655513763
Epoch 87, Training Loss: 0.06540344655513763, Validation Loss: 0.060141779482364655
Epoch 88, Training Loss: 0.060141775757074356, Validation Loss: 0.054959461092948914
Epoch 89, Training Loss: 0.054959461092948914, Validation Loss: 0.04990791529417038
Epoch 90, Training Loss: 0.04990791529417038, Validation Loss: 0.04503365233540535
Epoch 91, Training Loss: 0.04503364861011505, Validation Loss: 0.040410518646240234
Epoch 92, Training Loss: 0.040410514920949936, Validation Loss: 0.03611277416348457
Epoch 93, Training Loss: 0.036112770438194275, Validation Loss: 0.03218786045908928
Epoch 94, Training Loss: 0.03218786045908928, Validation Loss: 0.02866046316921711
Epoch 95, Training Loss: 0.028660455718636513, Validation Loss: 0.0255641657859087
Epoch 96, Training Loss: 0.02556416019797325, Validation Loss: 0.022818855941295624
Epoch 97, Training Loss: 0.022818852216005325, Validation Loss: 0.020386001095175743
Epoch 98, Training Loss: 0.02038600482046604, Validation Loss: 0.018270503729581833
Epoch 99, Training Loss: 0.018270501866936684, Validation Loss: 0.01635800115764141
Epoch 100, Training Loss: 0.016358008608222008, Validation Loss: 0.01459326408803463
Epoch 101, Training Loss: 0.014593265019357204, Validation Loss: 0.012940275482833385
Epoch 102, Training Loss: 0.012940279208123684, Validation Loss: 0.01139676570892334
Epoch 103, Training Loss: 0.01139676384627819, Validation Loss: 0.00995550211519003
Epoch 104, Training Loss: 0.00995550025254488, Validation Loss: 0.00862255971878767
Epoch 105, Training Loss: 0.00862256158143282, Validation Loss: 0.007435810286551714
Epoch 106, Training Loss: 0.007435807026922703, Validation Loss: 0.006384951062500477
Epoch 107, Training Loss: 0.0063849505968391895, Validation Loss: 0.005456242710351944
Epoch 108, Training Loss: 0.005456242244690657, Validation Loss: 0.004642152693122625
Epoch 109, Training Loss: 0.004642152227461338, Validation Loss: 0.003934219479560852
Epoch 110, Training Loss: 0.003934220410883427, Validation Loss: 0.0033386116847395897
Epoch 111, Training Loss: 0.0033386116847395897, Validation Loss: 0.0028335596434772015
Epoch 112, Training Loss: 0.0028335596434772015, Validation Loss: 0.002401038771495223
Epoch 113, Training Loss: 0.002401039469987154, Validation Loss: 0.002038133330643177
Epoch 114, Training Loss: 0.0020381317008286715, Validation Loss: 0.0017292938427999616
Epoch 115, Training Loss: 0.001729294192045927, Validation Loss: 0.001470238552428782
Epoch 116, Training Loss: 0.0014702389016747475, Validation Loss: 0.001256011426448822
Epoch 117, Training Loss: 0.0012560120085254312, Validation Loss: 0.001080881105735898
Epoch 118, Training Loss: 0.0010808812221512198, Validation Loss: 0.0009391519706696272
Epoch 119, Training Loss: 0.0009391524363309145, Validation Loss: 0.0008246524375863373
Epoch 120, Training Loss: 0.0008246530196629465, Validation Loss: 0.0007310270448215306
Epoch 121, Training Loss: 0.0007310278015211225, Validation Loss: 0.0006534077110700309
Epoch 122, Training Loss: 0.0006534078274853528, Validation Loss: 0.0005859569646418095
Epoch 123, Training Loss: 0.0005859559751115739, Validation Loss: 0.0005269292742013931
Epoch 124, Training Loss: 0.0005269299144856632, Validation Loss: 0.0004737061099149287
Epoch 125, Training Loss: 0.0004737064300570637, Validation Loss: 0.00042571654194034636
Epoch 126, Training Loss: 0.0004257175314705819, Validation Loss: 0.0003819078847300261
Epoch 127, Training Loss: 0.00038190738996490836, Validation Loss: 0.000341791776008904
Epoch 128, Training Loss: 0.00034179180511273444, Validation Loss: 0.0003086482174694538
Epoch 129, Training Loss: 0.00030864807195030153, Validation Loss: 0.0002787694684229791
Epoch 130, Training Loss: 0.00027876888634637, Validation Loss: 0.00025281161651946604
Epoch 131, Training Loss: 0.00025281161651946604, Validation Loss: 0.00023087977024260908
Epoch 132, Training Loss: 0.00023088011948857456, Validation Loss: 0.00021250781719572842
Epoch 133, Training Loss: 0.0002125074970535934, Validation Loss: 0.00019723224977497011
Epoch 134, Training Loss: 0.00019723267178051174, Validation Loss: 0.0001841291377786547
Epoch 135, Training Loss: 0.0001841293415054679, Validation Loss: 0.00017202306480612606
Epoch 136, Training Loss: 0.00017202270100824535, Validation Loss: 0.00015979590534698218
Epoch 137, Training Loss: 0.00015979543968569487, Validation Loss: 0.00014669913798570633
Epoch 138, Training Loss: 0.00014669843949377537, Validation Loss: 0.0001325018092757091
Epoch 139, Training Loss: 0.00013250143092591316, Validation Loss: 0.00011750056728487834
Epoch 140, Training Loss: 0.000117500800115522, Validation Loss: 0.00010237703827442601
Epoch 141, Training Loss: 0.00010237696551484987, Validation Loss: 8.796295151114464e-05
Epoch 142, Training Loss: 8.79624712979421e-05, Validation Loss: 7.499910134356469e-05
Epoch 143, Training Loss: 7.499911589547992e-05, Validation Loss: 6.397145625669509e-05
Epoch 144, Training Loss: 6.397123797796667e-05, Validation Loss: 5.5005355534376577e-05
Epoch 145, Training Loss: 5.5005159083520994e-05, Validation Loss: 4.794540291186422e-05
Epoch 146, Training Loss: 4.794548294739798e-05, Validation Loss: 4.242938302922994e-05
Epoch 147, Training Loss: 4.2429561290191486e-05, Validation Loss: 3.803081563091837e-05
Epoch 148, Training Loss: 3.8030746509321034e-05, Validation Loss: 3.438828935031779e-05
Epoch 149, Training Loss: 3.4388223866699263e-05, Validation Loss: 3.127103627775796e-05
Epoch 150, Training Loss: 3.1270890758605674e-05, Validation Loss: 2.8577935154316947e-05
Epoch 151, Training Loss: 2.8577984267030843e-05, Validation Loss: 2.6295516363461502e-05
Epoch 152, Training Loss: 2.6295374482288025e-05, Validation Loss: 2.4434384613414295e-05
Epoch 153, Training Loss: 2.4434359147562645e-05, Validation Loss: 2.2979458663030528e-05
Epoch 154, Training Loss: 2.2979264031164348e-05, Validation Loss: 2.185843732149806e-05
Epoch 155, Training Loss: 2.1858477339264937e-05, Validation Loss: 2.0953506464138627e-05
Epoch 156, Training Loss: 2.0953480998286977e-05, Validation Loss: 2.0124578441027552e-05
Epoch 157, Training Loss: 2.01246039068792e-05, Validation Loss: 1.9244344002800062e-05
Epoch 158, Training Loss: 1.924435855471529e-05, Validation Loss: 1.8224865925731137e-05
Epoch 159, Training Loss: 1.8224909581476822e-05, Validation Loss: 1.7030311937560327e-05
Epoch 160, Training Loss: 1.7030275557772256e-05, Validation Loss: 1.5673786037950777e-05
Epoch 161, Training Loss: 1.5673764210077934e-05, Validation Loss: 1.4205383195076138e-05
Epoch 162, Training Loss: 1.4205363186192699e-05, Validation Loss: 1.2693969438259955e-05
Epoch 163, Training Loss: 1.2693983080680482e-05, Validation Loss: 1.121086097555235e-05
Epoch 164, Training Loss: 1.1210877346456982e-05, Validation Loss: 9.81705125013832e-06
Epoch 165, Training Loss: 9.817043974180706e-06, Validation Loss: 8.555360182072036e-06
Epoch 166, Training Loss: 8.555298336432315e-06, Validation Loss: 7.446043127856683e-06
Epoch 167, Training Loss: 7.445990831911331e-06, Validation Loss: 6.488853614428081e-06
Epoch 168, Training Loss: 6.4888822635111865e-06, Validation Loss: 5.667023742716992e-06
Epoch 169, Training Loss: 5.666887773259077e-06, Validation Loss: 4.953606094204588e-06
Epoch 170, Training Loss: 4.953670213581063e-06, Validation Loss: 4.320650532463333e-06
Epoch 171, Training Loss: 4.3206068767176475e-06, Validation Loss: 3.7457787129824283e-06
Epoch 172, Training Loss: 3.7457753023772966e-06, Validation Loss: 3.2177581488213036e-06
Epoch 173, Training Loss: 3.2176974400499603e-06, Validation Loss: 2.7369785584596684e-06
Epoch 174, Training Loss: 2.7370222142053535e-06, Validation Loss: 2.3129794044507435e-06
Epoch 175, Training Loss: 2.312950982741313e-06, Validation Loss: 1.9576643808250083e-06
Epoch 176, Training Loss: 1.9576177692215424e-06, Validation Loss: 1.6788383163657272e-06
Epoch 177, Training Loss: 1.6787876120361034e-06, Validation Loss: 1.4756247992409044e-06
Epoch 178, Training Loss: 1.4756070640942198e-06, Validation Loss: 1.3367575775191654e-06
Epoch 179, Training Loss: 1.3367715610002051e-06, Validation Loss: 1.2433058600436198e-06
Epoch 180, Training Loss: 1.2433251868060324e-06, Validation Loss: 1.1737200793504599e-06
Epoch 181, Training Loss: 1.1737852219084743e-06, Validation Loss: 1.1092564591308474e-06
Epoch 182, Training Loss: 1.1092856766481418e-06, Validation Loss: 1.0380852017988218e-06
Epoch 183, Training Loss: 1.0380596222603344e-06, Validation Loss: 9.567986580805155e-07
Epoch 184, Training Loss: 9.568013865646208e-07, Validation Loss: 8.686191108608909e-07
Epoch 185, Training Loss: 8.686242836120073e-07, Validation Loss: 7.804771939845523e-07
Epoch 186, Training Loss: 7.804796950949822e-07, Validation Loss: 6.991812711021339e-07
Epoch 187, Training Loss: 6.991766099417873e-07, Validation Loss: 6.288009331001376e-07
Epoch 188, Training Loss: 6.287725113907072e-07, Validation Loss: 5.699909024770022e-07
Epoch 189, Training Loss: 5.700227347915643e-07, Validation Loss: 5.207523940953251e-07
Epoch 190, Training Loss: 5.207547246754984e-07, Validation Loss: 4.776379682880361e-07
Epoch 191, Training Loss: 4.776117634719412e-07, Validation Loss: 4.3778305780506344e-07
Epoch 192, Training Loss: 4.3780849523500365e-07, Validation Loss: 3.997610065198387e-07
Epoch 193, Training Loss: 3.9977928167900245e-07, Validation Loss: 3.6373410239320947e-07
Epoch 194, Training Loss: 3.637399288436427e-07, Validation Loss: 3.308447276140214e-07
Epoch 195, Training Loss: 3.3084870665334165e-07, Validation Loss: 3.0238476256272406e-07
Epoch 196, Training Loss: 3.02381323535883e-07, Validation Loss: 2.7912099653804034e-07
Epoch 197, Training Loss: 2.791073256958043e-07, Validation Loss: 2.607893065942335e-07
Epoch 198, Training Loss: 2.607879139304714e-07, Validation Loss: 2.4631157202748e-07
Epoch 199, Training Loss: 2.463185921897093e-07, Validation Loss: 2.3407757510085503e-07
Epoch 200, Training Loss: 2.340944718071114e-07, Validation Loss: 2.2239501618059876e-07
Epoch 201, Training Loss: 2.2241249553189846e-07, Validation Loss: 2.098752531765058e-07
Epoch 202, Training Loss: 2.0988278492950485e-07, Validation Loss: 1.9569671394492616e-07
Epoch 203, Training Loss: 1.957096600335717e-07, Validation Loss: 1.7963861864700448e-07
Epoch 204, Training Loss: 1.796307032009281e-07, Validation Loss: 1.619922045392741e-07
Epoch 205, Training Loss: 1.619765015448138e-07, Validation Loss: 1.4353047106396843e-07
Epoch 206, Training Loss: 1.435285668094366e-07, Validation Loss: 1.2521732628556492e-07
Epoch 207, Training Loss: 1.2521577730240097e-07, Validation Loss: 1.0802327921055621e-07
Epoch 208, Training Loss: 1.080193428038001e-07, Validation Loss: 9.266310030398017e-08
Epoch 209, Training Loss: 9.265897915611276e-08, Validation Loss: 7.953394742798992e-08
Epoch 210, Training Loss: 7.953885017286666e-08, Validation Loss: 6.86148950990173e-08
Epoch 211, Training Loss: 6.862446610966799e-08, Validation Loss: 5.9562704990412385e-08
Epoch 212, Training Loss: 5.9547861752662357e-08, Validation Loss: 5.183772699979272e-08
Epoch 213, Training Loss: 5.1835613135153835e-08, Validation Loss: 4.496341432513873e-08
Epoch 214, Training Loss: 4.496468974934942e-08, Validation Loss: 3.860429131918863e-08
Epoch 215, Training Loss: 3.8612135710991424e-08, Validation Loss: 3.27331477478765e-08
Epoch 216, Training Loss: 3.273063953201927e-08, Validation Loss: 2.747207616948799e-08
Epoch 217, Training Loss: 2.746811311737929e-08, Validation Loss: 2.305086432841108e-08
Epoch 218, Training Loss: 2.305364965593526e-08, Validation Loss: 1.9660285843769998e-08
Epoch 219, Training Loss: 1.965627838274031e-08, Validation Loss: 1.7311448274881513e-08
Epoch 220, Training Loss: 1.731048016040404e-08, Validation Loss: 1.5866149283283448e-08
Epoch 221, Training Loss: 1.586525755215007e-08, Validation Loss: 1.5027810107426376e-08
Epoch 222, Training Loss: 1.5030446220976046e-08, Validation Loss: 1.4493789279867997e-08
Epoch 223, Training Loss: 1.4491733146826391e-08, Validation Loss: 1.4000971937377926e-08
Epoch 224, Training Loss: 1.3997883741012629e-08, Validation Loss: 1.3407514209973215e-08
Epoch 225, Training Loss: 1.3404500620595172e-08, Validation Loss: 1.2681868000186114e-08
Epoch 226, Training Loss: 1.2686759198743403e-08, Validation Loss: 1.1868705129813861e-08
Epoch 227, Training Loss: 1.1864367266412046e-08, Validation Loss: 1.1024816615190502e-08
Epoch 228, Training Loss: 1.102331204094753e-08, Validation Loss: 1.0201387290464936e-08
Epoch 229, Training Loss: 1.0201596900571985e-08, Validation Loss: 9.412924661944544e-09
Epoch 230, Training Loss: 9.415181523309002e-09, Validation Loss: 8.639619686334754e-09
Epoch 231, Training Loss: 8.642052407026313e-09, Validation Loss: 7.864956685921243e-09
Epoch 232, Training Loss: 7.867152262974741e-09, Validation Loss: 7.074812735652358e-09
Epoch 233, Training Loss: 7.073660768242007e-09, Validation Loss: 6.27600060809641e-09
Epoch 234, Training Loss: 6.2746998708007595e-09, Validation Loss: 5.496381572100972e-09
Epoch 235, Training Loss: 5.496320287790013e-09, Validation Loss: 4.777973128256008e-09
Epoch 236, Training Loss: 4.776897100100541e-09, Validation Loss: 4.153221322411582e-09
Epoch 237, Training Loss: 4.1533327888032545e-09, Validation Loss: 3.64394070473395e-09
Epoch 238, Training Loss: 3.643327639579752e-09, Validation Loss: 3.2483873368960303e-09
Epoch 239, Training Loss: 3.246795277078718e-09, Validation Loss: 2.9568947290670167e-09
Epoch 240, Training Loss: 2.9560101033609953e-09, Validation Loss: 2.743582472319872e-09
Epoch 241, Training Loss: 2.743860916254448e-09, Validation Loss: 2.5805710901494194e-09
Epoch 242, Training Loss: 2.5785475976647376e-09, Validation Loss: 2.431171264305476e-09
Epoch 243, Training Loss: 2.4315824909137973e-09, Validation Loss: 2.2746140526663794e-09
Epoch 244, Training Loss: 2.2757684625673846e-09, Validation Loss: 2.0999033623070318e-09
Epoch 245, Training Loss: 2.1010035933244353e-09, Validation Loss: 1.9043935317597516e-09
Epoch 246, Training Loss: 1.9045305332809903e-09, Validation Loss: 1.698349461065618e-09
Epoch 247, Training Loss: 1.6991505980001875e-09, Validation Loss: 1.4992183050566155e-09
Epoch 248, Training Loss: 1.4988950081118446e-09, Validation Loss: 1.3206616911176638e-09
Epoch 249, Training Loss: 1.3200082138453695e-09, Validation Loss: 1.1746242867261003e-09
Epoch 250, Training Loss: 1.1756692286368775e-09, Validation Loss: 1.0627057012158048e-09
Epoch 251, Training Loss: 1.0618865786682363e-09, Validation Loss: 9.761570440858236e-10
Epoch 252, Training Loss: 9.750298346489217e-10, Validation Loss: 9.032570802425255e-10
Epoch 253, Training Loss: 9.033764292176727e-10, Validation Loss: 8.335496737288395e-10
Epoch 254, Training Loss: 8.336347168125258e-10, Validation Loss: 7.591831052700115e-10
Epoch 255, Training Loss: 7.600241547223163e-10, Validation Loss: 6.789199202827945e-10
Epoch 256, Training Loss: 6.791633366809435e-10, Validation Loss: 5.958004645201243e-10
Epoch 257, Training Loss: 5.958395443705911e-10, Validation Loss: 5.159052629544192e-10
Epoch 258, Training Loss: 5.152894222426596e-10, Validation Loss: 4.4383871578013157e-10
Epoch 259, Training Loss: 4.4380693564605167e-10, Validation Loss: 3.816140459189654e-10
Epoch 260, Training Loss: 3.817566540664785e-10, Validation Loss: 3.281622196205092e-10
Epoch 261, Training Loss: 3.287319583211712e-10, Validation Loss: 2.8331934021075256e-10
Epoch 262, Training Loss: 2.83099571563028e-10, Validation Loss: 2.4307039714344114e-10
Epoch 263, Training Loss: 2.432238022098687e-10, Validation Loss: 2.0736906636287245e-10
Epoch 264, Training Loss: 2.077024802149552e-10, Validation Loss: 1.7519155570688838e-10
Epoch 265, Training Loss: 1.7566935406332362e-10, Validation Loss: 1.4821326110858735e-10
Epoch 266, Training Loss: 1.479345396182552e-10, Validation Loss: 1.256791615222852e-10
Epoch 267, Training Loss: 1.262458748652051e-10, Validation Loss: 1.1006263955781748e-10
Epoch 268, Training Loss: 1.1028353924524836e-10, Validation Loss: 9.967613540107223e-11
Epoch 269, Training Loss: 9.969534919829215e-11, Validation Loss: 9.296832054195292e-11
Epoch 270, Training Loss: 9.309750192976196e-11, Validation Loss: 8.828188180487473e-11
Epoch 271, Training Loss: 8.832666542613055e-11, Validation Loss: 8.476865737128136e-11
Epoch 272, Training Loss: 8.492350572764096e-11, Validation Loss: 8.134532630821312e-11
Epoch 273, Training Loss: 8.152824249041402e-11, Validation Loss: 7.85056117336147e-11
Epoch 274, Training Loss: 7.867454604459923e-11, Validation Loss: 7.53396997565936e-11
Epoch 275, Training Loss: 7.512362953931984e-11, Validation Loss: 7.174571353685266e-11
Epoch 276, Training Loss: 7.178565381016355e-11, Validation Loss: 6.85068737849015e-11
Epoch 277, Training Loss: 6.841197747187167e-11, Validation Loss: 6.54846316061608e-11
Epoch 278, Training Loss: 6.583865397313815e-11, Validation Loss: 6.335202501484005e-11
Epoch 279, Training Loss: 6.321526635488794e-11, Validation Loss: 6.094598437034193e-11
Epoch 280, Training Loss: 6.100281391141493e-11, Validation Loss: 5.864366631191942e-11
Epoch 281, Training Loss: 5.868183022839091e-11, Validation Loss: 5.5694636402758846e-11
Epoch 282, Training Loss: 5.559275609301473e-11, Validation Loss: 5.170196215598111e-11
Epoch 283, Training Loss: 5.2026556673911983e-11, Validation Loss: 4.7045374540477525e-11
Epoch 284, Training Loss: 4.703954240015129e-11, Validation Loss: 4.1682848145319085e-11
Epoch 285, Training Loss: 4.170610037879108e-11, Validation Loss: 3.579212620730132e-11
Epoch 286, Training Loss: 3.5753129623561364e-11, Validation Loss: 2.995698480945386e-11
Epoch 287, Training Loss: 2.995736297917162e-11, Validation Loss: 2.471966381589752e-11
Epoch 288, Training Loss: 2.4701530751403133e-11, Validation Loss: 2.0106798170882456e-11
Epoch 289, Training Loss: 2.0176766507562505e-11, Validation Loss: 1.671744860598512e-11
Epoch 290, Training Loss: 1.654247051841029e-11, Validation Loss: 1.3738082720038403e-11
Epoch 291, Training Loss: 1.3768964267357742e-11, Validation Loss: 1.1481653301725903e-11
Epoch 292, Training Loss: 1.1508269164017815e-11, Validation Loss: 9.825508462402155e-12
Epoch 293, Training Loss: 9.67191951528612e-12, Validation Loss: 8.428216458078452e-12
Epoch 294, Training Loss: 8.315742192066544e-12, Validation Loss: 7.1314885420614704e-12
Epoch 295, Training Loss: 7.217304878737174e-12, Validation Loss: 6.231638469134104e-12
Epoch 296, Training Loss: 6.211451925725031e-12, Validation Loss: 5.601654123194022e-12
Epoch 297, Training Loss: 5.5561358465461286e-12, Validation Loss: 4.9402782212326635e-12
Epoch 298, Training Loss: 4.927203610394226e-12, Validation Loss: 4.479503139948049e-12
Epoch 299, Training Loss: 4.457534601848279e-12, Validation Loss: 4.103578154363019e-12
Epoch 300, Training Loss: 4.1691311861158376e-12, Validation Loss: 3.986849045345409e-12
Epoch 301, Training Loss: 4.01533233745921e-12, Validation Loss: 3.893753375283637e-12
Epoch 302, Training Loss: 3.856631160259472e-12, Validation Loss: 3.752055090233686e-12
Epoch 303, Training Loss: 3.735628559958792e-12, Validation Loss: 3.584228183348137e-12
Epoch 304, Training Loss: 3.584830132394301e-12, Validation Loss: 3.442994153668444e-12
Epoch 305, Training Loss: 3.3983519123759187e-12, Validation Loss: 3.1214679278857016e-12
Epoch 306, Training Loss: 3.0954993342907633e-12, Validation Loss: 2.8744203198205476e-12
Epoch 307, Training Loss: 2.920504333162044e-12, Validation Loss: 2.643502604315895e-12
Epoch 308, Training Loss: 2.6234960384674544e-12, Validation Loss: 2.3166824361653404e-12
Epoch 309, Training Loss: 2.329829688549334e-12, Validation Loss: 2.127745245619761e-12
Epoch 310, Training Loss: 2.0610371048723763e-12, Validation Loss: 1.8288831820506557e-12
Epoch 311, Training Loss: 1.824405643918725e-12, Validation Loss: 1.67122652522389e-12
Epoch 312, Training Loss: 1.6432147526349028e-12, Validation Loss: 1.4818486064951952e-12
Epoch 313, Training Loss: 1.4581728836546293e-12, Validation Loss: 1.3048702743323481e-12
Epoch 314, Training Loss: 1.2985905753493121e-12, Validation Loss: 1.173404364125663e-12
Epoch 315, Training Loss: 1.1996023749002993e-12, Validation Loss: 1.1233403530291897e-12
Epoch 316, Training Loss: 1.0807612400506872e-12, Validation Loss: 1.0046784367986894e-12
Epoch 317, Training Loss: 9.603385794920705e-13, Validation Loss: 9.544116798959612e-13
Epoch 318, Training Loss: 9.488434343785102e-13, Validation Loss: 8.644755918052471e-13
Epoch 319, Training Loss: 8.671813809570106e-13, Validation Loss: 7.932925692212545e-13
Epoch 320, Training Loss: 7.97709663082069e-13, Validation Loss: 7.52527218057103e-13
Epoch 321, Training Loss: 7.536930606531766e-13, Validation Loss: 6.945388817021503e-13
Epoch 322, Training Loss: 7.122504083918735e-13, Validation Loss: 6.569246557321107e-13
Epoch 323, Training Loss: 6.618621666357183e-13, Validation Loss: 5.886949998659685e-13
Epoch 324, Training Loss: 6.011761726452958e-13, Validation Loss: 5.385038660647712e-13
Epoch 325, Training Loss: 5.52790777562373e-13, Validation Loss: 4.959126100219369e-13
Epoch 326, Training Loss: 5.002520207970929e-13, Validation Loss: 4.451959092176272e-13
Epoch 327, Training Loss: 4.501210873215228e-13, Validation Loss: 3.9331247135045155e-13
Epoch 328, Training Loss: 3.921122595455101e-13, Validation Loss: 3.237458586803632e-13
Epoch 329, Training Loss: 3.347833349518631e-13, Validation Loss: 2.921062372020222e-13
Epoch 330, Training Loss: 2.908291012529429e-13, Validation Loss: 2.280106984296759e-13
Epoch 331, Training Loss: 2.4388775504355364e-13, Validation Loss: 2.0164654722463343e-13
Epoch 332, Training Loss: 2.0632819996806162e-13, Validation Loss: 1.7265099668938716e-13
Epoch 333, Training Loss: 1.63603709030756e-13, Validation Loss: 1.5245050772987045e-13
Epoch 334, Training Loss: 1.4112639550901973e-13, Validation Loss: 1.2460006442414906e-13
Epoch 335, Training Loss: 1.2690145971810257e-13, Validation Loss: 1.1435101997248065e-13
Epoch 336, Training Loss: 1.1620178018596772e-13, Validation Loss: 1.0166348286214794e-13
Epoch 337, Training Loss: 1.0577856543155309e-13, Validation Loss: 9.787607329432221e-14
Epoch 338, Training Loss: 9.119967828890088e-14, Validation Loss: 8.309853998487993e-14
Epoch 339, Training Loss: 8.199520842031363e-14, Validation Loss: 7.548991407023767e-14
Epoch 340, Training Loss: 8.681213571355012e-14, Validation Loss: 6.996345777027235e-14
Epoch 341, Training Loss: 7.037273053785847e-14, Validation Loss: 6.171890662388588e-14
Epoch 342, Training Loss: 7.101121042097161e-14, Validation Loss: 5.30761822296541e-14
Epoch 343, Training Loss: 6.198684008576136e-14, Validation Loss: 4.8792909410110344e-14
Epoch 344, Training Loss: 5.1615141875198736e-14, Validation Loss: 4.8913537066194723e-14
Epoch 345, Training Loss: 4.3135430665731944e-14, Validation Loss: 4.403812384201622e-14
Epoch 346, Training Loss: 4.4785711733131076e-14, Validation Loss: 4.089447286663092e-14
Epoch 347, Training Loss: 4.3401365129851904e-14, Validation Loss: 2.3678662044892933e-14
Epoch 348, Training Loss: 2.3942406081811293e-14, Validation Loss: 2.2023212382449656e-14
Epoch 349, Training Loss: 2.2586726461598997e-14, Validation Loss: 2.491126777786918e-14
Epoch 350, Training Loss: 2.0088202883896886e-14, Validation Loss: 1.5405067832811002e-14
Epoch 351, Training Loss: 1.6352826550020995e-14, Validation Loss: 1.3920165713198537e-14
Epoch 352, Training Loss: 1.3633135893527208e-14, Validation Loss: 1.5748863259508472e-14
Epoch 353, Training Loss: 1.1162682987697105e-14, Validation Loss: 1.5199494630578278e-14
Epoch 354, Training Loss: 1.2244683721552695e-14, Validation Loss: 1.4137080686594996e-14
Epoch 355, Training Loss: 9.84105748009622e-15, Validation Loss: 9.866269415771244e-15
Epoch 356, Training Loss: 8.200109021709936e-15, Validation Loss: 7.539792629216585e-15
Epoch 357, Training Loss: 4.792945672917352e-15, Validation Loss: 8.826644893233839e-15
Epoch 358, Training Loss: 6.1911997101574915e-15, Validation Loss: 9.558009562309934e-15
Epoch 359, Training Loss: 6.5738061864981535e-15, Validation Loss: 7.977564667346025e-15
Epoch 360, Training Loss: 6.7660602191517774e-15, Validation Loss: 7.492709455810508e-15
Epoch 361, Training Loss: 7.369510207698264e-15, Validation Loss: 7.846876800947106e-15
Epoch 362, Training Loss: 4.692665442291915e-15, Validation Loss: 7.257053878456047e-15
Epoch 363, Training Loss: 6.705645170672391e-15, Validation Loss: 8.547334084810839e-15
Epoch 364, Training Loss: 7.463386022209511e-15, Validation Loss: 1.0147177728332766e-14
Epoch 365, Training Loss: 7.7567211551402e-15, Validation Loss: 1.0712872917321287e-14
Epoch 366, Training Loss: 6.001347439425807e-15, Validation Loss: 9.671638185151151e-15
Epoch 367, Training Loss: 7.323673866790545e-15, Validation Loss: 7.198348565980693e-15
Epoch 368, Training Loss: 7.138058454861027e-15, Validation Loss: 7.874136015255644e-15
Epoch 369, Training Loss: 5.915144896383737e-15, Validation Loss: 7.539780770755324e-15
Epoch 370, Training Loss: 6.579644361087104e-15, Validation Loss: 7.395968975871647e-15
Epoch 371, Training Loss: 6.4136445381501005e-15, Validation Loss: 8.164864827807632e-15
Epoch 372, Training Loss: 5.966219289037277e-15, Validation Loss: 8.211735395943949e-15
Epoch 373, Training Loss: 7.415980976283477e-15, Validation Loss: 5.408051258334531e-15
Epoch 374, Training Loss: 5.811528626495539e-15, Validation Loss: 7.041618671618441e-15
Epoch 375, Training Loss: 5.2746986262835506e-15, Validation Loss: 6.476799314697381e-15
Epoch 376, Training Loss: 4.611433712100807e-15, Validation Loss: 4.955163070228391e-15
Epoch 377, Training Loss: 5.19977178583533e-15, Validation Loss: 8.021837385433113e-15
Epoch 378, Training Loss: 5.2759327532877e-15, Validation Loss: 5.425435762543979e-15
Epoch 379, Training Loss: 3.6301807710575375e-15, Validation Loss: 6.8996839017458796e-15
Epoch 380, Training Loss: 5.221589236974232e-15, Validation Loss: 7.088869134031601e-15
Epoch 381, Training Loss: 4.243939150572109e-15, Validation Loss: 1.0217100298128608e-14
Epoch 382, Training Loss: 6.079009772777186e-15, Validation Loss: 9.195498095609933e-15
Epoch 383, Training Loss: 6.273765940756999e-15, Validation Loss: 7.14764517375805e-15
Epoch 384, Training Loss: 3.75224499502046e-15, Validation Loss: 6.86132855582831e-15
Epoch 385, Training Loss: 4.135752290900527e-15, Validation Loss: 5.272367591612707e-15
Epoch 386, Training Loss: 4.4576438690984745e-15, Validation Loss: 5.393068516047024e-15
Epoch 387, Training Loss: 3.0061137888166443e-15, Validation Loss: 6.495330701517411e-15
Epoch 388, Training Loss: 3.0122187787839797e-15, Validation Loss: 6.177088141256235e-15
Epoch 389, Training Loss: 2.056119116384137e-15, Validation Loss: 6.3987744512445776e-15
Epoch 390, Training Loss: 1.5913466325115453e-15, Validation Loss: 5.7334326122751664e-15
Epoch 391, Training Loss: 1.5877771297926973e-15, Validation Loss: 5.892022590989589e-15
Epoch 392, Training Loss: 1.6516949771463356e-15, Validation Loss: 5.830372991989579e-15
Epoch 393, Training Loss: 1.8688024387800584e-15, Validation Loss: 5.6257421139106756e-15
Epoch 394, Training Loss: 1.912403883256447e-15, Validation Loss: 4.623046957324137e-15
Epoch 395, Training Loss: 1.4744863672183162e-15, Validation Loss: 5.343491254127756e-15
Epoch 396, Training Loss: 3.03910699266162e-15, Validation Loss: 4.704804271459017e-15
Epoch 397, Training Loss: 1.376974875539217e-15, Validation Loss: 5.153029966706996e-15
Epoch 398, Training Loss: 1.7469380087135693e-15, Validation Loss: 5.1821577356971765e-15
Epoch 399, Training Loss: 1.1484250575792727e-15, Validation Loss: 5.0544552369208556e-15
Epoch 400, Training Loss: 1.3900520054536394e-15, Validation Loss: 5.15841794328448e-15
Epoch 401, Training Loss: 1.2568786267501213e-15, Validation Loss: 4.8714668976772464e-15
Epoch 402, Training Loss: 1.7723250684504384e-15, Validation Loss: 7.588502952914338e-15
Epoch 403, Training Loss: 2.3130583023624933e-15, Validation Loss: 7.637408941222907e-15
Epoch 404, Training Loss: 2.3347423458122034e-15, Validation Loss: 3.1443912821811984e-15
Epoch 405, Training Loss: 1.5027089756252375e-15, Validation Loss: 4.383722033242171e-15
Epoch 406, Training Loss: 2.2117773023098758e-15, Validation Loss: 4.73589165117267e-15
Epoch 407, Training Loss: 2.977323985972418e-15, Validation Loss: 4.692252513730129e-15
Epoch 408, Training Loss: 2.1578672551071654e-15, Validation Loss: 4.737622139483911e-15
Epoch 409, Training Loss: 1.8611962946719516e-15, Validation Loss: 4.8741985789321415e-15
Epoch 410, Training Loss: 1.4618762700951862e-15, Validation Loss: 4.257037244551976e-15
Epoch 411, Training Loss: 2.3235333470629504e-15, Validation Loss: 4.121395082444567e-15
Epoch 412, Training Loss: 1.5901456456714571e-15, Validation Loss: 5.9183725154292495e-15
Epoch 413, Training Loss: 1.7456036141842886e-15, Validation Loss: 5.188045885230015e-15
Epoch 414, Training Loss: 1.3999266096736116e-15, Validation Loss: 5.069283819211963e-15
Epoch 415, Training Loss: 1.478389495039264e-15, Validation Loss: 5.070151180949951e-15
Epoch 416, Training Loss: 1.6318791707409133e-15, Validation Loss: 3.782485765303333e-15
Epoch 417, Training Loss: 1.3868494797591893e-15, Validation Loss: 3.875339634563718e-15
Epoch 418, Training Loss: 1.793575325152036e-15, Validation Loss: 3.841712426557722e-15
Epoch 419, Training Loss: 2.76291898295691e-15, Validation Loss: 3.193192873679018e-15
Epoch 420, Training Loss: 2.672446335069494e-15, Validation Loss: 3.3933533236205505e-15
Epoch 421, Training Loss: 2.6346493956224022e-15, Validation Loss: 4.148917300483227e-15
Epoch 422, Training Loss: 2.571498854239858e-15, Validation Loss: 4.2970358343872184e-15
Epoch 423, Training Loss: 3.3797465863558574e-15, Validation Loss: 3.761648331284404e-15
Epoch 424, Training Loss: 3.4073352964808772e-15, Validation Loss: 4.811690088523616e-15
Epoch 425, Training Loss: 2.4719523659049803e-15, Validation Loss: 5.103523855555297e-15
Epoch 426, Training Loss: 1.859628224928347e-15, Validation Loss: 4.993435406917129e-15
Epoch 427, Training Loss: 2.053116808102594e-15, Validation Loss: 3.896998690541484e-15
Epoch 428, Training Loss: 1.5587538634923839e-15, Validation Loss: 3.251293616388269e-15
Epoch 429, Training Loss: 1.217647131127736e-15, Validation Loss: 3.6005066658163776e-15
Epoch 430, Training Loss: 1.2427339176848034e-15, Validation Loss: 3.276447106789933e-15
Epoch 431, Training Loss: 1.6817524706752465e-15, Validation Loss: 3.630143078091385e-15
Epoch 432, Training Loss: 1.9469649450867908e-15, Validation Loss: 3.6963293855568884e-15
Epoch 433, Training Loss: 1.8128576066798064e-15, Validation Loss: 4.3336983849597e-15
Epoch 434, Training Loss: 1.9625442103274023e-15, Validation Loss: 4.603556305691342e-15
Epoch 435, Training Loss: 1.182785901996709e-15, Validation Loss: 5.05555214458755e-15
Epoch 436, Training Loss: 1.8841479229272278e-15, Validation Loss: 4.013421251559219e-15
Epoch 437, Training Loss: 1.3439817775733596e-15, Validation Loss: 4.7392027029634874e-15
Epoch 438, Training Loss: 1.5917469614582414e-15, Validation Loss: 4.703173733035552e-15
Epoch 439, Training Loss: 1.3868828316814874e-15, Validation Loss: 5.994904906828991e-15
Epoch 440, Training Loss: 1.3234987209637377e-15, Validation Loss: 6.277915131649124e-15
Epoch 441, Training Loss: 2.1641723566082896e-15, Validation Loss: 6.391339196033579e-15
Epoch 442, Training Loss: 2.992669681877824e-15, Validation Loss: 4.819437898892151e-15
Epoch 443, Training Loss: 2.033534465153259e-15, Validation Loss: 3.870143510948786e-15
Epoch 444, Training Loss: 1.7257543499774497e-15, Validation Loss: 4.593903094707958e-15
Epoch 445, Training Loss: 1.127575023945253e-15, Validation Loss: 5.0883450251405e-15
Epoch 446, Training Loss: 6.400509704116146e-16, Validation Loss: 4.013362806285859e-15
Epoch 447, Training Loss: 1.368935050562116e-15, Validation Loss: 4.424216984384504e-15
Epoch 448, Training Loss: 2.351055565101611e-15, Validation Loss: 5.6316510157507216e-15
Epoch 449, Training Loss: 1.828169844783796e-15, Validation Loss: 4.178774364840994e-15
Epoch 450, Training Loss: 2.5110503479590547e-15, Validation Loss: 3.5622135768204315e-15
Epoch 451, Training Loss: 1.1677738311934027e-15, Validation Loss: 3.813886123690997e-15
Epoch 452, Training Loss: 1.821664631748883e-15, Validation Loss: 4.443157064601584e-15
Epoch 453, Training Loss: 1.6727452281932627e-15, Validation Loss: 3.644050088535879e-15
Epoch 454, Training Loss: 1.3997263922607044e-15, Validation Loss: 3.166730082099136e-15
Epoch 455, Training Loss: 1.972985797226443e-15, Validation Loss: 3.354951602649119e-15
Epoch 456, Training Loss: 1.4560382013853543e-15, Validation Loss: 3.326128553761713e-15
Epoch 457, Training Loss: 1.2045032973687173e-15, Validation Loss: 3.3467910754770343e-15
Epoch 458, Training Loss: 1.850053999767295e-15, Validation Loss: 4.027027988823912e-15
Epoch 459, Training Loss: 1.8364430273378656e-15, Validation Loss: 2.398101469058009e-15
Epoch 460, Training Loss: 1.4251801558421697e-15, Validation Loss: 3.343054601388459e-15
Epoch 461, Training Loss: 1.1046566417331565e-15, Validation Loss: 2.8611684520913044e-15
Epoch 462, Training Loss: 1.0696618990338187e-15, Validation Loss: 3.268294626430847e-15
Epoch 463, Training Loss: 7.496054177160978e-16, Validation Loss: 3.1447624943703326e-15
Epoch 464, Training Loss: 3.385584549186571e-15, Validation Loss: 4.293316089199351e-15
Epoch 465, Training Loss: 2.7906076429697058e-15, Validation Loss: 4.356279012784079e-15
Epoch 466, Training Loss: 1.3290030586923514e-15, Validation Loss: 2.3870343483274213e-15
Epoch 467, Training Loss: 1.2412994673886282e-15, Validation Loss: 2.2428521882875575e-15
Epoch 468, Training Loss: 2.449300799071269e-15, Validation Loss: 2.274585854139966e-15
Epoch 469, Training Loss: 3.362165782260884e-15, Validation Loss: 4.0373859312194116e-15
Epoch 470, Training Loss: 2.4374247618760532e-15, Validation Loss: 3.759125443651007e-15
Epoch 471, Training Loss: 1.86326453737091e-15, Validation Loss: 3.797523141215939e-15
Epoch 472, Training Loss: 9.23745015517978e-16, Validation Loss: 3.9567547473879066e-15
Epoch 473, Training Loss: 2.4306192756613386e-15, Validation Loss: 3.757336510066406e-15
Epoch 474, Training Loss: 1.6827532401024275e-15, Validation Loss: 3.321779251335799e-15
Epoch 475, Training Loss: 1.8887850047969714e-15, Validation Loss: 3.7308154849714e-15
Epoch 476, Training Loss: 1.6811852762379413e-15, Validation Loss: 3.3369790458160405e-15
Epoch 477, Training Loss: 2.445330967405725e-15, Validation Loss: 4.383871958073835e-15
Epoch 478, Training Loss: 2.0173881113544605e-15, Validation Loss: 4.382137234597858e-15
Epoch 479, Training Loss: 1.4479317784427755e-15, Validation Loss: 4.698190638206855e-15
Epoch 480, Training Loss: 2.145690944732148e-15, Validation Loss: 4.470070265951169e-15
Epoch 481, Training Loss: 1.6785831910239761e-15, Validation Loss: 3.576183267703023e-15
Epoch 482, Training Loss: 2.3162943917374784e-15, Validation Loss: 3.481307107281069e-15
Epoch 483, Training Loss: 1.2320587614505574e-15, Validation Loss: 3.3866979739957366e-15
Epoch 484, Training Loss: 4.214949024435857e-15, Validation Loss: 2.879462246169629e-15
Epoch 485, Training Loss: 2.10836093219723e-15, Validation Loss: 3.0758572111441425e-15
Epoch 486, Training Loss: 2.719083757387079e-15, Validation Loss: 3.2906793778861732e-15
Epoch 487, Training Loss: 1.7497403113404418e-15, Validation Loss: 2.6980127540329442e-15
Epoch 488, Training Loss: 1.3266678947358897e-15, Validation Loss: 4.218164361503634e-15
Epoch 489, Training Loss: 1.9345216075751515e-15, Validation Loss: 2.461677432738312e-15
Epoch 490, Training Loss: 1.2063714285338867e-15, Validation Loss: 4.389017683228405e-15
Epoch 491, Training Loss: 2.2728928470366417e-15, Validation Loss: 3.020258392002844e-15
Epoch 492, Training Loss: 2.850422356847726e-15, Validation Loss: 2.7084378237895133e-15
Epoch 493, Training Loss: 3.0637598865914566e-15, Validation Loss: 3.7802966086511545e-15
Epoch 494, Training Loss: 1.6614361736771153e-15, Validation Loss: 5.437153616336295e-15
Epoch 495, Training Loss: 6.206687389960681e-16, Validation Loss: 5.079558752378631e-15
Epoch 496, Training Loss: 1.020288983813076e-15, Validation Loss: 3.1080412867662537e-15
Epoch 497, Training Loss: 3.5226277037887386e-15, Validation Loss: 2.6240659307046965e-15
Epoch 498, Training Loss: 8.180602911725854e-16, Validation Loss: 2.177641451019054e-15
Epoch 499, Training Loss: 1.3096542850782214e-15, Validation Loss: 2.584613465362196e-15
Epoch 500, Training Loss: 2.008047243770377e-15, Validation Loss: 2.6329189073111617e-15
