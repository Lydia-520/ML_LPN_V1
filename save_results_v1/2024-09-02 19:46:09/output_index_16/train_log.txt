Epoch 1, Training Loss: 0.5246361494064331, Validation Loss: 0.523100733757019
Epoch 2, Training Loss: 0.523100733757019, Validation Loss: 0.5215874314308167
Epoch 3, Training Loss: 0.5215873718261719, Validation Loss: 0.5200904607772827
Epoch 4, Training Loss: 0.5200904607772827, Validation Loss: 0.5186315774917603
Epoch 5, Training Loss: 0.518631637096405, Validation Loss: 0.5172049403190613
Epoch 6, Training Loss: 0.5172049403190613, Validation Loss: 0.5158435702323914
Epoch 7, Training Loss: 0.5158435106277466, Validation Loss: 0.5145371556282043
Epoch 8, Training Loss: 0.5145372152328491, Validation Loss: 0.5132228136062622
Epoch 9, Training Loss: 0.513222873210907, Validation Loss: 0.5119084715843201
Epoch 10, Training Loss: 0.5119084119796753, Validation Loss: 0.5106435418128967
Epoch 11, Training Loss: 0.5106436014175415, Validation Loss: 0.5093708634376526
Epoch 12, Training Loss: 0.5093708634376526, Validation Loss: 0.5080985426902771
Epoch 13, Training Loss: 0.5080985426902771, Validation Loss: 0.506802499294281
Epoch 14, Training Loss: 0.506802499294281, Validation Loss: 0.5054686665534973
Epoch 15, Training Loss: 0.5054686665534973, Validation Loss: 0.5041093826293945
Epoch 16, Training Loss: 0.5041093826293945, Validation Loss: 0.5027369260787964
Epoch 17, Training Loss: 0.5027369260787964, Validation Loss: 0.5013608932495117
Epoch 18, Training Loss: 0.5013608932495117, Validation Loss: 0.4999385476112366
Epoch 19, Training Loss: 0.4999385476112366, Validation Loss: 0.498474657535553
Epoch 20, Training Loss: 0.4984745681285858, Validation Loss: 0.4969639480113983
Epoch 21, Training Loss: 0.4969640076160431, Validation Loss: 0.49540719389915466
Epoch 22, Training Loss: 0.49540722370147705, Validation Loss: 0.493791788816452
Epoch 23, Training Loss: 0.493791788816452, Validation Loss: 0.4921301603317261
Epoch 24, Training Loss: 0.4921301007270813, Validation Loss: 0.49043333530426025
Epoch 25, Training Loss: 0.49043333530426025, Validation Loss: 0.48864123225212097
Epoch 26, Training Loss: 0.48864129185676575, Validation Loss: 0.4867505431175232
Epoch 27, Training Loss: 0.4867505431175232, Validation Loss: 0.4848068356513977
Epoch 28, Training Loss: 0.4848068952560425, Validation Loss: 0.4827471077442169
Epoch 29, Training Loss: 0.4827471077442169, Validation Loss: 0.48056066036224365
Epoch 30, Training Loss: 0.4805606007575989, Validation Loss: 0.47825807332992554
Epoch 31, Training Loss: 0.4782581031322479, Validation Loss: 0.47581833600997925
Epoch 32, Training Loss: 0.47581833600997925, Validation Loss: 0.47323155403137207
Epoch 33, Training Loss: 0.4732314944267273, Validation Loss: 0.4704812169075012
Epoch 34, Training Loss: 0.47048118710517883, Validation Loss: 0.46754157543182373
Epoch 35, Training Loss: 0.46754157543182373, Validation Loss: 0.464449942111969
Epoch 36, Training Loss: 0.464449942111969, Validation Loss: 0.46118077635765076
Epoch 37, Training Loss: 0.46118077635765076, Validation Loss: 0.4576977491378784
Epoch 38, Training Loss: 0.4576977491378784, Validation Loss: 0.45402461290359497
Epoch 39, Training Loss: 0.4540245831012726, Validation Loss: 0.45012152194976807
Epoch 40, Training Loss: 0.45012152194976807, Validation Loss: 0.44592681527137756
Epoch 41, Training Loss: 0.4459267854690552, Validation Loss: 0.4413904845714569
Epoch 42, Training Loss: 0.4413904845714569, Validation Loss: 0.4364599287509918
Epoch 43, Training Loss: 0.4364599287509918, Validation Loss: 0.43111035227775574
Epoch 44, Training Loss: 0.43111032247543335, Validation Loss: 0.42542150616645813
Epoch 45, Training Loss: 0.42542150616645813, Validation Loss: 0.4193914234638214
Epoch 46, Training Loss: 0.4193914234638214, Validation Loss: 0.4129467308521271
Epoch 47, Training Loss: 0.4129467308521271, Validation Loss: 0.4061081111431122
Epoch 48, Training Loss: 0.4061081111431122, Validation Loss: 0.3988167941570282
Epoch 49, Training Loss: 0.3988167941570282, Validation Loss: 0.39105403423309326
Epoch 50, Training Loss: 0.39105403423309326, Validation Loss: 0.3828464448451996
Epoch 51, Training Loss: 0.3828464150428772, Validation Loss: 0.3740502893924713
Epoch 52, Training Loss: 0.3740502893924713, Validation Loss: 0.36470291018486023
Epoch 53, Training Loss: 0.36470291018486023, Validation Loss: 0.3548644185066223
Epoch 54, Training Loss: 0.3548644185066223, Validation Loss: 0.3445854187011719
Epoch 55, Training Loss: 0.3445854187011719, Validation Loss: 0.3339075446128845
Epoch 56, Training Loss: 0.33390751481056213, Validation Loss: 0.3228890001773834
Epoch 57, Training Loss: 0.3228890001773834, Validation Loss: 0.3116272985935211
Epoch 58, Training Loss: 0.3116272985935211, Validation Loss: 0.3001241683959961
Epoch 59, Training Loss: 0.3001241683959961, Validation Loss: 0.2885721027851105
Epoch 60, Training Loss: 0.28857213258743286, Validation Loss: 0.2771610915660858
Epoch 61, Training Loss: 0.2771611213684082, Validation Loss: 0.2661796510219574
Epoch 62, Training Loss: 0.2661796510219574, Validation Loss: 0.25580230355262756
Epoch 63, Training Loss: 0.25580230355262756, Validation Loss: 0.24615882337093353
Epoch 64, Training Loss: 0.24615882337093353, Validation Loss: 0.23746143281459808
Epoch 65, Training Loss: 0.23746146261692047, Validation Loss: 0.2299836277961731
Epoch 66, Training Loss: 0.2299836277961731, Validation Loss: 0.22379571199417114
Epoch 67, Training Loss: 0.22379571199417114, Validation Loss: 0.21889565885066986
Epoch 68, Training Loss: 0.21889568865299225, Validation Loss: 0.2149847000837326
Epoch 69, Training Loss: 0.2149847000837326, Validation Loss: 0.21181437373161316
Epoch 70, Training Loss: 0.21181437373161316, Validation Loss: 0.2088877558708191
Epoch 71, Training Loss: 0.2088877558708191, Validation Loss: 0.20560020208358765
Epoch 72, Training Loss: 0.20560021698474884, Validation Loss: 0.20167864859104156
Epoch 73, Training Loss: 0.20167864859104156, Validation Loss: 0.1969466507434845
Epoch 74, Training Loss: 0.1969466507434845, Validation Loss: 0.1912725567817688
Epoch 75, Training Loss: 0.1912725269794464, Validation Loss: 0.18493156135082245
Epoch 76, Training Loss: 0.18493154644966125, Validation Loss: 0.17812645435333252
Epoch 77, Training Loss: 0.1781264692544937, Validation Loss: 0.17118898034095764
Epoch 78, Training Loss: 0.17118898034095764, Validation Loss: 0.16420480608940125
Epoch 79, Training Loss: 0.16420480608940125, Validation Loss: 0.15747793018817902
Epoch 80, Training Loss: 0.15747793018817902, Validation Loss: 0.1509735882282257
Epoch 81, Training Loss: 0.1509735882282257, Validation Loss: 0.14473295211791992
Epoch 82, Training Loss: 0.14473295211791992, Validation Loss: 0.138581320643425
Epoch 83, Training Loss: 0.13858133554458618, Validation Loss: 0.1324518620967865
Epoch 84, Training Loss: 0.1324518471956253, Validation Loss: 0.12636102735996246
Epoch 85, Training Loss: 0.12636102735996246, Validation Loss: 0.1201537698507309
Epoch 86, Training Loss: 0.12015377730131149, Validation Loss: 0.11377567052841187
Epoch 87, Training Loss: 0.11377567797899246, Validation Loss: 0.10734409093856812
Epoch 88, Training Loss: 0.10734409838914871, Validation Loss: 0.10072453320026398
Epoch 89, Training Loss: 0.10072453320026398, Validation Loss: 0.09397997707128525
Epoch 90, Training Loss: 0.09397997707128525, Validation Loss: 0.08710780739784241
Epoch 91, Training Loss: 0.08710780739784241, Validation Loss: 0.08020839840173721
Epoch 92, Training Loss: 0.08020839840173721, Validation Loss: 0.0733916163444519
Epoch 93, Training Loss: 0.07339160889387131, Validation Loss: 0.06666309386491776
Epoch 94, Training Loss: 0.06666310131549835, Validation Loss: 0.06017664447426796
Epoch 95, Training Loss: 0.060176633298397064, Validation Loss: 0.054034389555454254
Epoch 96, Training Loss: 0.054034389555454254, Validation Loss: 0.04829039052128792
Epoch 97, Training Loss: 0.04829039052128792, Validation Loss: 0.0430072657763958
Epoch 98, Training Loss: 0.0430072657763958, Validation Loss: 0.03821286931633949
Epoch 99, Training Loss: 0.03821286931633949, Validation Loss: 0.0340348444879055
Epoch 100, Training Loss: 0.0340348444879055, Validation Loss: 0.030447131022810936
Epoch 101, Training Loss: 0.030447129160165787, Validation Loss: 0.02737119235098362
Epoch 102, Training Loss: 0.027371183037757874, Validation Loss: 0.02472195401787758
Epoch 103, Training Loss: 0.024721946567296982, Validation Loss: 0.02243480458855629
Epoch 104, Training Loss: 0.02243480458855629, Validation Loss: 0.02045389637351036
Epoch 105, Training Loss: 0.02045389823615551, Validation Loss: 0.018723148852586746
Epoch 106, Training Loss: 0.018723148852586746, Validation Loss: 0.017179889604449272
Epoch 107, Training Loss: 0.01717989332973957, Validation Loss: 0.01576916314661503
Epoch 108, Training Loss: 0.01576916128396988, Validation Loss: 0.014448126778006554
Epoch 109, Training Loss: 0.014448123052716255, Validation Loss: 0.013183213770389557
Epoch 110, Training Loss: 0.013183213770389557, Validation Loss: 0.011975463479757309
Epoch 111, Training Loss: 0.011975460685789585, Validation Loss: 0.010810098610818386
Epoch 112, Training Loss: 0.010810100473463535, Validation Loss: 0.009696745313704014
Epoch 113, Training Loss: 0.009696746245026588, Validation Loss: 0.008647451177239418
Epoch 114, Training Loss: 0.008647453039884567, Validation Loss: 0.007669576443731785
Epoch 115, Training Loss: 0.007669578772038221, Validation Loss: 0.006781487260013819
Epoch 116, Training Loss: 0.006781486794352531, Validation Loss: 0.005968683399260044
Epoch 117, Training Loss: 0.0059686810709536076, Validation Loss: 0.005223249085247517
Epoch 118, Training Loss: 0.005223248153924942, Validation Loss: 0.004541471134871244
Epoch 119, Training Loss: 0.004541471134871244, Validation Loss: 0.003919451031833887
Epoch 120, Training Loss: 0.0039194501005113125, Validation Loss: 0.0033563808538019657
Epoch 121, Training Loss: 0.003356380620971322, Validation Loss: 0.0028516671154648066
Epoch 122, Training Loss: 0.002851666184142232, Validation Loss: 0.002400327706709504
Epoch 123, Training Loss: 0.0024003260768949986, Validation Loss: 0.002005003159865737
Epoch 124, Training Loss: 0.002005003858357668, Validation Loss: 0.001667565549723804
Epoch 125, Training Loss: 0.0016675652004778385, Validation Loss: 0.0013848526868969202
Epoch 126, Training Loss: 0.0013848509406670928, Validation Loss: 0.0011529582552611828
Epoch 127, Training Loss: 0.0011529582552611828, Validation Loss: 0.0009670206345617771
Epoch 128, Training Loss: 0.0009670190629549325, Validation Loss: 0.0008205565391108394
Epoch 129, Training Loss: 0.0008205559570342302, Validation Loss: 0.0007066944963298738
Epoch 130, Training Loss: 0.0007066934485919774, Validation Loss: 0.0006185229867696762
Epoch 131, Training Loss: 0.0006185235688462853, Validation Loss: 0.0005486034788191319
Epoch 132, Training Loss: 0.0005486030713655055, Validation Loss: 0.0004905861569568515
Epoch 133, Training Loss: 0.0004905860405415297, Validation Loss: 0.0004392776172608137
Epoch 134, Training Loss: 0.00043927840306423604, Validation Loss: 0.00039122076123021543
Epoch 135, Training Loss: 0.00039122026646509767, Validation Loss: 0.00034480029717087746
Epoch 136, Training Loss: 0.00034480023896321654, Validation Loss: 0.0002999287098646164
Epoch 137, Training Loss: 0.0002999296993948519, Validation Loss: 0.00025743659352883697
Epoch 138, Training Loss: 0.00025743612786754966, Validation Loss: 0.0002188830403611064
Epoch 139, Training Loss: 0.00021888256014790386, Validation Loss: 0.00018560903845354915
Epoch 140, Training Loss: 0.00018560838361736387, Validation Loss: 0.00015827039896976203
Epoch 141, Training Loss: 0.00015826986054889858, Validation Loss: 0.0001373744453303516
Epoch 142, Training Loss: 0.00013737370318267494, Validation Loss: 0.00012201340723549947
Epoch 143, Training Loss: 0.00012201356003060937, Validation Loss: 0.00011155939137097448
Epoch 144, Training Loss: 0.00011155941319884732, Validation Loss: 0.0001051016224664636
Epoch 145, Training Loss: 0.00010510158608667552, Validation Loss: 0.00010144778207177296
Epoch 146, Training Loss: 0.00010144736734218895, Validation Loss: 9.933205728884786e-05
Epoch 147, Training Loss: 9.933212277246639e-05, Validation Loss: 9.759526437846944e-05
Epoch 148, Training Loss: 9.759503154782578e-05, Validation Loss: 9.53769704210572e-05
Epoch 149, Training Loss: 9.537701407680288e-05, Validation Loss: 9.222850349033251e-05
Epoch 150, Training Loss: 9.222886001225561e-05, Validation Loss: 8.798954513622448e-05
Epoch 151, Training Loss: 8.798948692856357e-05, Validation Loss: 8.28250267659314e-05
Epoch 152, Training Loss: 8.282478665933013e-05, Validation Loss: 7.706761971348897e-05
Epoch 153, Training Loss: 7.706715405220166e-05, Validation Loss: 7.112528692232445e-05
Epoch 154, Training Loss: 7.11255197529681e-05, Validation Loss: 6.538446905324236e-05
Epoch 155, Training Loss: 6.538437446579337e-05, Validation Loss: 6.01328574703075e-05
Epoch 156, Training Loss: 6.013264282955788e-05, Validation Loss: 5.5519776651635766e-05
Epoch 157, Training Loss: 5.551970025408082e-05, Validation Loss: 5.154871178092435e-05
Epoch 158, Training Loss: 5.154848986421712e-05, Validation Loss: 4.8101897846208885e-05
Epoch 159, Training Loss: 4.810185055248439e-05, Validation Loss: 4.4985954446019605e-05
Epoch 160, Training Loss: 4.498584530665539e-05, Validation Loss: 4.1985695133917034e-05
Epoch 161, Training Loss: 4.198592068860307e-05, Validation Loss: 3.8916921766940504e-05
Epoch 162, Training Loss: 3.891714368364774e-05, Validation Loss: 3.5666678741108626e-05
Epoch 163, Training Loss: 3.5666453186422586e-05, Validation Loss: 3.22123451041989e-05
Epoch 164, Training Loss: 3.221233419026248e-05, Validation Loss: 2.8617774660233408e-05
Epoch 165, Training Loss: 2.861774009943474e-05, Validation Loss: 2.5013319827849045e-05
Epoch 166, Training Loss: 2.5013361664605327e-05, Validation Loss: 2.155948277504649e-05
Epoch 167, Training Loss: 2.1559300876106136e-05, Validation Loss: 1.8407392417429946e-05
Epoch 168, Training Loss: 1.8407410607323982e-05, Validation Loss: 1.5669511412852444e-05
Epoch 169, Training Loss: 1.566963328514248e-05, Validation Loss: 1.3397674592852127e-05
Epoch 170, Training Loss: 1.3397653674473986e-05, Validation Loss: 1.1578583325899672e-05
Epoch 171, Training Loss: 1.1578538760659285e-05, Validation Loss: 1.0145680789719336e-05
Epoch 172, Training Loss: 1.0145627129531931e-05, Validation Loss: 8.999249985208735e-06
Epoch 173, Training Loss: 8.999191777547821e-06, Validation Loss: 8.032157893467229e-06
Epoch 174, Training Loss: 8.032237019506283e-06, Validation Loss: 7.153410479077138e-06
Epoch 175, Training Loss: 7.153455499064876e-06, Validation Loss: 6.302604106167564e-06
Epoch 176, Training Loss: 6.3024704104464035e-06, Validation Loss: 5.455391146824695e-06
Epoch 177, Training Loss: 5.455318387248553e-06, Validation Loss: 4.619822448148625e-06
Epoch 178, Training Loss: 4.619769697455922e-06, Validation Loss: 3.825145540758967e-06
Epoch 179, Training Loss: 3.825166913884459e-06, Validation Loss: 3.1082192890607985e-06
Epoch 180, Training Loss: 3.1082922760106158e-06, Validation Loss: 2.501160906831501e-06
Epoch 181, Training Loss: 2.501197286619572e-06, Validation Loss: 2.0223658339091344e-06
Epoch 182, Training Loss: 2.022359467446222e-06, Validation Loss: 1.6733026768633863e-06
Epoch 183, Training Loss: 1.673328483775549e-06, Validation Loss: 1.4398292478290386e-06
Epoch 184, Training Loss: 1.4397990071302047e-06, Validation Loss: 1.2967590237167315e-06
Epoch 185, Training Loss: 1.2967716429557186e-06, Validation Loss: 1.2149017720730626e-06
Epoch 186, Training Loss: 1.2149066606070846e-06, Validation Loss: 1.1670965704979608e-06
Epoch 187, Training Loss: 1.1670725825752015e-06, Validation Loss: 1.1322704267513473e-06
Epoch 188, Training Loss: 1.1323251101202914e-06, Validation Loss: 1.0978568525388255e-06
Epoch 189, Training Loss: 1.0978841373798787e-06, Validation Loss: 1.0589507155600586e-06
Epoch 190, Training Loss: 1.0590041483737878e-06, Validation Loss: 1.0163076922253822e-06
Epoch 191, Training Loss: 1.0163545312025235e-06, Validation Loss: 9.734570767250261e-07
Epoch 192, Training Loss: 9.734274044603808e-07, Validation Loss: 9.339100301986036e-07
Epoch 193, Training Loss: 9.339373150396568e-07, Validation Loss: 8.998854355013464e-07
Epoch 194, Training Loss: 8.998668477033789e-07, Validation Loss: 8.710307497494796e-07
Epoch 195, Training Loss: 8.710605925443815e-07, Validation Loss: 8.451083317595476e-07
Epoch 196, Training Loss: 8.451194162262254e-07, Validation Loss: 8.187864750652807e-07
Epoch 197, Training Loss: 8.187886351151974e-07, Validation Loss: 7.887415449658874e-07
Epoch 198, Training Loss: 7.887205697443278e-07, Validation Loss: 7.526510898969718e-07
Epoch 199, Training Loss: 7.526581953243294e-07, Validation Loss: 7.096708145581943e-07
Epoch 200, Training Loss: 7.096510330484307e-07, Validation Loss: 6.603338533750502e-07
Epoch 201, Training Loss: 6.603290216844471e-07, Validation Loss: 6.063690989321913e-07
Epoch 202, Training Loss: 6.063104933673458e-07, Validation Loss: 5.498033033290994e-07
Epoch 203, Training Loss: 5.497936399478931e-07, Validation Loss: 4.929904093842197e-07
Epoch 204, Training Loss: 4.929952410748228e-07, Validation Loss: 4.3776333313871874e-07
Epoch 205, Training Loss: 4.377553466383688e-07, Validation Loss: 3.8550925296476635e-07
Epoch 206, Training Loss: 3.855238617234136e-07, Validation Loss: 3.370198555785464e-07
Epoch 207, Training Loss: 3.370190029272635e-07, Validation Loss: 2.9265711987136456e-07
Epoch 208, Training Loss: 2.9269440915413725e-07, Validation Loss: 2.5260820279982e-07
Epoch 209, Training Loss: 2.526121249957214e-07, Validation Loss: 2.1678953032733261e-07
Epoch 210, Training Loss: 2.1680094164366892e-07, Validation Loss: 1.8510617394440487e-07
Epoch 211, Training Loss: 1.8508795562865998e-07, Validation Loss: 1.573985031200209e-07
Epoch 212, Training Loss: 1.573826011735946e-07, Validation Loss: 1.3345245974960562e-07
Epoch 213, Training Loss: 1.3342688021111826e-07, Validation Loss: 1.1300258506707905e-07
Epoch 214, Training Loss: 1.1300689806148512e-07, Validation Loss: 9.577721016285068e-08
Epoch 215, Training Loss: 9.577242821023901e-08, Validation Loss: 8.14049840869302e-08
Epoch 216, Training Loss: 8.139156193465169e-08, Validation Loss: 6.94928061761857e-08
Epoch 217, Training Loss: 6.949385777943462e-08, Validation Loss: 5.966845151306188e-08
Epoch 218, Training Loss: 5.96720184375954e-08, Validation Loss: 5.157859916948837e-08
Epoch 219, Training Loss: 5.157458105031765e-08, Validation Loss: 4.489395877271818e-08
Epoch 220, Training Loss: 4.4887006112048766e-08, Validation Loss: 3.93396248909994e-08
Epoch 221, Training Loss: 3.9343731828012096e-08, Validation Loss: 3.467222953190685e-08
Epoch 222, Training Loss: 3.4675768034730936e-08, Validation Loss: 3.0703187547942434e-08
Epoch 223, Training Loss: 3.0708342535490374e-08, Validation Loss: 2.729845682836185e-08
Epoch 224, Training Loss: 2.730464565559032e-08, Validation Loss: 2.437675661326466e-08
Epoch 225, Training Loss: 2.4374763540890854e-08, Validation Loss: 2.1881577438875865e-08
Epoch 226, Training Loss: 2.1882252454474838e-08, Validation Loss: 1.9830100228546144e-08
Epoch 227, Training Loss: 1.9823042762823206e-08, Validation Loss: 1.8211958163760755e-08
Epoch 228, Training Loss: 1.8211954611047076e-08, Validation Loss: 1.7054924583703723e-08
Epoch 229, Training Loss: 1.7048636280492246e-08, Validation Loss: 1.631051205208678e-08
Epoch 230, Training Loss: 1.631787860389977e-08, Validation Loss: 1.5950808673892425e-08
Epoch 231, Training Loss: 1.5945532894079406e-08, Validation Loss: 1.5817459342315487e-08
Epoch 232, Training Loss: 1.58197277499994e-08, Validation Loss: 1.5799539454519618e-08
Epoch 233, Training Loss: 1.5796887353758393e-08, Validation Loss: 1.573368813012621e-08
Epoch 234, Training Loss: 1.5737432690343667e-08, Validation Loss: 1.5505060346754362e-08
Epoch 235, Training Loss: 1.55019286296465e-08, Validation Loss: 1.5036263789625082e-08
Epoch 236, Training Loss: 1.5039663736615694e-08, Validation Loss: 1.4320196584094447e-08
Epoch 237, Training Loss: 1.4320754360142018e-08, Validation Loss: 1.3368103068955861e-08
Epoch 238, Training Loss: 1.3370025087056092e-08, Validation Loss: 1.2280942485176638e-08
Epoch 239, Training Loss: 1.2283419614789182e-08, Validation Loss: 1.115014125474545e-08
Epoch 240, Training Loss: 1.1143275635561167e-08, Validation Loss: 1.0026993457756816e-08
Epoch 241, Training Loss: 1.0029227226482362e-08, Validation Loss: 8.9937186587008e-09
Epoch 242, Training Loss: 8.991835720451036e-09, Validation Loss: 8.060437650669883e-09
Epoch 243, Training Loss: 8.060201395210242e-09, Validation Loss: 7.2139143547644835e-09
Epoch 244, Training Loss: 7.214745245676113e-09, Validation Loss: 6.439144772940608e-09
Epoch 245, Training Loss: 6.441593924932931e-09, Validation Loss: 5.6953006755122715e-09
Epoch 246, Training Loss: 5.69829694541113e-09, Validation Loss: 4.976276279933245e-09
Epoch 247, Training Loss: 4.9734460993988705e-09, Validation Loss: 4.267063147267436e-09
Epoch 248, Training Loss: 4.267838082938624e-09, Validation Loss: 3.5871727810388165e-09
Epoch 249, Training Loss: 3.589801345071919e-09, Validation Loss: 2.9611575413923674e-09
Epoch 250, Training Loss: 2.959849254580149e-09, Validation Loss: 2.408354182747985e-09
Epoch 251, Training Loss: 2.4097261963618166e-09, Validation Loss: 1.9506547488390424e-09
Epoch 252, Training Loss: 1.9505619341941838e-09, Validation Loss: 1.5853433010803997e-09
Epoch 253, Training Loss: 1.5859946689289472e-09, Validation Loss: 1.3135393883700885e-09
Epoch 254, Training Loss: 1.3119162423080866e-09, Validation Loss: 1.108061087329304e-09
Epoch 255, Training Loss: 1.1075741435107034e-09, Validation Loss: 9.522220789648372e-10
Epoch 256, Training Loss: 9.523472010997125e-10, Validation Loss: 8.280048868769541e-10
Epoch 257, Training Loss: 8.294006037523616e-10, Validation Loss: 7.211238273185927e-10
Epoch 258, Training Loss: 7.225114395659205e-10, Validation Loss: 6.290267751118961e-10
Epoch 259, Training Loss: 6.284414655333137e-10, Validation Loss: 5.483593024102618e-10
Epoch 260, Training Loss: 5.4723164888415e-10, Validation Loss: 4.862129587834829e-10
Epoch 261, Training Loss: 4.858995983347825e-10, Validation Loss: 4.481487403396045e-10
Epoch 262, Training Loss: 4.480819326690977e-10, Validation Loss: 4.3266124016838603e-10
Epoch 263, Training Loss: 4.3316009112892573e-10, Validation Loss: 4.396762121050557e-10
Epoch 264, Training Loss: 4.3979300756724626e-10, Validation Loss: 4.5947343152441533e-10
Epoch 265, Training Loss: 4.5857734276566475e-10, Validation Loss: 4.829578403864332e-10
Epoch 266, Training Loss: 4.824458055274761e-10, Validation Loss: 5.009371806252716e-10
Epoch 267, Training Loss: 5.010189485510352e-10, Validation Loss: 5.077722131652251e-10
Epoch 268, Training Loss: 5.065814434601634e-10, Validation Loss: 4.962720234757967e-10
Epoch 269, Training Loss: 4.961254740365462e-10, Validation Loss: 4.690053900802127e-10
Epoch 270, Training Loss: 4.692647381787651e-10, Validation Loss: 4.297607825165528e-10
Epoch 271, Training Loss: 4.30068314294374e-10, Validation Loss: 3.817296478914045e-10
Epoch 272, Training Loss: 3.8146780179104667e-10, Validation Loss: 3.3098304652590116e-10
Epoch 273, Training Loss: 3.308840423876802e-10, Validation Loss: 2.832751810899481e-10
Epoch 274, Training Loss: 2.827175715758301e-10, Validation Loss: 2.411297828075476e-10
Epoch 275, Training Loss: 2.419461297975545e-10, Validation Loss: 2.0924177668302235e-10
Epoch 276, Training Loss: 2.086229522468841e-10, Validation Loss: 1.8241784471850764e-10
Epoch 277, Training Loss: 1.8282807212610663e-10, Validation Loss: 1.6404853864226965e-10
Epoch 278, Training Loss: 1.6414838932554687e-10, Validation Loss: 1.4968033756890264e-10
Epoch 279, Training Loss: 1.4948742244058622e-10, Validation Loss: 1.375358715804964e-10
Epoch 280, Training Loss: 1.379535513601482e-10, Validation Loss: 1.263115861904751e-10
Epoch 281, Training Loss: 1.2650078207165905e-10, Validation Loss: 1.1437244901157939e-10
Epoch 282, Training Loss: 1.1490916551615271e-10, Validation Loss: 1.0274842782154181e-10
Epoch 283, Training Loss: 1.0267073302649976e-10, Validation Loss: 8.98371654844965e-11
Epoch 284, Training Loss: 8.999620493277405e-11, Validation Loss: 7.718155975444674e-11
Epoch 285, Training Loss: 7.716045163919105e-11, Validation Loss: 6.453498152536596e-11
Epoch 286, Training Loss: 6.478263758769032e-11, Validation Loss: 5.377726736144339e-11
Epoch 287, Training Loss: 5.347825654533622e-11, Validation Loss: 4.475186887731297e-11
Epoch 288, Training Loss: 4.4746938793194246e-11, Validation Loss: 3.736836881595984e-11
Epoch 289, Training Loss: 3.759900377153791e-11, Validation Loss: 3.246974564219407e-11
Epoch 290, Training Loss: 3.242408425085941e-11, Validation Loss: 2.8425562251244152e-11
Epoch 291, Training Loss: 2.8728828344037893e-11, Validation Loss: 2.614468190553776e-11
Epoch 292, Training Loss: 2.6102430980556868e-11, Validation Loss: 2.423148487418203e-11
Epoch 293, Training Loss: 2.428576610646882e-11, Validation Loss: 2.2814569677898078e-11
Epoch 294, Training Loss: 2.2825083836885973e-11, Validation Loss: 2.1283788967374484e-11
Epoch 295, Training Loss: 2.122883639710249e-11, Validation Loss: 1.946849799427941e-11
Epoch 296, Training Loss: 1.96434066929152e-11, Validation Loss: 1.8238242513457514e-11
Epoch 297, Training Loss: 1.8290566977663403e-11, Validation Loss: 1.6689169143879745e-11
Epoch 298, Training Loss: 1.6834830404710566e-11, Validation Loss: 1.5505336597998465e-11
Epoch 299, Training Loss: 1.5527062274811598e-11, Validation Loss: 1.4194955974544676e-11
Epoch 300, Training Loss: 1.441575765009917e-11, Validation Loss: 1.3257609420003202e-11
Epoch 301, Training Loss: 1.3295444606375995e-11, Validation Loss: 1.2050555865672496e-11
Epoch 302, Training Loss: 1.2098536582294539e-11, Validation Loss: 1.1104024817687463e-11
Epoch 303, Training Loss: 1.11708420291734e-11, Validation Loss: 1.0195652482003492e-11
Epoch 304, Training Loss: 1.0149112453228248e-11, Validation Loss: 9.073563948802654e-12
Epoch 305, Training Loss: 9.109800587492334e-12, Validation Loss: 8.223071529256387e-12
Epoch 306, Training Loss: 8.093361918148911e-12, Validation Loss: 7.167844442990123e-12
Epoch 307, Training Loss: 7.102796649449683e-12, Validation Loss: 6.2254077760892645e-12
Epoch 308, Training Loss: 6.214770451734575e-12, Validation Loss: 5.378899582686447e-12
Epoch 309, Training Loss: 5.4597294567304555e-12, Validation Loss: 4.856396534913543e-12
Epoch 310, Training Loss: 4.931941140207119e-12, Validation Loss: 4.553611827884385e-12
Epoch 311, Training Loss: 4.4774487936716234e-12, Validation Loss: 4.28436322877368e-12
Epoch 312, Training Loss: 4.275402514658522e-12, Validation Loss: 4.1325588784335565e-12
Epoch 313, Training Loss: 4.032146144750115e-12, Validation Loss: 4.011528956238131e-12
Epoch 314, Training Loss: 3.960188080243121e-12, Validation Loss: 3.705009823246064e-12
Epoch 315, Training Loss: 3.761558772796825e-12, Validation Loss: 3.640819416783625e-12
Epoch 316, Training Loss: 3.59693806857575e-12, Validation Loss: 3.320571465362243e-12
Epoch 317, Training Loss: 3.34613543470641e-12, Validation Loss: 3.0560840316717908e-12
Epoch 318, Training Loss: 3.0088182379622852e-12, Validation Loss: 2.63705420347482e-12
Epoch 319, Training Loss: 2.6768327138215753e-12, Validation Loss: 2.3071182551209768e-12
Epoch 320, Training Loss: 2.367212328935331e-12, Validation Loss: 1.910267950766542e-12
Epoch 321, Training Loss: 1.9446261007721732e-12, Validation Loss: 1.6435525900318493e-12
Epoch 322, Training Loss: 1.556095855469175e-12, Validation Loss: 1.3157847207623252e-12
Epoch 323, Training Loss: 1.3292882419801977e-12, Validation Loss: 1.0915163087613089e-12
Epoch 324, Training Loss: 1.1412757674675311e-12, Validation Loss: 9.087860130228831e-13
Epoch 325, Training Loss: 9.732861218358924e-13, Validation Loss: 8.556519750547997e-13
Epoch 326, Training Loss: 8.387253565278474e-13, Validation Loss: 7.442294935704197e-13
Epoch 327, Training Loss: 7.307001141307334e-13, Validation Loss: 7.254493772194948e-13
Epoch 328, Training Loss: 6.816130234017781e-13, Validation Loss: 6.751942754901208e-13
Epoch 329, Training Loss: 6.787673179596554e-13, Validation Loss: 6.210402201181631e-13
Epoch 330, Training Loss: 6.059420001348903e-13, Validation Loss: 5.607162954432421e-13
Epoch 331, Training Loss: 5.445811445022042e-13, Validation Loss: 4.900265848477303e-13
Epoch 332, Training Loss: 4.769295852344313e-13, Validation Loss: 4.407159587358628e-13
Epoch 333, Training Loss: 4.1543873376126417e-13, Validation Loss: 3.75551938722532e-13
Epoch 334, Training Loss: 3.6718580107876486e-13, Validation Loss: 3.2161334142730147e-13
Epoch 335, Training Loss: 3.053750557546059e-13, Validation Loss: 2.592101338259878e-13
Epoch 336, Training Loss: 2.693680510850588e-13, Validation Loss: 2.3687771037207705e-13
Epoch 337, Training Loss: 2.270845729339388e-13, Validation Loss: 2.0194924291866423e-13
Epoch 338, Training Loss: 1.8415457147483855e-13, Validation Loss: 1.770131892626925e-13
Epoch 339, Training Loss: 1.7042369306139588e-13, Validation Loss: 1.4509671675960734e-13
Epoch 340, Training Loss: 1.5599239293947326e-13, Validation Loss: 1.4422120995279814e-13
Epoch 341, Training Loss: 1.2628178396641848e-13, Validation Loss: 1.215699904025952e-13
Epoch 342, Training Loss: 1.133342077412787e-13, Validation Loss: 1.1863351013358114e-13
Epoch 343, Training Loss: 1.1109681425681972e-13, Validation Loss: 9.947655221255458e-14
Epoch 344, Training Loss: 1.0004076424685246e-13, Validation Loss: 9.185471258393516e-14
Epoch 345, Training Loss: 9.787556507455386e-14, Validation Loss: 8.028397147389829e-14
Epoch 346, Training Loss: 8.14071642670118e-14, Validation Loss: 7.393047898049745e-14
Epoch 347, Training Loss: 7.760358653428889e-14, Validation Loss: 6.633550046070136e-14
Epoch 348, Training Loss: 7.219284848744567e-14, Validation Loss: 6.741779850312143e-14
Epoch 349, Training Loss: 6.84223592497743e-14, Validation Loss: 6.255162810246337e-14
Epoch 350, Training Loss: 6.318692991795841e-14, Validation Loss: 5.459754488248113e-14
Epoch 351, Training Loss: 6.138588715034338e-14, Validation Loss: 5.560935623116249e-14
Epoch 352, Training Loss: 6.249023515444638e-14, Validation Loss: 5.374753037925249e-14
Epoch 353, Training Loss: 5.523028527034367e-14, Validation Loss: 4.720562387706441e-14
Epoch 354, Training Loss: 4.7846234895072837e-14, Validation Loss: 4.715518137098952e-14
Epoch 355, Training Loss: 4.2616179140274324e-14, Validation Loss: 4.284079194909543e-14
Epoch 356, Training Loss: 4.146298782830085e-14, Validation Loss: 3.761300285446377e-14
Epoch 357, Training Loss: 3.954424813859894e-14, Validation Loss: 3.841824658423233e-14
Epoch 358, Training Loss: 3.6456308214220454e-14, Validation Loss: 3.583357636766267e-14
Epoch 359, Training Loss: 3.1225717134599276e-14, Validation Loss: 2.9246831329378734e-14
Epoch 360, Training Loss: 2.6885303472433744e-14, Validation Loss: 3.013787610857237e-14
Epoch 361, Training Loss: 2.7501797768367947e-14, Validation Loss: 2.8514110560554085e-14
Epoch 362, Training Loss: 2.228521830776025e-14, Validation Loss: 2.8142720494500964e-14
Epoch 363, Training Loss: 2.1751723076261602e-14, Validation Loss: 2.428095837456526e-14
Epoch 364, Training Loss: 2.3332323825287805e-14, Validation Loss: 2.2573323012241645e-14
Epoch 365, Training Loss: 2.0644036068280525e-14, Validation Loss: 1.8548630716769786e-14
Epoch 366, Training Loss: 1.888225666590252e-14, Validation Loss: 1.730390055418654e-14
Epoch 367, Training Loss: 1.612374648943607e-14, Validation Loss: 1.687649111713381e-14
Epoch 368, Training Loss: 1.441160829996485e-14, Validation Loss: 1.678802699612257e-14
Epoch 369, Training Loss: 1.0915606018081867e-14, Validation Loss: 1.561288567235395e-14
Epoch 370, Training Loss: 1.1521824957332928e-14, Validation Loss: 1.9133173235867662e-14
Epoch 371, Training Loss: 1.1999508340904044e-14, Validation Loss: 1.6698173741077835e-14
Epoch 372, Training Loss: 1.1454538354068941e-14, Validation Loss: 1.469790374207091e-14
Epoch 373, Training Loss: 1.2761451746408966e-14, Validation Loss: 1.2415389659544643e-14
Epoch 374, Training Loss: 1.155488550029721e-14, Validation Loss: 1.1192876324134932e-14
Epoch 375, Training Loss: 1.1190059092552364e-14, Validation Loss: 1.144891490233212e-14
Epoch 376, Training Loss: 1.1010715959597264e-14, Validation Loss: 1.4148171736006344e-14
Epoch 377, Training Loss: 9.106790029109885e-15, Validation Loss: 1.2855135284441186e-14
Epoch 378, Training Loss: 7.061684035105948e-15, Validation Loss: 1.1062765287173093e-14
Epoch 379, Training Loss: 6.899420898015757e-15, Validation Loss: 1.2873817443125827e-14
Epoch 380, Training Loss: 7.282794362690158e-15, Validation Loss: 1.0734902550213477e-14
Epoch 381, Training Loss: 8.2770585768362e-15, Validation Loss: 1.1037145081617492e-14
Epoch 382, Training Loss: 8.791070356482106e-15, Validation Loss: 1.1559030032508126e-14
Epoch 383, Training Loss: 9.679248776182231e-15, Validation Loss: 1.293533321092017e-14
Epoch 384, Training Loss: 8.690856194426555e-15, Validation Loss: 8.645495039002245e-15
Epoch 385, Training Loss: 8.51805130879131e-15, Validation Loss: 8.900499389970836e-15
Epoch 386, Training Loss: 7.891816133963683e-15, Validation Loss: 8.514723316341549e-15
Epoch 387, Training Loss: 7.253704710182603e-15, Validation Loss: 7.78493921074503e-15
Epoch 388, Training Loss: 7.079431916449767e-15, Validation Loss: 6.0074206656576205e-15
Epoch 389, Training Loss: 5.311481455534542e-15, Validation Loss: 9.083218796253692e-15
Epoch 390, Training Loss: 4.490423620640742e-15, Validation Loss: 6.403738064315488e-15
Epoch 391, Training Loss: 7.367929644218688e-15, Validation Loss: 6.410676958219395e-15
Epoch 392, Training Loss: 7.42851113467221e-15, Validation Loss: 5.618809149237399e-15
Epoch 393, Training Loss: 7.815087654436653e-15, Validation Loss: 7.99243856589981e-15
Epoch 394, Training Loss: 7.026322527140449e-15, Validation Loss: 8.331910736434495e-15
Epoch 395, Training Loss: 5.0478034871860675e-15, Validation Loss: 7.164975467858874e-15
Epoch 396, Training Loss: 4.0534067123837794e-15, Validation Loss: 7.331800300886503e-15
Epoch 397, Training Loss: 5.302274207397888e-15, Validation Loss: 1.1142254247075226e-14
Epoch 398, Training Loss: 5.8589870354972505e-15, Validation Loss: 1.1911671024273773e-14
Epoch 399, Training Loss: 4.898617268252062e-15, Validation Loss: 1.0310635605395059e-14
Epoch 400, Training Loss: 5.521783642711787e-15, Validation Loss: 9.891099339587057e-15
Epoch 401, Training Loss: 5.5567449276097084e-15, Validation Loss: 1.1646205816406591e-14
Epoch 402, Training Loss: 3.486285543428556e-15, Validation Loss: 1.1285717064384634e-14
Epoch 403, Training Loss: 3.895280060691505e-15, Validation Loss: 9.763415899052049e-15
Epoch 404, Training Loss: 3.110384391656596e-15, Validation Loss: 9.92454528254234e-15
Epoch 405, Training Loss: 3.0567413715905075e-15, Validation Loss: 8.87930747266348e-15
Epoch 406, Training Loss: 1.935042321079476e-15, Validation Loss: 8.658111594751598e-15
Epoch 407, Training Loss: 2.5304529081653353e-15, Validation Loss: 7.045786073718932e-15
Epoch 408, Training Loss: 3.148414900438893e-15, Validation Loss: 6.985437517325905e-15
Epoch 409, Training Loss: 2.020711021606539e-15, Validation Loss: 8.656043140294403e-15
Epoch 410, Training Loss: 2.116254220474456e-15, Validation Loss: 9.093187527009928e-15
Epoch 411, Training Loss: 1.446917880004912e-15, Validation Loss: 7.431055621645762e-15
Epoch 412, Training Loss: 2.4206314866637895e-15, Validation Loss: 7.50805006951823e-15
Epoch 413, Training Loss: 2.7048593213456007e-15, Validation Loss: 7.388487980881497e-15
Epoch 414, Training Loss: 1.4393118417759237e-15, Validation Loss: 6.94386471675819e-15
Epoch 415, Training Loss: 1.551134696252713e-15, Validation Loss: 6.988700711755202e-15
Epoch 416, Training Loss: 2.208995222594619e-15, Validation Loss: 6.9734884235389885e-15
Epoch 417, Training Loss: 2.2191367480720947e-15, Validation Loss: 5.421044320228939e-15
Epoch 418, Training Loss: 2.5361909211082728e-15, Validation Loss: 5.3633982224541264e-15
Epoch 419, Training Loss: 1.6109159523293166e-15, Validation Loss: 5.2270221062979214e-15
Epoch 420, Training Loss: 2.1294649698363078e-15, Validation Loss: 5.28533566603517e-15
Epoch 421, Training Loss: 2.124127179960948e-15, Validation Loss: 5.205138163072659e-15
Epoch 422, Training Loss: 1.6255943980305232e-15, Validation Loss: 5.232626923309903e-15
Epoch 423, Training Loss: 9.896181325512346e-16, Validation Loss: 6.384883534426081e-15
Epoch 424, Training Loss: 1.418094831117506e-15, Validation Loss: 7.46001144294765e-15
Epoch 425, Training Loss: 1.3014680292803638e-15, Validation Loss: 5.977223517571531e-15
Epoch 426, Training Loss: 9.317050076398004e-16, Validation Loss: 6.3404477624966465e-15
Epoch 427, Training Loss: 1.808407507333169e-15, Validation Loss: 7.520060149677349e-15
Epoch 428, Training Loss: 2.6125187540512523e-15, Validation Loss: 7.325237489611176e-15
Epoch 429, Training Loss: 1.8133448623827144e-15, Validation Loss: 7.152431756942985e-15
Epoch 430, Training Loss: 1.6965846528563797e-15, Validation Loss: 7.755581895826143e-15
Epoch 431, Training Loss: 2.0832944744308968e-15, Validation Loss: 7.806823153970292e-15
Epoch 432, Training Loss: 6.664257235045414e-16, Validation Loss: 8.032604021225662e-15
Epoch 433, Training Loss: 1.381665638121993e-15, Validation Loss: 8.988036009904832e-15
Epoch 434, Training Loss: 1.5333872384253673e-15, Validation Loss: 7.197267751939997e-15
Epoch 435, Training Loss: 8.158788636960504e-16, Validation Loss: 8.789344103335602e-15
Epoch 436, Training Loss: 1.0264475486143252e-15, Validation Loss: 8.765858420807082e-15
Epoch 437, Training Loss: 9.270345738477586e-16, Validation Loss: 8.74717626212244e-15
Epoch 438, Training Loss: 2.1541513215675608e-15, Validation Loss: 8.74717626212244e-15
Epoch 439, Training Loss: 2.1541513215675608e-15, Validation Loss: 8.912108823545904e-15
Epoch 440, Training Loss: 1.5088341885041885e-15, Validation Loss: 8.894094126823699e-15
Epoch 441, Training Loss: 1.7439559233436422e-15, Validation Loss: 8.722757149286046e-15
Epoch 442, Training Loss: 1.69858629758986e-15, Validation Loss: 8.157504111495992e-15
Epoch 443, Training Loss: 2.0959713812777414e-15, Validation Loss: 8.226893050535065e-15
Epoch 444, Training Loss: 1.3086737385626561e-15, Validation Loss: 8.162842113129589e-15
Epoch 445, Training Loss: 1.3246865787931435e-15, Validation Loss: 8.168179267730238e-15
Epoch 446, Training Loss: 1.0433945603065156e-15, Validation Loss: 8.168179267730238e-15
Epoch 447, Training Loss: 9.900183556188122e-16, Validation Loss: 8.168179267730238e-15
Epoch 448, Training Loss: 9.667998061060326e-16, Validation Loss: 8.168179267730238e-15
Epoch 449, Training Loss: 8.492389386863058e-16, Validation Loss: 8.168179267730238e-15
Epoch 450, Training Loss: 1.078756174151133e-15, Validation Loss: 8.111733839158159e-15
Epoch 451, Training Loss: 1.0915664886871701e-15, Validation Loss: 7.671380891638435e-15
Epoch 452, Training Loss: 1.0739523326698986e-15, Validation Loss: 7.663374736220988e-15
Epoch 453, Training Loss: 1.6944496004337069e-15, Validation Loss: 7.524596858142843e-15
Epoch 454, Training Loss: 1.6984527840215491e-15, Validation Loss: 7.506848976799024e-15
Epoch 455, Training Loss: 1.6237262668653538e-15, Validation Loss: 7.44373231673437e-15
Epoch 456, Training Loss: 1.7526295407235262e-15, Validation Loss: 7.7938796435033e-15
Epoch 457, Training Loss: 1.4168938442774177e-15, Validation Loss: 7.74317201611592e-15
Epoch 458, Training Loss: 1.3832668480296588e-15, Validation Loss: 7.71755181056032e-15
Epoch 459, Training Loss: 1.3656527978915057e-15, Validation Loss: 7.929988520764646e-15
Epoch 460, Training Loss: 1.3469711686024568e-15, Validation Loss: 8.546216001320463e-15
Epoch 461, Training Loss: 1.6223918723360731e-15, Validation Loss: 8.460813904413549e-15
Epoch 462, Training Loss: 1.144942587495755e-15, Validation Loss: 8.481363770746885e-15
Epoch 463, Training Loss: 1.1529489546714396e-15, Validation Loss: 8.891292141834182e-15
Epoch 464, Training Loss: 1.1529489546714396e-15, Validation Loss: 8.891292141834182e-15
Epoch 465, Training Loss: 1.1991193441977322e-15, Validation Loss: 8.580642808428667e-15
Epoch 466, Training Loss: 1.2418201808929528e-15, Validation Loss: 6.359129497664814e-15
Epoch 467, Training Loss: 9.469171899768956e-16, Validation Loss: 5.180051164757355e-15
Epoch 468, Training Loss: 9.441149932291415e-16, Validation Loss: 5.106392332631174e-15
Epoch 469, Training Loss: 1.2659729018674355e-15, Validation Loss: 5.5303318992154776e-15
Epoch 470, Training Loss: 1.6801714836791964e-15, Validation Loss: 5.628544098900193e-15
Epoch 471, Training Loss: 1.7178016635147975e-15, Validation Loss: 5.615733572605919e-15
Epoch 472, Training Loss: 1.4103552793202066e-15, Validation Loss: 5.607727417188471e-15
Epoch 473, Training Loss: 1.3262878945799277e-15, Validation Loss: 7.657370119657902e-15
Epoch 474, Training Loss: 1.415959778694833e-15, Validation Loss: 7.175383808714735e-15
Epoch 475, Training Loss: 1.4066189111107495e-15, Validation Loss: 8.789210272129935e-15
Epoch 476, Training Loss: 1.3545772068314452e-15, Validation Loss: 8.789210272129935e-15
Epoch 477, Training Loss: 1.3545772068314452e-15, Validation Loss: 1.0547820077219314e-14
Epoch 478, Training Loss: 1.1031757105040008e-15, Validation Loss: 9.510855238136287e-15
Epoch 479, Training Loss: 3.753925084871339e-16, Validation Loss: 9.984835393662007e-15
Epoch 480, Training Loss: 3.753925084871339e-16, Validation Loss: 9.984835393662007e-15
Epoch 481, Training Loss: 3.6178158899726376e-16, Validation Loss: 9.765993420310544e-15
Epoch 482, Training Loss: 3.6178158899726376e-16, Validation Loss: 9.726361595741462e-15
Epoch 483, Training Loss: 4.70535431347914e-16, Validation Loss: 9.588650979176858e-15
Epoch 484, Training Loss: 4.70535431347914e-16, Validation Loss: 9.311095223020569e-15
Epoch 485, Training Loss: 4.409116716275565e-16, Validation Loss: 9.311095223020569e-15
Epoch 486, Training Loss: 4.457155131087909e-16, Validation Loss: 9.349125308286393e-15
Epoch 487, Training Loss: 4.441142502615658e-16, Validation Loss: 9.349125308286393e-15
Epoch 488, Training Loss: 4.457155131087909e-16, Validation Loss: 5.9589420054709415e-15
Epoch 489, Training Loss: 4.457155131087909e-16, Validation Loss: 5.9989740531076006e-15
Epoch 490, Training Loss: 4.841463508377841e-16, Validation Loss: 7.337647369321399e-15
Epoch 491, Training Loss: 7.915927350323751e-16, Validation Loss: 7.43532551473287e-15
Epoch 492, Training Loss: 6.963163515428432e-16, Validation Loss: 7.43532551473287e-15
Epoch 493, Training Loss: 7.176668228300127e-16, Validation Loss: 7.43532551473287e-15
Epoch 494, Training Loss: 6.21589834386648e-16, Validation Loss: 7.43532551473287e-15
Epoch 495, Training Loss: 6.584193033892978e-16, Validation Loss: 7.766924514022826e-15
Epoch 496, Training Loss: 6.584193033892978e-16, Validation Loss: 7.766924514022826e-15
Epoch 497, Training Loss: 6.309306490311724e-16, Validation Loss: 7.766924514022826e-15
Epoch 498, Training Loss: 6.326653725071492e-16, Validation Loss: 6.633215806869149e-15
Epoch 499, Training Loss: 7.367487810657576e-16, Validation Loss: 6.633215806869149e-15
Epoch 500, Training Loss: 7.3514746527897335e-16, Validation Loss: 6.461878405815023e-15
