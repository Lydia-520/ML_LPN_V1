Epoch 1, Training Loss: 0.4972359836101532, Validation Loss: 0.4957582354545593
Epoch 2, Training Loss: 0.4957582354545593, Validation Loss: 0.4942907392978668
Epoch 3, Training Loss: 0.4942907392978668, Validation Loss: 0.49287712574005127
Epoch 4, Training Loss: 0.49287712574005127, Validation Loss: 0.49146395921707153
Epoch 5, Training Loss: 0.49146395921707153, Validation Loss: 0.4900497496128082
Epoch 6, Training Loss: 0.4900497496128082, Validation Loss: 0.4886316657066345
Epoch 7, Training Loss: 0.48863163590431213, Validation Loss: 0.4872073233127594
Epoch 8, Training Loss: 0.4872073233127594, Validation Loss: 0.48576754331588745
Epoch 9, Training Loss: 0.48576754331588745, Validation Loss: 0.48432257771492004
Epoch 10, Training Loss: 0.48432257771492004, Validation Loss: 0.4828633666038513
Epoch 11, Training Loss: 0.48286333680152893, Validation Loss: 0.48139312863349915
Epoch 12, Training Loss: 0.48139315843582153, Validation Loss: 0.47993433475494385
Epoch 13, Training Loss: 0.47993433475494385, Validation Loss: 0.4784463047981262
Epoch 14, Training Loss: 0.4784463047981262, Validation Loss: 0.47691744565963745
Epoch 15, Training Loss: 0.47691744565963745, Validation Loss: 0.4753393232822418
Epoch 16, Training Loss: 0.4753393232822418, Validation Loss: 0.47373300790786743
Epoch 17, Training Loss: 0.47373297810554504, Validation Loss: 0.4720946252346039
Epoch 18, Training Loss: 0.4720946252346039, Validation Loss: 0.47040942311286926
Epoch 19, Training Loss: 0.47040942311286926, Validation Loss: 0.46870410442352295
Epoch 20, Training Loss: 0.4687040150165558, Validation Loss: 0.4669477641582489
Epoch 21, Training Loss: 0.4669477343559265, Validation Loss: 0.4651099443435669
Epoch 22, Training Loss: 0.4651099145412445, Validation Loss: 0.46320924162864685
Epoch 23, Training Loss: 0.46320927143096924, Validation Loss: 0.46126407384872437
Epoch 24, Training Loss: 0.46126410365104675, Validation Loss: 0.45926186442375183
Epoch 25, Training Loss: 0.4592619240283966, Validation Loss: 0.4571993947029114
Epoch 26, Training Loss: 0.4571993947029114, Validation Loss: 0.455059677362442
Epoch 27, Training Loss: 0.455059677362442, Validation Loss: 0.45284411311149597
Epoch 28, Training Loss: 0.45284411311149597, Validation Loss: 0.4504961371421814
Epoch 29, Training Loss: 0.450496107339859, Validation Loss: 0.4480115473270416
Epoch 30, Training Loss: 0.4480115473270416, Validation Loss: 0.4453429579734802
Epoch 31, Training Loss: 0.4453429579734802, Validation Loss: 0.4424501657485962
Epoch 32, Training Loss: 0.4424501657485962, Validation Loss: 0.4394463300704956
Epoch 33, Training Loss: 0.4394463300704956, Validation Loss: 0.4362882971763611
Epoch 34, Training Loss: 0.43628832697868347, Validation Loss: 0.43289706110954285
Epoch 35, Training Loss: 0.43289706110954285, Validation Loss: 0.4292598366737366
Epoch 36, Training Loss: 0.4292598366737366, Validation Loss: 0.4253906309604645
Epoch 37, Training Loss: 0.42539066076278687, Validation Loss: 0.4212722182273865
Epoch 38, Training Loss: 0.4212722182273865, Validation Loss: 0.41687625646591187
Epoch 39, Training Loss: 0.41687625646591187, Validation Loss: 0.4121762812137604
Epoch 40, Training Loss: 0.4121762812137604, Validation Loss: 0.4071556031703949
Epoch 41, Training Loss: 0.4071556329727173, Validation Loss: 0.40179863572120667
Epoch 42, Training Loss: 0.4017986059188843, Validation Loss: 0.39614254236221313
Epoch 43, Training Loss: 0.39614254236221313, Validation Loss: 0.3901480436325073
Epoch 44, Training Loss: 0.39014798402786255, Validation Loss: 0.3837621510028839
Epoch 45, Training Loss: 0.3837621510028839, Validation Loss: 0.3769395053386688
Epoch 46, Training Loss: 0.3769395053386688, Validation Loss: 0.36964139342308044
Epoch 47, Training Loss: 0.3696414530277252, Validation Loss: 0.36189472675323486
Epoch 48, Training Loss: 0.36189472675323486, Validation Loss: 0.35361748933792114
Epoch 49, Training Loss: 0.3536175489425659, Validation Loss: 0.34480535984039307
Epoch 50, Training Loss: 0.3448053300380707, Validation Loss: 0.3354758620262146
Epoch 51, Training Loss: 0.335475891828537, Validation Loss: 0.3256378769874573
Epoch 52, Training Loss: 0.3256378769874573, Validation Loss: 0.31531980633735657
Epoch 53, Training Loss: 0.31531980633735657, Validation Loss: 0.30458447337150574
Epoch 54, Training Loss: 0.30458447337150574, Validation Loss: 0.2934521734714508
Epoch 55, Training Loss: 0.2934522032737732, Validation Loss: 0.28195253014564514
Epoch 56, Training Loss: 0.28195250034332275, Validation Loss: 0.27018818259239197
Epoch 57, Training Loss: 0.27018818259239197, Validation Loss: 0.25835078954696655
Epoch 58, Training Loss: 0.25835075974464417, Validation Loss: 0.24657048285007477
Epoch 59, Training Loss: 0.24657048285007477, Validation Loss: 0.2349623292684555
Epoch 60, Training Loss: 0.2349623292684555, Validation Loss: 0.22365589439868927
Epoch 61, Training Loss: 0.22365589439868927, Validation Loss: 0.21293549239635468
Epoch 62, Training Loss: 0.21293547749519348, Validation Loss: 0.20315004885196686
Epoch 63, Training Loss: 0.20315004885196686, Validation Loss: 0.19436044991016388
Epoch 64, Training Loss: 0.19436046481132507, Validation Loss: 0.18668073415756226
Epoch 65, Training Loss: 0.18668073415756226, Validation Loss: 0.18007098138332367
Epoch 66, Training Loss: 0.18007095158100128, Validation Loss: 0.17468006908893585
Epoch 67, Training Loss: 0.17468009889125824, Validation Loss: 0.17006701231002808
Epoch 68, Training Loss: 0.17006702721118927, Validation Loss: 0.16562792658805847
Epoch 69, Training Loss: 0.16562792658805847, Validation Loss: 0.16112051904201508
Epoch 70, Training Loss: 0.16112051904201508, Validation Loss: 0.15608762204647064
Epoch 71, Training Loss: 0.15608766674995422, Validation Loss: 0.1503235399723053
Epoch 72, Training Loss: 0.1503235399723053, Validation Loss: 0.14389467239379883
Epoch 73, Training Loss: 0.14389467239379883, Validation Loss: 0.13689708709716797
Epoch 74, Training Loss: 0.13689707219600677, Validation Loss: 0.12961745262145996
Epoch 75, Training Loss: 0.12961745262145996, Validation Loss: 0.12216265499591827
Epoch 76, Training Loss: 0.12216265499591827, Validation Loss: 0.11448615044355392
Epoch 77, Training Loss: 0.11448615044355392, Validation Loss: 0.1069120392203331
Epoch 78, Training Loss: 0.1069120317697525, Validation Loss: 0.09974120557308197
Epoch 79, Training Loss: 0.09974120557308197, Validation Loss: 0.0927971825003624
Epoch 80, Training Loss: 0.0927971825003624, Validation Loss: 0.08605308085680008
Epoch 81, Training Loss: 0.08605308085680008, Validation Loss: 0.07954957336187363
Epoch 82, Training Loss: 0.07954957336187363, Validation Loss: 0.07328366488218307
Epoch 83, Training Loss: 0.07328366488218307, Validation Loss: 0.06724974513053894
Epoch 84, Training Loss: 0.06724973767995834, Validation Loss: 0.06164845451712608
Epoch 85, Training Loss: 0.06164845451712608, Validation Loss: 0.05629502981901169
Epoch 86, Training Loss: 0.05629502609372139, Validation Loss: 0.05123212933540344
Epoch 87, Training Loss: 0.05123212933540344, Validation Loss: 0.04633207246661186
Epoch 88, Training Loss: 0.04633207246661186, Validation Loss: 0.041594963520765305
Epoch 89, Training Loss: 0.041594963520765305, Validation Loss: 0.037132151424884796
Epoch 90, Training Loss: 0.037132155150175095, Validation Loss: 0.033008426427841187
Epoch 91, Training Loss: 0.033008430153131485, Validation Loss: 0.02921302616596222
Epoch 92, Training Loss: 0.02921302616596222, Validation Loss: 0.025776708498597145
Epoch 93, Training Loss: 0.025776701048016548, Validation Loss: 0.022757280617952347
Epoch 94, Training Loss: 0.022757280617952347, Validation Loss: 0.020126529037952423
Epoch 95, Training Loss: 0.020126530900597572, Validation Loss: 0.01794961653649807
Epoch 96, Training Loss: 0.01794961281120777, Validation Loss: 0.016097957268357277
Epoch 97, Training Loss: 0.016097957268357277, Validation Loss: 0.014441323466598988
Epoch 98, Training Loss: 0.01444132812321186, Validation Loss: 0.01292764488607645
Epoch 99, Training Loss: 0.012927641160786152, Validation Loss: 0.011527898721396923
Epoch 100, Training Loss: 0.011527903378009796, Validation Loss: 0.010214759968221188
Epoch 101, Training Loss: 0.010214762762188911, Validation Loss: 0.008937690407037735
Epoch 102, Training Loss: 0.00893768947571516, Validation Loss: 0.007741469889879227
Epoch 103, Training Loss: 0.007741464767605066, Validation Loss: 0.006662970874458551
Epoch 104, Training Loss: 0.006662968546152115, Validation Loss: 0.005680630449205637
Epoch 105, Training Loss: 0.005680629517883062, Validation Loss: 0.00481184059754014
Epoch 106, Training Loss: 0.004811839200556278, Validation Loss: 0.0040796492248773575
Epoch 107, Training Loss: 0.00407964875921607, Validation Loss: 0.0035066690761595964
Epoch 108, Training Loss: 0.0035066697746515274, Validation Loss: 0.0030267853289842606
Epoch 109, Training Loss: 0.003026783000677824, Validation Loss: 0.0026226085610687733
Epoch 110, Training Loss: 0.002622609958052635, Validation Loss: 0.0022857312578707933
Epoch 111, Training Loss: 0.0022857326548546553, Validation Loss: 0.002003658562898636
Epoch 112, Training Loss: 0.0020036601927131414, Validation Loss: 0.0017633665120229125
Epoch 113, Training Loss: 0.0017633669776841998, Validation Loss: 0.0015454301610589027
Epoch 114, Training Loss: 0.0015454288804903626, Validation Loss: 0.0013481257483363152
Epoch 115, Training Loss: 0.001348125864751637, Validation Loss: 0.0011669294908642769
Epoch 116, Training Loss: 0.0011669285595417023, Validation Loss: 0.0009993689600378275
Epoch 117, Training Loss: 0.0009993696585297585, Validation Loss: 0.0008440947276540101
Epoch 118, Training Loss: 0.0008440933306701481, Validation Loss: 0.0007030860870145261
Epoch 119, Training Loss: 0.0007030865526758134, Validation Loss: 0.0005784397362731397
Epoch 120, Training Loss: 0.0005784393288195133, Validation Loss: 0.0004722672456409782
Epoch 121, Training Loss: 0.0004722672456409782, Validation Loss: 0.0003857423726003617
Epoch 122, Training Loss: 0.00038574193604290485, Validation Loss: 0.0003187273978255689
Epoch 123, Training Loss: 0.0003187276015523821, Validation Loss: 0.0002698061289265752
Epoch 124, Training Loss: 0.0002698054595384747, Validation Loss: 0.00023993258946575224
Epoch 125, Training Loss: 0.0002399320073891431, Validation Loss: 0.00022400917077902704
Epoch 126, Training Loss: 0.00022400963644031435, Validation Loss: 0.00021556516003329307
Epoch 127, Training Loss: 0.00021556536376010627, Validation Loss: 0.00021125983039382845
Epoch 128, Training Loss: 0.00021125993225723505, Validation Loss: 0.00020845375547651201
Epoch 129, Training Loss: 0.00020845378458034247, Validation Loss: 0.0002053724747383967
Epoch 130, Training Loss: 0.00020537280943244696, Validation Loss: 0.00020090554608032107
Epoch 131, Training Loss: 0.00020090512407477945, Validation Loss: 0.0001947318232851103
Epoch 132, Training Loss: 0.0001947318232851103, Validation Loss: 0.00018703751266002655
Epoch 133, Training Loss: 0.00018703792011365294, Validation Loss: 0.0001782379549695179
Epoch 134, Training Loss: 0.0001782378094503656, Validation Loss: 0.00016873070853762329
Epoch 135, Training Loss: 0.000168730563018471, Validation Loss: 0.00015877617988735437
Epoch 136, Training Loss: 0.0001587759325047955, Validation Loss: 0.0001484772947151214
Epoch 137, Training Loss: 0.00014847726561129093, Validation Loss: 0.00013781788584310561
Epoch 138, Training Loss: 0.00013781779853161424, Validation Loss: 0.0001267316984012723
Epoch 139, Training Loss: 0.00012673212040681392, Validation Loss: 0.00011518879182403907
Epoch 140, Training Loss: 0.00011518927931319922, Validation Loss: 0.0001032757354550995
Epoch 141, Training Loss: 0.0001032759464578703, Validation Loss: 9.12052346393466e-05
Epoch 142, Training Loss: 9.120514005189762e-05, Validation Loss: 7.930486026452854e-05
Epoch 143, Training Loss: 7.930484571261331e-05, Validation Loss: 6.797015521442518e-05
Epoch 144, Training Loss: 6.796992238378152e-05, Validation Loss: 5.7595872931415215e-05
Epoch 145, Training Loss: 5.7595771068008617e-05, Validation Loss: 4.8511679779039696e-05
Epoch 146, Training Loss: 4.851157427765429e-05, Validation Loss: 4.0924991481006145e-05
Epoch 147, Training Loss: 4.09250205848366e-05, Validation Loss: 3.489186201477423e-05
Epoch 148, Training Loss: 3.489181472104974e-05, Validation Loss: 3.031668165931478e-05
Epoch 149, Training Loss: 3.0316672564367764e-05, Validation Loss: 2.6977830202667974e-05
Epoch 150, Training Loss: 2.6977671950589865e-05, Validation Loss: 2.4573471819167025e-05
Epoch 151, Training Loss: 2.4573580958531238e-05, Validation Loss: 2.277725434396416e-05
Epoch 152, Training Loss: 2.277721796417609e-05, Validation Loss: 2.1288984498823993e-05
Epoch 153, Training Loss: 2.1288979041855782e-05, Validation Loss: 1.9876877558999695e-05
Epoch 154, Training Loss: 1.987691030080896e-05, Validation Loss: 1.8397684470983222e-05
Epoch 155, Training Loss: 1.8397751773591153e-05, Validation Loss: 1.6800984667497687e-05
Epoch 156, Training Loss: 1.680101195233874e-05, Validation Loss: 1.5111450011318084e-05
Epoch 157, Training Loss: 1.5111454558791593e-05, Validation Loss: 1.3404554010776337e-05
Epoch 158, Training Loss: 1.3404476703726687e-05, Validation Loss: 1.1773733604059089e-05
Epoch 159, Training Loss: 1.1773886399168987e-05, Validation Loss: 1.0303579983883537e-05
Epoch 160, Training Loss: 1.0303498129360378e-05, Validation Loss: 9.048655556398444e-06
Epoch 161, Training Loss: 9.048586434801109e-06, Validation Loss: 8.025572242331691e-06
Epoch 162, Training Loss: 8.025604984140955e-06, Validation Loss: 7.214265679067466e-06
Epoch 163, Training Loss: 7.214205652417149e-06, Validation Loss: 6.56846441415837e-06
Epoch 164, Training Loss: 6.568320259248139e-06, Validation Loss: 6.0295601542748045e-06
Epoch 165, Training Loss: 6.029531505191699e-06, Validation Loss: 5.541509835893521e-06
Epoch 166, Training Loss: 5.541533482755767e-06, Validation Loss: 5.064895958639681e-06
Epoch 167, Training Loss: 5.064934157417156e-06, Validation Loss: 4.581218036037171e-06
Epoch 168, Training Loss: 4.581247139867628e-06, Validation Loss: 4.092878498340724e-06
Epoch 169, Training Loss: 4.092889867024496e-06, Validation Loss: 3.617582251536078e-06
Epoch 170, Training Loss: 3.6175799777993234e-06, Validation Loss: 3.179943178110989e-06
Epoch 171, Training Loss: 3.1800400392967276e-06, Validation Loss: 2.8031954570906237e-06
Epoch 172, Training Loss: 2.8031799956806935e-06, Validation Loss: 2.5010292574734194e-06
Epoch 173, Training Loss: 2.5010283479787176e-06, Validation Loss: 2.2754127257940127e-06
Epoch 174, Training Loss: 2.2754086330678547e-06, Validation Loss: 2.1153759917069692e-06
Epoch 175, Training Loss: 2.1153978195798118e-06, Validation Loss: 2.001057509914972e-06
Epoch 176, Training Loss: 2.001049324462656e-06, Validation Loss: 1.908471631395514e-06
Epoch 177, Training Loss: 1.908472086142865e-06, Validation Loss: 1.8155459429181064e-06
Epoch 178, Training Loss: 1.8155419638787862e-06, Validation Loss: 1.7065361817003577e-06
Epoch 179, Training Loss: 1.7065060546883615e-06, Validation Loss: 1.574219709254976e-06
Epoch 180, Training Loss: 1.5742260757178883e-06, Validation Loss: 1.420611511093739e-06
Epoch 181, Training Loss: 1.4206111700332258e-06, Validation Loss: 1.2543342791104806e-06
Epoch 182, Training Loss: 1.2543471257231431e-06, Validation Loss: 1.087649934561341e-06
Epoch 183, Training Loss: 1.0876962051042938e-06, Validation Loss: 9.330699413112598e-07
Epoch 184, Training Loss: 9.330378247796034e-07, Validation Loss: 8.00005295786832e-07
Epoch 185, Training Loss: 7.999977356121235e-07, Validation Loss: 6.933208283044223e-07
Epoch 186, Training Loss: 6.933787517482415e-07, Validation Loss: 6.128666427684948e-07
Epoch 187, Training Loss: 6.12876760897052e-07, Validation Loss: 5.543327006307663e-07
Epoch 188, Training Loss: 5.543357701753848e-07, Validation Loss: 5.110233587402035e-07
Epoch 189, Training Loss: 5.110373422212433e-07, Validation Loss: 4.758487079925544e-07
Epoch 190, Training Loss: 4.7584296680724947e-07, Validation Loss: 4.428822535373911e-07
Epoch 191, Training Loss: 4.4288316303209285e-07, Validation Loss: 4.0847359628060076e-07
Epoch 192, Training Loss: 4.084838280959957e-07, Validation Loss: 3.7147731291042874e-07
Epoch 193, Training Loss: 3.7149095533095533e-07, Validation Loss: 3.328274260638864e-07
Epoch 194, Training Loss: 3.3281759215242346e-07, Validation Loss: 2.946553081528691e-07
Epoch 195, Training Loss: 2.9465127227013e-07, Validation Loss: 2.5942546244550613e-07
Epoch 196, Training Loss: 2.59436546912184e-07, Validation Loss: 2.2901416230070026e-07
Epoch 197, Training Loss: 2.2900313467744127e-07, Validation Loss: 2.0421249757873738e-07
Epoch 198, Training Loss: 2.0421397550762777e-07, Validation Loss: 1.8471820339982514e-07
Epoch 199, Training Loss: 1.847147075295652e-07, Validation Loss: 1.692901037131378e-07
Epoch 200, Training Loss: 1.692740170256002e-07, Validation Loss: 1.5626390847955918e-07
Epoch 201, Training Loss: 1.5625008131792129e-07, Validation Loss: 1.4399701342426852e-07
Epoch 202, Training Loss: 1.4400362147171109e-07, Validation Loss: 1.313395898705494e-07
Epoch 203, Training Loss: 1.3133562504208385e-07, Validation Loss: 1.1777574115967582e-07
Epoch 204, Training Loss: 1.1778602271306227e-07, Validation Loss: 1.0346558099172398e-07
Epoch 205, Training Loss: 1.0345745948825424e-07, Validation Loss: 8.90324542979215e-08
Epoch 206, Training Loss: 8.902350145945093e-08, Validation Loss: 7.536857538070763e-08
Epoch 207, Training Loss: 7.536677770758615e-08, Validation Loss: 6.333492308385757e-08
Epoch 208, Training Loss: 6.33343333333869e-08, Validation Loss: 5.348659115611554e-08
Epoch 209, Training Loss: 5.3491870488642235e-08, Validation Loss: 4.6074024595554874e-08
Epoch 210, Training Loss: 4.608055093058283e-08, Validation Loss: 4.09145535229527e-08
Epoch 211, Training Loss: 4.0915697496757275e-08, Validation Loss: 3.7569837019191255e-08
Epoch 212, Training Loss: 3.756739630489392e-08, Validation Loss: 3.544417737089134e-08
Epoch 213, Training Loss: 3.5445964385871775e-08, Validation Loss: 3.396118231080436e-08
Epoch 214, Training Loss: 3.395896541746879e-08, Validation Loss: 3.262586645291776e-08
Epoch 215, Training Loss: 3.2618931555816744e-08, Validation Loss: 3.1135883205024584e-08
Epoch 216, Training Loss: 3.1127704858135985e-08, Validation Loss: 2.9345541108227735e-08
Epoch 217, Training Loss: 2.934993759140525e-08, Validation Loss: 2.731474246786547e-08
Epoch 218, Training Loss: 2.7314623451957232e-08, Validation Loss: 2.513297303607942e-08
Epoch 219, Training Loss: 2.5135145520494007e-08, Validation Loss: 2.294859058338261e-08
Epoch 220, Training Loss: 2.2942060695640976e-08, Validation Loss: 2.0869396877287727e-08
Epoch 221, Training Loss: 2.086965800174312e-08, Validation Loss: 1.896288281955094e-08
Epoch 222, Training Loss: 1.896116863520092e-08, Validation Loss: 1.7231981175314104e-08
Epoch 223, Training Loss: 1.7229195847789924e-08, Validation Loss: 1.5652943829991273e-08
Epoch 224, Training Loss: 1.5652290130674373e-08, Validation Loss: 1.416590755809466e-08
Epoch 225, Training Loss: 1.41678029308423e-08, Validation Loss: 1.2745309696526874e-08
Epoch 226, Training Loss: 1.2746108168926185e-08, Validation Loss: 1.136155614034351e-08
Epoch 227, Training Loss: 1.1359230889240735e-08, Validation Loss: 1.0031344643834927e-08
Epoch 228, Training Loss: 1.0029527430788221e-08, Validation Loss: 8.782618188263314e-09
Epoch 229, Training Loss: 8.781891658315999e-09, Validation Loss: 7.666183243770774e-09
Epoch 230, Training Loss: 7.666004719908415e-09, Validation Loss: 6.709214073197245e-09
Epoch 231, Training Loss: 6.7112382318157415e-09, Validation Loss: 5.933035396310515e-09
Epoch 232, Training Loss: 5.930041346857706e-09, Validation Loss: 5.319196194619735e-09
Epoch 233, Training Loss: 5.32063371139202e-09, Validation Loss: 4.840761125279869e-09
Epoch 234, Training Loss: 4.8411736841558195e-09, Validation Loss: 4.4455590320069405e-09
Epoch 235, Training Loss: 4.444235646161587e-09, Validation Loss: 4.085665583630771e-09
Epoch 236, Training Loss: 4.088839933302779e-09, Validation Loss: 3.72319908237273e-09
Epoch 237, Training Loss: 3.722144592543941e-09, Validation Loss: 3.3361491347250194e-09
Epoch 238, Training Loss: 3.334942100252647e-09, Validation Loss: 2.920178321375033e-09
Epoch 239, Training Loss: 2.919509745069604e-09, Validation Loss: 2.4986408497795765e-09
Epoch 240, Training Loss: 2.500057494358998e-09, Validation Loss: 2.0955854829196596e-09
Epoch 241, Training Loss: 2.097483520202559e-09, Validation Loss: 1.7412346009493262e-09
Epoch 242, Training Loss: 1.7410715091870088e-09, Validation Loss: 1.453448805754931e-09
Epoch 243, Training Loss: 1.4549853544210123e-09, Validation Loss: 1.2441502272864113e-09
Epoch 244, Training Loss: 1.2439403951347572e-09, Validation Loss: 1.1055822923822234e-09
Epoch 245, Training Loss: 1.1052181392301463e-09, Validation Loss: 1.0235607916797562e-09
Epoch 246, Training Loss: 1.0222009905191953e-09, Validation Loss: 9.72966263113051e-10
Epoch 247, Training Loss: 9.742031625847858e-10, Validation Loss: 9.389262700665313e-10
Epoch 248, Training Loss: 9.394133249074343e-10, Validation Loss: 9.012087742732433e-10
Epoch 249, Training Loss: 9.031494441202881e-10, Validation Loss: 8.572027532238735e-10
Epoch 250, Training Loss: 8.587354161093685e-10, Validation Loss: 8.026065367872093e-10
Epoch 251, Training Loss: 8.026895259583e-10, Validation Loss: 7.421669945273379e-10
Epoch 252, Training Loss: 7.418554104354769e-10, Validation Loss: 6.85880241491077e-10
Epoch 253, Training Loss: 6.847389877329135e-10, Validation Loss: 6.35828778516867e-10
Epoch 254, Training Loss: 6.35613450761241e-10, Validation Loss: 5.958391002813812e-10
Epoch 255, Training Loss: 5.961677818078215e-10, Validation Loss: 5.651974999132392e-10
Epoch 256, Training Loss: 5.656607959814153e-10, Validation Loss: 5.390695112517108e-10
Epoch 257, Training Loss: 5.380295653445444e-10, Validation Loss: 5.116396195603556e-10
Epoch 258, Training Loss: 5.115204926298134e-10, Validation Loss: 4.773600958962732e-10
Epoch 259, Training Loss: 4.779432960511087e-10, Validation Loss: 4.3510284264414167e-10
Epoch 260, Training Loss: 4.3514503111907743e-10, Validation Loss: 3.8697542392718276e-10
Epoch 261, Training Loss: 3.8681080560820646e-10, Validation Loss: 3.321847241721798e-10
Epoch 262, Training Loss: 3.3209476835160956e-10, Validation Loss: 2.7808638725090873e-10
Epoch 263, Training Loss: 2.7810687086571306e-10, Validation Loss: 2.279327976362211e-10
Epoch 264, Training Loss: 2.2757715156807024e-10, Validation Loss: 1.8565486648025598e-10
Epoch 265, Training Loss: 1.8639643994955435e-10, Validation Loss: 1.5428028299346863e-10
Epoch 266, Training Loss: 1.539871979927554e-10, Validation Loss: 1.316827896724604e-10
Epoch 267, Training Loss: 1.3197434811651476e-10, Validation Loss: 1.1666681509758803e-10
Epoch 268, Training Loss: 1.1725412307761474e-10, Validation Loss: 1.0765041635885098e-10
Epoch 269, Training Loss: 1.0731923683060529e-10, Validation Loss: 9.920892579673435e-11
Epoch 270, Training Loss: 9.940662182295057e-11, Validation Loss: 9.12175820988459e-11
Epoch 271, Training Loss: 9.120073446444721e-11, Validation Loss: 8.293147418791946e-11
Epoch 272, Training Loss: 8.264184475637038e-11, Validation Loss: 7.315803518537223e-11
Epoch 273, Training Loss: 7.333600393621964e-11, Validation Loss: 6.320814704974254e-11
Epoch 274, Training Loss: 6.371305566466035e-11, Validation Loss: 5.384256582252611e-11
Epoch 275, Training Loss: 5.4045184993967155e-11, Validation Loss: 4.646795101481693e-11
Epoch 276, Training Loss: 4.615052090484184e-11, Validation Loss: 4.0136401147083944e-11
Epoch 277, Training Loss: 3.9890757363991725e-11, Validation Loss: 3.627092029501178e-11
Epoch 278, Training Loss: 3.5998044822793673e-11, Validation Loss: 3.3791865139409794e-11
Epoch 279, Training Loss: 3.382361057902017e-11, Validation Loss: 3.223059666379591e-11
Epoch 280, Training Loss: 3.248456018067891e-11, Validation Loss: 3.125538022841212e-11
Epoch 281, Training Loss: 3.136871665199159e-11, Validation Loss: 3.01029548510634e-11
Epoch 282, Training Loss: 3.006080454004412e-11, Validation Loss: 2.8754741643322035e-11
Epoch 283, Training Loss: 2.8696335238609372e-11, Validation Loss: 2.7058787502309833e-11
Epoch 284, Training Loss: 2.7026698587451214e-11, Validation Loss: 2.5565534064742046e-11
Epoch 285, Training Loss: 2.5468065156797337e-11, Validation Loss: 2.3894721271067176e-11
Epoch 286, Training Loss: 2.3744187171992337e-11, Validation Loss: 2.235765045321969e-11
Epoch 287, Training Loss: 2.20473691386891e-11, Validation Loss: 2.039623504812571e-11
Epoch 288, Training Loss: 2.079849660552302e-11, Validation Loss: 1.9432315132017486e-11
Epoch 289, Training Loss: 1.94122252994422e-11, Validation Loss: 1.8085897363073755e-11
Epoch 290, Training Loss: 1.8192187339893806e-11, Validation Loss: 1.6779203027006417e-11
Epoch 291, Training Loss: 1.6932776361611168e-11, Validation Loss: 1.5341996770223965e-11
Epoch 292, Training Loss: 1.538393544497918e-11, Validation Loss: 1.3765663955944696e-11
Epoch 293, Training Loss: 1.3716980676314883e-11, Validation Loss: 1.1970958946339039e-11
Epoch 294, Training Loss: 1.2018574503669388e-11, Validation Loss: 1.0094741882682445e-11
Epoch 295, Training Loss: 1.0103476215383989e-11, Validation Loss: 8.51049959671446e-12
Epoch 296, Training Loss: 8.342686784457154e-12, Validation Loss: 6.827505574791282e-12
Epoch 297, Training Loss: 6.740023469897771e-12, Validation Loss: 5.462067863976072e-12
Epoch 298, Training Loss: 5.358502704055912e-12, Validation Loss: 4.394776209615259e-12
Epoch 299, Training Loss: 4.326441115087842e-12, Validation Loss: 3.611286183285989e-12
Epoch 300, Training Loss: 3.619760957987439e-12, Validation Loss: 2.958220907817166e-12
Epoch 301, Training Loss: 3.091517493392093e-12, Validation Loss: 2.618396601969386e-12
Epoch 302, Training Loss: 2.663995760099347e-12, Validation Loss: 2.4327037780047522e-12
Epoch 303, Training Loss: 2.434073775869905e-12, Validation Loss: 2.2761842324164894e-12
Epoch 304, Training Loss: 2.2327190010024145e-12, Validation Loss: 2.0717774284334523e-12
Epoch 305, Training Loss: 2.1561964453492566e-12, Validation Loss: 1.9894481027848965e-12
Epoch 306, Training Loss: 1.972836173938508e-12, Validation Loss: 1.8856270711520295e-12
Epoch 307, Training Loss: 1.8928070916190975e-12, Validation Loss: 1.6825658704852642e-12
Epoch 308, Training Loss: 1.7487463300353001e-12, Validation Loss: 1.6079929271786697e-12
Epoch 309, Training Loss: 1.6029316545970729e-12, Validation Loss: 1.4986874588562848e-12
Epoch 310, Training Loss: 1.4961836023591468e-12, Validation Loss: 1.4110111733536823e-12
Epoch 311, Training Loss: 1.379526267525355e-12, Validation Loss: 1.2626199998727605e-12
Epoch 312, Training Loss: 1.2724023223942282e-12, Validation Loss: 1.174945449093634e-12
Epoch 313, Training Loss: 1.1900690936178515e-12, Validation Loss: 1.1005866357161054e-12
Epoch 314, Training Loss: 1.1382006448457105e-12, Validation Loss: 1.0240410949768908e-12
Epoch 315, Training Loss: 1.043097899722234e-12, Validation Loss: 9.841117721079429e-13
Epoch 316, Training Loss: 9.766114783191227e-13, Validation Loss: 9.087017163039723e-13
Epoch 317, Training Loss: 8.788018598417102e-13, Validation Loss: 8.181177632050896e-13
Epoch 318, Training Loss: 8.123044337865482e-13, Validation Loss: 7.604256850937685e-13
Epoch 319, Training Loss: 7.401518091997017e-13, Validation Loss: 6.933694070287988e-13
Epoch 320, Training Loss: 6.687125896423507e-13, Validation Loss: 6.130697078471359e-13
Epoch 321, Training Loss: 6.06693026979771e-13, Validation Loss: 5.727399349057805e-13
Epoch 322, Training Loss: 5.344564309346655e-13, Validation Loss: 5.110139741915098e-13
Epoch 323, Training Loss: 4.699479737649281e-13, Validation Loss: 4.540557383206356e-13
Epoch 324, Training Loss: 4.3502476469205187e-13, Validation Loss: 3.9485710708053734e-13
Epoch 325, Training Loss: 3.9441767994002896e-13, Validation Loss: 3.46388120010116e-13
Epoch 326, Training Loss: 3.449176166035739e-13, Validation Loss: 3.1256101222856825e-13
Epoch 327, Training Loss: 3.028217596384025e-13, Validation Loss: 2.9358105031219994e-13
Epoch 328, Training Loss: 2.7024137593499586e-13, Validation Loss: 2.6362405639544784e-13
Epoch 329, Training Loss: 2.413802393640835e-13, Validation Loss: 2.1199846890994356e-13
Epoch 330, Training Loss: 2.2343199068252523e-13, Validation Loss: 2.022137882487507e-13
Epoch 331, Training Loss: 1.8079488644032193e-13, Validation Loss: 1.7463291826069066e-13
Epoch 332, Training Loss: 1.741310139699928e-13, Validation Loss: 1.618873356765485e-13
Epoch 333, Training Loss: 1.5187104232625842e-13, Validation Loss: 1.5166221143531056e-13
Epoch 334, Training Loss: 1.2797122844916686e-13, Validation Loss: 1.268499601149095e-13
Epoch 335, Training Loss: 1.1371993299293115e-13, Validation Loss: 8.957875538345358e-14
Epoch 336, Training Loss: 9.974340147225758e-14, Validation Loss: 8.550602446141115e-14
Epoch 337, Training Loss: 8.572950563421472e-14, Validation Loss: 7.772308594248753e-14
Epoch 338, Training Loss: 7.46336789570444e-14, Validation Loss: 6.320134980685246e-14
Epoch 339, Training Loss: 6.931474572915639e-14, Validation Loss: 5.743592857180777e-14
Epoch 340, Training Loss: 5.974014279140974e-14, Validation Loss: 5.363821908334343e-14
Epoch 341, Training Loss: 4.36130860972158e-14, Validation Loss: 4.0087626550526154e-14
Epoch 342, Training Loss: 3.5095326167758345e-14, Validation Loss: 4.099341986739738e-14
Epoch 343, Training Loss: 3.268392501087902e-14, Validation Loss: 3.147018778383581e-14
Epoch 344, Training Loss: 3.195907826033205e-14, Validation Loss: 3.1668711977881486e-14
Epoch 345, Training Loss: 3.11972669919669e-14, Validation Loss: 2.6740896213388148e-14
Epoch 346, Training Loss: 2.7829235294788042e-14, Validation Loss: 2.2972543192809752e-14
Epoch 347, Training Loss: 1.926730767932896e-14, Validation Loss: 2.0143476865902912e-14
Epoch 348, Training Loss: 1.8545395050911274e-14, Validation Loss: 2.1441883506353662e-14
Epoch 349, Training Loss: 1.691168703015812e-14, Validation Loss: 1.8762403197931932e-14
Epoch 350, Training Loss: 1.4267968452769467e-14, Validation Loss: 1.7938141884431616e-14
Epoch 351, Training Loss: 1.4454783263352297e-14, Validation Loss: 1.6961192717793346e-14
Epoch 352, Training Loss: 1.3823745411713738e-14, Validation Loss: 1.4518302264066897e-14
Epoch 353, Training Loss: 1.449481573450543e-14, Validation Loss: 1.5701116012271747e-14
Epoch 354, Training Loss: 1.0559929260233261e-14, Validation Loss: 1.509249573461522e-14
Epoch 355, Training Loss: 1.121592154953088e-14, Validation Loss: 1.613536439334061e-14
Epoch 356, Training Loss: 1.291434966371784e-14, Validation Loss: 1.2542985008653137e-14
Epoch 357, Training Loss: 1.0163744845748113e-14, Validation Loss: 1.6356441686639876e-14
Epoch 358, Training Loss: 1.0411543487434411e-14, Validation Loss: 1.6007362468417434e-14
Epoch 359, Training Loss: 9.888991921614288e-15, Validation Loss: 1.4675093144801352e-14
Epoch 360, Training Loss: 1.0826009414020149e-14, Validation Loss: 1.3513262943798832e-14
Epoch 361, Training Loss: 1.0647732695545642e-14, Validation Loss: 1.3295888878544961e-14
Epoch 362, Training Loss: 1.2172955277513307e-14, Validation Loss: 1.3358872554436897e-14
Epoch 363, Training Loss: 1.1740609332443978e-14, Validation Loss: 1.1744244797853593e-14
Epoch 364, Training Loss: 1.1927424990059755e-14, Validation Loss: 1.232497736275472e-14
Epoch 365, Training Loss: 1.016067604538021e-14, Validation Loss: 9.913577899941291e-15
Epoch 366, Training Loss: 7.46811839528582e-15, Validation Loss: 8.821502556211058e-15
Epoch 367, Training Loss: 7.187893638312733e-15, Validation Loss: 8.506983976302486e-15
Epoch 368, Training Loss: 6.651463861168322e-15, Validation Loss: 7.926885839078853e-15
Epoch 369, Training Loss: 5.506146143956052e-15, Validation Loss: 6.8284056557179566e-15
Epoch 370, Training Loss: 5.918476276965288e-15, Validation Loss: 8.924085022387132e-15
Epoch 371, Training Loss: 5.972786758993813e-15, Validation Loss: 8.659072977146732e-15
Epoch 372, Training Loss: 5.925014947801618e-15, Validation Loss: 6.6469267291863546e-15
Epoch 373, Training Loss: 3.996269257893793e-15, Validation Loss: 8.452006455827998e-15
Epoch 374, Training Loss: 4.559654164518678e-15, Validation Loss: 8.27933540139842e-15
Epoch 375, Training Loss: 3.662134665476232e-15, Validation Loss: 6.3404147282117036e-15
Epoch 376, Training Loss: 5.512684391275908e-15, Validation Loss: 8.56206144666475e-15
Epoch 377, Training Loss: 4.361362057500552e-15, Validation Loss: 5.826535932738517e-15
Epoch 378, Training Loss: 3.763015865977746e-15, Validation Loss: 4.978923614948295e-15
Epoch 379, Training Loss: 3.5842055167464686e-15, Validation Loss: 5.448099399597188e-15
Epoch 380, Training Loss: 3.566057835851545e-15, Validation Loss: 4.986662954987358e-15
Epoch 381, Training Loss: 4.6362488128400426e-15, Validation Loss: 5.558321255924549e-15
Epoch 382, Training Loss: 3.8569577490588786e-15, Validation Loss: 5.625041194146823e-15
Epoch 383, Training Loss: 4.057117987242174e-15, Validation Loss: 5.5182892082878895e-15
Epoch 384, Training Loss: 3.832938435773588e-15, Validation Loss: 5.379110683625694e-15
Epoch 385, Training Loss: 3.439556429794431e-15, Validation Loss: 5.454004066272498e-15
Epoch 386, Training Loss: 3.740063814205996e-15, Validation Loss: 6.475856567027087e-15
Epoch 387, Training Loss: 4.781431954065324e-15, Validation Loss: 5.3332074271151414e-15
Epoch 388, Training Loss: 3.4758522151007512e-15, Validation Loss: 5.042841144664578e-15
Epoch 389, Training Loss: 3.375371661183289e-15, Validation Loss: 6.60089006498661e-15
Epoch 390, Training Loss: 3.1682723173378493e-15, Validation Loss: 6.447166714070637e-15
Epoch 391, Training Loss: 3.115429955165153e-15, Validation Loss: 5.684188657820643e-15
Epoch 392, Training Loss: 3.122102033690675e-15, Validation Loss: 5.126408144691267e-15
Epoch 393, Training Loss: 2.9939993118467765e-15, Validation Loss: 5.266120300110233e-15
Epoch 394, Training Loss: 2.550443944511721e-15, Validation Loss: 4.70940747201087e-15
Epoch 395, Training Loss: 3.4508988362328763e-15, Validation Loss: 4.690192106085933e-15
Epoch 396, Training Loss: 3.3147897472132933e-15, Validation Loss: 4.660168176237557e-15
Epoch 397, Training Loss: 1.466241666147098e-15, Validation Loss: 4.6381504018066285e-15
Epoch 398, Training Loss: 7.48866804986092e-16, Validation Loss: 4.881945542267729e-15
Epoch 399, Training Loss: 9.08995101411847e-16, Validation Loss: 4.952935797093586e-15
Epoch 400, Training Loss: 1.815988663969332e-15, Validation Loss: 4.554216212997305e-15
Epoch 401, Training Loss: 2.499202898125809e-15, Validation Loss: 4.636949309087422e-15
Epoch 402, Training Loss: 2.5659230481063196e-15, Validation Loss: 4.396222968994223e-15
Epoch 403, Training Loss: 2.6273056199697074e-15, Validation Loss: 4.394621653207439e-15
Epoch 404, Training Loss: 2.5760643618255585e-15, Validation Loss: 4.497104169495737e-15
Epoch 405, Training Loss: 1.815454821454325e-15, Validation Loss: 4.4490655429251565e-15
Epoch 406, Training Loss: 2.2508704139245035e-15, Validation Loss: 4.4490655429251565e-15
Epoch 407, Training Loss: 2.7136413589427333e-15, Validation Loss: 4.460274329916173e-15
Epoch 408, Training Loss: 1.731520950282357e-15, Validation Loss: 4.398891969811022e-15
Epoch 409, Training Loss: 1.86496114436426e-15, Validation Loss: 4.505643955669955e-15
Epoch 410, Training Loss: 1.2361906940463823e-15, Validation Loss: 7.467350983435608e-15
Epoch 411, Training Loss: 1.104351709872145e-15, Validation Loss: 7.59852250564741e-15
Epoch 412, Training Loss: 1.104351709872145e-15, Validation Loss: 5.9975065685264825e-15
Epoch 413, Training Loss: 1.1203645501026323e-15, Validation Loss: 5.062356783769317e-15
Epoch 414, Training Loss: 1.1417149684502426e-15, Validation Loss: 5.425314636832521e-15
Epoch 415, Training Loss: 7.706175522803984e-16, Validation Loss: 5.425314636832521e-15
Epoch 416, Training Loss: 7.305855046437393e-16, Validation Loss: 4.859761325862666e-15
Epoch 417, Training Loss: 1.0380318888383302e-15, Validation Loss: 4.859761325862666e-15
Epoch 418, Training Loss: 1.1864174498789435e-15, Validation Loss: 4.859761325862666e-15
Epoch 419, Training Loss: 1.1864174498789435e-15, Validation Loss: 5.3354757813478884e-15
Epoch 420, Training Loss: 1.3919154779375989e-15, Validation Loss: 4.488130278936051e-15
Epoch 421, Training Loss: 1.4906613083790843e-15, Validation Loss: 4.475219802754001e-15
Epoch 422, Training Loss: 2.4611723893435116e-15, Validation Loss: 6.884317030016792e-15
Epoch 423, Training Loss: 1.0429691380087571e-15, Validation Loss: 3.6776472268722476e-15
Epoch 424, Training Loss: 7.947702732548812e-16, Validation Loss: 3.6776472268722476e-15
Epoch 425, Training Loss: 7.905001684095354e-16, Validation Loss: 3.6916584223692546e-15
Epoch 426, Training Loss: 1.5617849708941334e-15, Validation Loss: 3.815758066504429e-15
Epoch 427, Training Loss: 1.1641329659487485e-15, Validation Loss: 3.260112711676844e-15
Epoch 428, Training Loss: 1.2281842209915794e-15, Validation Loss: 3.61506377404789e-15
Epoch 429, Training Loss: 1.4950648209136226e-15, Validation Loss: 3.61506377404789e-15
Epoch 430, Training Loss: 1.782628694858195e-15, Validation Loss: 3.61506377404789e-15
Epoch 431, Training Loss: 1.782628694858195e-15, Validation Loss: 3.61506377404789e-15
Epoch 432, Training Loss: 1.7441977512500833e-15, Validation Loss: 3.82856816928223e-15
Epoch 433, Training Loss: 1.7441977512500833e-15, Validation Loss: 3.835507063186137e-15
Epoch 434, Training Loss: 1.7534052111449743e-15, Validation Loss: 3.341110872532747e-15
Epoch 435, Training Loss: 1.3279976305839605e-15, Validation Loss: 4.030997185214746e-15
Epoch 436, Training Loss: 8.449437934294568e-16, Validation Loss: 3.3491172397084315e-15
Epoch 437, Training Loss: 8.449437934294568e-16, Validation Loss: 3.402493444396135e-15
Epoch 438, Training Loss: 8.449437934294568e-16, Validation Loss: 3.1516257905836974e-15
Epoch 439, Training Loss: 8.449437934294568e-16, Validation Loss: 3.9729504408558824e-15
Epoch 440, Training Loss: 8.609566336599441e-16, Validation Loss: 3.3681991979441763e-15
Epoch 441, Training Loss: 1.0824674490095276e-15, Validation Loss: 3.396221800696427e-15
Epoch 442, Training Loss: 1.1422487050861312e-15, Validation Loss: 3.396221800696427e-15
Epoch 443, Training Loss: 1.2997082124533246e-15, Validation Loss: 3.396221800696427e-15
Epoch 444, Training Loss: 1.3530843112619095e-15, Validation Loss: 4.0494116814880545e-15
Epoch 445, Training Loss: 1.2041650135854076e-15, Validation Loss: 4.8819125079827864e-15
Epoch 446, Training Loss: 8.861768279062041e-16, Validation Loss: 3.956504025635519e-15
Epoch 447, Training Loss: 1.4065939236388054e-15, Validation Loss: 4.4704158553936484e-15
Epoch 448, Training Loss: 1.1450510077130036e-15, Validation Loss: 2.7001640059607333e-15
Epoch 449, Training Loss: 1.1503885858301266e-15, Validation Loss: 2.7001640059607333e-15
Epoch 450, Training Loss: 1.1359770613864235e-15, Validation Loss: 2.8795075624323072e-15
Epoch 451, Training Loss: 5.995471254233349e-16, Validation Loss: 4.813057199700484e-15
Epoch 452, Training Loss: 1.3654942968512507e-15, Validation Loss: 3.4553023487674146e-15
Epoch 453, Training Loss: 1.3654942968512507e-15, Validation Loss: 3.4553023487674146e-15
Epoch 454, Training Loss: 5.328270283823833e-16, Validation Loss: 3.4553023487674146e-15
Epoch 455, Training Loss: 5.136116095178867e-16, Validation Loss: 3.3592255191427275e-15
Epoch 456, Training Loss: 6.283702272503002e-16, Validation Loss: 3.3592255191427275e-15
Epoch 457, Training Loss: 6.283702272503002e-16, Validation Loss: 3.061386712031487e-15
Epoch 458, Training Loss: 1.9594368699604e-15, Validation Loss: 3.061386712031487e-15
Epoch 459, Training Loss: 1.9594368699604e-15, Validation Loss: 2.9973353511095376e-15
Epoch 460, Training Loss: 1.4747818758377895e-15, Validation Loss: 2.9973353511095376e-15
Epoch 461, Training Loss: 1.4747818758377895e-15, Validation Loss: 2.9973353511095376e-15
Epoch 462, Training Loss: 8.669614619812667e-16, Validation Loss: 2.9973353511095376e-15
Epoch 463, Training Loss: 8.029101010593174e-16, Validation Loss: 2.9973353511095376e-15
Epoch 464, Training Loss: 6.961579034421475e-16, Validation Loss: 2.9973353511095376e-15
Epoch 465, Training Loss: 6.908202723854653e-16, Validation Loss: 3.0080107191020203e-15
Epoch 466, Training Loss: 6.908202723854653e-16, Validation Loss: 3.0080107191020203e-15
Epoch 467, Training Loss: 1.878438709104497e-15, Validation Loss: 3.0080107191020203e-15
Epoch 468, Training Loss: 1.878438709104497e-15, Validation Loss: 3.0192195060930365e-15
Epoch 469, Training Loss: 1.8997892333312257e-15, Validation Loss: 3.0192195060930365e-15
Epoch 470, Training Loss: 1.890181550368757e-15, Validation Loss: 3.765284220210493e-15
Epoch 471, Training Loss: 1.1722727408136255e-15, Validation Loss: 4.3020142705347056e-15
Epoch 472, Training Loss: 2.0156152713958573e-15, Validation Loss: 4.125339291363456e-15
Epoch 473, Training Loss: 1.260209901452554e-15, Validation Loss: 3.898490739078072e-15
Epoch 474, Training Loss: 1.2309865236184519e-15, Validation Loss: 4.464944869587333e-15
Epoch 475, Training Loss: 1.4544989307619565e-15, Validation Loss: 3.5687268366683435e-15
Epoch 476, Training Loss: 7.152398616778923e-16, Validation Loss: 3.719680813363269e-15
Epoch 477, Training Loss: 1.4117980940667359e-15, Validation Loss: 3.719680813363269e-15
Epoch 478, Training Loss: 1.7934372587816334e-15, Validation Loss: 4.559020160357658e-15
Epoch 479, Training Loss: 1.7042991113026167e-15, Validation Loss: 3.554715217654863e-15
Epoch 480, Training Loss: 2.2620794126737565e-15, Validation Loss: 3.0890088799579232e-15
Epoch 481, Training Loss: 1.6429166453183473e-15, Validation Loss: 2.974517130543454e-15
Epoch 482, Training Loss: 8.469453852233779e-16, Validation Loss: 2.38404389850714e-15
Epoch 483, Training Loss: 9.789178829659262e-16, Validation Loss: 4.158299037407016e-15
Epoch 484, Training Loss: 1.1150268661063909e-15, Validation Loss: 4.136948724938524e-15
Epoch 485, Training Loss: 9.629050427354389e-16, Validation Loss: 3.443059334547801e-15
Epoch 486, Training Loss: 1.132374100866159e-15, Validation Loss: 3.443059334547801e-15
Epoch 487, Training Loss: 1.1590622032100107e-15, Validation Loss: 3.4238439686228635e-15
Epoch 488, Training Loss: 1.1590622032100107e-15, Validation Loss: 3.3491172397084315e-15
Epoch 489, Training Loss: 1.033628376303792e-15, Validation Loss: 4.032865316379915e-15
Epoch 490, Training Loss: 1.033628376303792e-15, Validation Loss: 3.0208542796812373e-15
Epoch 491, Training Loss: 7.261819391696418e-16, Validation Loss: 2.867131140523501e-15
Epoch 492, Training Loss: 5.647192482146062e-16, Validation Loss: 2.8244300920700436e-15
Epoch 493, Training Loss: 6.704039196204397e-16, Validation Loss: 2.805214726145106e-15
Epoch 494, Training Loss: 3.3573572291588805e-16, Validation Loss: 2.805214726145106e-15
Epoch 495, Training Loss: 3.3573572291588805e-16, Validation Loss: 3.76585130876868e-15
Epoch 496, Training Loss: 3.309318814346537e-16, Validation Loss: 3.76585130876868e-15
Epoch 497, Training Loss: 3.7897037565633607e-16, Validation Loss: 3.76585130876868e-15
Epoch 498, Training Loss: 9.581012012542045e-16, Validation Loss: 3.4114006311112242e-15
Epoch 499, Training Loss: 7.872975897755261e-16, Validation Loss: 3.604221752323035e-15
Epoch 500, Training Loss: 2.145719532094118e-15, Validation Loss: 3.604221752323035e-15
