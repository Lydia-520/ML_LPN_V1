Epoch 1, Training Loss: 0.2359284907579422, Validation Loss: 0.2883143424987793
Epoch 2, Training Loss: 0.2350061535835266, Validation Loss: 0.28725138306617737
Epoch 3, Training Loss: 0.2340894341468811, Validation Loss: 0.28618526458740234
Epoch 4, Training Loss: 0.23316799104213715, Validation Loss: 0.2851230204105377
Epoch 5, Training Loss: 0.2322467714548111, Validation Loss: 0.28406277298927307
Epoch 6, Training Loss: 0.23132893443107605, Validation Loss: 0.2830110192298889
Epoch 7, Training Loss: 0.2304171919822693, Validation Loss: 0.281952440738678
Epoch 8, Training Loss: 0.22950516641139984, Validation Loss: 0.2808859646320343
Epoch 9, Training Loss: 0.22858884930610657, Validation Loss: 0.2798011302947998
Epoch 10, Training Loss: 0.22766150534152985, Validation Loss: 0.2786969840526581
Epoch 11, Training Loss: 0.22671964764595032, Validation Loss: 0.2775793969631195
Epoch 12, Training Loss: 0.2257625162601471, Validation Loss: 0.27644187211990356
Epoch 13, Training Loss: 0.22478727996349335, Validation Loss: 0.27528461813926697
Epoch 14, Training Loss: 0.2237936556339264, Validation Loss: 0.27411404252052307
Epoch 15, Training Loss: 0.22278936207294464, Validation Loss: 0.27293020486831665
Epoch 16, Training Loss: 0.22177278995513916, Validation Loss: 0.27170777320861816
Epoch 17, Training Loss: 0.2207285463809967, Validation Loss: 0.2704540193080902
Epoch 18, Training Loss: 0.21966798603534698, Validation Loss: 0.26918643712997437
Epoch 19, Training Loss: 0.21859902143478394, Validation Loss: 0.26789796352386475
Epoch 20, Training Loss: 0.21751119196414948, Validation Loss: 0.26655811071395874
Epoch 21, Training Loss: 0.21639534831047058, Validation Loss: 0.26518478989601135
Epoch 22, Training Loss: 0.21524812281131744, Validation Loss: 0.26376327872276306
Epoch 23, Training Loss: 0.21406321227550507, Validation Loss: 0.26229342818260193
Epoch 24, Training Loss: 0.21283605694770813, Validation Loss: 0.2607760429382324
Epoch 25, Training Loss: 0.21156556904315948, Validation Loss: 0.25920236110687256
Epoch 26, Training Loss: 0.21024049818515778, Validation Loss: 0.25756144523620605
Epoch 27, Training Loss: 0.20885318517684937, Validation Loss: 0.25584083795547485
Epoch 28, Training Loss: 0.20740026235580444, Validation Loss: 0.254042387008667
Epoch 29, Training Loss: 0.2058786004781723, Validation Loss: 0.2521698772907257
Epoch 30, Training Loss: 0.2042812705039978, Validation Loss: 0.25021061301231384
Epoch 31, Training Loss: 0.2026081383228302, Validation Loss: 0.24815180897712708
Epoch 32, Training Loss: 0.20085392892360687, Validation Loss: 0.24595683813095093
Epoch 33, Training Loss: 0.19900424778461456, Validation Loss: 0.24364128708839417
Epoch 34, Training Loss: 0.19707125425338745, Validation Loss: 0.24120527505874634
Epoch 35, Training Loss: 0.1950438767671585, Validation Loss: 0.2386103719472885
Epoch 36, Training Loss: 0.19287791848182678, Validation Loss: 0.23584043979644775
Epoch 37, Training Loss: 0.1905679702758789, Validation Loss: 0.23288442194461823
Epoch 38, Training Loss: 0.18811222910881042, Validation Loss: 0.22974172234535217
Epoch 39, Training Loss: 0.1855120211839676, Validation Loss: 0.2263854593038559
Epoch 40, Training Loss: 0.1827429085969925, Validation Loss: 0.22285506129264832
Epoch 41, Training Loss: 0.17983558773994446, Validation Loss: 0.21913309395313263
Epoch 42, Training Loss: 0.17678114771842957, Validation Loss: 0.21518602967262268
Epoch 43, Training Loss: 0.17356887459754944, Validation Loss: 0.2110092043876648
Epoch 44, Training Loss: 0.17019714415073395, Validation Loss: 0.20665277540683746
Epoch 45, Training Loss: 0.16672229766845703, Validation Loss: 0.20208728313446045
Epoch 46, Training Loss: 0.1631157398223877, Validation Loss: 0.19735023379325867
Epoch 47, Training Loss: 0.15941078960895538, Validation Loss: 0.19246654212474823
Epoch 48, Training Loss: 0.1556353121995926, Validation Loss: 0.18747246265411377
Epoch 49, Training Loss: 0.15182821452617645, Validation Loss: 0.18241992592811584
Epoch 50, Training Loss: 0.14804969727993011, Validation Loss: 0.1773863434791565
Epoch 51, Training Loss: 0.14436931908130646, Validation Loss: 0.1724768877029419
Epoch 52, Training Loss: 0.14086544513702393, Validation Loss: 0.16777530312538147
Epoch 53, Training Loss: 0.13761939108371735, Validation Loss: 0.1633899062871933
Epoch 54, Training Loss: 0.1347246617078781, Validation Loss: 0.15943747758865356
Epoch 55, Training Loss: 0.1322726160287857, Validation Loss: 0.156005859375
Epoch 56, Training Loss: 0.13031668961048126, Validation Loss: 0.15317566692829132
Epoch 57, Training Loss: 0.12889134883880615, Validation Loss: 0.15091590583324432
Epoch 58, Training Loss: 0.12793730199337006, Validation Loss: 0.14915750920772552
Epoch 59, Training Loss: 0.12733033299446106, Validation Loss: 0.1477854996919632
Epoch 60, Training Loss: 0.12690040469169617, Validation Loss: 0.14662805199623108
Epoch 61, Training Loss: 0.12645141780376434, Validation Loss: 0.14554022252559662
Epoch 62, Training Loss: 0.12583108246326447, Validation Loss: 0.14445002377033234
Epoch 63, Training Loss: 0.12497542053461075, Validation Loss: 0.1433110237121582
Epoch 64, Training Loss: 0.12388923019170761, Validation Loss: 0.14214617013931274
Epoch 65, Training Loss: 0.12262839823961258, Validation Loss: 0.14101985096931458
Epoch 66, Training Loss: 0.1212967187166214, Validation Loss: 0.1400020569562912
Epoch 67, Training Loss: 0.12000148743391037, Validation Loss: 0.13913317024707794
Epoch 68, Training Loss: 0.11881937831640244, Validation Loss: 0.13843552768230438
Epoch 69, Training Loss: 0.11780700832605362, Validation Loss: 0.1378910094499588
Epoch 70, Training Loss: 0.11698411405086517, Validation Loss: 0.13746054470539093
Epoch 71, Training Loss: 0.11633679270744324, Validation Loss: 0.13708823919296265
Epoch 72, Training Loss: 0.11583011597394943, Validation Loss: 0.13672052323818207
Epoch 73, Training Loss: 0.11542220413684845, Validation Loss: 0.13630566000938416
Epoch 74, Training Loss: 0.11507300287485123, Validation Loss: 0.1357962042093277
Epoch 75, Training Loss: 0.11474049836397171, Validation Loss: 0.13516919314861298
Epoch 76, Training Loss: 0.11440233141183853, Validation Loss: 0.13440755009651184
Epoch 77, Training Loss: 0.11403805017471313, Validation Loss: 0.13351663947105408
Epoch 78, Training Loss: 0.11364040523767471, Validation Loss: 0.13251474499702454
Epoch 79, Training Loss: 0.1132112517952919, Validation Loss: 0.13141772150993347
Epoch 80, Training Loss: 0.11275476962327957, Validation Loss: 0.13024507462978363
Epoch 81, Training Loss: 0.11227714270353317, Validation Loss: 0.12901853024959564
Epoch 82, Training Loss: 0.11178809404373169, Validation Loss: 0.1277313530445099
Epoch 83, Training Loss: 0.11127576231956482, Validation Loss: 0.1264173686504364
Epoch 84, Training Loss: 0.11075565218925476, Validation Loss: 0.1251148134469986
Epoch 85, Training Loss: 0.11024004966020584, Validation Loss: 0.12384933233261108
Epoch 86, Training Loss: 0.10974517464637756, Validation Loss: 0.12266077101230621
Epoch 87, Training Loss: 0.10928185284137726, Validation Loss: 0.12155060470104218
Epoch 88, Training Loss: 0.10881836712360382, Validation Loss: 0.12051855027675629
Epoch 89, Training Loss: 0.10834360867738724, Validation Loss: 0.11956226080656052
Epoch 90, Training Loss: 0.10784939676523209, Validation Loss: 0.11868041008710861
Epoch 91, Training Loss: 0.10733365267515182, Validation Loss: 0.1178654283285141
Epoch 92, Training Loss: 0.10679150372743607, Validation Loss: 0.11710523813962936
Epoch 93, Training Loss: 0.10621661692857742, Validation Loss: 0.11639311164617538
Epoch 94, Training Loss: 0.10561419278383255, Validation Loss: 0.11571945250034332
Epoch 95, Training Loss: 0.10499116778373718, Validation Loss: 0.11507713049650192
Epoch 96, Training Loss: 0.10435214638710022, Validation Loss: 0.11444475501775742
Epoch 97, Training Loss: 0.10369522869586945, Validation Loss: 0.11382809281349182
Epoch 98, Training Loss: 0.10303673893213272, Validation Loss: 0.1131846010684967
Epoch 99, Training Loss: 0.10235139727592468, Validation Loss: 0.11251288652420044
Epoch 100, Training Loss: 0.10164504498243332, Validation Loss: 0.11180510371923447
Epoch 101, Training Loss: 0.10091859847307205, Validation Loss: 0.11104364693164825
Epoch 102, Training Loss: 0.10016292333602905, Validation Loss: 0.11022109538316727
Epoch 103, Training Loss: 0.0993761345744133, Validation Loss: 0.10933822393417358
Epoch 104, Training Loss: 0.09855657815933228, Validation Loss: 0.10841671377420425
Epoch 105, Training Loss: 0.09771953523159027, Validation Loss: 0.10745960474014282
Epoch 106, Training Loss: 0.09685225039720535, Validation Loss: 0.10645611584186554
Epoch 107, Training Loss: 0.09595317393541336, Validation Loss: 0.10540734976530075
Epoch 108, Training Loss: 0.09501626342535019, Validation Loss: 0.1043274775147438
Epoch 109, Training Loss: 0.0940646231174469, Validation Loss: 0.10321256518363953
Epoch 110, Training Loss: 0.09308220446109772, Validation Loss: 0.10207080096006393
Epoch 111, Training Loss: 0.09207276254892349, Validation Loss: 0.1009293645620346
Epoch 112, Training Loss: 0.09104219079017639, Validation Loss: 0.09978531301021576
Epoch 113, Training Loss: 0.08999942243099213, Validation Loss: 0.09864433109760284
Epoch 114, Training Loss: 0.08894093334674835, Validation Loss: 0.09750717878341675
Epoch 115, Training Loss: 0.08786502480506897, Validation Loss: 0.09637825936079025
Epoch 116, Training Loss: 0.08679217845201492, Validation Loss: 0.09526894241571426
Epoch 117, Training Loss: 0.08571905642747879, Validation Loss: 0.09419915080070496
Epoch 118, Training Loss: 0.0846463292837143, Validation Loss: 0.0931723341345787
Epoch 119, Training Loss: 0.0835728645324707, Validation Loss: 0.09219494462013245
Epoch 120, Training Loss: 0.08251812309026718, Validation Loss: 0.09123136848211288
Epoch 121, Training Loss: 0.08145999908447266, Validation Loss: 0.09029729664325714
Epoch 122, Training Loss: 0.08041293919086456, Validation Loss: 0.0894450843334198
Epoch 123, Training Loss: 0.0793994888663292, Validation Loss: 0.08866333216428757
Epoch 124, Training Loss: 0.07842709869146347, Validation Loss: 0.08797068893909454
Epoch 125, Training Loss: 0.07752055674791336, Validation Loss: 0.08738254010677338
Epoch 126, Training Loss: 0.07668018341064453, Validation Loss: 0.0868222638964653
Epoch 127, Training Loss: 0.07587631046772003, Validation Loss: 0.08626703172922134
Epoch 128, Training Loss: 0.07511348277330399, Validation Loss: 0.08573871105909348
Epoch 129, Training Loss: 0.07440171390771866, Validation Loss: 0.08525142073631287
Epoch 130, Training Loss: 0.07374051213264465, Validation Loss: 0.08477316796779633
Epoch 131, Training Loss: 0.07312524318695068, Validation Loss: 0.08432609587907791
Epoch 132, Training Loss: 0.07255981117486954, Validation Loss: 0.08386123180389404
Epoch 133, Training Loss: 0.07204248756170273, Validation Loss: 0.08337465673685074
Epoch 134, Training Loss: 0.07155578583478928, Validation Loss: 0.08285612612962723
Epoch 135, Training Loss: 0.07109798491001129, Validation Loss: 0.08233417570590973
Epoch 136, Training Loss: 0.07068318128585815, Validation Loss: 0.08180386573076248
Epoch 137, Training Loss: 0.0702829360961914, Validation Loss: 0.08126351982355118
Epoch 138, Training Loss: 0.06989400833845139, Validation Loss: 0.08073627203702927
Epoch 139, Training Loss: 0.06951451301574707, Validation Loss: 0.08018548786640167
Epoch 140, Training Loss: 0.06912241131067276, Validation Loss: 0.07966310530900955
Epoch 141, Training Loss: 0.06873738765716553, Validation Loss: 0.07916874438524246
Epoch 142, Training Loss: 0.06836424022912979, Validation Loss: 0.0786934494972229
Epoch 143, Training Loss: 0.06799092143774033, Validation Loss: 0.07823210954666138
Epoch 144, Training Loss: 0.06761842221021652, Validation Loss: 0.07777639478445053
Epoch 145, Training Loss: 0.06725192070007324, Validation Loss: 0.07731076329946518
Epoch 146, Training Loss: 0.0668913796544075, Validation Loss: 0.0768468901515007
Epoch 147, Training Loss: 0.06654850393533707, Validation Loss: 0.07638656347990036
Epoch 148, Training Loss: 0.06622358411550522, Validation Loss: 0.07592662423849106
Epoch 149, Training Loss: 0.06589677929878235, Validation Loss: 0.07547308504581451
Epoch 150, Training Loss: 0.06556783616542816, Validation Loss: 0.07502611726522446
Epoch 151, Training Loss: 0.06524453312158585, Validation Loss: 0.07459252327680588
Epoch 152, Training Loss: 0.0649258941411972, Validation Loss: 0.07418731600046158
Epoch 153, Training Loss: 0.06461465358734131, Validation Loss: 0.07380030304193497
Epoch 154, Training Loss: 0.06430884450674057, Validation Loss: 0.07343994081020355
Epoch 155, Training Loss: 0.06400172412395477, Validation Loss: 0.07310782372951508
Epoch 156, Training Loss: 0.0636928528547287, Validation Loss: 0.07283331453800201
Epoch 157, Training Loss: 0.06339196115732193, Validation Loss: 0.07259957492351532
Epoch 158, Training Loss: 0.06309476494789124, Validation Loss: 0.07237432897090912
Epoch 159, Training Loss: 0.06279481947422028, Validation Loss: 0.07214567810297012
Epoch 160, Training Loss: 0.06248892471194267, Validation Loss: 0.07189875841140747
Epoch 161, Training Loss: 0.06218724325299263, Validation Loss: 0.0716470405459404
Epoch 162, Training Loss: 0.06188679859042168, Validation Loss: 0.07138655334711075
Epoch 163, Training Loss: 0.06157657504081726, Validation Loss: 0.07112790644168854
Epoch 164, Training Loss: 0.06126091256737709, Validation Loss: 0.07083272188901901
Epoch 165, Training Loss: 0.0609445720911026, Validation Loss: 0.07050421088933945
Epoch 166, Training Loss: 0.06062345579266548, Validation Loss: 0.0701790452003479
Epoch 167, Training Loss: 0.06030447781085968, Validation Loss: 0.06985636055469513
Epoch 168, Training Loss: 0.05998848378658295, Validation Loss: 0.06951961666345596
Epoch 169, Training Loss: 0.05966591089963913, Validation Loss: 0.06917321681976318
Epoch 170, Training Loss: 0.059337928891181946, Validation Loss: 0.06881256401538849
Epoch 171, Training Loss: 0.05900828540325165, Validation Loss: 0.06844384968280792
Epoch 172, Training Loss: 0.058668993413448334, Validation Loss: 0.06805982440710068
Epoch 173, Training Loss: 0.058323439210653305, Validation Loss: 0.06765229254961014
Epoch 174, Training Loss: 0.057974763214588165, Validation Loss: 0.06722772121429443
Epoch 175, Training Loss: 0.05761794000864029, Validation Loss: 0.06678228080272675
Epoch 176, Training Loss: 0.057251445949077606, Validation Loss: 0.0663079023361206
Epoch 177, Training Loss: 0.05688001215457916, Validation Loss: 0.06583665311336517
Epoch 178, Training Loss: 0.056507501751184464, Validation Loss: 0.06537828594446182
Epoch 179, Training Loss: 0.05612795799970627, Validation Loss: 0.06492116302251816
Epoch 180, Training Loss: 0.05573491007089615, Validation Loss: 0.06448020040988922
Epoch 181, Training Loss: 0.055335018783807755, Validation Loss: 0.06400297582149506
Epoch 182, Training Loss: 0.054929349571466446, Validation Loss: 0.06351424753665924
Epoch 183, Training Loss: 0.0545162670314312, Validation Loss: 0.06299638748168945
Epoch 184, Training Loss: 0.054103318601846695, Validation Loss: 0.06250222772359848
Epoch 185, Training Loss: 0.053680431097745895, Validation Loss: 0.06200363487005234
Epoch 186, Training Loss: 0.053240228444337845, Validation Loss: 0.06149294227361679
Epoch 187, Training Loss: 0.05280067399144173, Validation Loss: 0.060956500470638275
Epoch 188, Training Loss: 0.0523502379655838, Validation Loss: 0.0604468509554863
Epoch 189, Training Loss: 0.05189456418156624, Validation Loss: 0.059952400624752045
Epoch 190, Training Loss: 0.05142654478549957, Validation Loss: 0.05940205231308937
Epoch 191, Training Loss: 0.050941385328769684, Validation Loss: 0.05880889669060707
Epoch 192, Training Loss: 0.050449565052986145, Validation Loss: 0.058203890919685364
Epoch 193, Training Loss: 0.04995820298790932, Validation Loss: 0.05763287842273712
Epoch 194, Training Loss: 0.04945104569196701, Validation Loss: 0.05707674100995064
Epoch 195, Training Loss: 0.04894004762172699, Validation Loss: 0.05651411786675453
Epoch 196, Training Loss: 0.04842254891991615, Validation Loss: 0.05594830587506294
Epoch 197, Training Loss: 0.04789276793599129, Validation Loss: 0.055358823388814926
Epoch 198, Training Loss: 0.04735661670565605, Validation Loss: 0.05478321388363838
Epoch 199, Training Loss: 0.04681272804737091, Validation Loss: 0.05421805754303932
Epoch 200, Training Loss: 0.04626444727182388, Validation Loss: 0.05363504961133003
Epoch 201, Training Loss: 0.045703042298555374, Validation Loss: 0.05301939696073532
Epoch 202, Training Loss: 0.04513837769627571, Validation Loss: 0.05237068235874176
Epoch 203, Training Loss: 0.044560253620147705, Validation Loss: 0.05171683058142662
Epoch 204, Training Loss: 0.04397831857204437, Validation Loss: 0.05107327923178673
Epoch 205, Training Loss: 0.043386053293943405, Validation Loss: 0.05042724683880806
Epoch 206, Training Loss: 0.04280617833137512, Validation Loss: 0.04973447322845459
Epoch 207, Training Loss: 0.04220849275588989, Validation Loss: 0.049021054059267044
Epoch 208, Training Loss: 0.04160921648144722, Validation Loss: 0.048328548669815063
Epoch 209, Training Loss: 0.041002944111824036, Validation Loss: 0.047687795013189316
Epoch 210, Training Loss: 0.04039909318089485, Validation Loss: 0.04706726223230362
Epoch 211, Training Loss: 0.03980761393904686, Validation Loss: 0.04643367975950241
Epoch 212, Training Loss: 0.039205946028232574, Validation Loss: 0.045805007219314575
Epoch 213, Training Loss: 0.038593839854002, Validation Loss: 0.04512591287493706
Epoch 214, Training Loss: 0.03797934576869011, Validation Loss: 0.044426094740629196
Epoch 215, Training Loss: 0.037365447729825974, Validation Loss: 0.04371574521064758
Epoch 216, Training Loss: 0.03675965219736099, Validation Loss: 0.043015867471694946
Epoch 217, Training Loss: 0.03614233061671257, Validation Loss: 0.04239064082503319
Epoch 218, Training Loss: 0.0355367586016655, Validation Loss: 0.041799671947956085
Epoch 219, Training Loss: 0.034942302852869034, Validation Loss: 0.04118741676211357
Epoch 220, Training Loss: 0.03435271978378296, Validation Loss: 0.040511973202228546
Epoch 221, Training Loss: 0.033753395080566406, Validation Loss: 0.03983338549733162
Epoch 222, Training Loss: 0.03316221386194229, Validation Loss: 0.039177246391773224
Epoch 223, Training Loss: 0.03257933631539345, Validation Loss: 0.03855288773775101
Epoch 224, Training Loss: 0.032007526606321335, Validation Loss: 0.03797566145658493
Epoch 225, Training Loss: 0.03144678846001625, Validation Loss: 0.03743640333414078
Epoch 226, Training Loss: 0.030896274372935295, Validation Loss: 0.03690485283732414
Epoch 227, Training Loss: 0.030360713601112366, Validation Loss: 0.03640878200531006
Epoch 228, Training Loss: 0.029849298298358917, Validation Loss: 0.03593074902892113
Epoch 229, Training Loss: 0.029350483790040016, Validation Loss: 0.03547880798578262
Epoch 230, Training Loss: 0.02886926755309105, Validation Loss: 0.03503146395087242
Epoch 231, Training Loss: 0.028402412310242653, Validation Loss: 0.034543998539447784
Epoch 232, Training Loss: 0.02794073335826397, Validation Loss: 0.034032221883535385
Epoch 233, Training Loss: 0.027490315958857536, Validation Loss: 0.033530011773109436
Epoch 234, Training Loss: 0.02706442028284073, Validation Loss: 0.03305923193693161
Epoch 235, Training Loss: 0.026668686419725418, Validation Loss: 0.03258998319506645
Epoch 236, Training Loss: 0.026285000145435333, Validation Loss: 0.03213503211736679
Epoch 237, Training Loss: 0.02591553144156933, Validation Loss: 0.03171694278717041
Epoch 238, Training Loss: 0.025563087314367294, Validation Loss: 0.03133731335401535
Epoch 239, Training Loss: 0.02521171048283577, Validation Loss: 0.03096942789852619
Epoch 240, Training Loss: 0.024866662919521332, Validation Loss: 0.03060196340084076
Epoch 241, Training Loss: 0.024532413110136986, Validation Loss: 0.030230063945055008
Epoch 242, Training Loss: 0.024200860410928726, Validation Loss: 0.029875224456191063
Epoch 243, Training Loss: 0.023879138752818108, Validation Loss: 0.029542993754148483
Epoch 244, Training Loss: 0.02356806769967079, Validation Loss: 0.02924359403550625
Epoch 245, Training Loss: 0.023266751319169998, Validation Loss: 0.02895900420844555
Epoch 246, Training Loss: 0.022971486672759056, Validation Loss: 0.028667336329817772
Epoch 247, Training Loss: 0.02268064394593239, Validation Loss: 0.028360193595290184
Epoch 248, Training Loss: 0.02239607460796833, Validation Loss: 0.02806648053228855
Epoch 249, Training Loss: 0.02212640270590782, Validation Loss: 0.027762891724705696
Epoch 250, Training Loss: 0.021854344755411148, Validation Loss: 0.027460342273116112
Epoch 251, Training Loss: 0.021583441644906998, Validation Loss: 0.027158770710229874
Epoch 252, Training Loss: 0.021315747871994972, Validation Loss: 0.02684902586042881
Epoch 253, Training Loss: 0.021049128845334053, Validation Loss: 0.02655065432190895
Epoch 254, Training Loss: 0.020786350592970848, Validation Loss: 0.026261094957590103
Epoch 255, Training Loss: 0.020531674847006798, Validation Loss: 0.02596510946750641
Epoch 256, Training Loss: 0.020275739952921867, Validation Loss: 0.025655733421444893
Epoch 257, Training Loss: 0.020015297457575798, Validation Loss: 0.025351280346512794
Epoch 258, Training Loss: 0.019755221903324127, Validation Loss: 0.025060052052140236
Epoch 259, Training Loss: 0.019495034590363503, Validation Loss: 0.024782484397292137
Epoch 260, Training Loss: 0.019235877320170403, Validation Loss: 0.02450764924287796
Epoch 261, Training Loss: 0.01897428371012211, Validation Loss: 0.024247532710433006
Epoch 262, Training Loss: 0.018719421699643135, Validation Loss: 0.023998908698558807
Epoch 263, Training Loss: 0.018465623259544373, Validation Loss: 0.023763541132211685
Epoch 264, Training Loss: 0.018215222284197807, Validation Loss: 0.0235440693795681
Epoch 265, Training Loss: 0.017962411046028137, Validation Loss: 0.023357117548584938
Epoch 266, Training Loss: 0.017715200781822205, Validation Loss: 0.023155132308602333
Epoch 267, Training Loss: 0.017466256394982338, Validation Loss: 0.022934818640351295
Epoch 268, Training Loss: 0.017217179760336876, Validation Loss: 0.02273714169859886
Epoch 269, Training Loss: 0.016969680786132812, Validation Loss: 0.022554636001586914
Epoch 270, Training Loss: 0.01672203652560711, Validation Loss: 0.022374195978045464
Epoch 271, Training Loss: 0.01647748053073883, Validation Loss: 0.022190315648913383
Epoch 272, Training Loss: 0.016238057985901833, Validation Loss: 0.021986380219459534
Epoch 273, Training Loss: 0.015996316447854042, Validation Loss: 0.021777953952550888
Epoch 274, Training Loss: 0.015755224972963333, Validation Loss: 0.021579232066869736
Epoch 275, Training Loss: 0.01551070623099804, Validation Loss: 0.021385423839092255
Epoch 276, Training Loss: 0.015268543735146523, Validation Loss: 0.021199561655521393
Epoch 277, Training Loss: 0.015030790120363235, Validation Loss: 0.021006932482123375
Epoch 278, Training Loss: 0.014799878932535648, Validation Loss: 0.02080491930246353
Epoch 279, Training Loss: 0.014567664824426174, Validation Loss: 0.020602185279130936
Epoch 280, Training Loss: 0.014337751083076, Validation Loss: 0.0203942209482193
Epoch 281, Training Loss: 0.014105258509516716, Validation Loss: 0.020187297835946083
Epoch 282, Training Loss: 0.013871230185031891, Validation Loss: 0.0199968870729208
Epoch 283, Training Loss: 0.01364397443830967, Validation Loss: 0.0198074858635664
Epoch 284, Training Loss: 0.013416307047009468, Validation Loss: 0.019626127555966377
Epoch 285, Training Loss: 0.013191629201173782, Validation Loss: 0.01945381425321102
Epoch 286, Training Loss: 0.01297658309340477, Validation Loss: 0.019254561513662338
Epoch 287, Training Loss: 0.012759906239807606, Validation Loss: 0.01904837228357792
Epoch 288, Training Loss: 0.012551821768283844, Validation Loss: 0.01884187012910843
Epoch 289, Training Loss: 0.012345664203166962, Validation Loss: 0.018641768023371696
Epoch 290, Training Loss: 0.012138807214796543, Validation Loss: 0.01845872774720192
Epoch 291, Training Loss: 0.011932714842259884, Validation Loss: 0.018298491835594177
Epoch 292, Training Loss: 0.011729085817933083, Validation Loss: 0.01812760904431343
Epoch 293, Training Loss: 0.011527704074978828, Validation Loss: 0.017947282642126083
Epoch 294, Training Loss: 0.011330069974064827, Validation Loss: 0.017769141122698784
Epoch 295, Training Loss: 0.011134611442685127, Validation Loss: 0.017588350921869278
Epoch 296, Training Loss: 0.010943297296762466, Validation Loss: 0.017425160855054855
Epoch 297, Training Loss: 0.010762332007288933, Validation Loss: 0.017250899225473404
Epoch 298, Training Loss: 0.010595454834401608, Validation Loss: 0.01706777513027191
Epoch 299, Training Loss: 0.010422158055007458, Validation Loss: 0.016877438873052597
Epoch 300, Training Loss: 0.010245400480926037, Validation Loss: 0.016682010143995285
Epoch 301, Training Loss: 0.010072226636111736, Validation Loss: 0.01648731902241707
Epoch 302, Training Loss: 0.009906443767249584, Validation Loss: 0.01628078892827034
Epoch 303, Training Loss: 0.009741832502186298, Validation Loss: 0.016069980338215828
Epoch 304, Training Loss: 0.009576908312737942, Validation Loss: 0.015871668234467506
Epoch 305, Training Loss: 0.00941716879606247, Validation Loss: 0.015671489760279655
Epoch 306, Training Loss: 0.009260156191885471, Validation Loss: 0.015492857433855534
Epoch 307, Training Loss: 0.009104836732149124, Validation Loss: 0.015319572761654854
Epoch 308, Training Loss: 0.00895154383033514, Validation Loss: 0.015155368484556675
Epoch 309, Training Loss: 0.008800397627055645, Validation Loss: 0.014988762326538563
Epoch 310, Training Loss: 0.008648166432976723, Validation Loss: 0.014793180860579014
Epoch 311, Training Loss: 0.008493296802043915, Validation Loss: 0.014575046487152576
Epoch 312, Training Loss: 0.008340477012097836, Validation Loss: 0.014363426715135574
Epoch 313, Training Loss: 0.008194309659302235, Validation Loss: 0.014155182987451553
Epoch 314, Training Loss: 0.008050059899687767, Validation Loss: 0.013959307223558426
Epoch 315, Training Loss: 0.00791617389768362, Validation Loss: 0.013783789239823818
Epoch 316, Training Loss: 0.007791661657392979, Validation Loss: 0.013594109565019608
Epoch 317, Training Loss: 0.007664999458938837, Validation Loss: 0.01340959221124649
Epoch 318, Training Loss: 0.007542293053120375, Validation Loss: 0.013240893371403217
Epoch 319, Training Loss: 0.007422525901347399, Validation Loss: 0.013056808151304722
Epoch 320, Training Loss: 0.0073029170744121075, Validation Loss: 0.012858363799750805
Epoch 321, Training Loss: 0.007186416536569595, Validation Loss: 0.012658016756176949
Epoch 322, Training Loss: 0.007072447799146175, Validation Loss: 0.012463380582630634
Epoch 323, Training Loss: 0.0069588483311235905, Validation Loss: 0.012250028550624847
Epoch 324, Training Loss: 0.00684543838724494, Validation Loss: 0.012039676308631897
Epoch 325, Training Loss: 0.006738884374499321, Validation Loss: 0.011838889680802822
Epoch 326, Training Loss: 0.006629738956689835, Validation Loss: 0.01165764406323433
Epoch 327, Training Loss: 0.006526430137455463, Validation Loss: 0.011483591981232166
Epoch 328, Training Loss: 0.006423331331461668, Validation Loss: 0.011328850872814655
Epoch 329, Training Loss: 0.00632807333022356, Validation Loss: 0.011160517111420631
Epoch 330, Training Loss: 0.0062275296077132225, Validation Loss: 0.010998173616826534
Epoch 331, Training Loss: 0.006130818277597427, Validation Loss: 0.010843271389603615
Epoch 332, Training Loss: 0.0060326033271849155, Validation Loss: 0.010693156160414219
Epoch 333, Training Loss: 0.0059351846575737, Validation Loss: 0.010558443143963814
Epoch 334, Training Loss: 0.005842851009219885, Validation Loss: 0.010396472178399563
Epoch 335, Training Loss: 0.005753642413765192, Validation Loss: 0.010209663771092892
Epoch 336, Training Loss: 0.0056614018976688385, Validation Loss: 0.010047480463981628
Epoch 337, Training Loss: 0.0055747078731656075, Validation Loss: 0.009882542304694653
Epoch 338, Training Loss: 0.005483868066221476, Validation Loss: 0.009689303115010262
Epoch 339, Training Loss: 0.0053947181440889835, Validation Loss: 0.009498809464275837
Epoch 340, Training Loss: 0.005310897249728441, Validation Loss: 0.009320376440882683
Epoch 341, Training Loss: 0.005226834211498499, Validation Loss: 0.009163446724414825
Epoch 342, Training Loss: 0.005139445420354605, Validation Loss: 0.009014689363539219
Epoch 343, Training Loss: 0.005053963046520948, Validation Loss: 0.008851882070302963
Epoch 344, Training Loss: 0.004971311893314123, Validation Loss: 0.008701465092599392
Epoch 345, Training Loss: 0.004891127347946167, Validation Loss: 0.0085298465564847
Epoch 346, Training Loss: 0.004807366523891687, Validation Loss: 0.00837706308811903
Epoch 347, Training Loss: 0.004726759623736143, Validation Loss: 0.008217105641961098
Epoch 348, Training Loss: 0.004645501263439655, Validation Loss: 0.008059491403400898
Epoch 349, Training Loss: 0.004563746973872185, Validation Loss: 0.00789602566510439
Epoch 350, Training Loss: 0.004480861127376556, Validation Loss: 0.007732626516371965
Epoch 351, Training Loss: 0.0044026486575603485, Validation Loss: 0.007555812131613493
Epoch 352, Training Loss: 0.004325914662331343, Validation Loss: 0.00739386398345232
Epoch 353, Training Loss: 0.004249433521181345, Validation Loss: 0.00723455473780632
Epoch 354, Training Loss: 0.004171611741185188, Validation Loss: 0.00707960594445467
Epoch 355, Training Loss: 0.004094795323908329, Validation Loss: 0.0069366758689284325
Epoch 356, Training Loss: 0.00401987973600626, Validation Loss: 0.00680749723687768
Epoch 357, Training Loss: 0.003940659575164318, Validation Loss: 0.006690183654427528
Epoch 358, Training Loss: 0.003863468999043107, Validation Loss: 0.0065537141636013985
Epoch 359, Training Loss: 0.003788973903283477, Validation Loss: 0.0064013986848294735
Epoch 360, Training Loss: 0.0037144033703953028, Validation Loss: 0.006238825153559446
Epoch 361, Training Loss: 0.0036411085166037083, Validation Loss: 0.0060872724279761314
Epoch 362, Training Loss: 0.0035696097183972597, Validation Loss: 0.005930131301283836
Epoch 363, Training Loss: 0.003495088079944253, Validation Loss: 0.005794030148535967
Epoch 364, Training Loss: 0.0034224558621644974, Validation Loss: 0.005665276665240526
Epoch 365, Training Loss: 0.0033500671852380037, Validation Loss: 0.0055304402485489845
Epoch 366, Training Loss: 0.003281442681327462, Validation Loss: 0.005384367424994707
Epoch 367, Training Loss: 0.0032131155021488667, Validation Loss: 0.005230458453297615
Epoch 368, Training Loss: 0.0031414725817739964, Validation Loss: 0.0050878943875432014
Epoch 369, Training Loss: 0.0030711302533745766, Validation Loss: 0.004958810284733772
Epoch 370, Training Loss: 0.0030044533777981997, Validation Loss: 0.004827931057661772
Epoch 371, Training Loss: 0.0029341336339712143, Validation Loss: 0.004707826767116785
Epoch 372, Training Loss: 0.002865137532353401, Validation Loss: 0.004612249322235584
Epoch 373, Training Loss: 0.002800510497763753, Validation Loss: 0.004487840458750725
Epoch 374, Training Loss: 0.0027304780669510365, Validation Loss: 0.004347905516624451
Epoch 375, Training Loss: 0.0026623946614563465, Validation Loss: 0.004219872411340475
Epoch 376, Training Loss: 0.0025973336305469275, Validation Loss: 0.004097501747310162
Epoch 377, Training Loss: 0.0025300276465713978, Validation Loss: 0.003985010087490082
Epoch 378, Training Loss: 0.0024662006180733442, Validation Loss: 0.003863050602376461
Epoch 379, Training Loss: 0.002401634817942977, Validation Loss: 0.003737696446478367
Epoch 380, Training Loss: 0.002337987069040537, Validation Loss: 0.003609281498938799
Epoch 381, Training Loss: 0.0022757842671126127, Validation Loss: 0.0034948554821312428
Epoch 382, Training Loss: 0.0022176802158355713, Validation Loss: 0.003390410216525197
Epoch 383, Training Loss: 0.0021554268896579742, Validation Loss: 0.003295516362413764
Epoch 384, Training Loss: 0.002097552642226219, Validation Loss: 0.0031912156846374273
Epoch 385, Training Loss: 0.0020368166733533144, Validation Loss: 0.003085205564275384
Epoch 386, Training Loss: 0.0019794325344264507, Validation Loss: 0.0029718957375735044
Epoch 387, Training Loss: 0.0019201459363102913, Validation Loss: 0.002875856589525938
Epoch 388, Training Loss: 0.0018631733255460858, Validation Loss: 0.0027780395466834307
Epoch 389, Training Loss: 0.001805629814043641, Validation Loss: 0.0026662605814635754
Epoch 390, Training Loss: 0.0017499537207186222, Validation Loss: 0.002566148526966572
Epoch 391, Training Loss: 0.001695479964837432, Validation Loss: 0.002463599434122443
Epoch 392, Training Loss: 0.0016365094343200326, Validation Loss: 0.0023736627772450447
Epoch 393, Training Loss: 0.001583561417646706, Validation Loss: 0.002285710768774152
Epoch 394, Training Loss: 0.001532414578832686, Validation Loss: 0.0022069623228162527
Epoch 395, Training Loss: 0.0014789325650781393, Validation Loss: 0.0021432889625430107
Epoch 396, Training Loss: 0.0014302748022601008, Validation Loss: 0.002058172831311822
Epoch 397, Training Loss: 0.0013786773197352886, Validation Loss: 0.0019673574715852737
Epoch 398, Training Loss: 0.001331656938418746, Validation Loss: 0.0018860928248614073
Epoch 399, Training Loss: 0.0012827315367758274, Validation Loss: 0.0018260794458910823
Epoch 400, Training Loss: 0.001237668446265161, Validation Loss: 0.0017476548673585057
Epoch 401, Training Loss: 0.0011891239555552602, Validation Loss: 0.0016678078100085258
Epoch 402, Training Loss: 0.0011419325601309538, Validation Loss: 0.0016022820491343737
Epoch 403, Training Loss: 0.0010991247836500406, Validation Loss: 0.001529757515527308
Epoch 404, Training Loss: 0.0010538632050156593, Validation Loss: 0.0014713547425344586
Epoch 405, Training Loss: 0.0010127105051651597, Validation Loss: 0.0013991103041917086
Epoch 406, Training Loss: 0.0009707443532533944, Validation Loss: 0.001319360570050776
Epoch 407, Training Loss: 0.0009295039344578981, Validation Loss: 0.0012510897358879447
Epoch 408, Training Loss: 0.0008905573049560189, Validation Loss: 0.0011911829933524132
Epoch 409, Training Loss: 0.0008515654481016099, Validation Loss: 0.0011406814446672797
Epoch 410, Training Loss: 0.0008153386879712343, Validation Loss: 0.0010932080913335085
Epoch 411, Training Loss: 0.0007797535508871078, Validation Loss: 0.001042626448906958
Epoch 412, Training Loss: 0.000744027376640588, Validation Loss: 0.0009878703858703375
Epoch 413, Training Loss: 0.0007081461953930557, Validation Loss: 0.0009340436663478613
Epoch 414, Training Loss: 0.0006745513528585434, Validation Loss: 0.0008830417064018548
Epoch 415, Training Loss: 0.0006431230576708913, Validation Loss: 0.000838777341414243
Epoch 416, Training Loss: 0.0006119710742495954, Validation Loss: 0.0007972032180987298
Epoch 417, Training Loss: 0.0005810832954011858, Validation Loss: 0.0007586592109873891
Epoch 418, Training Loss: 0.0005517378449440002, Validation Loss: 0.000719635107088834
Epoch 419, Training Loss: 0.0005242214538156986, Validation Loss: 0.0006754495552740991
Epoch 420, Training Loss: 0.0004955862532369792, Validation Loss: 0.0006317389779724181
Epoch 421, Training Loss: 0.00046906908391974866, Validation Loss: 0.0005891049513593316
Epoch 422, Training Loss: 0.00044465274550020695, Validation Loss: 0.0005538184195756912
Epoch 423, Training Loss: 0.00042026874143630266, Validation Loss: 0.0005224079941399395
Epoch 424, Training Loss: 0.0003975916188210249, Validation Loss: 0.0004925119574181736
Epoch 425, Training Loss: 0.00037557180621661246, Validation Loss: 0.00046415365068241954
Epoch 426, Training Loss: 0.00035470977309159935, Validation Loss: 0.00043506527435965836
Epoch 427, Training Loss: 0.00033457542303949594, Validation Loss: 0.00040930911200121045
Epoch 428, Training Loss: 0.0003149918338749558, Validation Loss: 0.00038440647767856717
Epoch 429, Training Loss: 0.00029652888770215213, Validation Loss: 0.0003567236999515444
Epoch 430, Training Loss: 0.0002794226456899196, Validation Loss: 0.0003321251133456826
Epoch 431, Training Loss: 0.000263055699178949, Validation Loss: 0.00030927732586860657
Epoch 432, Training Loss: 0.0002472018823027611, Validation Loss: 0.0002890910836867988
Epoch 433, Training Loss: 0.00023147667525336146, Validation Loss: 0.00027283094823360443
Epoch 434, Training Loss: 0.00021749672305304557, Validation Loss: 0.00025592377642169595
Epoch 435, Training Loss: 0.0002042291744146496, Validation Loss: 0.0002399067161604762
Epoch 436, Training Loss: 0.00019204258569516242, Validation Loss: 0.00022266025189310312
Epoch 437, Training Loss: 0.00017968681640923023, Validation Loss: 0.0002066001616185531
Epoch 438, Training Loss: 0.00016821169992908835, Validation Loss: 0.0001909489801619202
Epoch 439, Training Loss: 0.00015730819723103195, Validation Loss: 0.00017668557120487094
Epoch 440, Training Loss: 0.00014669474330730736, Validation Loss: 0.0001652202772675082
Epoch 441, Training Loss: 0.00013689276238437742, Validation Loss: 0.00015510407683905214
Epoch 442, Training Loss: 0.0001279615389648825, Validation Loss: 0.00014517060481011868
Epoch 443, Training Loss: 0.00011939992691623047, Validation Loss: 0.00013536951155401766
Epoch 444, Training Loss: 0.00011139073467347771, Validation Loss: 0.00012565604993142188
Epoch 445, Training Loss: 0.00010374469275120646, Validation Loss: 0.000116348935989663
Epoch 446, Training Loss: 9.623500955058262e-05, Validation Loss: 0.00010786685743369162
Epoch 447, Training Loss: 8.953063661465421e-05, Validation Loss: 9.993530693463981e-05
Epoch 448, Training Loss: 8.335586608154699e-05, Validation Loss: 9.247489651897922e-05
Epoch 449, Training Loss: 7.743445166852325e-05, Validation Loss: 8.571902435505763e-05
Epoch 450, Training Loss: 7.191848271759227e-05, Validation Loss: 7.902965444372967e-05
Epoch 451, Training Loss: 6.689164001727477e-05, Validation Loss: 7.286706386366859e-05
Epoch 452, Training Loss: 6.207396654644981e-05, Validation Loss: 6.704672705382109e-05
Epoch 453, Training Loss: 5.749943738919683e-05, Validation Loss: 6.183915684232488e-05
Epoch 454, Training Loss: 5.309694824973121e-05, Validation Loss: 5.7499652029946446e-05
Epoch 455, Training Loss: 4.9268364818999544e-05, Validation Loss: 5.328486076905392e-05
Epoch 456, Training Loss: 4.56590460089501e-05, Validation Loss: 4.881082350038923e-05
Epoch 457, Training Loss: 4.206786979921162e-05, Validation Loss: 4.480460120248608e-05
Epoch 458, Training Loss: 3.8884358218638226e-05, Validation Loss: 4.118658762308769e-05
Epoch 459, Training Loss: 3.597878458094783e-05, Validation Loss: 3.773768185055815e-05
Epoch 460, Training Loss: 3.313230990897864e-05, Validation Loss: 3.453868703218177e-05
Epoch 461, Training Loss: 3.0555234843632206e-05, Validation Loss: 3.151199416606687e-05
Epoch 462, Training Loss: 2.8199930966366082e-05, Validation Loss: 2.872466211556457e-05
Epoch 463, Training Loss: 2.600078187242616e-05, Validation Loss: 2.6185423848801292e-05
Epoch 464, Training Loss: 2.39093933487311e-05, Validation Loss: 2.4014478185563348e-05
Epoch 465, Training Loss: 2.200692870246712e-05, Validation Loss: 2.2093878214946017e-05
Epoch 466, Training Loss: 2.023348497459665e-05, Validation Loss: 2.0449298972380348e-05
Epoch 467, Training Loss: 1.8600623661768623e-05, Validation Loss: 1.8934473700937815e-05
Epoch 468, Training Loss: 1.7155762179754674e-05, Validation Loss: 1.74650576809654e-05
Epoch 469, Training Loss: 1.5799081666045822e-05, Validation Loss: 1.5985478967195377e-05
Epoch 470, Training Loss: 1.4498172276944388e-05, Validation Loss: 1.4608762285206467e-05
Epoch 471, Training Loss: 1.328086818830343e-05, Validation Loss: 1.3419717106444295e-05
Epoch 472, Training Loss: 1.2163518476882018e-05, Validation Loss: 1.23092495414312e-05
Epoch 473, Training Loss: 1.1184290997334756e-05, Validation Loss: 1.1190804798388854e-05
Epoch 474, Training Loss: 1.0243910764984321e-05, Validation Loss: 1.0171612302656285e-05
Epoch 475, Training Loss: 9.401805073139258e-06, Validation Loss: 9.291776223108172e-06
Epoch 476, Training Loss: 8.614279977336992e-06, Validation Loss: 8.552860890631564e-06
Epoch 477, Training Loss: 7.883009857323486e-06, Validation Loss: 7.891649147495627e-06
Epoch 478, Training Loss: 7.198764251370449e-06, Validation Loss: 7.267089586093789e-06
Epoch 479, Training Loss: 6.576461146323709e-06, Validation Loss: 6.647635927947704e-06
Epoch 480, Training Loss: 5.998558208375471e-06, Validation Loss: 6.058645340090152e-06
Epoch 481, Training Loss: 5.464370133267948e-06, Validation Loss: 5.517990757653024e-06
Epoch 482, Training Loss: 4.983071903552627e-06, Validation Loss: 5.0359567467239685e-06
Epoch 483, Training Loss: 4.5521783249569125e-06, Validation Loss: 4.603812158165965e-06
Epoch 484, Training Loss: 4.150128006585874e-06, Validation Loss: 4.205352979624877e-06
Epoch 485, Training Loss: 3.787107061725692e-06, Validation Loss: 3.82365396944806e-06
Epoch 486, Training Loss: 3.4442766718711937e-06, Validation Loss: 3.4639917885215255e-06
Epoch 487, Training Loss: 3.1274216780730058e-06, Validation Loss: 3.1504712296737125e-06
Epoch 488, Training Loss: 2.846146799129201e-06, Validation Loss: 2.880561169149587e-06
Epoch 489, Training Loss: 2.599691470095422e-06, Validation Loss: 2.6258619527652627e-06
Epoch 490, Training Loss: 2.361478209422785e-06, Validation Loss: 2.3853510811022716e-06
Epoch 491, Training Loss: 2.137460569429095e-06, Validation Loss: 2.1729824766225647e-06
Epoch 492, Training Loss: 1.941205027833348e-06, Validation Loss: 1.9646067812573165e-06
Epoch 493, Training Loss: 1.762434067131835e-06, Validation Loss: 1.7698818055578158e-06
Epoch 494, Training Loss: 1.5984629726517596e-06, Validation Loss: 1.5988940731404e-06
Epoch 495, Training Loss: 1.4547742921422468e-06, Validation Loss: 1.4484828625427326e-06
Epoch 496, Training Loss: 1.3180145970181911e-06, Validation Loss: 1.3147645177014056e-06
Epoch 497, Training Loss: 1.1927103287234786e-06, Validation Loss: 1.1967583759542322e-06
Epoch 498, Training Loss: 1.0798790981425554e-06, Validation Loss: 1.0859475878532976e-06
Epoch 499, Training Loss: 9.780061418496189e-07, Validation Loss: 9.821591220315895e-07
Epoch 500, Training Loss: 8.847817412060976e-07, Validation Loss: 8.863603397912811e-07
