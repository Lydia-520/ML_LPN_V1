Epoch 1, Training Loss: 0.25137442350387573, Validation Loss: 0.2990700900554657
Epoch 2, Training Loss: 0.2505563795566559, Validation Loss: 0.2981407642364502
Epoch 3, Training Loss: 0.24974779784679413, Validation Loss: 0.29721441864967346
Epoch 4, Training Loss: 0.24894382059574127, Validation Loss: 0.296293705701828
Epoch 5, Training Loss: 0.24814572930335999, Validation Loss: 0.2953733503818512
Epoch 6, Training Loss: 0.24734897911548615, Validation Loss: 0.2944491505622864
Epoch 7, Training Loss: 0.24655170738697052, Validation Loss: 0.29352229833602905
Epoch 8, Training Loss: 0.2457498162984848, Validation Loss: 0.29260119795799255
Epoch 9, Training Loss: 0.24495460093021393, Validation Loss: 0.2916927635669708
Epoch 10, Training Loss: 0.2441648542881012, Validation Loss: 0.29078027606010437
Epoch 11, Training Loss: 0.24336938560009003, Validation Loss: 0.2898680865764618
Epoch 12, Training Loss: 0.24257051944732666, Validation Loss: 0.2889489233493805
Epoch 13, Training Loss: 0.24176932871341705, Validation Loss: 0.28802290558815
Epoch 14, Training Loss: 0.24096769094467163, Validation Loss: 0.2870923578739166
Epoch 15, Training Loss: 0.24016179144382477, Validation Loss: 0.2861417233943939
Epoch 16, Training Loss: 0.2393403947353363, Validation Loss: 0.28516924381256104
Epoch 17, Training Loss: 0.2385033220052719, Validation Loss: 0.2841707170009613
Epoch 18, Training Loss: 0.23764604330062866, Validation Loss: 0.28314292430877686
Epoch 19, Training Loss: 0.23676779866218567, Validation Loss: 0.28208813071250916
Epoch 20, Training Loss: 0.23587140440940857, Validation Loss: 0.281009703874588
Epoch 21, Training Loss: 0.23495246469974518, Validation Loss: 0.279933363199234
Epoch 22, Training Loss: 0.23402749001979828, Validation Loss: 0.2788466215133667
Epoch 23, Training Loss: 0.23308853805065155, Validation Loss: 0.2777040898799896
Epoch 24, Training Loss: 0.23210838437080383, Validation Loss: 0.27651119232177734
Epoch 25, Training Loss: 0.23108401894569397, Validation Loss: 0.2752595543861389
Epoch 26, Training Loss: 0.23000827431678772, Validation Loss: 0.2739388048648834
Epoch 27, Training Loss: 0.22888202965259552, Validation Loss: 0.2725347876548767
Epoch 28, Training Loss: 0.22769136726856232, Validation Loss: 0.2710464894771576
Epoch 29, Training Loss: 0.22643396258354187, Validation Loss: 0.2694889307022095
Epoch 30, Training Loss: 0.225099578499794, Validation Loss: 0.26783183217048645
Epoch 31, Training Loss: 0.2236880660057068, Validation Loss: 0.2660522162914276
Epoch 32, Training Loss: 0.22218501567840576, Validation Loss: 0.26414358615875244
Epoch 33, Training Loss: 0.220585897564888, Validation Loss: 0.26210451126098633
Epoch 34, Training Loss: 0.21887603402137756, Validation Loss: 0.25992250442504883
Epoch 35, Training Loss: 0.2170502245426178, Validation Loss: 0.2575831413269043
Epoch 36, Training Loss: 0.21508444845676422, Validation Loss: 0.2550588548183441
Epoch 37, Training Loss: 0.21296760439872742, Validation Loss: 0.2523311674594879
Epoch 38, Training Loss: 0.21069380640983582, Validation Loss: 0.2494017630815506
Epoch 39, Training Loss: 0.20825877785682678, Validation Loss: 0.2462824583053589
Epoch 40, Training Loss: 0.20566608011722565, Validation Loss: 0.2429470717906952
Epoch 41, Training Loss: 0.20290108025074005, Validation Loss: 0.23938176035881042
Epoch 42, Training Loss: 0.1999792754650116, Validation Loss: 0.23556652665138245
Epoch 43, Training Loss: 0.19686420261859894, Validation Loss: 0.23147906363010406
Epoch 44, Training Loss: 0.19353878498077393, Validation Loss: 0.22708794474601746
Epoch 45, Training Loss: 0.18999309837818146, Validation Loss: 0.22240902483463287
Epoch 46, Training Loss: 0.18623293936252594, Validation Loss: 0.21741360425949097
Epoch 47, Training Loss: 0.18224553763866425, Validation Loss: 0.21210689842700958
Epoch 48, Training Loss: 0.1780315637588501, Validation Loss: 0.20649954676628113
Epoch 49, Training Loss: 0.17360644042491913, Validation Loss: 0.20054708421230316
Epoch 50, Training Loss: 0.16896584630012512, Validation Loss: 0.19432473182678223
Epoch 51, Training Loss: 0.1641700267791748, Validation Loss: 0.18783937394618988
Epoch 52, Training Loss: 0.15924541652202606, Validation Loss: 0.18109531700611115
Epoch 53, Training Loss: 0.1542253941297531, Validation Loss: 0.1742211878299713
Epoch 54, Training Loss: 0.14921432733535767, Validation Loss: 0.16733995079994202
Epoch 55, Training Loss: 0.1443002074956894, Validation Loss: 0.16058409214019775
Epoch 56, Training Loss: 0.1395988017320633, Validation Loss: 0.15408961474895477
Epoch 57, Training Loss: 0.1352497637271881, Validation Loss: 0.1480354517698288
Epoch 58, Training Loss: 0.13139724731445312, Validation Loss: 0.1426200121641159
Epoch 59, Training Loss: 0.12818500399589539, Validation Loss: 0.1380397230386734
Epoch 60, Training Loss: 0.12573383748531342, Validation Loss: 0.13444027304649353
Epoch 61, Training Loss: 0.12409234791994095, Validation Loss: 0.13185562193393707
Epoch 62, Training Loss: 0.12319717556238174, Validation Loss: 0.1301615834236145
Epoch 63, Training Loss: 0.12285039573907852, Validation Loss: 0.12912781536579132
Epoch 64, Training Loss: 0.12275378406047821, Validation Loss: 0.1284550428390503
Epoch 65, Training Loss: 0.12261181324720383, Validation Loss: 0.12785042822360992
Epoch 66, Training Loss: 0.12214494496583939, Validation Loss: 0.12717066705226898
Epoch 67, Training Loss: 0.12123945355415344, Validation Loss: 0.12636516988277435
Epoch 68, Training Loss: 0.11992618441581726, Validation Loss: 0.1255110204219818
Epoch 69, Training Loss: 0.11835400760173798, Validation Loss: 0.1247086301445961
Epoch 70, Training Loss: 0.11668533831834793, Validation Loss: 0.12404928356409073
Epoch 71, Training Loss: 0.11507023870944977, Validation Loss: 0.12359371036291122
Epoch 72, Training Loss: 0.11362411826848984, Validation Loss: 0.12336058914661407
Epoch 73, Training Loss: 0.11240018159151077, Validation Loss: 0.1233755499124527
Epoch 74, Training Loss: 0.1114727109670639, Validation Loss: 0.12354948371648788
Epoch 75, Training Loss: 0.11075689643621445, Validation Loss: 0.12379374355077744
Epoch 76, Training Loss: 0.11020996421575546, Validation Loss: 0.12406008690595627
Epoch 77, Training Loss: 0.10980331152677536, Validation Loss: 0.1242360770702362
Epoch 78, Training Loss: 0.10947002470493317, Validation Loss: 0.12426380813121796
Epoch 79, Training Loss: 0.1091553121805191, Validation Loss: 0.12410406768321991
Epoch 80, Training Loss: 0.10882408916950226, Validation Loss: 0.12374766170978546
Epoch 81, Training Loss: 0.10845479369163513, Validation Loss: 0.12321638315916061
Epoch 82, Training Loss: 0.10803987085819244, Validation Loss: 0.12251617759466171
Epoch 83, Training Loss: 0.10758065432310104, Validation Loss: 0.12165229022502899
Epoch 84, Training Loss: 0.10708766430616379, Validation Loss: 0.12070171535015106
Epoch 85, Training Loss: 0.10658933967351913, Validation Loss: 0.11967983841896057
Epoch 86, Training Loss: 0.10608389973640442, Validation Loss: 0.11862243711948395
Epoch 87, Training Loss: 0.10559310019016266, Validation Loss: 0.11756735295057297
Epoch 88, Training Loss: 0.10513720661401749, Validation Loss: 0.11651716381311417
Epoch 89, Training Loss: 0.10472768545150757, Validation Loss: 0.11549516022205353
Epoch 90, Training Loss: 0.10436321049928665, Validation Loss: 0.11455783247947693
Epoch 91, Training Loss: 0.10402291268110275, Validation Loss: 0.11368858069181442
Epoch 92, Training Loss: 0.10369908064603806, Validation Loss: 0.11282973736524582
Epoch 93, Training Loss: 0.10335207730531693, Validation Loss: 0.11200305819511414
Epoch 94, Training Loss: 0.10298257321119308, Validation Loss: 0.11123273521661758
Epoch 95, Training Loss: 0.10258448868989944, Validation Loss: 0.11051855236291885
Epoch 96, Training Loss: 0.10217512398958206, Validation Loss: 0.10985011607408524
Epoch 97, Training Loss: 0.10173854231834412, Validation Loss: 0.10922469943761826
Epoch 98, Training Loss: 0.10127534717321396, Validation Loss: 0.10866155475378036
Epoch 99, Training Loss: 0.10080096870660782, Validation Loss: 0.10813376307487488
Epoch 100, Training Loss: 0.10033150017261505, Validation Loss: 0.10763877630233765
Epoch 101, Training Loss: 0.09986403584480286, Validation Loss: 0.10716050863265991
Epoch 102, Training Loss: 0.09940050542354584, Validation Loss: 0.10671602934598923
Epoch 103, Training Loss: 0.09894368052482605, Validation Loss: 0.10628029704093933
Epoch 104, Training Loss: 0.09848581254482269, Validation Loss: 0.10584070533514023
Epoch 105, Training Loss: 0.09801512956619263, Validation Loss: 0.1053592637181282
Epoch 106, Training Loss: 0.09753182530403137, Validation Loss: 0.1048194095492363
Epoch 107, Training Loss: 0.09703106433153152, Validation Loss: 0.10424095392227173
Epoch 108, Training Loss: 0.09650961309671402, Validation Loss: 0.1036493107676506
Epoch 109, Training Loss: 0.09596289694309235, Validation Loss: 0.10302479565143585
Epoch 110, Training Loss: 0.09540320932865143, Validation Loss: 0.10233911871910095
Epoch 111, Training Loss: 0.0948205515742302, Validation Loss: 0.10160896927118301
Epoch 112, Training Loss: 0.0942210927605629, Validation Loss: 0.100865438580513
Epoch 113, Training Loss: 0.0936015248298645, Validation Loss: 0.10009665042161942
Epoch 114, Training Loss: 0.09295929968357086, Validation Loss: 0.09927259385585785
Epoch 115, Training Loss: 0.0922776386141777, Validation Loss: 0.09848802536725998
Epoch 116, Training Loss: 0.09156850725412369, Validation Loss: 0.0977432057261467
Epoch 117, Training Loss: 0.09085927158594131, Validation Loss: 0.09698764234781265
Epoch 118, Training Loss: 0.0901370421051979, Validation Loss: 0.09622664004564285
Epoch 119, Training Loss: 0.08939242362976074, Validation Loss: 0.09550441801548004
Epoch 120, Training Loss: 0.0886208713054657, Validation Loss: 0.09479402005672455
Epoch 121, Training Loss: 0.0878199115395546, Validation Loss: 0.09409745037555695
Epoch 122, Training Loss: 0.08699879050254822, Validation Loss: 0.09334135055541992
Epoch 123, Training Loss: 0.08611833304166794, Validation Loss: 0.09258516132831573
Epoch 124, Training Loss: 0.08520916849374771, Validation Loss: 0.09178664535284042
Epoch 125, Training Loss: 0.08427876979112625, Validation Loss: 0.09095672518014908
Epoch 126, Training Loss: 0.08332017809152603, Validation Loss: 0.09011075645685196
Epoch 127, Training Loss: 0.08234605938196182, Validation Loss: 0.08926628530025482
Epoch 128, Training Loss: 0.08136716485023499, Validation Loss: 0.088422030210495
Epoch 129, Training Loss: 0.08037865161895752, Validation Loss: 0.08759377151727676
Epoch 130, Training Loss: 0.07939311116933823, Validation Loss: 0.08675501495599747
Epoch 131, Training Loss: 0.07840041071176529, Validation Loss: 0.08585653454065323
Epoch 132, Training Loss: 0.07737957686185837, Validation Loss: 0.0849413201212883
Epoch 133, Training Loss: 0.07637377083301544, Validation Loss: 0.08405232429504395
Epoch 134, Training Loss: 0.07538318634033203, Validation Loss: 0.08321090787649155
Epoch 135, Training Loss: 0.07441599667072296, Validation Loss: 0.08244539797306061
Epoch 136, Training Loss: 0.07350777834653854, Validation Loss: 0.08169269561767578
Epoch 137, Training Loss: 0.07258721441030502, Validation Loss: 0.08096029609441757
Epoch 138, Training Loss: 0.07169771194458008, Validation Loss: 0.0802515521645546
Epoch 139, Training Loss: 0.07084451615810394, Validation Loss: 0.0795648843050003
Epoch 140, Training Loss: 0.07002774626016617, Validation Loss: 0.07892008870840073
Epoch 141, Training Loss: 0.06926830112934113, Validation Loss: 0.07830019295215607
Epoch 142, Training Loss: 0.06855034083127975, Validation Loss: 0.07768972963094711
Epoch 143, Training Loss: 0.06787509471178055, Validation Loss: 0.0770968571305275
Epoch 144, Training Loss: 0.06723691523075104, Validation Loss: 0.0765128955245018
Epoch 145, Training Loss: 0.0666084960103035, Validation Loss: 0.07594750076532364
Epoch 146, Training Loss: 0.06600746512413025, Validation Loss: 0.07540000230073929
Epoch 147, Training Loss: 0.0654485896229744, Validation Loss: 0.07491602748632431
Epoch 148, Training Loss: 0.06494458019733429, Validation Loss: 0.07443258911371231
Epoch 149, Training Loss: 0.064464271068573, Validation Loss: 0.07394597679376602
Epoch 150, Training Loss: 0.0639977753162384, Validation Loss: 0.07344187051057816
Epoch 151, Training Loss: 0.06355401128530502, Validation Loss: 0.07291088998317719
Epoch 152, Training Loss: 0.0631309449672699, Validation Loss: 0.07236137241125107
Epoch 153, Training Loss: 0.06272458285093307, Validation Loss: 0.07180407643318176
Epoch 154, Training Loss: 0.062329791486263275, Validation Loss: 0.07122743874788284
Epoch 155, Training Loss: 0.061943791806697845, Validation Loss: 0.07067541033029556
Epoch 156, Training Loss: 0.06156785041093826, Validation Loss: 0.0701652318239212
Epoch 157, Training Loss: 0.0612034872174263, Validation Loss: 0.06968828290700912
Epoch 158, Training Loss: 0.06084694713354111, Validation Loss: 0.0692572221159935
Epoch 159, Training Loss: 0.060492195188999176, Validation Loss: 0.06885123252868652
Epoch 160, Training Loss: 0.06013505905866623, Validation Loss: 0.06846019625663757
Epoch 161, Training Loss: 0.059783753007650375, Validation Loss: 0.06808490306138992
Epoch 162, Training Loss: 0.059442393481731415, Validation Loss: 0.06771796941757202
Epoch 163, Training Loss: 0.059105034917593, Validation Loss: 0.06735925376415253
Epoch 164, Training Loss: 0.058787550777196884, Validation Loss: 0.0669870525598526
Epoch 165, Training Loss: 0.05846543610095978, Validation Loss: 0.06660393625497818
Epoch 166, Training Loss: 0.058141812682151794, Validation Loss: 0.06623557955026627
Epoch 167, Training Loss: 0.05782405287027359, Validation Loss: 0.06589474529027939
Epoch 168, Training Loss: 0.05750999227166176, Validation Loss: 0.06557301431894302
Epoch 169, Training Loss: 0.05719056725502014, Validation Loss: 0.0652494877576828
Epoch 170, Training Loss: 0.056859079748392105, Validation Loss: 0.06493432074785233
Epoch 171, Training Loss: 0.05652917921543121, Validation Loss: 0.06461754441261292
Epoch 172, Training Loss: 0.05620027333498001, Validation Loss: 0.0642661601305008
Epoch 173, Training Loss: 0.0558670312166214, Validation Loss: 0.06390305608510971
Epoch 174, Training Loss: 0.055529143661260605, Validation Loss: 0.0635494664311409
Epoch 175, Training Loss: 0.055187176913022995, Validation Loss: 0.06320375949144363
Epoch 176, Training Loss: 0.05483890697360039, Validation Loss: 0.06283647567033768
Epoch 177, Training Loss: 0.054483987390995026, Validation Loss: 0.06244828924536705
Epoch 178, Training Loss: 0.05411892011761665, Validation Loss: 0.0620594397187233
Epoch 179, Training Loss: 0.05373852327466011, Validation Loss: 0.061683401465415955
Epoch 180, Training Loss: 0.053348515182733536, Validation Loss: 0.061309441924095154
Epoch 181, Training Loss: 0.052953168749809265, Validation Loss: 0.060909293591976166
Epoch 182, Training Loss: 0.05254215747117996, Validation Loss: 0.06047968566417694
Epoch 183, Training Loss: 0.052112530916929245, Validation Loss: 0.060045987367630005
Epoch 184, Training Loss: 0.05167440325021744, Validation Loss: 0.05960799753665924
Epoch 185, Training Loss: 0.05122961476445198, Validation Loss: 0.0591510646045208
Epoch 186, Training Loss: 0.05077463015913963, Validation Loss: 0.058665499091148376
Epoch 187, Training Loss: 0.050318993628025055, Validation Loss: 0.058147672563791275
Epoch 188, Training Loss: 0.04985705018043518, Validation Loss: 0.05765293538570404
Epoch 189, Training Loss: 0.04938863217830658, Validation Loss: 0.05716686323285103
Epoch 190, Training Loss: 0.04890589416027069, Validation Loss: 0.05665120109915733
Epoch 191, Training Loss: 0.048417460173368454, Validation Loss: 0.05612702667713165
Epoch 192, Training Loss: 0.04792020469903946, Validation Loss: 0.055599287152290344
Epoch 193, Training Loss: 0.04740915447473526, Validation Loss: 0.05508347973227501
Epoch 194, Training Loss: 0.046883776783943176, Validation Loss: 0.05456618219614029
Epoch 195, Training Loss: 0.046348121017217636, Validation Loss: 0.05403190106153488
Epoch 196, Training Loss: 0.04580162838101387, Validation Loss: 0.0534808486700058
Epoch 197, Training Loss: 0.04525948688387871, Validation Loss: 0.05293763801455498
Epoch 198, Training Loss: 0.044706761837005615, Validation Loss: 0.0523921437561512
Epoch 199, Training Loss: 0.04413912072777748, Validation Loss: 0.051842618733644485
Epoch 200, Training Loss: 0.043567463755607605, Validation Loss: 0.05124466493725777
Epoch 201, Training Loss: 0.04297196865081787, Validation Loss: 0.050620708614587784
Epoch 202, Training Loss: 0.04236466437578201, Validation Loss: 0.0499965064227581
Epoch 203, Training Loss: 0.041749101132154465, Validation Loss: 0.049396589398384094
Epoch 204, Training Loss: 0.04113997519016266, Validation Loss: 0.0487540140748024
Epoch 205, Training Loss: 0.04051890969276428, Validation Loss: 0.04807734489440918
Epoch 206, Training Loss: 0.039896976202726364, Validation Loss: 0.04740159958600998
Epoch 207, Training Loss: 0.03926898166537285, Validation Loss: 0.0467250682413578
Epoch 208, Training Loss: 0.038635168224573135, Validation Loss: 0.04603420943021774
Epoch 209, Training Loss: 0.03799397498369217, Validation Loss: 0.045351967215538025
Epoch 210, Training Loss: 0.03735508397221565, Validation Loss: 0.04467284679412842
Epoch 211, Training Loss: 0.03671526536345482, Validation Loss: 0.04405360296368599
Epoch 212, Training Loss: 0.03609905764460564, Validation Loss: 0.04343909025192261
Epoch 213, Training Loss: 0.0354752242565155, Validation Loss: 0.04278453812003136
Epoch 214, Training Loss: 0.034841299057006836, Validation Loss: 0.042105454951524734
Epoch 215, Training Loss: 0.0342082604765892, Validation Loss: 0.04141485318541527
Epoch 216, Training Loss: 0.03356898948550224, Validation Loss: 0.040756821632385254
Epoch 217, Training Loss: 0.03294367343187332, Validation Loss: 0.040104106068611145
Epoch 218, Training Loss: 0.03232945129275322, Validation Loss: 0.039450135082006454
Epoch 219, Training Loss: 0.031728345900774, Validation Loss: 0.038771145045757294
Epoch 220, Training Loss: 0.031124679371714592, Validation Loss: 0.03810589015483856
Epoch 221, Training Loss: 0.03051714226603508, Validation Loss: 0.0374562069773674
Epoch 222, Training Loss: 0.02991730161011219, Validation Loss: 0.03681441396474838
Epoch 223, Training Loss: 0.029326455667614937, Validation Loss: 0.03618171811103821
Epoch 224, Training Loss: 0.02874358370900154, Validation Loss: 0.03555840253829956
Epoch 225, Training Loss: 0.028166253119707108, Validation Loss: 0.03496139869093895
Epoch 226, Training Loss: 0.02760138548910618, Validation Loss: 0.034393422305583954
Epoch 227, Training Loss: 0.027052588760852814, Validation Loss: 0.033841945230960846
Epoch 228, Training Loss: 0.02651173062622547, Validation Loss: 0.03330955654382706
Epoch 229, Training Loss: 0.025987451896071434, Validation Loss: 0.03275448828935623
Epoch 230, Training Loss: 0.025476420298218727, Validation Loss: 0.03218983858823776
Epoch 231, Training Loss: 0.02497135102748871, Validation Loss: 0.0316186286509037
Epoch 232, Training Loss: 0.024488596245646477, Validation Loss: 0.031028734520077705
Epoch 233, Training Loss: 0.024013647809624672, Validation Loss: 0.030471019446849823
Epoch 234, Training Loss: 0.023554688319563866, Validation Loss: 0.029941236600279808
Epoch 235, Training Loss: 0.02310674637556076, Validation Loss: 0.029454195871949196
Epoch 236, Training Loss: 0.02266683056950569, Validation Loss: 0.028997592628002167
Epoch 237, Training Loss: 0.022244194522500038, Validation Loss: 0.02853766456246376
Epoch 238, Training Loss: 0.021821584552526474, Validation Loss: 0.028085704892873764
Epoch 239, Training Loss: 0.021409936249256134, Validation Loss: 0.027659503743052483
Epoch 240, Training Loss: 0.02101411484181881, Validation Loss: 0.027259008958935738
Epoch 241, Training Loss: 0.020633423700928688, Validation Loss: 0.026874782517552376
Epoch 242, Training Loss: 0.02026228792965412, Validation Loss: 0.026513321325182915
Epoch 243, Training Loss: 0.019898507744073868, Validation Loss: 0.026130633428692818
Epoch 244, Training Loss: 0.019534951075911522, Validation Loss: 0.02571823075413704
Epoch 245, Training Loss: 0.01916978694498539, Validation Loss: 0.025301091372966766
Epoch 246, Training Loss: 0.01880517415702343, Validation Loss: 0.024913037195801735
Epoch 247, Training Loss: 0.018450813367962837, Validation Loss: 0.024546831846237183
Epoch 248, Training Loss: 0.01810034178197384, Validation Loss: 0.024183152243494987
Epoch 249, Training Loss: 0.017747873440384865, Validation Loss: 0.023807082325220108
Epoch 250, Training Loss: 0.017394082620739937, Validation Loss: 0.023449594154953957
Epoch 251, Training Loss: 0.017051367089152336, Validation Loss: 0.023129122331738472
Epoch 252, Training Loss: 0.01671786978840828, Validation Loss: 0.022810734808444977
Epoch 253, Training Loss: 0.0163873378187418, Validation Loss: 0.022496351972222328
Epoch 254, Training Loss: 0.016060449182987213, Validation Loss: 0.02217775583267212
Epoch 255, Training Loss: 0.015739895403385162, Validation Loss: 0.021849770098924637
Epoch 256, Training Loss: 0.015427486971020699, Validation Loss: 0.021500183269381523
Epoch 257, Training Loss: 0.01511984784156084, Validation Loss: 0.021168647333979607
Epoch 258, Training Loss: 0.014825292862951756, Validation Loss: 0.020858293399214745
Epoch 259, Training Loss: 0.014541552402079105, Validation Loss: 0.02055409923195839
Epoch 260, Training Loss: 0.0142623670399189, Validation Loss: 0.020270897075533867
Epoch 261, Training Loss: 0.013990181498229504, Validation Loss: 0.019995804876089096
Epoch 262, Training Loss: 0.013727821409702301, Validation Loss: 0.01969267427921295
Epoch 263, Training Loss: 0.013469042256474495, Validation Loss: 0.019397037103772163
Epoch 264, Training Loss: 0.013215223327279091, Validation Loss: 0.01911080628633499
Epoch 265, Training Loss: 0.012967871502041817, Validation Loss: 0.01883462257683277
Epoch 266, Training Loss: 0.012720741331577301, Validation Loss: 0.01855122484266758
Epoch 267, Training Loss: 0.012475921772420406, Validation Loss: 0.018275121226906776
Epoch 268, Training Loss: 0.01223480049520731, Validation Loss: 0.018016010522842407
Epoch 269, Training Loss: 0.01199549250304699, Validation Loss: 0.017770379781723022
Epoch 270, Training Loss: 0.011762042529881, Validation Loss: 0.017520075663924217
Epoch 271, Training Loss: 0.011539511382579803, Validation Loss: 0.01726749911904335
Epoch 272, Training Loss: 0.011319511570036411, Validation Loss: 0.017014557495713234
Epoch 273, Training Loss: 0.011101970449090004, Validation Loss: 0.016765449196100235
Epoch 274, Training Loss: 0.010888692922890186, Validation Loss: 0.016522929072380066
Epoch 275, Training Loss: 0.010681049898266792, Validation Loss: 0.016281692311167717
Epoch 276, Training Loss: 0.01047504786401987, Validation Loss: 0.016035046428442
Epoch 277, Training Loss: 0.010266769677400589, Validation Loss: 0.0158102884888649
Epoch 278, Training Loss: 0.010064288042485714, Validation Loss: 0.015554701909422874
Epoch 279, Training Loss: 0.00986329186707735, Validation Loss: 0.015302447602152824
Epoch 280, Training Loss: 0.009672748856246471, Validation Loss: 0.015036381781101227
Epoch 281, Training Loss: 0.009485767222940922, Validation Loss: 0.014771788381040096
Epoch 282, Training Loss: 0.009299968369305134, Validation Loss: 0.01450782734900713
Epoch 283, Training Loss: 0.009114449843764305, Validation Loss: 0.014229371212422848
Epoch 284, Training Loss: 0.008931227028369904, Validation Loss: 0.013948752544820309
Epoch 285, Training Loss: 0.008751485496759415, Validation Loss: 0.01368498895317316
Epoch 286, Training Loss: 0.008576825261116028, Validation Loss: 0.013417155481874943
Epoch 287, Training Loss: 0.008401508443057537, Validation Loss: 0.013193454593420029
Epoch 288, Training Loss: 0.008230144158005714, Validation Loss: 0.0129857724532485
Epoch 289, Training Loss: 0.00805174931883812, Validation Loss: 0.012821655720472336
Epoch 290, Training Loss: 0.007886732928454876, Validation Loss: 0.012626122683286667
Epoch 291, Training Loss: 0.0077228303998708725, Validation Loss: 0.012400783598423004
Epoch 292, Training Loss: 0.007560817990452051, Validation Loss: 0.012183916755020618
Epoch 293, Training Loss: 0.007407013326883316, Validation Loss: 0.011977766640484333
Epoch 294, Training Loss: 0.007251406088471413, Validation Loss: 0.011799714528024197
Epoch 295, Training Loss: 0.0071006035432219505, Validation Loss: 0.011611657217144966
Epoch 296, Training Loss: 0.006950157228857279, Validation Loss: 0.011398393660783768
Epoch 297, Training Loss: 0.006799702066928148, Validation Loss: 0.011174656450748444
Epoch 298, Training Loss: 0.006654234603047371, Validation Loss: 0.010969756171107292
Epoch 299, Training Loss: 0.0065180109813809395, Validation Loss: 0.010764727368950844
Epoch 300, Training Loss: 0.0063889408484101295, Validation Loss: 0.01054330077022314
Epoch 301, Training Loss: 0.006261349190026522, Validation Loss: 0.010311458259820938
Epoch 302, Training Loss: 0.006137903779745102, Validation Loss: 0.010070640593767166
Epoch 303, Training Loss: 0.006010180804878473, Validation Loss: 0.009861652739346027
Epoch 304, Training Loss: 0.005888151470571756, Validation Loss: 0.009663048200309277
Epoch 305, Training Loss: 0.005764125380665064, Validation Loss: 0.009474962018430233
Epoch 306, Training Loss: 0.005639980081468821, Validation Loss: 0.009308116510510445
Epoch 307, Training Loss: 0.00552239827811718, Validation Loss: 0.00912485271692276
Epoch 308, Training Loss: 0.00540861114859581, Validation Loss: 0.008930661715567112
Epoch 309, Training Loss: 0.005298410542309284, Validation Loss: 0.008729787543416023
Epoch 310, Training Loss: 0.005185022950172424, Validation Loss: 0.008521640673279762
Epoch 311, Training Loss: 0.0050730942748487, Validation Loss: 0.008320481516420841
Epoch 312, Training Loss: 0.004960315767675638, Validation Loss: 0.008122309111058712
Epoch 313, Training Loss: 0.004849283490329981, Validation Loss: 0.007930763997137547
Epoch 314, Training Loss: 0.004742547869682312, Validation Loss: 0.00774097815155983
Epoch 315, Training Loss: 0.004639136604964733, Validation Loss: 0.007544548716396093
Epoch 316, Training Loss: 0.004534994717687368, Validation Loss: 0.007357400376349688
Epoch 317, Training Loss: 0.004433695692569017, Validation Loss: 0.007196065504103899
Epoch 318, Training Loss: 0.0043333000503480434, Validation Loss: 0.0070428098551929
Epoch 319, Training Loss: 0.004233428742736578, Validation Loss: 0.00688206497579813
Epoch 320, Training Loss: 0.004134650342166424, Validation Loss: 0.006694546435028315
Epoch 321, Training Loss: 0.004033842124044895, Validation Loss: 0.006523663178086281
Epoch 322, Training Loss: 0.0039371163584291935, Validation Loss: 0.006344470661133528
Epoch 323, Training Loss: 0.0038402723148465157, Validation Loss: 0.006189830135554075
Epoch 324, Training Loss: 0.0037565911188721657, Validation Loss: 0.006004851311445236
Epoch 325, Training Loss: 0.0036680814810097218, Validation Loss: 0.005827614571899176
Epoch 326, Training Loss: 0.0035811790730804205, Validation Loss: 0.005653632804751396
Epoch 327, Training Loss: 0.003492082701995969, Validation Loss: 0.005483847111463547
Epoch 328, Training Loss: 0.0034028152003884315, Validation Loss: 0.005312702152878046
Epoch 329, Training Loss: 0.003318136790767312, Validation Loss: 0.005136421415954828
Epoch 330, Training Loss: 0.0032342062331736088, Validation Loss: 0.0049659800715744495
Epoch 331, Training Loss: 0.0031516295857727528, Validation Loss: 0.004789081867784262
Epoch 332, Training Loss: 0.0030655264854431152, Validation Loss: 0.00461686821654439
Epoch 333, Training Loss: 0.0029820550698786974, Validation Loss: 0.004458697512745857
Epoch 334, Training Loss: 0.0029078733641654253, Validation Loss: 0.0042978255078196526
Epoch 335, Training Loss: 0.002830428071320057, Validation Loss: 0.00415243674069643
Epoch 336, Training Loss: 0.0027538002468645573, Validation Loss: 0.004017949569970369
Epoch 337, Training Loss: 0.002679077908396721, Validation Loss: 0.003872629487887025
Epoch 338, Training Loss: 0.0026037234347313643, Validation Loss: 0.003730124793946743
Epoch 339, Training Loss: 0.0025339275598526, Validation Loss: 0.00358524895273149
Epoch 340, Training Loss: 0.002459883689880371, Validation Loss: 0.0034442415926605463
Epoch 341, Training Loss: 0.002390041248872876, Validation Loss: 0.0033066284377127886
Epoch 342, Training Loss: 0.0023201678413897753, Validation Loss: 0.0031713054049760103
Epoch 343, Training Loss: 0.002251953585073352, Validation Loss: 0.003045998513698578
Epoch 344, Training Loss: 0.0021853309590369463, Validation Loss: 0.002920572180300951
Epoch 345, Training Loss: 0.0021170966792851686, Validation Loss: 0.002798935165628791
Epoch 346, Training Loss: 0.002050295239314437, Validation Loss: 0.002695152536034584
Epoch 347, Training Loss: 0.001988775795325637, Validation Loss: 0.0025847838260233402
Epoch 348, Training Loss: 0.001926684402860701, Validation Loss: 0.0024787303991615772
Epoch 349, Training Loss: 0.0018678322667255998, Validation Loss: 0.002373333787545562
Epoch 350, Training Loss: 0.0018080298323184252, Validation Loss: 0.002267559990286827
Epoch 351, Training Loss: 0.0017470673192292452, Validation Loss: 0.0021687308326363564
Epoch 352, Training Loss: 0.0016892018029466271, Validation Loss: 0.0020775434095412493
Epoch 353, Training Loss: 0.0016332307131960988, Validation Loss: 0.0019822975154966116
Epoch 354, Training Loss: 0.001576643786393106, Validation Loss: 0.0018868404440581799
Epoch 355, Training Loss: 0.0015226651448756456, Validation Loss: 0.001798414858058095
Epoch 356, Training Loss: 0.0014731063274666667, Validation Loss: 0.0017217184649780393
Epoch 357, Training Loss: 0.0014233323745429516, Validation Loss: 0.0016511483117938042
Epoch 358, Training Loss: 0.0013760100118815899, Validation Loss: 0.001584892743267119
Epoch 359, Training Loss: 0.0013304301537573338, Validation Loss: 0.0015125013887882233
Epoch 360, Training Loss: 0.0012838714756071568, Validation Loss: 0.0014436423080042005
Epoch 361, Training Loss: 0.0012387463357299566, Validation Loss: 0.001385570620186627
Epoch 362, Training Loss: 0.0011970933992415667, Validation Loss: 0.0013298046542331576
Epoch 363, Training Loss: 0.0011559699196368456, Validation Loss: 0.001271850778721273
Epoch 364, Training Loss: 0.0011145807802677155, Validation Loss: 0.0012142173945903778
Epoch 365, Training Loss: 0.001074471278116107, Validation Loss: 0.0011603472521528602
Epoch 366, Training Loss: 0.0010361508466303349, Validation Loss: 0.0011061250697821379
Epoch 367, Training Loss: 0.0009981237817555666, Validation Loss: 0.0010573707986623049
Epoch 368, Training Loss: 0.000961661571636796, Validation Loss: 0.0010110780131071806
Epoch 369, Training Loss: 0.0009255943587049842, Validation Loss: 0.0009678993956185877
Epoch 370, Training Loss: 0.0008914528298191726, Validation Loss: 0.0009253951138816774
Epoch 371, Training Loss: 0.0008565406897105277, Validation Loss: 0.0008836813503876328
Epoch 372, Training Loss: 0.000823167443741113, Validation Loss: 0.0008440500241704285
Epoch 373, Training Loss: 0.0007916698814369738, Validation Loss: 0.0008044057758525014
Epoch 374, Training Loss: 0.0007608944433741271, Validation Loss: 0.0007664283621124923
Epoch 375, Training Loss: 0.000730376981664449, Validation Loss: 0.0007300123106688261
Epoch 376, Training Loss: 0.0007015283335931599, Validation Loss: 0.0006960105383768678
Epoch 377, Training Loss: 0.0006736890645697713, Validation Loss: 0.0006633856100961566
Epoch 378, Training Loss: 0.0006455644033849239, Validation Loss: 0.0006356020458042622
Epoch 379, Training Loss: 0.0006198751507326961, Validation Loss: 0.0006084913038648665
Epoch 380, Training Loss: 0.0005928860628046095, Validation Loss: 0.0005841447273269296
Epoch 381, Training Loss: 0.0005679352907463908, Validation Loss: 0.0005569403292611241
Epoch 382, Training Loss: 0.0005435218918137252, Validation Loss: 0.000530094897840172
Epoch 383, Training Loss: 0.0005204126937314868, Validation Loss: 0.0005056969821453094
Epoch 384, Training Loss: 0.000497945467941463, Validation Loss: 0.00048323997179977596
Epoch 385, Training Loss: 0.0004757090355269611, Validation Loss: 0.0004622083797585219
Epoch 386, Training Loss: 0.0004540298832580447, Validation Loss: 0.0004411767004057765
Epoch 387, Training Loss: 0.0004329512012191117, Validation Loss: 0.0004200464172754437
Epoch 388, Training Loss: 0.000412650202633813, Validation Loss: 0.0003999493201263249
Epoch 389, Training Loss: 0.0003933752013836056, Validation Loss: 0.0003816829703282565
Epoch 390, Training Loss: 0.00037526179221458733, Validation Loss: 0.0003644677926786244
Epoch 391, Training Loss: 0.00035786887747235596, Validation Loss: 0.00034710299223661423
Epoch 392, Training Loss: 0.00034179992508143187, Validation Loss: 0.0003286255232524127
Epoch 393, Training Loss: 0.0003250669105909765, Validation Loss: 0.00031195158953778446
Epoch 394, Training Loss: 0.00030962019809521735, Validation Loss: 0.00029662728775292635
Epoch 395, Training Loss: 0.0002946050954051316, Validation Loss: 0.0002822622482199222
Epoch 396, Training Loss: 0.0002799589419737458, Validation Loss: 0.0002675137366168201
Epoch 397, Training Loss: 0.00026515201898291707, Validation Loss: 0.00025303519214503467
Epoch 398, Training Loss: 0.0002509340993128717, Validation Loss: 0.000240262015722692
Epoch 399, Training Loss: 0.00023778715694788843, Validation Loss: 0.00022744307352695614
Epoch 400, Training Loss: 0.00022505233937408775, Validation Loss: 0.0002155281836166978
Epoch 401, Training Loss: 0.00021302682580426335, Validation Loss: 0.0002043913846137002
Epoch 402, Training Loss: 0.00020139281696174294, Validation Loss: 0.00019262587011326104
Epoch 403, Training Loss: 0.00018958465079776943, Validation Loss: 0.0001812070404412225
Epoch 404, Training Loss: 0.0001788428344298154, Validation Loss: 0.00016894418513402343
Epoch 405, Training Loss: 0.0001676462561590597, Validation Loss: 0.0001577929506311193
Epoch 406, Training Loss: 0.00015735467604827136, Validation Loss: 0.00014702499902341515
Epoch 407, Training Loss: 0.00014730490511283278, Validation Loss: 0.00013701837451662868
Epoch 408, Training Loss: 0.00013814955309499055, Validation Loss: 0.00012837165559176356
Epoch 409, Training Loss: 0.00012962207256350666, Validation Loss: 0.00011966643069172278
Epoch 410, Training Loss: 0.00012106601934647188, Validation Loss: 0.00011168454511789605
Epoch 411, Training Loss: 0.00011327992251608521, Validation Loss: 0.00010366861533839256
Epoch 412, Training Loss: 0.0001055498214554973, Validation Loss: 9.606579260434955e-05
Epoch 413, Training Loss: 9.848883200902492e-05, Validation Loss: 8.931704360293224e-05
Epoch 414, Training Loss: 9.179547487292439e-05, Validation Loss: 8.321136556332931e-05
Epoch 415, Training Loss: 8.539334521628916e-05, Validation Loss: 7.732247468084097e-05
Epoch 416, Training Loss: 7.936168549349532e-05, Validation Loss: 7.1417358412873e-05
Epoch 417, Training Loss: 7.362607721006498e-05, Validation Loss: 6.569633114850149e-05
Epoch 418, Training Loss: 6.815778760937974e-05, Validation Loss: 6.0510508774314076e-05
Epoch 419, Training Loss: 6.312018376775086e-05, Validation Loss: 5.591912486124784e-05
Epoch 420, Training Loss: 5.838818469783291e-05, Validation Loss: 5.1711973355850205e-05
Epoch 421, Training Loss: 5.392503953771666e-05, Validation Loss: 4.7698769776616246e-05
Epoch 422, Training Loss: 4.982115569873713e-05, Validation Loss: 4.373619958641939e-05
Epoch 423, Training Loss: 4.584289854392409e-05, Validation Loss: 4.003834692412056e-05
Epoch 424, Training Loss: 4.2158368160016835e-05, Validation Loss: 3.685132469399832e-05
Epoch 425, Training Loss: 3.885616752086207e-05, Validation Loss: 3.3892076316988096e-05
Epoch 426, Training Loss: 3.561648554750718e-05, Validation Loss: 3.114669380011037e-05
Epoch 427, Training Loss: 3.265176201239228e-05, Validation Loss: 2.8547221518238075e-05
Epoch 428, Training Loss: 2.998348827532027e-05, Validation Loss: 2.592432065284811e-05
Epoch 429, Training Loss: 2.7408757887315005e-05, Validation Loss: 2.3508720914833248e-05
Epoch 430, Training Loss: 2.506414966774173e-05, Validation Loss: 2.1355008357204497e-05
Epoch 431, Training Loss: 2.2898077077115886e-05, Validation Loss: 1.9466198864392936e-05
Epoch 432, Training Loss: 2.0810877686017193e-05, Validation Loss: 1.778534169716295e-05
Epoch 433, Training Loss: 1.891554711619392e-05, Validation Loss: 1.624449396331329e-05
Epoch 434, Training Loss: 1.721840089885518e-05, Validation Loss: 1.4736817320226692e-05
Epoch 435, Training Loss: 1.565019010740798e-05, Validation Loss: 1.3274454431666527e-05
Epoch 436, Training Loss: 1.419093314325437e-05, Validation Loss: 1.1997093679383397e-05
Epoch 437, Training Loss: 1.2891706319351215e-05, Validation Loss: 1.089537727239076e-05
Epoch 438, Training Loss: 1.1711278602888342e-05, Validation Loss: 9.878070159174968e-06
Epoch 439, Training Loss: 1.0603750524751376e-05, Validation Loss: 8.949191396823153e-06
Epoch 440, Training Loss: 9.587922249920666e-06, Validation Loss: 8.058994353632443e-06
Epoch 441, Training Loss: 8.657756552565843e-06, Validation Loss: 7.234472832351457e-06
Epoch 442, Training Loss: 7.816430297680199e-06, Validation Loss: 6.494123226730153e-06
Epoch 443, Training Loss: 7.050276053632842e-06, Validation Loss: 5.8535943026072346e-06
Epoch 444, Training Loss: 6.363316515489714e-06, Validation Loss: 5.28808686794946e-06
Epoch 445, Training Loss: 5.742293978983071e-06, Validation Loss: 4.768240614794195e-06
Epoch 446, Training Loss: 5.1734273256442975e-06, Validation Loss: 4.292310677556088e-06
Epoch 447, Training Loss: 4.658949364966247e-06, Validation Loss: 3.856070634356001e-06
Epoch 448, Training Loss: 4.185988927929429e-06, Validation Loss: 3.490165909170173e-06
Epoch 449, Training Loss: 3.7689394503104268e-06, Validation Loss: 3.1687907267041737e-06
Epoch 450, Training Loss: 3.388883669686038e-06, Validation Loss: 2.862398787328857e-06
Epoch 451, Training Loss: 3.0392420740099624e-06, Validation Loss: 2.578240810180432e-06
Epoch 452, Training Loss: 2.7331122964824317e-06, Validation Loss: 2.3202658212539973e-06
Epoch 453, Training Loss: 2.457900336594321e-06, Validation Loss: 2.0899226456094766e-06
Epoch 454, Training Loss: 2.2104720756033203e-06, Validation Loss: 1.8861237549572252e-06
Epoch 455, Training Loss: 1.988295935007045e-06, Validation Loss: 1.7048411109499284e-06
Epoch 456, Training Loss: 1.788692202353559e-06, Validation Loss: 1.5410134892590577e-06
Epoch 457, Training Loss: 1.6086377172541688e-06, Validation Loss: 1.3814537851430941e-06
Epoch 458, Training Loss: 1.4402862689166795e-06, Validation Loss: 1.2360939081190736e-06
Epoch 459, Training Loss: 1.2885590194855467e-06, Validation Loss: 1.1092115528299473e-06
Epoch 460, Training Loss: 1.1573453093660646e-06, Validation Loss: 9.956554549717112e-07
Epoch 461, Training Loss: 1.0359206044086022e-06, Validation Loss: 8.962418860392063e-07
Epoch 462, Training Loss: 9.250780408365245e-07, Validation Loss: 8.096363330878376e-07
Epoch 463, Training Loss: 8.293617383969831e-07, Validation Loss: 7.291382644325495e-07
Epoch 464, Training Loss: 7.421378427352465e-07, Validation Loss: 6.543100994349516e-07
Epoch 465, Training Loss: 6.616299401684955e-07, Validation Loss: 5.865151138095825e-07
Epoch 466, Training Loss: 5.898091330891475e-07, Validation Loss: 5.241416829449008e-07
Epoch 467, Training Loss: 5.24915890309785e-07, Validation Loss: 4.6955221932876157e-07
Epoch 468, Training Loss: 4.674109845836938e-07, Validation Loss: 4.1915950532711577e-07
Epoch 469, Training Loss: 4.152864505613252e-07, Validation Loss: 3.7140179642847215e-07
Epoch 470, Training Loss: 3.670689352475165e-07, Validation Loss: 3.30494913214352e-07
Epoch 471, Training Loss: 3.24878442370391e-07, Validation Loss: 2.945831170109159e-07
Epoch 472, Training Loss: 2.872950517485151e-07, Validation Loss: 2.6046967604997917e-07
Epoch 473, Training Loss: 2.52754801977062e-07, Validation Loss: 2.304108903672386e-07
Epoch 474, Training Loss: 2.229816402632423e-07, Validation Loss: 2.0410489298683387e-07
Epoch 475, Training Loss: 1.9683344021359517e-07, Validation Loss: 1.8007362712069153e-07
Epoch 476, Training Loss: 1.7262432550069207e-07, Validation Loss: 1.5854588752972631e-07
Epoch 477, Training Loss: 1.5078228443599073e-07, Validation Loss: 1.3971965984183043e-07
Epoch 478, Training Loss: 1.317837359238183e-07, Validation Loss: 1.2285889283703e-07
Epoch 479, Training Loss: 1.1511736630609448e-07, Validation Loss: 1.077777866953511e-07
Epoch 480, Training Loss: 1.003427030354942e-07, Validation Loss: 9.427978397980041e-08
Epoch 481, Training Loss: 8.714921051478086e-08, Validation Loss: 8.16186869201374e-08
Epoch 482, Training Loss: 7.503184917823091e-08, Validation Loss: 7.05093086139641e-08
Epoch 483, Training Loss: 6.456567547274972e-08, Validation Loss: 6.096076532458028e-08
Epoch 484, Training Loss: 5.576601580514762e-08, Validation Loss: 5.230025834634944e-08
Epoch 485, Training Loss: 4.7929106017363665e-08, Validation Loss: 4.4832660250904155e-08
Epoch 486, Training Loss: 4.10490912372552e-08, Validation Loss: 3.859334540834425e-08
Epoch 487, Training Loss: 3.5106477724866636e-08, Validation Loss: 3.301250472986794e-08
Epoch 488, Training Loss: 2.981619573461103e-08, Validation Loss: 2.8315231048736678e-08
Epoch 489, Training Loss: 2.5343513954112495e-08, Validation Loss: 2.457804093580762e-08
Epoch 490, Training Loss: 2.1687160511874026e-08, Validation Loss: 2.1242891889983184e-08
Epoch 491, Training Loss: 1.8399095580434732e-08, Validation Loss: 1.827023154987728e-08
Epoch 492, Training Loss: 1.546042938116443e-08, Validation Loss: 1.5859916047133993e-08
Epoch 493, Training Loss: 1.3032132706314314e-08, Validation Loss: 1.3742961435525558e-08
Epoch 494, Training Loss: 1.097438584451993e-08, Validation Loss: 1.1981438952091139e-08
Epoch 495, Training Loss: 9.308616988334961e-09, Validation Loss: 1.0483730328303409e-08
Epoch 496, Training Loss: 7.927851264355468e-09, Validation Loss: 9.015018065383629e-09
Epoch 497, Training Loss: 6.645032080143665e-09, Validation Loss: 7.750723618471511e-09
Epoch 498, Training Loss: 5.574915196149277e-09, Validation Loss: 6.7378476131807474e-09
Epoch 499, Training Loss: 4.748183624059266e-09, Validation Loss: 5.846379824703263e-09
Epoch 500, Training Loss: 4.042924217628752e-09, Validation Loss: 5.165917027483147e-09
