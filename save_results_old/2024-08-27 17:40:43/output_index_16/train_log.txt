Epoch 1, Training Loss: 0.2403029054403305, Validation Loss: 0.28527721762657166
Epoch 2, Training Loss: 0.23937636613845825, Validation Loss: 0.28433045744895935
Epoch 3, Training Loss: 0.23846535384655, Validation Loss: 0.28340545296669006
Epoch 4, Training Loss: 0.23756685853004456, Validation Loss: 0.2825053930282593
Epoch 5, Training Loss: 0.23668603599071503, Validation Loss: 0.2816230356693268
Epoch 6, Training Loss: 0.2358209639787674, Validation Loss: 0.2807405889034271
Epoch 7, Training Loss: 0.23496371507644653, Validation Loss: 0.27985429763793945
Epoch 8, Training Loss: 0.23410330712795258, Validation Loss: 0.27895689010620117
Epoch 9, Training Loss: 0.2332349419593811, Validation Loss: 0.27805083990097046
Epoch 10, Training Loss: 0.23236003518104553, Validation Loss: 0.2771366834640503
Epoch 11, Training Loss: 0.23147793114185333, Validation Loss: 0.27621135115623474
Epoch 12, Training Loss: 0.2305874526500702, Validation Loss: 0.27528101205825806
Epoch 13, Training Loss: 0.22969314455986023, Validation Loss: 0.27433842420578003
Epoch 14, Training Loss: 0.2287856936454773, Validation Loss: 0.27339035272598267
Epoch 15, Training Loss: 0.22786255180835724, Validation Loss: 0.2724311947822571
Epoch 16, Training Loss: 0.2269243597984314, Validation Loss: 0.271442711353302
Epoch 17, Training Loss: 0.22595633566379547, Validation Loss: 0.27040600776672363
Epoch 18, Training Loss: 0.2249506115913391, Validation Loss: 0.2693309485912323
Epoch 19, Training Loss: 0.2239149659872055, Validation Loss: 0.2682483494281769
Epoch 20, Training Loss: 0.22286678850650787, Validation Loss: 0.26713454723358154
Epoch 21, Training Loss: 0.22179904580116272, Validation Loss: 0.2659769654273987
Epoch 22, Training Loss: 0.2207055538892746, Validation Loss: 0.2647717595100403
Epoch 23, Training Loss: 0.21957537531852722, Validation Loss: 0.2635100483894348
Epoch 24, Training Loss: 0.2183978408575058, Validation Loss: 0.26218265295028687
Epoch 25, Training Loss: 0.21716316044330597, Validation Loss: 0.2607705593109131
Epoch 26, Training Loss: 0.2158571034669876, Validation Loss: 0.25927892327308655
Epoch 27, Training Loss: 0.21448178589344025, Validation Loss: 0.25770413875579834
Epoch 28, Training Loss: 0.213032528758049, Validation Loss: 0.25604143738746643
Epoch 29, Training Loss: 0.21151386201381683, Validation Loss: 0.2542799413204193
Epoch 30, Training Loss: 0.20991328358650208, Validation Loss: 0.2524212896823883
Epoch 31, Training Loss: 0.20823609828948975, Validation Loss: 0.2504650950431824
Epoch 32, Training Loss: 0.20647269487380981, Validation Loss: 0.24839553236961365
Epoch 33, Training Loss: 0.20461443066596985, Validation Loss: 0.24621938169002533
Epoch 34, Training Loss: 0.20266443490982056, Validation Loss: 0.24392710626125336
Epoch 35, Training Loss: 0.20061495900154114, Validation Loss: 0.2414904236793518
Epoch 36, Training Loss: 0.1984451860189438, Validation Loss: 0.23890194296836853
Epoch 37, Training Loss: 0.1961532086133957, Validation Loss: 0.2361481487751007
Epoch 38, Training Loss: 0.19371919333934784, Validation Loss: 0.23322714865207672
Epoch 39, Training Loss: 0.1911279708147049, Validation Loss: 0.2301502674818039
Epoch 40, Training Loss: 0.18840928375720978, Validation Loss: 0.22687409818172455
Epoch 41, Training Loss: 0.18552954494953156, Validation Loss: 0.223422572016716
Epoch 42, Training Loss: 0.18253371119499207, Validation Loss: 0.2198127806186676
Epoch 43, Training Loss: 0.17942333221435547, Validation Loss: 0.216031014919281
Epoch 44, Training Loss: 0.17618480324745178, Validation Loss: 0.21212472021579742
Epoch 45, Training Loss: 0.1728610098361969, Validation Loss: 0.20808535814285278
Epoch 46, Training Loss: 0.1694532185792923, Validation Loss: 0.20385214686393738
Epoch 47, Training Loss: 0.16597282886505127, Validation Loss: 0.1995529681444168
Epoch 48, Training Loss: 0.16250698268413544, Validation Loss: 0.19524142146110535
Epoch 49, Training Loss: 0.15909305214881897, Validation Loss: 0.19094763696193695
Epoch 50, Training Loss: 0.15572746098041534, Validation Loss: 0.18680180609226227
Epoch 51, Training Loss: 0.15253625810146332, Validation Loss: 0.18284177780151367
Epoch 52, Training Loss: 0.14957602322101593, Validation Loss: 0.17909802496433258
Epoch 53, Training Loss: 0.14686767756938934, Validation Loss: 0.1756267249584198
Epoch 54, Training Loss: 0.14448367059230804, Validation Loss: 0.17248032987117767
Epoch 55, Training Loss: 0.14244814217090607, Validation Loss: 0.1695840209722519
Epoch 56, Training Loss: 0.14069455862045288, Validation Loss: 0.16684654355049133
Epoch 57, Training Loss: 0.1391279697418213, Validation Loss: 0.16425418853759766
Epoch 58, Training Loss: 0.13770370185375214, Validation Loss: 0.16169095039367676
Epoch 59, Training Loss: 0.13627617061138153, Validation Loss: 0.15908388793468475
Epoch 60, Training Loss: 0.1347789466381073, Validation Loss: 0.1564447581768036
Epoch 61, Training Loss: 0.13317707180976868, Validation Loss: 0.15374009311199188
Epoch 62, Training Loss: 0.13143125176429749, Validation Loss: 0.15100911259651184
Epoch 63, Training Loss: 0.12957186996936798, Validation Loss: 0.14831764996051788
Epoch 64, Training Loss: 0.12767578661441803, Validation Loss: 0.14574575424194336
Epoch 65, Training Loss: 0.12583903968334198, Validation Loss: 0.1433754712343216
Epoch 66, Training Loss: 0.12414190173149109, Validation Loss: 0.14123092591762543
Epoch 67, Training Loss: 0.12259837985038757, Validation Loss: 0.13927893340587616
Epoch 68, Training Loss: 0.1212017610669136, Validation Loss: 0.13750724494457245
Epoch 69, Training Loss: 0.11995945125818253, Validation Loss: 0.1358666718006134
Epoch 70, Training Loss: 0.11884564906358719, Validation Loss: 0.13433554768562317
Epoch 71, Training Loss: 0.11784988641738892, Validation Loss: 0.13285724818706512
Epoch 72, Training Loss: 0.11692698299884796, Validation Loss: 0.13142959773540497
Epoch 73, Training Loss: 0.11607770621776581, Validation Loss: 0.13003353774547577
Epoch 74, Training Loss: 0.11528127640485764, Validation Loss: 0.12862974405288696
Epoch 75, Training Loss: 0.11449827253818512, Validation Loss: 0.12721975147724152
Epoch 76, Training Loss: 0.1137307807803154, Validation Loss: 0.12581767141819
Epoch 77, Training Loss: 0.1129758283495903, Validation Loss: 0.12443907558917999
Epoch 78, Training Loss: 0.11224223673343658, Validation Loss: 0.12309617549180984
Epoch 79, Training Loss: 0.11154529452323914, Validation Loss: 0.12182740867137909
Epoch 80, Training Loss: 0.11089450120925903, Validation Loss: 0.12063838541507721
Epoch 81, Training Loss: 0.11028198152780533, Validation Loss: 0.11955129355192184
Epoch 82, Training Loss: 0.10970594733953476, Validation Loss: 0.1185653954744339
Epoch 83, Training Loss: 0.10915997624397278, Validation Loss: 0.11766228824853897
Epoch 84, Training Loss: 0.10861983895301819, Validation Loss: 0.11683761328458786
Epoch 85, Training Loss: 0.10807833820581436, Validation Loss: 0.1160816103219986
Epoch 86, Training Loss: 0.10752146691083908, Validation Loss: 0.11537209153175354
Epoch 87, Training Loss: 0.10694513469934464, Validation Loss: 0.11470130831003189
Epoch 88, Training Loss: 0.1063452735543251, Validation Loss: 0.11405902355909348
Epoch 89, Training Loss: 0.10572828352451324, Validation Loss: 0.11342953890562057
Epoch 90, Training Loss: 0.10509025305509567, Validation Loss: 0.11280562728643417
Epoch 91, Training Loss: 0.10443926602602005, Validation Loss: 0.112176313996315
Epoch 92, Training Loss: 0.10377360135316849, Validation Loss: 0.11153272539377213
Epoch 93, Training Loss: 0.10308337956666946, Validation Loss: 0.11086137592792511
Epoch 94, Training Loss: 0.10236519575119019, Validation Loss: 0.11014921218156815
Epoch 95, Training Loss: 0.10162054002285004, Validation Loss: 0.10938026010990143
Epoch 96, Training Loss: 0.10084464401006699, Validation Loss: 0.10854347050189972
Epoch 97, Training Loss: 0.10003305226564407, Validation Loss: 0.1076439693570137
Epoch 98, Training Loss: 0.0991891399025917, Validation Loss: 0.10667671263217926
Epoch 99, Training Loss: 0.0983053669333458, Validation Loss: 0.10565542429685593
Epoch 100, Training Loss: 0.09738427400588989, Validation Loss: 0.10458109527826309
Epoch 101, Training Loss: 0.0964261069893837, Validation Loss: 0.10346263647079468
Epoch 102, Training Loss: 0.09543612599372864, Validation Loss: 0.10229022055864334
Epoch 103, Training Loss: 0.09442014247179031, Validation Loss: 0.10107813030481339
Epoch 104, Training Loss: 0.09338062256574631, Validation Loss: 0.09985309094190598
Epoch 105, Training Loss: 0.09232556074857712, Validation Loss: 0.09862937033176422
Epoch 106, Training Loss: 0.0912393108010292, Validation Loss: 0.09741654247045517
Epoch 107, Training Loss: 0.09012587368488312, Validation Loss: 0.09622592478990555
Epoch 108, Training Loss: 0.08899086713790894, Validation Loss: 0.09506843984127045
Epoch 109, Training Loss: 0.08784042298793793, Validation Loss: 0.0939561054110527
Epoch 110, Training Loss: 0.08668018877506256, Validation Loss: 0.09288349747657776
Epoch 111, Training Loss: 0.08552073687314987, Validation Loss: 0.09186789393424988
Epoch 112, Training Loss: 0.08436305820941925, Validation Loss: 0.0908997654914856
Epoch 113, Training Loss: 0.08320851624011993, Validation Loss: 0.08999118208885193
Epoch 114, Training Loss: 0.08207517862319946, Validation Loss: 0.08912984281778336
Epoch 115, Training Loss: 0.08096376061439514, Validation Loss: 0.08829358220100403
Epoch 116, Training Loss: 0.07987695932388306, Validation Loss: 0.08750133961439133
Epoch 117, Training Loss: 0.07883434742689133, Validation Loss: 0.08677861094474792
Epoch 118, Training Loss: 0.07784298062324524, Validation Loss: 0.0861441045999527
Epoch 119, Training Loss: 0.07691588997840881, Validation Loss: 0.08557037264108658
Epoch 120, Training Loss: 0.07603473961353302, Validation Loss: 0.08504488319158554
Epoch 121, Training Loss: 0.07520893961191177, Validation Loss: 0.0845593586564064
Epoch 122, Training Loss: 0.07443562895059586, Validation Loss: 0.08413126319646835
Epoch 123, Training Loss: 0.07371270656585693, Validation Loss: 0.0837419256567955
Epoch 124, Training Loss: 0.07306070625782013, Validation Loss: 0.08335395902395248
Epoch 125, Training Loss: 0.07246576249599457, Validation Loss: 0.08297501504421234
Epoch 126, Training Loss: 0.07190465182065964, Validation Loss: 0.08258071541786194
Epoch 127, Training Loss: 0.07135846465826035, Validation Loss: 0.08218052238225937
Epoch 128, Training Loss: 0.0708296149969101, Validation Loss: 0.08175323903560638
Epoch 129, Training Loss: 0.07031799107789993, Validation Loss: 0.0812966451048851
Epoch 130, Training Loss: 0.06981154531240463, Validation Loss: 0.08079399168491364
Epoch 131, Training Loss: 0.0693182572722435, Validation Loss: 0.08027615398168564
Epoch 132, Training Loss: 0.06882157921791077, Validation Loss: 0.07976280897855759
Epoch 133, Training Loss: 0.06832142919301987, Validation Loss: 0.07923831045627594
Epoch 134, Training Loss: 0.06781192123889923, Validation Loss: 0.07869476824998856
Epoch 135, Training Loss: 0.06730399280786514, Validation Loss: 0.07812152802944183
Epoch 136, Training Loss: 0.06679785996675491, Validation Loss: 0.0775270089507103
Epoch 137, Training Loss: 0.06629598140716553, Validation Loss: 0.076912060379982
Epoch 138, Training Loss: 0.06580989062786102, Validation Loss: 0.07625589519739151
Epoch 139, Training Loss: 0.0653364509344101, Validation Loss: 0.07558666914701462
Epoch 140, Training Loss: 0.06486531347036362, Validation Loss: 0.0749533474445343
Epoch 141, Training Loss: 0.0644107535481453, Validation Loss: 0.07434998452663422
Epoch 142, Training Loss: 0.06397703289985657, Validation Loss: 0.07376370579004288
Epoch 143, Training Loss: 0.06355877965688705, Validation Loss: 0.0732124000787735
Epoch 144, Training Loss: 0.06315664947032928, Validation Loss: 0.07270140945911407
Epoch 145, Training Loss: 0.06277204304933548, Validation Loss: 0.0722237229347229
Epoch 146, Training Loss: 0.06238856166601181, Validation Loss: 0.07178333401679993
Epoch 147, Training Loss: 0.06200985983014107, Validation Loss: 0.07136286795139313
Epoch 148, Training Loss: 0.06162941828370094, Validation Loss: 0.07096045464277267
Epoch 149, Training Loss: 0.06125741824507713, Validation Loss: 0.07059729099273682
Epoch 150, Training Loss: 0.06089601665735245, Validation Loss: 0.07023435086011887
Epoch 151, Training Loss: 0.06052900105714798, Validation Loss: 0.0698670744895935
Epoch 152, Training Loss: 0.060159556567668915, Validation Loss: 0.06948688626289368
Epoch 153, Training Loss: 0.05978366360068321, Validation Loss: 0.06908462196588516
Epoch 154, Training Loss: 0.059397295117378235, Validation Loss: 0.06865878403186798
Epoch 155, Training Loss: 0.05900052934885025, Validation Loss: 0.0682193785905838
Epoch 156, Training Loss: 0.05860556662082672, Validation Loss: 0.06777574867010117
Epoch 157, Training Loss: 0.05820952355861664, Validation Loss: 0.06731237471103668
Epoch 158, Training Loss: 0.05780674144625664, Validation Loss: 0.06683596223592758
Epoch 159, Training Loss: 0.057397615164518356, Validation Loss: 0.06637676805257797
Epoch 160, Training Loss: 0.05699053406715393, Validation Loss: 0.065940260887146
Epoch 161, Training Loss: 0.05657630041241646, Validation Loss: 0.06548938900232315
Epoch 162, Training Loss: 0.05614279955625534, Validation Loss: 0.06502324342727661
Epoch 163, Training Loss: 0.0556991808116436, Validation Loss: 0.06456540524959564
Epoch 164, Training Loss: 0.0552702322602272, Validation Loss: 0.06408484280109406
Epoch 165, Training Loss: 0.054825831204652786, Validation Loss: 0.06359153985977173
Epoch 166, Training Loss: 0.054379694163799286, Validation Loss: 0.06309012323617935
Epoch 167, Training Loss: 0.05392884835600853, Validation Loss: 0.06255384534597397
Epoch 168, Training Loss: 0.05346323549747467, Validation Loss: 0.061989594250917435
Epoch 169, Training Loss: 0.052993904799222946, Validation Loss: 0.061429768800735474
Epoch 170, Training Loss: 0.05252080783247948, Validation Loss: 0.060866955667734146
Epoch 171, Training Loss: 0.052050162106752396, Validation Loss: 0.06030045449733734
Epoch 172, Training Loss: 0.051570646464824677, Validation Loss: 0.05973881110548973
Epoch 173, Training Loss: 0.051088932901620865, Validation Loss: 0.05916186794638634
Epoch 174, Training Loss: 0.050594478845596313, Validation Loss: 0.05856849253177643
Epoch 175, Training Loss: 0.05010503903031349, Validation Loss: 0.05794452130794525
Epoch 176, Training Loss: 0.04961322993040085, Validation Loss: 0.05732603371143341
Epoch 177, Training Loss: 0.04911317303776741, Validation Loss: 0.05670266970992088
Epoch 178, Training Loss: 0.04860607534646988, Validation Loss: 0.056095417588949203
Epoch 179, Training Loss: 0.04810627922415733, Validation Loss: 0.05547304451465607
Epoch 180, Training Loss: 0.0476091094315052, Validation Loss: 0.054871752858161926
Epoch 181, Training Loss: 0.04712807387113571, Validation Loss: 0.05427703633904457
Epoch 182, Training Loss: 0.04664663225412369, Validation Loss: 0.05367748811841011
Epoch 183, Training Loss: 0.04616279527544975, Validation Loss: 0.053091976791620255
Epoch 184, Training Loss: 0.045685429126024246, Validation Loss: 0.052518002688884735
Epoch 185, Training Loss: 0.04520642012357712, Validation Loss: 0.05197027325630188
Epoch 186, Training Loss: 0.044731754809617996, Validation Loss: 0.051447443664073944
Epoch 187, Training Loss: 0.04427317529916763, Validation Loss: 0.05094011127948761
Epoch 188, Training Loss: 0.04382886365056038, Validation Loss: 0.050458576530218124
Epoch 189, Training Loss: 0.04339016601443291, Validation Loss: 0.050007279962301254
Epoch 190, Training Loss: 0.04295092821121216, Validation Loss: 0.04960426315665245
Epoch 191, Training Loss: 0.04251750931143761, Validation Loss: 0.049219898879528046
Epoch 192, Training Loss: 0.04210452362895012, Validation Loss: 0.04879467189311981
Epoch 193, Training Loss: 0.04170077294111252, Validation Loss: 0.04833674058318138
Epoch 194, Training Loss: 0.04129061475396156, Validation Loss: 0.0478830523788929
Epoch 195, Training Loss: 0.04088447242975235, Validation Loss: 0.04743722826242447
Epoch 196, Training Loss: 0.0404791384935379, Validation Loss: 0.04698919132351875
Epoch 197, Training Loss: 0.040070388466119766, Validation Loss: 0.04654379189014435
Epoch 198, Training Loss: 0.03967399150133133, Validation Loss: 0.04611411318182945
Epoch 199, Training Loss: 0.039266981184482574, Validation Loss: 0.04570057988166809
Epoch 200, Training Loss: 0.038868870586156845, Validation Loss: 0.045238930732011795
Epoch 201, Training Loss: 0.03845720738172531, Validation Loss: 0.044767603278160095
Epoch 202, Training Loss: 0.03804536163806915, Validation Loss: 0.0443754717707634
Epoch 203, Training Loss: 0.03763938695192337, Validation Loss: 0.043979793787002563
Epoch 204, Training Loss: 0.037219174206256866, Validation Loss: 0.04358495771884918
Epoch 205, Training Loss: 0.03679415211081505, Validation Loss: 0.043191540986299515
Epoch 206, Training Loss: 0.03635929152369499, Validation Loss: 0.04277845844626427
Epoch 207, Training Loss: 0.03592471033334732, Validation Loss: 0.04238078370690346
Epoch 208, Training Loss: 0.03549328073859215, Validation Loss: 0.04196041822433472
Epoch 209, Training Loss: 0.035054080188274384, Validation Loss: 0.04152660444378853
Epoch 210, Training Loss: 0.034616369754076004, Validation Loss: 0.041113466024398804
Epoch 211, Training Loss: 0.03416137769818306, Validation Loss: 0.04069367051124573
Epoch 212, Training Loss: 0.03369785100221634, Validation Loss: 0.04025285691022873
Epoch 213, Training Loss: 0.03323429077863693, Validation Loss: 0.039851512759923935
Epoch 214, Training Loss: 0.03276314213871956, Validation Loss: 0.039445552974939346
Epoch 215, Training Loss: 0.03229542821645737, Validation Loss: 0.03905357047915459
Epoch 216, Training Loss: 0.03182700276374817, Validation Loss: 0.03865622729063034
Epoch 217, Training Loss: 0.03135852888226509, Validation Loss: 0.038217294961214066
Epoch 218, Training Loss: 0.030887847766280174, Validation Loss: 0.03777725249528885
Epoch 219, Training Loss: 0.03041190467774868, Validation Loss: 0.037381917238235474
Epoch 220, Training Loss: 0.029941357672214508, Validation Loss: 0.03696826100349426
Epoch 221, Training Loss: 0.0294790156185627, Validation Loss: 0.036558154970407486
Epoch 222, Training Loss: 0.029014969244599342, Validation Loss: 0.03614995256066322
Epoch 223, Training Loss: 0.028551317751407623, Validation Loss: 0.035744912922382355
Epoch 224, Training Loss: 0.028085224330425262, Validation Loss: 0.035357650369405746
Epoch 225, Training Loss: 0.027627136558294296, Validation Loss: 0.034947432577610016
Epoch 226, Training Loss: 0.02716968208551407, Validation Loss: 0.03453514724969864
Epoch 227, Training Loss: 0.026714684441685677, Validation Loss: 0.03413974493741989
Epoch 228, Training Loss: 0.026261333376169205, Validation Loss: 0.03377607464790344
Epoch 229, Training Loss: 0.025813255459070206, Validation Loss: 0.03338787704706192
Epoch 230, Training Loss: 0.02537732571363449, Validation Loss: 0.032972853630781174
Epoch 231, Training Loss: 0.024949559941887856, Validation Loss: 0.0325714647769928
Epoch 232, Training Loss: 0.024534720927476883, Validation Loss: 0.03217869624495506
Epoch 233, Training Loss: 0.024116721004247665, Validation Loss: 0.031783152371644974
Epoch 234, Training Loss: 0.02370443381369114, Validation Loss: 0.03137866407632828
Epoch 235, Training Loss: 0.023311253637075424, Validation Loss: 0.030998026952147484
Epoch 236, Training Loss: 0.022929228842258453, Validation Loss: 0.030652180314064026
Epoch 237, Training Loss: 0.022561509162187576, Validation Loss: 0.030307363718748093
Epoch 238, Training Loss: 0.02221626602113247, Validation Loss: 0.02995140664279461
Epoch 239, Training Loss: 0.02187347784638405, Validation Loss: 0.029583478346467018
Epoch 240, Training Loss: 0.02153836563229561, Validation Loss: 0.029195670038461685
Epoch 241, Training Loss: 0.021211795508861542, Validation Loss: 0.028822509571909904
Epoch 242, Training Loss: 0.020892547443509102, Validation Loss: 0.028471369296312332
Epoch 243, Training Loss: 0.020589828491210938, Validation Loss: 0.028144363313913345
Epoch 244, Training Loss: 0.02029217779636383, Validation Loss: 0.027861591428518295
Epoch 245, Training Loss: 0.019993994385004044, Validation Loss: 0.02759099379181862
Epoch 246, Training Loss: 0.019701991230249405, Validation Loss: 0.02728445827960968
Epoch 247, Training Loss: 0.01940802112221718, Validation Loss: 0.026981361210346222
Epoch 248, Training Loss: 0.019122112542390823, Validation Loss: 0.02665828913450241
Epoch 249, Training Loss: 0.01883929781615734, Validation Loss: 0.026316918432712555
Epoch 250, Training Loss: 0.018557028844952583, Validation Loss: 0.026001302525401115
Epoch 251, Training Loss: 0.01828758418560028, Validation Loss: 0.02572210505604744
Epoch 252, Training Loss: 0.018002906814217567, Validation Loss: 0.02547552064061165
Epoch 253, Training Loss: 0.017742909491062164, Validation Loss: 0.025182776153087616
Epoch 254, Training Loss: 0.017464615404605865, Validation Loss: 0.024862119928002357
Epoch 255, Training Loss: 0.017185695469379425, Validation Loss: 0.024545613676309586
Epoch 256, Training Loss: 0.016919683665037155, Validation Loss: 0.024246064946055412
Epoch 257, Training Loss: 0.016649918630719185, Validation Loss: 0.023923635482788086
Epoch 258, Training Loss: 0.01637556590139866, Validation Loss: 0.023596398532390594
Epoch 259, Training Loss: 0.01610466279089451, Validation Loss: 0.023261914029717445
Epoch 260, Training Loss: 0.015836909413337708, Validation Loss: 0.022935161367058754
Epoch 261, Training Loss: 0.015573950484395027, Validation Loss: 0.022601623088121414
Epoch 262, Training Loss: 0.015306332148611546, Validation Loss: 0.022275924682617188
Epoch 263, Training Loss: 0.015040187165141106, Validation Loss: 0.02199358120560646
Epoch 264, Training Loss: 0.01478063128888607, Validation Loss: 0.021707989275455475
Epoch 265, Training Loss: 0.014522419311106205, Validation Loss: 0.021421540528535843
Epoch 266, Training Loss: 0.01426701433956623, Validation Loss: 0.02112169936299324
Epoch 267, Training Loss: 0.014017288573086262, Validation Loss: 0.020793616771697998
Epoch 268, Training Loss: 0.013766784220933914, Validation Loss: 0.020432578399777412
Epoch 269, Training Loss: 0.013519831001758575, Validation Loss: 0.020084360614418983
Epoch 270, Training Loss: 0.013272572308778763, Validation Loss: 0.019752103835344315
Epoch 271, Training Loss: 0.013025321997702122, Validation Loss: 0.019438493996858597
Epoch 272, Training Loss: 0.012782416306436062, Validation Loss: 0.01912030577659607
Epoch 273, Training Loss: 0.012533360160887241, Validation Loss: 0.01880011521279812
Epoch 274, Training Loss: 0.01228177361190319, Validation Loss: 0.018498845398426056
Epoch 275, Training Loss: 0.012040648609399796, Validation Loss: 0.018234748393297195
Epoch 276, Training Loss: 0.011808105744421482, Validation Loss: 0.017954161390662193
Epoch 277, Training Loss: 0.011579102836549282, Validation Loss: 0.017675431445240974
Epoch 278, Training Loss: 0.011361218057572842, Validation Loss: 0.01742059737443924
Epoch 279, Training Loss: 0.011138971894979477, Validation Loss: 0.017147699370980263
Epoch 280, Training Loss: 0.010920794680714607, Validation Loss: 0.016851507127285004
Epoch 281, Training Loss: 0.010695851407945156, Validation Loss: 0.01655489206314087
Epoch 282, Training Loss: 0.010479966178536415, Validation Loss: 0.0162710752338171
Epoch 283, Training Loss: 0.010261664167046547, Validation Loss: 0.015973912551999092
Epoch 284, Training Loss: 0.01005702093243599, Validation Loss: 0.015644151717424393
Epoch 285, Training Loss: 0.009848866611719131, Validation Loss: 0.015363151207566261
Epoch 286, Training Loss: 0.009650030173361301, Validation Loss: 0.015105587430298328
Epoch 287, Training Loss: 0.009452779777348042, Validation Loss: 0.014843473210930824
Epoch 288, Training Loss: 0.009247459471225739, Validation Loss: 0.014593848958611488
Epoch 289, Training Loss: 0.009050491265952587, Validation Loss: 0.01432825904339552
Epoch 290, Training Loss: 0.008854947984218597, Validation Loss: 0.014087260700762272
Epoch 291, Training Loss: 0.008665772154927254, Validation Loss: 0.013846618123352528
Epoch 292, Training Loss: 0.008480215445160866, Validation Loss: 0.013606594875454903
Epoch 293, Training Loss: 0.008305758237838745, Validation Loss: 0.013337169773876667
Epoch 294, Training Loss: 0.00812182854861021, Validation Loss: 0.01308594923466444
Epoch 295, Training Loss: 0.007941830903291702, Validation Loss: 0.012879909947514534
Epoch 296, Training Loss: 0.007767640985548496, Validation Loss: 0.012682282365858555
Epoch 297, Training Loss: 0.007597650866955519, Validation Loss: 0.012464780360460281
Epoch 298, Training Loss: 0.007431232836097479, Validation Loss: 0.01225386280566454
Epoch 299, Training Loss: 0.007272066082805395, Validation Loss: 0.012042492628097534
Epoch 300, Training Loss: 0.007108975201845169, Validation Loss: 0.011835964396595955
Epoch 301, Training Loss: 0.006950352340936661, Validation Loss: 0.011626781895756721
Epoch 302, Training Loss: 0.006800190079957247, Validation Loss: 0.011416091583669186
Epoch 303, Training Loss: 0.006652933079749346, Validation Loss: 0.011211559176445007
Epoch 304, Training Loss: 0.006507917307317257, Validation Loss: 0.01101672276854515
Epoch 305, Training Loss: 0.006363891996443272, Validation Loss: 0.010841229930520058
Epoch 306, Training Loss: 0.006228319834917784, Validation Loss: 0.010652749799191952
Epoch 307, Training Loss: 0.006088958587497473, Validation Loss: 0.010454577393829823
Epoch 308, Training Loss: 0.00595511170104146, Validation Loss: 0.010279778391122818
Epoch 309, Training Loss: 0.005822478793561459, Validation Loss: 0.010126260109245777
Epoch 310, Training Loss: 0.0057001919485628605, Validation Loss: 0.009934893809258938
Epoch 311, Training Loss: 0.0055746776051819324, Validation Loss: 0.009734341874718666
Epoch 312, Training Loss: 0.005450238473713398, Validation Loss: 0.009571077302098274
Epoch 313, Training Loss: 0.005336229223757982, Validation Loss: 0.009382002055644989
Epoch 314, Training Loss: 0.00521819619461894, Validation Loss: 0.009250136092305183
Epoch 315, Training Loss: 0.005102928262203932, Validation Loss: 0.009114447981119156
Epoch 316, Training Loss: 0.0049936845898628235, Validation Loss: 0.008937350474298
Epoch 317, Training Loss: 0.004880805965512991, Validation Loss: 0.008774848654866219
Epoch 318, Training Loss: 0.00477374205365777, Validation Loss: 0.008617992512881756
Epoch 319, Training Loss: 0.004671609029173851, Validation Loss: 0.008454346098005772
Epoch 320, Training Loss: 0.0045676506124436855, Validation Loss: 0.008294859901070595
Epoch 321, Training Loss: 0.004469090141355991, Validation Loss: 0.008125856518745422
Epoch 322, Training Loss: 0.004367358982563019, Validation Loss: 0.007977691479027271
Epoch 323, Training Loss: 0.004271447192877531, Validation Loss: 0.007801814004778862
Epoch 324, Training Loss: 0.004172489978373051, Validation Loss: 0.007663327269256115
Epoch 325, Training Loss: 0.004080125130712986, Validation Loss: 0.007540868129581213
Epoch 326, Training Loss: 0.003989171236753464, Validation Loss: 0.007388796657323837
Epoch 327, Training Loss: 0.0038987044245004654, Validation Loss: 0.007231263443827629
Epoch 328, Training Loss: 0.0038075901102274656, Validation Loss: 0.007099551148712635
Epoch 329, Training Loss: 0.0037237650249153376, Validation Loss: 0.006951114162802696
Epoch 330, Training Loss: 0.0036362861283123493, Validation Loss: 0.006795789580792189
Epoch 331, Training Loss: 0.0035510160960257053, Validation Loss: 0.006642865017056465
Epoch 332, Training Loss: 0.0034682443365454674, Validation Loss: 0.0064816647209227085
Epoch 333, Training Loss: 0.00338869565166533, Validation Loss: 0.00631101056933403
Epoch 334, Training Loss: 0.003305702470242977, Validation Loss: 0.0061693331226706505
Epoch 335, Training Loss: 0.003229948226362467, Validation Loss: 0.006036065053194761
Epoch 336, Training Loss: 0.0031491988338530064, Validation Loss: 0.005902435164898634
Epoch 337, Training Loss: 0.0030741773080080748, Validation Loss: 0.005744450725615025
Epoch 338, Training Loss: 0.0029992584604769945, Validation Loss: 0.0055956714786589146
Epoch 339, Training Loss: 0.0029239088762551546, Validation Loss: 0.0054602231830358505
Epoch 340, Training Loss: 0.00285297236405313, Validation Loss: 0.0053091407753527164
Epoch 341, Training Loss: 0.002780538983643055, Validation Loss: 0.005154648795723915
Epoch 342, Training Loss: 0.0027076774276793003, Validation Loss: 0.005020225420594215
Epoch 343, Training Loss: 0.002640580991283059, Validation Loss: 0.004885218571871519
Epoch 344, Training Loss: 0.0025719054974615574, Validation Loss: 0.004737547133117914
Epoch 345, Training Loss: 0.002503686584532261, Validation Loss: 0.004598016384989023
Epoch 346, Training Loss: 0.0024408057797700167, Validation Loss: 0.004465917591005564
Epoch 347, Training Loss: 0.002376607386395335, Validation Loss: 0.0043519786559045315
Epoch 348, Training Loss: 0.002314049517735839, Validation Loss: 0.0042269425466656685
Epoch 349, Training Loss: 0.002250242978334427, Validation Loss: 0.004103252198547125
Epoch 350, Training Loss: 0.002192426472902298, Validation Loss: 0.003961262293159962
Epoch 351, Training Loss: 0.0021321915555745363, Validation Loss: 0.0038320214953273535
Epoch 352, Training Loss: 0.002074469579383731, Validation Loss: 0.0037101884372532368
Epoch 353, Training Loss: 0.0020171792712062597, Validation Loss: 0.0035973633639514446
Epoch 354, Training Loss: 0.001962369540706277, Validation Loss: 0.0034901073668152094
Epoch 355, Training Loss: 0.001909285900183022, Validation Loss: 0.0033796585630625486
Epoch 356, Training Loss: 0.00185592460911721, Validation Loss: 0.0032608327455818653
Epoch 357, Training Loss: 0.0018004088196903467, Validation Loss: 0.00314592057839036
Epoch 358, Training Loss: 0.0017481782706454396, Validation Loss: 0.0030338854994624853
Epoch 359, Training Loss: 0.0017000584630295634, Validation Loss: 0.0029150662012398243
Epoch 360, Training Loss: 0.001648466568440199, Validation Loss: 0.0028092628344893456
Epoch 361, Training Loss: 0.0015994457062333822, Validation Loss: 0.0027020182460546494
Epoch 362, Training Loss: 0.0015504742041230202, Validation Loss: 0.002610202878713608
Epoch 363, Training Loss: 0.0015017654513940215, Validation Loss: 0.002516207518056035
Epoch 364, Training Loss: 0.0014553017681464553, Validation Loss: 0.0024190391413867474
Epoch 365, Training Loss: 0.0014114693040028214, Validation Loss: 0.002323917346075177
Epoch 366, Training Loss: 0.0013657199451699853, Validation Loss: 0.002244670642539859
Epoch 367, Training Loss: 0.0013227559393271804, Validation Loss: 0.002163745230063796
Epoch 368, Training Loss: 0.0012801497941836715, Validation Loss: 0.0020705026108771563
Epoch 369, Training Loss: 0.0012365069705992937, Validation Loss: 0.0019770220387727022
Epoch 370, Training Loss: 0.0011942590354010463, Validation Loss: 0.0018893005326390266
Epoch 371, Training Loss: 0.0011526501039043069, Validation Loss: 0.0018006982281804085
Epoch 372, Training Loss: 0.0011107681784778833, Validation Loss: 0.00172158342320472
Epoch 373, Training Loss: 0.0010698015103116632, Validation Loss: 0.00164868647698313
Epoch 374, Training Loss: 0.001029908424243331, Validation Loss: 0.0015710329171270132
Epoch 375, Training Loss: 0.0009912310633808374, Validation Loss: 0.0014978807885199785
Epoch 376, Training Loss: 0.0009549636743031442, Validation Loss: 0.0014308119425550103
Epoch 377, Training Loss: 0.0009190930286422372, Validation Loss: 0.001356361317448318
Epoch 378, Training Loss: 0.0008821498486213386, Validation Loss: 0.0012834597146138549
Epoch 379, Training Loss: 0.0008464783895760775, Validation Loss: 0.0012161420891061425
Epoch 380, Training Loss: 0.0008120501879602671, Validation Loss: 0.0011554379016160965
Epoch 381, Training Loss: 0.000779285910539329, Validation Loss: 0.0010962480446323752
Epoch 382, Training Loss: 0.0007468342082574964, Validation Loss: 0.0010428279638290405
Epoch 383, Training Loss: 0.0007156653446145356, Validation Loss: 0.000989615684375167
Epoch 384, Training Loss: 0.0006849548080936074, Validation Loss: 0.000939310877583921
Epoch 385, Training Loss: 0.0006554761785082519, Validation Loss: 0.0008897758671082556
Epoch 386, Training Loss: 0.0006265872507356107, Validation Loss: 0.0008362017688341439
Epoch 387, Training Loss: 0.0005979532725177705, Validation Loss: 0.0007883771904744208
Epoch 388, Training Loss: 0.0005714262370020151, Validation Loss: 0.0007442538626492023
Epoch 389, Training Loss: 0.0005453803460113704, Validation Loss: 0.0007048887782730162
Epoch 390, Training Loss: 0.0005212317337282002, Validation Loss: 0.0006683954852633178
Epoch 391, Training Loss: 0.0004957889905199409, Validation Loss: 0.0006318905507214367
Epoch 392, Training Loss: 0.00047234154772013426, Validation Loss: 0.0005939463153481483
Epoch 393, Training Loss: 0.00044869520934298635, Validation Loss: 0.0005626003257930279
Epoch 394, Training Loss: 0.00042860236135311425, Validation Loss: 0.0005324188387021422
Epoch 395, Training Loss: 0.0004051418509334326, Validation Loss: 0.0005035231588408351
Epoch 396, Training Loss: 0.0003854016540572047, Validation Loss: 0.0004704869934357703
Epoch 397, Training Loss: 0.000365130283171311, Validation Loss: 0.00043885124614462256
Epoch 398, Training Loss: 0.00034636285272426903, Validation Loss: 0.0004110740264877677
Epoch 399, Training Loss: 0.0003282043326180428, Validation Loss: 0.00038796887383796275
Epoch 400, Training Loss: 0.00031065341318026185, Validation Loss: 0.0003663297975435853
Epoch 401, Training Loss: 0.000292917771730572, Validation Loss: 0.0003471458039712161
Epoch 402, Training Loss: 0.0002778859343379736, Validation Loss: 0.0003260204102844
Epoch 403, Training Loss: 0.00026178627740591764, Validation Loss: 0.00030582735780626535
Epoch 404, Training Loss: 0.0002475873043294996, Validation Loss: 0.0002829361765179783
Epoch 405, Training Loss: 0.00023273118131328374, Validation Loss: 0.00026319894823245704
Epoch 406, Training Loss: 0.00021925781038589776, Validation Loss: 0.0002462537377141416
Epoch 407, Training Loss: 0.00020557460084091872, Validation Loss: 0.0002333708544028923
Epoch 408, Training Loss: 0.00019487152167130262, Validation Loss: 0.00021612456475850195
Epoch 409, Training Loss: 0.00018175072909798473, Validation Loss: 0.00020137050887569785
Epoch 410, Training Loss: 0.00017105488223023713, Validation Loss: 0.00018704522517509758
Epoch 411, Training Loss: 0.00015962841280270368, Validation Loss: 0.00017481147369835526
Epoch 412, Training Loss: 0.0001499541976954788, Validation Loss: 0.00016135409532580525
Epoch 413, Training Loss: 0.00013949559070169926, Validation Loss: 0.0001513155148131773
Epoch 414, Training Loss: 0.00013247501919977367, Validation Loss: 0.00014156843826640397
Epoch 415, Training Loss: 0.00012399772822391242, Validation Loss: 0.00013379272422753274
Epoch 416, Training Loss: 0.00011626882042037323, Validation Loss: 0.00012576609151437879
Epoch 417, Training Loss: 0.00010884500079555437, Validation Loss: 0.00011680343595799059
Epoch 418, Training Loss: 0.00010136943456018344, Validation Loss: 0.00010901905625360087
Epoch 419, Training Loss: 9.496101847616956e-05, Validation Loss: 0.00010112517338711768
Epoch 420, Training Loss: 8.829732541926205e-05, Validation Loss: 9.397403482580557e-05
Epoch 421, Training Loss: 8.195708505809307e-05, Validation Loss: 8.73071257956326e-05
Epoch 422, Training Loss: 7.651610212633386e-05, Validation Loss: 8.016957872314379e-05
Epoch 423, Training Loss: 7.112919411156327e-05, Validation Loss: 7.455216837115586e-05
Epoch 424, Training Loss: 6.634879537159577e-05, Validation Loss: 6.963259511394426e-05
Epoch 425, Training Loss: 6.168079562485218e-05, Validation Loss: 6.500920426333323e-05
Epoch 426, Training Loss: 5.739285552408546e-05, Validation Loss: 5.9925274399574846e-05
Epoch 427, Training Loss: 5.307756146066822e-05, Validation Loss: 5.5343964049825445e-05
Epoch 428, Training Loss: 4.9189318815479055e-05, Validation Loss: 5.12140613864176e-05
Epoch 429, Training Loss: 4.56456073152367e-05, Validation Loss: 4.737397830467671e-05
Epoch 430, Training Loss: 4.2450777982594445e-05, Validation Loss: 4.3274845666019246e-05
Epoch 431, Training Loss: 3.9189719245769083e-05, Validation Loss: 3.957430089940317e-05
Epoch 432, Training Loss: 3.6303299566498026e-05, Validation Loss: 3.630405990406871e-05
Epoch 433, Training Loss: 3.3486234315205365e-05, Validation Loss: 3.3467134926468134e-05
Epoch 434, Training Loss: 3.098928209510632e-05, Validation Loss: 3.052269312320277e-05
Epoch 435, Training Loss: 2.846219103957992e-05, Validation Loss: 2.8023139748256654e-05
Epoch 436, Training Loss: 2.6329349566367455e-05, Validation Loss: 2.5776249458431266e-05
Epoch 437, Training Loss: 2.4260394638986327e-05, Validation Loss: 2.36925516219344e-05
Epoch 438, Training Loss: 2.2243935745791532e-05, Validation Loss: 2.1727044440922327e-05
Epoch 439, Training Loss: 2.0432868041098118e-05, Validation Loss: 1.990776763705071e-05
Epoch 440, Training Loss: 1.877045724540949e-05, Validation Loss: 1.8222293874714524e-05
Epoch 441, Training Loss: 1.7208974895766005e-05, Validation Loss: 1.6747730114730075e-05
Epoch 442, Training Loss: 1.5811901903362013e-05, Validation Loss: 1.526496089354623e-05
Epoch 443, Training Loss: 1.443161818315275e-05, Validation Loss: 1.3886045962863136e-05
Epoch 444, Training Loss: 1.3199948625697289e-05, Validation Loss: 1.2656828403123654e-05
Epoch 445, Training Loss: 1.2123238775529899e-05, Validation Loss: 1.15741859190166e-05
Epoch 446, Training Loss: 1.1163165254401974e-05, Validation Loss: 1.0582680260995403e-05
Epoch 447, Training Loss: 1.0175614079344086e-05, Validation Loss: 9.671079169493169e-06
Epoch 448, Training Loss: 9.227253030985594e-06, Validation Loss: 8.852711289364379e-06
Epoch 449, Training Loss: 8.387309208046645e-06, Validation Loss: 8.132485163514502e-06
Epoch 450, Training Loss: 7.64348624215927e-06, Validation Loss: 7.4361478255013935e-06
Epoch 451, Training Loss: 6.924778517714003e-06, Validation Loss: 6.82674954077811e-06
Epoch 452, Training Loss: 6.301810117292916e-06, Validation Loss: 6.298125299508683e-06
Epoch 453, Training Loss: 5.755620804848149e-06, Validation Loss: 5.76199772694963e-06
Epoch 454, Training Loss: 5.223474545346107e-06, Validation Loss: 5.2052778301003855e-06
Epoch 455, Training Loss: 4.698340035247384e-06, Validation Loss: 4.749203526444035e-06
Epoch 456, Training Loss: 4.26303540734807e-06, Validation Loss: 4.370037913759006e-06
Epoch 457, Training Loss: 3.871396529575577e-06, Validation Loss: 4.034476205561077e-06
Epoch 458, Training Loss: 3.509289172143326e-06, Validation Loss: 3.7129427710169693e-06
Epoch 459, Training Loss: 3.1646502520743525e-06, Validation Loss: 3.419720997044351e-06
Epoch 460, Training Loss: 2.8608458251255797e-06, Validation Loss: 3.1484223654842936e-06
Epoch 461, Training Loss: 2.594006900835666e-06, Validation Loss: 2.907381258410169e-06
Epoch 462, Training Loss: 2.3577738375024637e-06, Validation Loss: 2.6717011678556446e-06
Epoch 463, Training Loss: 2.1294724774634233e-06, Validation Loss: 2.4413961909885984e-06
Epoch 464, Training Loss: 1.917317149491282e-06, Validation Loss: 2.239241439383477e-06
Epoch 465, Training Loss: 1.7410466170986183e-06, Validation Loss: 2.052072431979468e-06
Epoch 466, Training Loss: 1.5818027350178454e-06, Validation Loss: 1.876911142062454e-06
Epoch 467, Training Loss: 1.4357470945469686e-06, Validation Loss: 1.7157669844891643e-06
Epoch 468, Training Loss: 1.2989632978133159e-06, Validation Loss: 1.5752925719425548e-06
Epoch 469, Training Loss: 1.1721082273652428e-06, Validation Loss: 1.4625331914430717e-06
Epoch 470, Training Loss: 1.066557047124661e-06, Validation Loss: 1.3442448789646733e-06
Epoch 471, Training Loss: 9.641487395128934e-07, Validation Loss: 1.2302720051593496e-06
Epoch 472, Training Loss: 8.730414151614241e-07, Validation Loss: 1.1354115940775955e-06
Epoch 473, Training Loss: 8.004629421520804e-07, Validation Loss: 1.037813945004018e-06
Epoch 474, Training Loss: 7.269819661814836e-07, Validation Loss: 9.449996127841587e-07
Epoch 475, Training Loss: 6.581888669643376e-07, Validation Loss: 8.644913123134756e-07
Epoch 476, Training Loss: 6.006349622111884e-07, Validation Loss: 7.88682086749759e-07
Epoch 477, Training Loss: 5.487132170856057e-07, Validation Loss: 7.218712880785461e-07
Epoch 478, Training Loss: 5.023863423048169e-07, Validation Loss: 6.613119012399693e-07
Epoch 479, Training Loss: 4.570217981836322e-07, Validation Loss: 6.105944407863717e-07
Epoch 480, Training Loss: 4.17687601839134e-07, Validation Loss: 5.640885660795902e-07
Epoch 481, Training Loss: 3.8392983015000937e-07, Validation Loss: 5.164080221220502e-07
Epoch 482, Training Loss: 3.521852249832591e-07, Validation Loss: 4.7288486371144245e-07
Epoch 483, Training Loss: 3.2443000463899807e-07, Validation Loss: 4.318024480198801e-07
Epoch 484, Training Loss: 2.978846396217705e-07, Validation Loss: 3.937001338272239e-07
Epoch 485, Training Loss: 2.729678101331956e-07, Validation Loss: 3.608197971516347e-07
Epoch 486, Training Loss: 2.5169617856590776e-07, Validation Loss: 3.307534939267498e-07
Epoch 487, Training Loss: 2.3254314385212638e-07, Validation Loss: 3.040604497073218e-07
Epoch 488, Training Loss: 2.1509461589630519e-07, Validation Loss: 2.79539108305471e-07
Epoch 489, Training Loss: 1.982301682801335e-07, Validation Loss: 2.5833006134234893e-07
Epoch 490, Training Loss: 1.832031415460733e-07, Validation Loss: 2.397641480911261e-07
Epoch 491, Training Loss: 1.696401881190468e-07, Validation Loss: 2.224415140972269e-07
Epoch 492, Training Loss: 1.566248641893253e-07, Validation Loss: 2.0687069479663478e-07
Epoch 493, Training Loss: 1.452069966489944e-07, Validation Loss: 1.9067056200583465e-07
Epoch 494, Training Loss: 1.343260151998038e-07, Validation Loss: 1.7413108821529022e-07
Epoch 495, Training Loss: 1.239889684256923e-07, Validation Loss: 1.584377287144889e-07
Epoch 496, Training Loss: 1.1439307456839742e-07, Validation Loss: 1.4408621495931584e-07
Epoch 497, Training Loss: 1.0553575435778839e-07, Validation Loss: 1.3194278380979085e-07
Epoch 498, Training Loss: 9.794707267474223e-08, Validation Loss: 1.203972885832627e-07
Epoch 499, Training Loss: 9.043165505318029e-08, Validation Loss: 1.0977884556950812e-07
Epoch 500, Training Loss: 8.326283307269478e-08, Validation Loss: 1.0056549371029178e-07
