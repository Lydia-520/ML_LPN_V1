Epoch 1, Training Loss: 0.24976375699043274, Validation Loss: 0.2942982614040375
Epoch 2, Training Loss: 0.2488759160041809, Validation Loss: 0.2932797968387604
Epoch 3, Training Loss: 0.24799296259880066, Validation Loss: 0.2922590672969818
Epoch 4, Training Loss: 0.24711181223392487, Validation Loss: 0.2912321984767914
Epoch 5, Training Loss: 0.24622777104377747, Validation Loss: 0.29020798206329346
Epoch 6, Training Loss: 0.24534353613853455, Validation Loss: 0.2891794741153717
Epoch 7, Training Loss: 0.24445442855358124, Validation Loss: 0.28813785314559937
Epoch 8, Training Loss: 0.2435513734817505, Validation Loss: 0.28708067536354065
Epoch 9, Training Loss: 0.24263544380664825, Validation Loss: 0.28601139783859253
Epoch 10, Training Loss: 0.24171094596385956, Validation Loss: 0.28492632508277893
Epoch 11, Training Loss: 0.24076732993125916, Validation Loss: 0.2838210165500641
Epoch 12, Training Loss: 0.239802747964859, Validation Loss: 0.2826921045780182
Epoch 13, Training Loss: 0.23882097005844116, Validation Loss: 0.28154855966567993
Epoch 14, Training Loss: 0.23782452940940857, Validation Loss: 0.28037819266319275
Epoch 15, Training Loss: 0.23680852353572845, Validation Loss: 0.27917906641960144
Epoch 16, Training Loss: 0.23577328026294708, Validation Loss: 0.2779635488986969
Epoch 17, Training Loss: 0.23471692204475403, Validation Loss: 0.27671679854393005
Epoch 18, Training Loss: 0.2336353212594986, Validation Loss: 0.2754669785499573
Epoch 19, Training Loss: 0.23255299031734467, Validation Loss: 0.27420324087142944
Epoch 20, Training Loss: 0.23145602643489838, Validation Loss: 0.2729122042655945
Epoch 21, Training Loss: 0.2303277552127838, Validation Loss: 0.2715701460838318
Epoch 22, Training Loss: 0.2291724532842636, Validation Loss: 0.2702431380748749
Epoch 23, Training Loss: 0.22802738845348358, Validation Loss: 0.2688712179660797
Epoch 24, Training Loss: 0.2268415242433548, Validation Loss: 0.2674466073513031
Epoch 25, Training Loss: 0.22560736536979675, Validation Loss: 0.2659494876861572
Epoch 26, Training Loss: 0.2243129312992096, Validation Loss: 0.26438355445861816
Epoch 27, Training Loss: 0.2229585349559784, Validation Loss: 0.2627342641353607
Epoch 28, Training Loss: 0.22153356671333313, Validation Loss: 0.2610434889793396
Epoch 29, Training Loss: 0.22006890177726746, Validation Loss: 0.25930124521255493
Epoch 30, Training Loss: 0.2185593694448471, Validation Loss: 0.257468581199646
Epoch 31, Training Loss: 0.21698398888111115, Validation Loss: 0.2555302679538727
Epoch 32, Training Loss: 0.2153274565935135, Validation Loss: 0.2534896731376648
Epoch 33, Training Loss: 0.21358120441436768, Validation Loss: 0.2513142228126526
Epoch 34, Training Loss: 0.21171772480010986, Validation Loss: 0.24900870025157928
Epoch 35, Training Loss: 0.20974783599376678, Validation Loss: 0.24659615755081177
Epoch 36, Training Loss: 0.20768703520298004, Validation Loss: 0.2440379112958908
Epoch 37, Training Loss: 0.20551306009292603, Validation Loss: 0.24132612347602844
Epoch 38, Training Loss: 0.20321549475193024, Validation Loss: 0.23844243586063385
Epoch 39, Training Loss: 0.20077551901340485, Validation Loss: 0.23537418246269226
Epoch 40, Training Loss: 0.19818097352981567, Validation Loss: 0.23206743597984314
Epoch 41, Training Loss: 0.19541306793689728, Validation Loss: 0.2285510152578354
Epoch 42, Training Loss: 0.1924818605184555, Validation Loss: 0.2248212844133377
Epoch 43, Training Loss: 0.18938982486724854, Validation Loss: 0.22088366746902466
Epoch 44, Training Loss: 0.18614013493061066, Validation Loss: 0.21670958399772644
Epoch 45, Training Loss: 0.1827087104320526, Validation Loss: 0.21232707798480988
Epoch 46, Training Loss: 0.17913125455379486, Validation Loss: 0.20773306488990784
Epoch 47, Training Loss: 0.1754124015569687, Validation Loss: 0.2029242217540741
Epoch 48, Training Loss: 0.17156434059143066, Validation Loss: 0.19798535108566284
Epoch 49, Training Loss: 0.1676366925239563, Validation Loss: 0.19290781021118164
Epoch 50, Training Loss: 0.16365347802639008, Validation Loss: 0.18770824372768402
Epoch 51, Training Loss: 0.1596258133649826, Validation Loss: 0.18245668709278107
Epoch 52, Training Loss: 0.15561054646968842, Validation Loss: 0.17723484337329865
Epoch 53, Training Loss: 0.15169331431388855, Validation Loss: 0.17208313941955566
Epoch 54, Training Loss: 0.14793220162391663, Validation Loss: 0.16709347069263458
Epoch 55, Training Loss: 0.14439880847930908, Validation Loss: 0.16237154603004456
Epoch 56, Training Loss: 0.141189306974411, Validation Loss: 0.15803749859333038
Epoch 57, Training Loss: 0.13839198648929596, Validation Loss: 0.1542031317949295
Epoch 58, Training Loss: 0.13608701527118683, Validation Loss: 0.15090574324131012
Epoch 59, Training Loss: 0.134306862950325, Validation Loss: 0.14815878868103027
Epoch 60, Training Loss: 0.13298778235912323, Validation Loss: 0.14588959515094757
Epoch 61, Training Loss: 0.13202348351478577, Validation Loss: 0.14400453865528107
Epoch 62, Training Loss: 0.1312703639268875, Validation Loss: 0.14237762987613678
Epoch 63, Training Loss: 0.1305730640888214, Validation Loss: 0.1409529447555542
Epoch 64, Training Loss: 0.12983117997646332, Validation Loss: 0.13958315551280975
Epoch 65, Training Loss: 0.1288924217224121, Validation Loss: 0.13822036981582642
Epoch 66, Training Loss: 0.12772177159786224, Validation Loss: 0.1368698924779892
Epoch 67, Training Loss: 0.1263706237077713, Validation Loss: 0.13556399941444397
Epoch 68, Training Loss: 0.12490182369947433, Validation Loss: 0.13436394929885864
Epoch 69, Training Loss: 0.12340069562196732, Validation Loss: 0.1333278864622116
Epoch 70, Training Loss: 0.1219593733549118, Validation Loss: 0.13249079883098602
Epoch 71, Training Loss: 0.1206473857164383, Validation Loss: 0.1318587064743042
Epoch 72, Training Loss: 0.1195126324892044, Validation Loss: 0.13141702115535736
Epoch 73, Training Loss: 0.11856728047132492, Validation Loss: 0.13110952079296112
Epoch 74, Training Loss: 0.11779607087373734, Validation Loss: 0.13087265193462372
Epoch 75, Training Loss: 0.11714862287044525, Validation Loss: 0.1306641846895218
Epoch 76, Training Loss: 0.11659421026706696, Validation Loss: 0.13044452667236328
Epoch 77, Training Loss: 0.1161036267876625, Validation Loss: 0.13017351925373077
Epoch 78, Training Loss: 0.11563970893621445, Validation Loss: 0.12983106076717377
Epoch 79, Training Loss: 0.11518297344446182, Validation Loss: 0.12942415475845337
Epoch 80, Training Loss: 0.11473102122545242, Validation Loss: 0.128960981965065
Epoch 81, Training Loss: 0.11427320539951324, Validation Loss: 0.12841789424419403
Epoch 82, Training Loss: 0.11378289014101028, Validation Loss: 0.12782719731330872
Epoch 83, Training Loss: 0.11329203844070435, Validation Loss: 0.12720414996147156
Epoch 84, Training Loss: 0.11281861364841461, Validation Loss: 0.1265547275543213
Epoch 85, Training Loss: 0.11235956102609634, Validation Loss: 0.12592506408691406
Epoch 86, Training Loss: 0.11195146292448044, Validation Loss: 0.1252930909395218
Epoch 87, Training Loss: 0.11156081408262253, Validation Loss: 0.12466618418693542
Epoch 88, Training Loss: 0.11117799580097198, Validation Loss: 0.12405452132225037
Epoch 89, Training Loss: 0.11079778522253036, Validation Loss: 0.12345859408378601
Epoch 90, Training Loss: 0.11042602360248566, Validation Loss: 0.12288659065961838
Epoch 91, Training Loss: 0.11006695032119751, Validation Loss: 0.12234951555728912
Epoch 92, Training Loss: 0.10970005393028259, Validation Loss: 0.12183728814125061
Epoch 93, Training Loss: 0.10931722074747086, Validation Loss: 0.1213456466794014
Epoch 94, Training Loss: 0.10892000794410706, Validation Loss: 0.12086846679449081
Epoch 95, Training Loss: 0.10850152373313904, Validation Loss: 0.1203945130109787
Epoch 96, Training Loss: 0.10806673765182495, Validation Loss: 0.11993259936571121
Epoch 97, Training Loss: 0.10762668401002884, Validation Loss: 0.11947793513536453
Epoch 98, Training Loss: 0.10717436671257019, Validation Loss: 0.11902385205030441
Epoch 99, Training Loss: 0.10672252625226974, Validation Loss: 0.11854364722967148
Epoch 100, Training Loss: 0.1062680184841156, Validation Loss: 0.11803345382213593
Epoch 101, Training Loss: 0.10580604523420334, Validation Loss: 0.11747585237026215
Epoch 102, Training Loss: 0.10532788187265396, Validation Loss: 0.11687231808900833
Epoch 103, Training Loss: 0.10483739525079727, Validation Loss: 0.11623319983482361
Epoch 104, Training Loss: 0.10433287918567657, Validation Loss: 0.11555001139640808
Epoch 105, Training Loss: 0.10380715876817703, Validation Loss: 0.11482439190149307
Epoch 106, Training Loss: 0.1032596230506897, Validation Loss: 0.11405771970748901
Epoch 107, Training Loss: 0.10268788784742355, Validation Loss: 0.1132618859410286
Epoch 108, Training Loss: 0.10209657996892929, Validation Loss: 0.11244572699069977
Epoch 109, Training Loss: 0.10148415714502335, Validation Loss: 0.11160434037446976
Epoch 110, Training Loss: 0.100845567882061, Validation Loss: 0.11073222011327744
Epoch 111, Training Loss: 0.1001807227730751, Validation Loss: 0.1098354160785675
Epoch 112, Training Loss: 0.0994894802570343, Validation Loss: 0.10891006886959076
Epoch 113, Training Loss: 0.09877496212720871, Validation Loss: 0.10795837640762329
Epoch 114, Training Loss: 0.09803130477666855, Validation Loss: 0.10700290650129318
Epoch 115, Training Loss: 0.09725949913263321, Validation Loss: 0.10602428764104843
Epoch 116, Training Loss: 0.09645078331232071, Validation Loss: 0.1049899011850357
Epoch 117, Training Loss: 0.0955946296453476, Validation Loss: 0.10393601655960083
Epoch 118, Training Loss: 0.09470859915018082, Validation Loss: 0.10283538699150085
Epoch 119, Training Loss: 0.09379944950342178, Validation Loss: 0.10169974714517593
Epoch 120, Training Loss: 0.09284606575965881, Validation Loss: 0.10051637887954712
Epoch 121, Training Loss: 0.09185995161533356, Validation Loss: 0.09929251670837402
Epoch 122, Training Loss: 0.09084460139274597, Validation Loss: 0.09802435338497162
Epoch 123, Training Loss: 0.0897938534617424, Validation Loss: 0.09672018885612488
Epoch 124, Training Loss: 0.08869671821594238, Validation Loss: 0.09541069716215134
Epoch 125, Training Loss: 0.08757254481315613, Validation Loss: 0.09408126026391983
Epoch 126, Training Loss: 0.08642195910215378, Validation Loss: 0.09279240667819977
Epoch 127, Training Loss: 0.08527933806180954, Validation Loss: 0.0915725976228714
Epoch 128, Training Loss: 0.08414465188980103, Validation Loss: 0.09038636088371277
Epoch 129, Training Loss: 0.08300870656967163, Validation Loss: 0.08923408389091492
Epoch 130, Training Loss: 0.08188293874263763, Validation Loss: 0.08811900019645691
Epoch 131, Training Loss: 0.0807785838842392, Validation Loss: 0.08705893158912659
Epoch 132, Training Loss: 0.07970983535051346, Validation Loss: 0.08608491718769073
Epoch 133, Training Loss: 0.07867851853370667, Validation Loss: 0.08520737290382385
Epoch 134, Training Loss: 0.07768314331769943, Validation Loss: 0.08440234512090683
Epoch 135, Training Loss: 0.07670988887548447, Validation Loss: 0.08367794007062912
Epoch 136, Training Loss: 0.0757741928100586, Validation Loss: 0.08303637057542801
Epoch 137, Training Loss: 0.07492300122976303, Validation Loss: 0.0824277251958847
Epoch 138, Training Loss: 0.07410652935504913, Validation Loss: 0.08183715492486954
Epoch 139, Training Loss: 0.07334130257368088, Validation Loss: 0.0812942162156105
Epoch 140, Training Loss: 0.07262369245290756, Validation Loss: 0.08079212158918381
Epoch 141, Training Loss: 0.07196419686079025, Validation Loss: 0.0803263857960701
Epoch 142, Training Loss: 0.07135996222496033, Validation Loss: 0.07988554239273071
Epoch 143, Training Loss: 0.07079360634088516, Validation Loss: 0.07948044687509537
Epoch 144, Training Loss: 0.07027162611484528, Validation Loss: 0.07913181930780411
Epoch 145, Training Loss: 0.0698033943772316, Validation Loss: 0.07883631438016891
Epoch 146, Training Loss: 0.06936705112457275, Validation Loss: 0.07857289910316467
Epoch 147, Training Loss: 0.068959541618824, Validation Loss: 0.0783432126045227
Epoch 148, Training Loss: 0.06859157979488373, Validation Loss: 0.0781235545873642
Epoch 149, Training Loss: 0.06824955344200134, Validation Loss: 0.07788477838039398
Epoch 150, Training Loss: 0.06791360676288605, Validation Loss: 0.07762609422206879
Epoch 151, Training Loss: 0.06759041547775269, Validation Loss: 0.0773467868566513
Epoch 152, Training Loss: 0.0672881230711937, Validation Loss: 0.07701890915632248
Epoch 153, Training Loss: 0.06698343902826309, Validation Loss: 0.0766667053103447
Epoch 154, Training Loss: 0.06667307764291763, Validation Loss: 0.07629794627428055
Epoch 155, Training Loss: 0.06638597697019577, Validation Loss: 0.07591990381479263
Epoch 156, Training Loss: 0.066099613904953, Validation Loss: 0.07554488629102707
Epoch 157, Training Loss: 0.06581167131662369, Validation Loss: 0.07518170028924942
Epoch 158, Training Loss: 0.06552565097808838, Validation Loss: 0.07482544332742691
Epoch 159, Training Loss: 0.06524597108364105, Validation Loss: 0.07447675615549088
Epoch 160, Training Loss: 0.06496479362249374, Validation Loss: 0.07414094358682632
Epoch 161, Training Loss: 0.0646912157535553, Validation Loss: 0.07382724434137344
Epoch 162, Training Loss: 0.06442089378833771, Validation Loss: 0.07353249192237854
Epoch 163, Training Loss: 0.06416159868240356, Validation Loss: 0.07324664294719696
Epoch 164, Training Loss: 0.0639130249619484, Validation Loss: 0.07295701652765274
Epoch 165, Training Loss: 0.06367633491754532, Validation Loss: 0.0726824402809143
Epoch 166, Training Loss: 0.06344921141862869, Validation Loss: 0.07241217792034149
Epoch 167, Training Loss: 0.0632297471165657, Validation Loss: 0.07214710861444473
Epoch 168, Training Loss: 0.06300574541091919, Validation Loss: 0.07187867164611816
Epoch 169, Training Loss: 0.06278666853904724, Validation Loss: 0.07162848860025406
Epoch 170, Training Loss: 0.06257647275924683, Validation Loss: 0.07137521356344223
Epoch 171, Training Loss: 0.06236213818192482, Validation Loss: 0.07111155241727829
Epoch 172, Training Loss: 0.06213824450969696, Validation Loss: 0.07084450870752335
Epoch 173, Training Loss: 0.06191415339708328, Validation Loss: 0.0705811083316803
Epoch 174, Training Loss: 0.06169012933969498, Validation Loss: 0.07033045589923859
Epoch 175, Training Loss: 0.061465512961149216, Validation Loss: 0.07007153332233429
Epoch 176, Training Loss: 0.06123999133706093, Validation Loss: 0.06980009377002716
Epoch 177, Training Loss: 0.06101560965180397, Validation Loss: 0.06951572000980377
Epoch 178, Training Loss: 0.060786496847867966, Validation Loss: 0.06923912465572357
Epoch 179, Training Loss: 0.06055380403995514, Validation Loss: 0.06898777186870575
Epoch 180, Training Loss: 0.06031322851777077, Validation Loss: 0.06874139606952667
Epoch 181, Training Loss: 0.06007224693894386, Validation Loss: 0.06848780065774918
Epoch 182, Training Loss: 0.05981823429465294, Validation Loss: 0.06822621077299118
Epoch 183, Training Loss: 0.059567563235759735, Validation Loss: 0.06792989373207092
Epoch 184, Training Loss: 0.059306614100933075, Validation Loss: 0.0675995945930481
Epoch 185, Training Loss: 0.059044305235147476, Validation Loss: 0.06724345684051514
Epoch 186, Training Loss: 0.05877574905753136, Validation Loss: 0.066910520195961
Epoch 187, Training Loss: 0.058502014726400375, Validation Loss: 0.06657412648200989
Epoch 188, Training Loss: 0.058223046362400055, Validation Loss: 0.06626082956790924
Epoch 189, Training Loss: 0.05793965235352516, Validation Loss: 0.0659290999174118
Epoch 190, Training Loss: 0.05765252187848091, Validation Loss: 0.06557489186525345
Epoch 191, Training Loss: 0.05736203491687775, Validation Loss: 0.06519535928964615
Epoch 192, Training Loss: 0.05705973878502846, Validation Loss: 0.06480160355567932
Epoch 193, Training Loss: 0.05675031244754791, Validation Loss: 0.06438805162906647
Epoch 194, Training Loss: 0.05643005669116974, Validation Loss: 0.06398172676563263
Epoch 195, Training Loss: 0.05609896779060364, Validation Loss: 0.06355055421590805
Epoch 196, Training Loss: 0.05574974790215492, Validation Loss: 0.06311701983213425
Epoch 197, Training Loss: 0.05539597570896149, Validation Loss: 0.06265997886657715
Epoch 198, Training Loss: 0.055027980357408524, Validation Loss: 0.062191441655159
Epoch 199, Training Loss: 0.054643917828798294, Validation Loss: 0.06171311065554619
Epoch 200, Training Loss: 0.05425660312175751, Validation Loss: 0.061243318021297455
Epoch 201, Training Loss: 0.053860872983932495, Validation Loss: 0.060788463801145554
Epoch 202, Training Loss: 0.05346152186393738, Validation Loss: 0.060315657407045364
Epoch 203, Training Loss: 0.053037721663713455, Validation Loss: 0.059811726212501526
Epoch 204, Training Loss: 0.05260051041841507, Validation Loss: 0.05927374213933945
Epoch 205, Training Loss: 0.052151039242744446, Validation Loss: 0.05869748443365097
Epoch 206, Training Loss: 0.051667600870132446, Validation Loss: 0.05813460052013397
Epoch 207, Training Loss: 0.0511728897690773, Validation Loss: 0.05757194384932518
Epoch 208, Training Loss: 0.050656918436288834, Validation Loss: 0.057012494653463364
Epoch 209, Training Loss: 0.05011727288365364, Validation Loss: 0.05641698092222214
Epoch 210, Training Loss: 0.049562033265829086, Validation Loss: 0.05580587312579155
Epoch 211, Training Loss: 0.04898630827665329, Validation Loss: 0.055218443274497986
Epoch 212, Training Loss: 0.04841935262084007, Validation Loss: 0.05464489758014679
Epoch 213, Training Loss: 0.047860708087682724, Validation Loss: 0.054003819823265076
Epoch 214, Training Loss: 0.04727382957935333, Validation Loss: 0.05333288386464119
Epoch 215, Training Loss: 0.04667644575238228, Validation Loss: 0.05261627212166786
Epoch 216, Training Loss: 0.04606090486049652, Validation Loss: 0.05188459903001785
Epoch 217, Training Loss: 0.045441895723342896, Validation Loss: 0.05122208967804909
Epoch 218, Training Loss: 0.04481884837150574, Validation Loss: 0.05052024871110916
Epoch 219, Training Loss: 0.044159866869449615, Validation Loss: 0.049801696091890335
Epoch 220, Training Loss: 0.04349938780069351, Validation Loss: 0.04907253384590149
Epoch 221, Training Loss: 0.04285630211234093, Validation Loss: 0.04836037755012512
Epoch 222, Training Loss: 0.0421869121491909, Validation Loss: 0.04761345684528351
Epoch 223, Training Loss: 0.04148389771580696, Validation Loss: 0.04687345027923584
Epoch 224, Training Loss: 0.04078800603747368, Validation Loss: 0.04607507586479187
Epoch 225, Training Loss: 0.04010009765625, Validation Loss: 0.04522525519132614
Epoch 226, Training Loss: 0.03941578418016434, Validation Loss: 0.0444808192551136
Epoch 227, Training Loss: 0.038740284740924835, Validation Loss: 0.04369239881634712
Epoch 228, Training Loss: 0.03806143254041672, Validation Loss: 0.04291151463985443
Epoch 229, Training Loss: 0.037365030497312546, Validation Loss: 0.042145319283008575
Epoch 230, Training Loss: 0.036693867295980453, Validation Loss: 0.04141080006957054
Epoch 231, Training Loss: 0.03601831942796707, Validation Loss: 0.04069754481315613
Epoch 232, Training Loss: 0.03535003587603569, Validation Loss: 0.03994636610150337
Epoch 233, Training Loss: 0.03469885140657425, Validation Loss: 0.039171770215034485
Epoch 234, Training Loss: 0.03404664620757103, Validation Loss: 0.03847230225801468
Epoch 235, Training Loss: 0.033422715961933136, Validation Loss: 0.03780771419405937
Epoch 236, Training Loss: 0.0328037329018116, Validation Loss: 0.037167999893426895
Epoch 237, Training Loss: 0.03218686580657959, Validation Loss: 0.0365278460085392
Epoch 238, Training Loss: 0.031605638563632965, Validation Loss: 0.03588959202170372
Epoch 239, Training Loss: 0.031010476872324944, Validation Loss: 0.035310789942741394
Epoch 240, Training Loss: 0.030423559248447418, Validation Loss: 0.034696582704782486
Epoch 241, Training Loss: 0.029839061200618744, Validation Loss: 0.03409329801797867
Epoch 242, Training Loss: 0.02926582656800747, Validation Loss: 0.033484406769275665
Epoch 243, Training Loss: 0.028719358146190643, Validation Loss: 0.032845497131347656
Epoch 244, Training Loss: 0.02816697768867016, Validation Loss: 0.0321820005774498
Epoch 245, Training Loss: 0.027611125260591507, Validation Loss: 0.03156429901719093
Epoch 246, Training Loss: 0.02707408182322979, Validation Loss: 0.030989941209554672
Epoch 247, Training Loss: 0.026536570861935616, Validation Loss: 0.03043144755065441
Epoch 248, Training Loss: 0.025995193049311638, Validation Loss: 0.029911793768405914
Epoch 249, Training Loss: 0.025472985580563545, Validation Loss: 0.029381509870290756
Epoch 250, Training Loss: 0.024997515603899956, Validation Loss: 0.028900587931275368
Epoch 251, Training Loss: 0.02453223429620266, Validation Loss: 0.028411878272891045
Epoch 252, Training Loss: 0.024069562554359436, Validation Loss: 0.02791932038962841
Epoch 253, Training Loss: 0.023605363443493843, Validation Loss: 0.02738235704600811
Epoch 254, Training Loss: 0.023148123174905777, Validation Loss: 0.02690816856920719
Epoch 255, Training Loss: 0.022705554962158203, Validation Loss: 0.026490533724427223
Epoch 256, Training Loss: 0.022282302379608154, Validation Loss: 0.02607550099492073
Epoch 257, Training Loss: 0.021866682916879654, Validation Loss: 0.025665858760476112
Epoch 258, Training Loss: 0.021450100466609, Validation Loss: 0.025247523561120033
Epoch 259, Training Loss: 0.021038955077528954, Validation Loss: 0.02481861598789692
Epoch 260, Training Loss: 0.020645413547754288, Validation Loss: 0.024433914572000504
Epoch 261, Training Loss: 0.020254826173186302, Validation Loss: 0.02408885769546032
Epoch 262, Training Loss: 0.019885549321770668, Validation Loss: 0.02373925782740116
Epoch 263, Training Loss: 0.019519230350852013, Validation Loss: 0.023383447900414467
Epoch 264, Training Loss: 0.019165141507983208, Validation Loss: 0.023012502118945122
Epoch 265, Training Loss: 0.018818078562617302, Validation Loss: 0.022637777030467987
Epoch 266, Training Loss: 0.018486691638827324, Validation Loss: 0.022316530346870422
Epoch 267, Training Loss: 0.018163934350013733, Validation Loss: 0.02201846055686474
Epoch 268, Training Loss: 0.01784956455230713, Validation Loss: 0.02173496223986149
Epoch 269, Training Loss: 0.017539840191602707, Validation Loss: 0.02145536243915558
Epoch 270, Training Loss: 0.01723422296345234, Validation Loss: 0.021214481443166733
Epoch 271, Training Loss: 0.016944780945777893, Validation Loss: 0.020986825227737427
Epoch 272, Training Loss: 0.01666400022804737, Validation Loss: 0.020741691812872887
Epoch 273, Training Loss: 0.01637980341911316, Validation Loss: 0.02043491043150425
Epoch 274, Training Loss: 0.016103137284517288, Validation Loss: 0.020142141729593277
Epoch 275, Training Loss: 0.015837637707591057, Validation Loss: 0.019890038296580315
Epoch 276, Training Loss: 0.015578988008201122, Validation Loss: 0.0196384284645319
Epoch 277, Training Loss: 0.015325197950005531, Validation Loss: 0.019383171573281288
Epoch 278, Training Loss: 0.015076206997036934, Validation Loss: 0.019109314307570457
Epoch 279, Training Loss: 0.014844696968793869, Validation Loss: 0.018840184435248375
Epoch 280, Training Loss: 0.01462232880294323, Validation Loss: 0.018579954281449318
Epoch 281, Training Loss: 0.014402452856302261, Validation Loss: 0.018337083980441093
Epoch 282, Training Loss: 0.014187239110469818, Validation Loss: 0.018070358783006668
Epoch 283, Training Loss: 0.013982294127345085, Validation Loss: 0.01783069781959057
Epoch 284, Training Loss: 0.013771139085292816, Validation Loss: 0.01763489842414856
Epoch 285, Training Loss: 0.01356943603605032, Validation Loss: 0.01741812936961651
Epoch 286, Training Loss: 0.013365404680371284, Validation Loss: 0.017183173447847366
Epoch 287, Training Loss: 0.01315953116863966, Validation Loss: 0.016959350556135178
Epoch 288, Training Loss: 0.012970300391316414, Validation Loss: 0.016747023910284042
Epoch 289, Training Loss: 0.012769541703164577, Validation Loss: 0.01655813492834568
Epoch 290, Training Loss: 0.01257771160453558, Validation Loss: 0.016336165368556976
Epoch 291, Training Loss: 0.012378024868667126, Validation Loss: 0.016104040667414665
Epoch 292, Training Loss: 0.012190026231110096, Validation Loss: 0.01592845842242241
Epoch 293, Training Loss: 0.011987138539552689, Validation Loss: 0.01574159413576126
Epoch 294, Training Loss: 0.011793311685323715, Validation Loss: 0.015464878641068935
Epoch 295, Training Loss: 0.01158788613975048, Validation Loss: 0.01520467083901167
Epoch 296, Training Loss: 0.011388489976525307, Validation Loss: 0.014994153752923012
Epoch 297, Training Loss: 0.011218879371881485, Validation Loss: 0.01477876678109169
Epoch 298, Training Loss: 0.011044260114431381, Validation Loss: 0.014559326693415642
Epoch 299, Training Loss: 0.010856462642550468, Validation Loss: 0.01434952300041914
Epoch 300, Training Loss: 0.01066767517477274, Validation Loss: 0.014132213778793812
Epoch 301, Training Loss: 0.010480503551661968, Validation Loss: 0.013911544345319271
Epoch 302, Training Loss: 0.010296785272657871, Validation Loss: 0.01364990882575512
Epoch 303, Training Loss: 0.010118914768099785, Validation Loss: 0.013367859646677971
Epoch 304, Training Loss: 0.009930798783898354, Validation Loss: 0.01311437040567398
Epoch 305, Training Loss: 0.009761931374669075, Validation Loss: 0.01287275180220604
Epoch 306, Training Loss: 0.009593873284757137, Validation Loss: 0.0126399677246809
Epoch 307, Training Loss: 0.009419417940080166, Validation Loss: 0.012444696389138699
Epoch 308, Training Loss: 0.009248542599380016, Validation Loss: 0.012298785150051117
Epoch 309, Training Loss: 0.009069946594536304, Validation Loss: 0.012175164185464382
Epoch 310, Training Loss: 0.00892059039324522, Validation Loss: 0.011988796293735504
Epoch 311, Training Loss: 0.008757798932492733, Validation Loss: 0.011764987371861935
Epoch 312, Training Loss: 0.008583898656070232, Validation Loss: 0.011544717475771904
Epoch 313, Training Loss: 0.008420286700129509, Validation Loss: 0.011349706910550594
Epoch 314, Training Loss: 0.00826097559183836, Validation Loss: 0.011174783110618591
Epoch 315, Training Loss: 0.008108872920274734, Validation Loss: 0.010979115962982178
Epoch 316, Training Loss: 0.00794904213398695, Validation Loss: 0.01080716960132122
Epoch 317, Training Loss: 0.007794511038810015, Validation Loss: 0.010634099133312702
Epoch 318, Training Loss: 0.0076477243565022945, Validation Loss: 0.010430127382278442
Epoch 319, Training Loss: 0.007494025863707066, Validation Loss: 0.010240676812827587
Epoch 320, Training Loss: 0.007346197031438351, Validation Loss: 0.01005635131150484
Epoch 321, Training Loss: 0.0071959588676691055, Validation Loss: 0.00984928011894226
Epoch 322, Training Loss: 0.007047279272228479, Validation Loss: 0.009651456959545612
Epoch 323, Training Loss: 0.006903586909174919, Validation Loss: 0.009474895894527435
Epoch 324, Training Loss: 0.006766807287931442, Validation Loss: 0.0092844283208251
Epoch 325, Training Loss: 0.0066293515264987946, Validation Loss: 0.00911549013108015
Epoch 326, Training Loss: 0.00649103382602334, Validation Loss: 0.00896134227514267
Epoch 327, Training Loss: 0.006361817941069603, Validation Loss: 0.00880558229982853
Epoch 328, Training Loss: 0.0062324837781488895, Validation Loss: 0.008633963763713837
Epoch 329, Training Loss: 0.00609921757131815, Validation Loss: 0.008453374728560448
Epoch 330, Training Loss: 0.005972621962428093, Validation Loss: 0.008257354609668255
Epoch 331, Training Loss: 0.005846325308084488, Validation Loss: 0.008068922907114029
Epoch 332, Training Loss: 0.005726479925215244, Validation Loss: 0.007899087853729725
Epoch 333, Training Loss: 0.0056119333021342754, Validation Loss: 0.00776707474142313
Epoch 334, Training Loss: 0.0054974365048110485, Validation Loss: 0.007654785178601742
Epoch 335, Training Loss: 0.005385237280279398, Validation Loss: 0.00753147853538394
Epoch 336, Training Loss: 0.005268821492791176, Validation Loss: 0.007390048820525408
Epoch 337, Training Loss: 0.00516003230586648, Validation Loss: 0.007229133043438196
Epoch 338, Training Loss: 0.005054971668869257, Validation Loss: 0.007101621478796005
Epoch 339, Training Loss: 0.004953012801706791, Validation Loss: 0.0069494713097810745
Epoch 340, Training Loss: 0.004852007608860731, Validation Loss: 0.006801315117627382
Epoch 341, Training Loss: 0.004751676693558693, Validation Loss: 0.0066976104862987995
Epoch 342, Training Loss: 0.00465960381552577, Validation Loss: 0.006578139029443264
Epoch 343, Training Loss: 0.004566143732517958, Validation Loss: 0.006419662851840258
Epoch 344, Training Loss: 0.0044695110991597176, Validation Loss: 0.006273515988141298
Epoch 345, Training Loss: 0.004372384399175644, Validation Loss: 0.006150359287858009
Epoch 346, Training Loss: 0.004285706672817469, Validation Loss: 0.0060280691832304
Epoch 347, Training Loss: 0.004197701811790466, Validation Loss: 0.005896521732211113
Epoch 348, Training Loss: 0.004113165196031332, Validation Loss: 0.005775191821157932
Epoch 349, Training Loss: 0.0040248678997159, Validation Loss: 0.005696319043636322
Epoch 350, Training Loss: 0.00394472386687994, Validation Loss: 0.005577199161052704
Epoch 351, Training Loss: 0.0038578195963054895, Validation Loss: 0.005438605323433876
Epoch 352, Training Loss: 0.003775515127927065, Validation Loss: 0.005318582057952881
Epoch 353, Training Loss: 0.003691228339448571, Validation Loss: 0.005202242638915777
Epoch 354, Training Loss: 0.0036100014112889767, Validation Loss: 0.005096939392387867
Epoch 355, Training Loss: 0.0035340781323611736, Validation Loss: 0.004989241249859333
Epoch 356, Training Loss: 0.0034597967751324177, Validation Loss: 0.004881739616394043
Epoch 357, Training Loss: 0.0033805007115006447, Validation Loss: 0.004784541204571724
Epoch 358, Training Loss: 0.003305693157017231, Validation Loss: 0.004701065830886364
Epoch 359, Training Loss: 0.0032351643312722445, Validation Loss: 0.004582475405186415
Epoch 360, Training Loss: 0.0031595558393746614, Validation Loss: 0.00447110366076231
Epoch 361, Training Loss: 0.0030872856732457876, Validation Loss: 0.004355737008154392
Epoch 362, Training Loss: 0.0030164700001478195, Validation Loss: 0.0042363484390079975
Epoch 363, Training Loss: 0.0029440231155604124, Validation Loss: 0.0041236006654798985
Epoch 364, Training Loss: 0.002876223996281624, Validation Loss: 0.00401958217844367
Epoch 365, Training Loss: 0.0028082069475203753, Validation Loss: 0.003934370819479227
Epoch 366, Training Loss: 0.0027424416039139032, Validation Loss: 0.003854112233966589
Epoch 367, Training Loss: 0.0026801766362041235, Validation Loss: 0.003766512731090188
Epoch 368, Training Loss: 0.0026158285327255726, Validation Loss: 0.003677413100376725
Epoch 369, Training Loss: 0.0025534355081617832, Validation Loss: 0.003574653994292021
Epoch 370, Training Loss: 0.0024918827693909407, Validation Loss: 0.0034834377001971006
Epoch 371, Training Loss: 0.002431259723380208, Validation Loss: 0.003395376494154334
Epoch 372, Training Loss: 0.002373897237703204, Validation Loss: 0.0032946597784757614
Epoch 373, Training Loss: 0.002316690981388092, Validation Loss: 0.0031978010665625334
Epoch 374, Training Loss: 0.002260517096146941, Validation Loss: 0.0031069566030055285
Epoch 375, Training Loss: 0.0022010470274835825, Validation Loss: 0.0030216893646866083
Epoch 376, Training Loss: 0.0021467641927301884, Validation Loss: 0.002911296207457781
Epoch 377, Training Loss: 0.002090009395033121, Validation Loss: 0.002807645360007882
Epoch 378, Training Loss: 0.0020359321497380733, Validation Loss: 0.002720828400924802
Epoch 379, Training Loss: 0.00198181951418519, Validation Loss: 0.002620832994580269
Epoch 380, Training Loss: 0.0019293715013191104, Validation Loss: 0.002535018837079406
Epoch 381, Training Loss: 0.0018782797269523144, Validation Loss: 0.0024594201240688562
Epoch 382, Training Loss: 0.0018300862284377217, Validation Loss: 0.0023752101697027683
Epoch 383, Training Loss: 0.00177996966522187, Validation Loss: 0.002293450990691781
Epoch 384, Training Loss: 0.0017347527900710702, Validation Loss: 0.0022244188003242016
Epoch 385, Training Loss: 0.0016826760256662965, Validation Loss: 0.0021598224993795156
Epoch 386, Training Loss: 0.001640409347601235, Validation Loss: 0.002074645832180977
Epoch 387, Training Loss: 0.0015940336743369699, Validation Loss: 0.0019998387433588505
Epoch 388, Training Loss: 0.0015501109883189201, Validation Loss: 0.001926064258441329
Epoch 389, Training Loss: 0.0015089509543031454, Validation Loss: 0.0018434531521052122
Epoch 390, Training Loss: 0.0014634305844083428, Validation Loss: 0.0017679727170616388
Epoch 391, Training Loss: 0.0014278648886829615, Validation Loss: 0.001703151734545827
Epoch 392, Training Loss: 0.001387171447277069, Validation Loss: 0.0016517858020961285
Epoch 393, Training Loss: 0.0013478741748258471, Validation Loss: 0.0015947847859933972
Epoch 394, Training Loss: 0.0013102535158395767, Validation Loss: 0.0015325210988521576
Epoch 395, Training Loss: 0.0012705313274636865, Validation Loss: 0.0014789941487833858
Epoch 396, Training Loss: 0.001241557882167399, Validation Loss: 0.0014270796673372388
Epoch 397, Training Loss: 0.0012021964648738503, Validation Loss: 0.0013665149454027414
Epoch 398, Training Loss: 0.001171995885670185, Validation Loss: 0.0013031583512201905
Epoch 399, Training Loss: 0.0011375242611393332, Validation Loss: 0.0012507474748417735
Epoch 400, Training Loss: 0.0011059753596782684, Validation Loss: 0.0012085475027561188
Epoch 401, Training Loss: 0.0010778434807434678, Validation Loss: 0.0011601975420489907
Epoch 402, Training Loss: 0.0010477742180228233, Validation Loss: 0.0011157722910866141
Epoch 403, Training Loss: 0.0010193726047873497, Validation Loss: 0.0010799543233588338
Epoch 404, Training Loss: 0.000993433059193194, Validation Loss: 0.0010432882700115442
Epoch 405, Training Loss: 0.0009670876315794885, Validation Loss: 0.0010018724715337157
Epoch 406, Training Loss: 0.0009403944131918252, Validation Loss: 0.0009598414180800319
Epoch 407, Training Loss: 0.0009163041249848902, Validation Loss: 0.0009193205623887479
Epoch 408, Training Loss: 0.0008935018558986485, Validation Loss: 0.0008862915565259755
Epoch 409, Training Loss: 0.0008689207024872303, Validation Loss: 0.0008555004606023431
Epoch 410, Training Loss: 0.0008483278215862811, Validation Loss: 0.0008225246565416455
Epoch 411, Training Loss: 0.0008275644504465163, Validation Loss: 0.0007907497929409146
Epoch 412, Training Loss: 0.00080667226575315, Validation Loss: 0.0007637146045453846
Epoch 413, Training Loss: 0.0007878849864937365, Validation Loss: 0.0007367009529843926
Epoch 414, Training Loss: 0.0007679502014070749, Validation Loss: 0.0007148560835048556
Epoch 415, Training Loss: 0.0007500615320168436, Validation Loss: 0.0006923030596226454
Epoch 416, Training Loss: 0.0007316335686482489, Validation Loss: 0.0006693133618682623
Epoch 417, Training Loss: 0.0007147893775254488, Validation Loss: 0.0006448152707889676
Epoch 418, Training Loss: 0.000696604314725846, Validation Loss: 0.0006251637823879719
Epoch 419, Training Loss: 0.0006840378046035767, Validation Loss: 0.0006070509552955627
Epoch 420, Training Loss: 0.0006648998823948205, Validation Loss: 0.0005901473923586309
Epoch 421, Training Loss: 0.0006512675900012255, Validation Loss: 0.0005707262898795307
Epoch 422, Training Loss: 0.0006356001831591129, Validation Loss: 0.0005533004296012223
Epoch 423, Training Loss: 0.0006216095644049346, Validation Loss: 0.0005362944793887436
Epoch 424, Training Loss: 0.0006065568304620683, Validation Loss: 0.0005207133363001049
Epoch 425, Training Loss: 0.000593060627579689, Validation Loss: 0.0005054174107499421
Epoch 426, Training Loss: 0.0005791696603409946, Validation Loss: 0.0004899121704511344
Epoch 427, Training Loss: 0.0005666090291924775, Validation Loss: 0.0004744496545754373
Epoch 428, Training Loss: 0.0005537872784771025, Validation Loss: 0.0004600160464178771
Epoch 429, Training Loss: 0.0005419133813120425, Validation Loss: 0.00044667485053651035
Epoch 430, Training Loss: 0.0005293877911753953, Validation Loss: 0.0004349744995124638
Epoch 431, Training Loss: 0.0005170116201043129, Validation Loss: 0.0004253344377502799
Epoch 432, Training Loss: 0.000505447736941278, Validation Loss: 0.0004157281946390867
Epoch 433, Training Loss: 0.0004937530611641705, Validation Loss: 0.0004052052099723369
Epoch 434, Training Loss: 0.0004823864728678018, Validation Loss: 0.0003945575444959104
Epoch 435, Training Loss: 0.00047148557496257126, Validation Loss: 0.0003837340045720339
Epoch 436, Training Loss: 0.0004606425645761192, Validation Loss: 0.0003723443951457739
Epoch 437, Training Loss: 0.0004497187037486583, Validation Loss: 0.00036063726292923093
Epoch 438, Training Loss: 0.0004390258982311934, Validation Loss: 0.0003506848297547549
Epoch 439, Training Loss: 0.0004296233528293669, Validation Loss: 0.0003407596377655864
Epoch 440, Training Loss: 0.0004195227811578661, Validation Loss: 0.00033220983459614217
Epoch 441, Training Loss: 0.00040969994734041393, Validation Loss: 0.0003243855608161539
Epoch 442, Training Loss: 0.0003997661406174302, Validation Loss: 0.0003162953653372824
Epoch 443, Training Loss: 0.0003895785484928638, Validation Loss: 0.0003088630910497159
Epoch 444, Training Loss: 0.00038076844066381454, Validation Loss: 0.00030124353361316025
Epoch 445, Training Loss: 0.0003717837098520249, Validation Loss: 0.00029277565772645175
Epoch 446, Training Loss: 0.0003623755183070898, Validation Loss: 0.00028434692649170756
Epoch 447, Training Loss: 0.00035324488999322057, Validation Loss: 0.0002764176169876009
Epoch 448, Training Loss: 0.00034463126212358475, Validation Loss: 0.00026902195531874895
Epoch 449, Training Loss: 0.00033578264992684126, Validation Loss: 0.00026157405227422714
Epoch 450, Training Loss: 0.0003269277513027191, Validation Loss: 0.00025471090339124203
Epoch 451, Training Loss: 0.0003186424437444657, Validation Loss: 0.00024776262580417097
Epoch 452, Training Loss: 0.00031039331224747, Validation Loss: 0.00024071999359875917
Epoch 453, Training Loss: 0.0003020010481122881, Validation Loss: 0.00023330723342951387
Epoch 454, Training Loss: 0.0002935400407295674, Validation Loss: 0.00022604783589486033
Epoch 455, Training Loss: 0.00028508479590527713, Validation Loss: 0.00021892589575145394
Epoch 456, Training Loss: 0.00027717064949683845, Validation Loss: 0.000211950289667584
Epoch 457, Training Loss: 0.00026892698951996863, Validation Loss: 0.00020462636894080788
Epoch 458, Training Loss: 0.00026032805908471346, Validation Loss: 0.00019736083049792796
Epoch 459, Training Loss: 0.00025256071239709854, Validation Loss: 0.00019086923566646874
Epoch 460, Training Loss: 0.0002450292813591659, Validation Loss: 0.00018443343287799507
Epoch 461, Training Loss: 0.000237312211538665, Validation Loss: 0.00017813636804930866
Epoch 462, Training Loss: 0.0002293143334100023, Validation Loss: 0.00017248310905415565
Epoch 463, Training Loss: 0.00022210912720765918, Validation Loss: 0.00016644364222884178
Epoch 464, Training Loss: 0.00021476572146639228, Validation Loss: 0.00016036104352679104
Epoch 465, Training Loss: 0.00020752310228999704, Validation Loss: 0.00015447873738594353
Epoch 466, Training Loss: 0.00020041890093125403, Validation Loss: 0.0001487352274125442
Epoch 467, Training Loss: 0.00019326063920743763, Validation Loss: 0.00014296495646703988
Epoch 468, Training Loss: 0.00018594386347103864, Validation Loss: 0.00013748959463555366
Epoch 469, Training Loss: 0.00017922343977261335, Validation Loss: 0.00013223027053754777
Epoch 470, Training Loss: 0.00017279978783335537, Validation Loss: 0.00012701500963885337
Epoch 471, Training Loss: 0.00016628247976768762, Validation Loss: 0.00012198884360259399
Epoch 472, Training Loss: 0.00015997923037502915, Validation Loss: 0.0001174310382339172
Epoch 473, Training Loss: 0.00015384303696919233, Validation Loss: 0.00011297475430183113
Epoch 474, Training Loss: 0.00014778116019442677, Validation Loss: 0.00010828665108419955
Epoch 475, Training Loss: 0.00014221621677279472, Validation Loss: 0.00010392433614470065
Epoch 476, Training Loss: 0.00013658138050232083, Validation Loss: 0.00010003939678426832
Epoch 477, Training Loss: 0.0001312325766775757, Validation Loss: 9.578667231835425e-05
Epoch 478, Training Loss: 0.00012552579573821276, Validation Loss: 9.184101509163156e-05
Epoch 479, Training Loss: 0.0001202890562126413, Validation Loss: 8.800457726465538e-05
Epoch 480, Training Loss: 0.00011511656339280307, Validation Loss: 8.425588748650625e-05
Epoch 481, Training Loss: 0.00010996908531524241, Validation Loss: 8.061376865953207e-05
Epoch 482, Training Loss: 0.00010553844185778871, Validation Loss: 7.663642463739961e-05
Epoch 483, Training Loss: 0.00010083294910145923, Validation Loss: 7.271726644830778e-05
Epoch 484, Training Loss: 9.627067629480734e-05, Validation Loss: 6.889703217893839e-05
Epoch 485, Training Loss: 9.204706293530762e-05, Validation Loss: 6.545212818309665e-05
Epoch 486, Training Loss: 8.827161946101114e-05, Validation Loss: 6.21935396338813e-05
Epoch 487, Training Loss: 8.431022433796898e-05, Validation Loss: 5.936768866376951e-05
Epoch 488, Training Loss: 8.081542910076678e-05, Validation Loss: 5.670015525538474e-05
Epoch 489, Training Loss: 7.692910003243014e-05, Validation Loss: 5.449369564303197e-05
Epoch 490, Training Loss: 7.381688192253932e-05, Validation Loss: 5.203212276683189e-05
Epoch 491, Training Loss: 7.026798266451806e-05, Validation Loss: 4.941455335938372e-05
Epoch 492, Training Loss: 6.679526995867491e-05, Validation Loss: 4.676283788285218e-05
Epoch 493, Training Loss: 6.387906614691019e-05, Validation Loss: 4.4249085476621985e-05
Epoch 494, Training Loss: 6.063380351406522e-05, Validation Loss: 4.204709694022313e-05
Epoch 495, Training Loss: 5.7758603361435235e-05, Validation Loss: 3.975283107138239e-05
Epoch 496, Training Loss: 5.4884534620214254e-05, Validation Loss: 3.76293646695558e-05
Epoch 497, Training Loss: 5.221419996814802e-05, Validation Loss: 3.561678386176936e-05
Epoch 498, Training Loss: 4.978351716999896e-05, Validation Loss: 3.363582072779536e-05
Epoch 499, Training Loss: 4.725932376459241e-05, Validation Loss: 3.200023638783023e-05
Epoch 500, Training Loss: 4.518951755017042e-05, Validation Loss: 3.0172102924552746e-05
