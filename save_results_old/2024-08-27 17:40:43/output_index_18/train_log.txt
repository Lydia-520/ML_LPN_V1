Epoch 1, Training Loss: 0.2571859657764435, Validation Loss: 0.30640459060668945
Epoch 2, Training Loss: 0.2561286389827728, Validation Loss: 0.3052736818790436
Epoch 3, Training Loss: 0.25509804487228394, Validation Loss: 0.3041614890098572
Epoch 4, Training Loss: 0.2540837824344635, Validation Loss: 0.3030594289302826
Epoch 5, Training Loss: 0.25307726860046387, Validation Loss: 0.3019627034664154
Epoch 6, Training Loss: 0.2520749568939209, Validation Loss: 0.30087628960609436
Epoch 7, Training Loss: 0.2510868012905121, Validation Loss: 0.2998062074184418
Epoch 8, Training Loss: 0.2501153349876404, Validation Loss: 0.29873448610305786
Epoch 9, Training Loss: 0.24914111196994781, Validation Loss: 0.29765820503234863
Epoch 10, Training Loss: 0.24816645681858063, Validation Loss: 0.29656660556793213
Epoch 11, Training Loss: 0.24718168377876282, Validation Loss: 0.2954557240009308
Epoch 12, Training Loss: 0.24618177115917206, Validation Loss: 0.29433199763298035
Epoch 13, Training Loss: 0.24517211318016052, Validation Loss: 0.2931968867778778
Epoch 14, Training Loss: 0.24415504932403564, Validation Loss: 0.29203760623931885
Epoch 15, Training Loss: 0.24312140047550201, Validation Loss: 0.2908540964126587
Epoch 16, Training Loss: 0.2420727014541626, Validation Loss: 0.289645254611969
Epoch 17, Training Loss: 0.2410012185573578, Validation Loss: 0.2883974015712738
Epoch 18, Training Loss: 0.23990286886692047, Validation Loss: 0.28711509704589844
Epoch 19, Training Loss: 0.2387695014476776, Validation Loss: 0.28579455614089966
Epoch 20, Training Loss: 0.2376038134098053, Validation Loss: 0.2844352722167969
Epoch 21, Training Loss: 0.23640236258506775, Validation Loss: 0.28302475810050964
Epoch 22, Training Loss: 0.23515339195728302, Validation Loss: 0.2815593183040619
Epoch 23, Training Loss: 0.23386138677597046, Validation Loss: 0.280038982629776
Epoch 24, Training Loss: 0.23252332210540771, Validation Loss: 0.27846628427505493
Epoch 25, Training Loss: 0.2311355173587799, Validation Loss: 0.27684497833251953
Epoch 26, Training Loss: 0.22971883416175842, Validation Loss: 0.27517062425613403
Epoch 27, Training Loss: 0.2282649576663971, Validation Loss: 0.2734452784061432
Epoch 28, Training Loss: 0.22677059471607208, Validation Loss: 0.2716733515262604
Epoch 29, Training Loss: 0.22523029148578644, Validation Loss: 0.2698131799697876
Epoch 30, Training Loss: 0.2236253321170807, Validation Loss: 0.2678629457950592
Epoch 31, Training Loss: 0.22193904221057892, Validation Loss: 0.26582154631614685
Epoch 32, Training Loss: 0.22017119824886322, Validation Loss: 0.26369643211364746
Epoch 33, Training Loss: 0.21833045780658722, Validation Loss: 0.2614649534225464
Epoch 34, Training Loss: 0.21640653908252716, Validation Loss: 0.25912076234817505
Epoch 35, Training Loss: 0.21438410878181458, Validation Loss: 0.256634384393692
Epoch 36, Training Loss: 0.21224796772003174, Validation Loss: 0.2539966106414795
Epoch 37, Training Loss: 0.2100001871585846, Validation Loss: 0.2512068748474121
Epoch 38, Training Loss: 0.20764315128326416, Validation Loss: 0.24827103316783905
Epoch 39, Training Loss: 0.20516052842140198, Validation Loss: 0.24516767263412476
Epoch 40, Training Loss: 0.2025425285100937, Validation Loss: 0.24192434549331665
Epoch 41, Training Loss: 0.19980871677398682, Validation Loss: 0.238515704870224
Epoch 42, Training Loss: 0.19693928956985474, Validation Loss: 0.23493847250938416
Epoch 43, Training Loss: 0.1939351111650467, Validation Loss: 0.23115959763526917
Epoch 44, Training Loss: 0.19076906144618988, Validation Loss: 0.2271680235862732
Epoch 45, Training Loss: 0.18743453919887543, Validation Loss: 0.22292545437812805
Epoch 46, Training Loss: 0.18390899896621704, Validation Loss: 0.21845073997974396
Epoch 47, Training Loss: 0.18021181225776672, Validation Loss: 0.21379713714122772
Epoch 48, Training Loss: 0.17636646330356598, Validation Loss: 0.20892561972141266
Epoch 49, Training Loss: 0.17235642671585083, Validation Loss: 0.20378072559833527
Epoch 50, Training Loss: 0.16817893087863922, Validation Loss: 0.19838307797908783
Epoch 51, Training Loss: 0.1638520061969757, Validation Loss: 0.1927923709154129
Epoch 52, Training Loss: 0.1594253033399582, Validation Loss: 0.18705040216445923
Epoch 53, Training Loss: 0.1549433469772339, Validation Loss: 0.18124765157699585
Epoch 54, Training Loss: 0.1504734754562378, Validation Loss: 0.17545869946479797
Epoch 55, Training Loss: 0.14609090983867645, Validation Loss: 0.16978533565998077
Epoch 56, Training Loss: 0.14188551902770996, Validation Loss: 0.1643206626176834
Epoch 57, Training Loss: 0.13794603943824768, Validation Loss: 0.15918998420238495
Epoch 58, Training Loss: 0.1343831717967987, Validation Loss: 0.1545136272907257
Epoch 59, Training Loss: 0.13129934668540955, Validation Loss: 0.15041667222976685
Epoch 60, Training Loss: 0.12879833579063416, Validation Loss: 0.1469580978155136
Epoch 61, Training Loss: 0.1269291341304779, Validation Loss: 0.14417622983455658
Epoch 62, Training Loss: 0.1256687194108963, Validation Loss: 0.14205683767795563
Epoch 63, Training Loss: 0.1249520480632782, Validation Loss: 0.14054939150810242
Epoch 64, Training Loss: 0.1246410682797432, Validation Loss: 0.13950860500335693
Epoch 65, Training Loss: 0.12454190850257874, Validation Loss: 0.13870862126350403
Epoch 66, Training Loss: 0.12437310814857483, Validation Loss: 0.13801056146621704
Epoch 67, Training Loss: 0.12400580197572708, Validation Loss: 0.1373337358236313
Epoch 68, Training Loss: 0.1233576238155365, Validation Loss: 0.13662543892860413
Epoch 69, Training Loss: 0.12243104726076126, Validation Loss: 0.13593100011348724
Epoch 70, Training Loss: 0.12130962312221527, Validation Loss: 0.13530755043029785
Epoch 71, Training Loss: 0.12011241167783737, Validation Loss: 0.13481901586055756
Epoch 72, Training Loss: 0.11895856261253357, Validation Loss: 0.13446325063705444
Epoch 73, Training Loss: 0.11792975664138794, Validation Loss: 0.13425172865390778
Epoch 74, Training Loss: 0.11706354469060898, Validation Loss: 0.13418391346931458
Epoch 75, Training Loss: 0.11638966202735901, Validation Loss: 0.13423170149326324
Epoch 76, Training Loss: 0.11589546501636505, Validation Loss: 0.13434024155139923
Epoch 77, Training Loss: 0.11554528772830963, Validation Loss: 0.1344478875398636
Epoch 78, Training Loss: 0.11529535055160522, Validation Loss: 0.13449858129024506
Epoch 79, Training Loss: 0.11510328203439713, Validation Loss: 0.13444772362709045
Epoch 80, Training Loss: 0.11492887139320374, Validation Loss: 0.13426858186721802
Epoch 81, Training Loss: 0.11474921554327011, Validation Loss: 0.13393497467041016
Epoch 82, Training Loss: 0.11453472077846527, Validation Loss: 0.13343074917793274
Epoch 83, Training Loss: 0.1142740324139595, Validation Loss: 0.13276003301143646
Epoch 84, Training Loss: 0.11396514624357224, Validation Loss: 0.13195176422595978
Epoch 85, Training Loss: 0.11361443251371384, Validation Loss: 0.13103392720222473
Epoch 86, Training Loss: 0.11323372274637222, Validation Loss: 0.1300564706325531
Epoch 87, Training Loss: 0.11284484714269638, Validation Loss: 0.12902753055095673
Epoch 88, Training Loss: 0.11245682090520859, Validation Loss: 0.12798014283180237
Epoch 89, Training Loss: 0.11208512634038925, Validation Loss: 0.12694552540779114
Epoch 90, Training Loss: 0.11174195259809494, Validation Loss: 0.12595072388648987
Epoch 91, Training Loss: 0.1114291101694107, Validation Loss: 0.12500666081905365
Epoch 92, Training Loss: 0.11114250123500824, Validation Loss: 0.12412887066602707
Epoch 93, Training Loss: 0.11087960749864578, Validation Loss: 0.12332307547330856
Epoch 94, Training Loss: 0.11063121259212494, Validation Loss: 0.12258569896221161
Epoch 95, Training Loss: 0.11038162559270859, Validation Loss: 0.12190677970647812
Epoch 96, Training Loss: 0.11011912673711777, Validation Loss: 0.1212901920080185
Epoch 97, Training Loss: 0.10984160751104355, Validation Loss: 0.12073220312595367
Epoch 98, Training Loss: 0.1095467135310173, Validation Loss: 0.1202303096652031
Epoch 99, Training Loss: 0.1092367097735405, Validation Loss: 0.11977799236774445
Epoch 100, Training Loss: 0.10891833901405334, Validation Loss: 0.11936631798744202
Epoch 101, Training Loss: 0.1085907369852066, Validation Loss: 0.11899734288454056
Epoch 102, Training Loss: 0.10826066136360168, Validation Loss: 0.1186559796333313
Epoch 103, Training Loss: 0.10793198645114899, Validation Loss: 0.11832861602306366
Epoch 104, Training Loss: 0.1076057031750679, Validation Loss: 0.11800140887498856
Epoch 105, Training Loss: 0.10728174448013306, Validation Loss: 0.11766130477190018
Epoch 106, Training Loss: 0.10695657879114151, Validation Loss: 0.117294080555439
Epoch 107, Training Loss: 0.10662849247455597, Validation Loss: 0.11689074337482452
Epoch 108, Training Loss: 0.10629624873399734, Validation Loss: 0.11645347625017166
Epoch 109, Training Loss: 0.10595785826444626, Validation Loss: 0.11597371846437454
Epoch 110, Training Loss: 0.10560867190361023, Validation Loss: 0.11544870585203171
Epoch 111, Training Loss: 0.10524667799472809, Validation Loss: 0.11488061398267746
Epoch 112, Training Loss: 0.10487356781959534, Validation Loss: 0.11426199972629547
Epoch 113, Training Loss: 0.10447972267866135, Validation Loss: 0.11360711604356766
Epoch 114, Training Loss: 0.10407084971666336, Validation Loss: 0.11291942000389099
Epoch 115, Training Loss: 0.10364910960197449, Validation Loss: 0.11221496015787125
Epoch 116, Training Loss: 0.10321947932243347, Validation Loss: 0.11151334643363953
Epoch 117, Training Loss: 0.10278382897377014, Validation Loss: 0.11080210655927658
Epoch 118, Training Loss: 0.10233350098133087, Validation Loss: 0.11009656637907028
Epoch 119, Training Loss: 0.1018693596124649, Validation Loss: 0.10939743369817734
Epoch 120, Training Loss: 0.10138840228319168, Validation Loss: 0.10869003087282181
Epoch 121, Training Loss: 0.1008872464299202, Validation Loss: 0.10799361020326614
Epoch 122, Training Loss: 0.10037017613649368, Validation Loss: 0.10728317499160767
Epoch 123, Training Loss: 0.09983335435390472, Validation Loss: 0.10655513405799866
Epoch 124, Training Loss: 0.09927541762590408, Validation Loss: 0.10580811649560928
Epoch 125, Training Loss: 0.09869569540023804, Validation Loss: 0.10505411028862
Epoch 126, Training Loss: 0.09809191524982452, Validation Loss: 0.10428924113512039
Epoch 127, Training Loss: 0.09746331721544266, Validation Loss: 0.10350082814693451
Epoch 128, Training Loss: 0.09680627286434174, Validation Loss: 0.10266826301813126
Epoch 129, Training Loss: 0.09612566977739334, Validation Loss: 0.10178998857736588
Epoch 130, Training Loss: 0.09543296694755554, Validation Loss: 0.10084515810012817
Epoch 131, Training Loss: 0.09470885246992111, Validation Loss: 0.0998692661523819
Epoch 132, Training Loss: 0.09395959228277206, Validation Loss: 0.09888654202222824
Epoch 133, Training Loss: 0.09317567199468613, Validation Loss: 0.0978977382183075
Epoch 134, Training Loss: 0.09236572682857513, Validation Loss: 0.09690544009208679
Epoch 135, Training Loss: 0.09155020117759705, Validation Loss: 0.0958729162812233
Epoch 136, Training Loss: 0.0907115489244461, Validation Loss: 0.09479953348636627
Epoch 137, Training Loss: 0.08985434472560883, Validation Loss: 0.09373603761196136
Epoch 138, Training Loss: 0.08898685872554779, Validation Loss: 0.09264805912971497
Epoch 139, Training Loss: 0.08809998631477356, Validation Loss: 0.0915367603302002
Epoch 140, Training Loss: 0.08719640970230103, Validation Loss: 0.09039216488599777
Epoch 141, Training Loss: 0.08627321571111679, Validation Loss: 0.08926882594823837
Epoch 142, Training Loss: 0.08535700291395187, Validation Loss: 0.08823074400424957
Epoch 143, Training Loss: 0.08444177359342575, Validation Loss: 0.08724889904260635
Epoch 144, Training Loss: 0.0835159495472908, Validation Loss: 0.08629846572875977
Epoch 145, Training Loss: 0.0825694352388382, Validation Loss: 0.08538088947534561
Epoch 146, Training Loss: 0.08160924911499023, Validation Loss: 0.084523044526577
Epoch 147, Training Loss: 0.08064907044172287, Validation Loss: 0.08375432342290878
Epoch 148, Training Loss: 0.07974560558795929, Validation Loss: 0.08299515396356583
Epoch 149, Training Loss: 0.07884977757930756, Validation Loss: 0.08226674050092697
Epoch 150, Training Loss: 0.07798906415700912, Validation Loss: 0.08154783397912979
Epoch 151, Training Loss: 0.07715349644422531, Validation Loss: 0.08083760738372803
Epoch 152, Training Loss: 0.07633604854345322, Validation Loss: 0.08016916364431381
Epoch 153, Training Loss: 0.07555121928453445, Validation Loss: 0.0795440673828125
Epoch 154, Training Loss: 0.07480122148990631, Validation Loss: 0.07899846881628036
Epoch 155, Training Loss: 0.0740976631641388, Validation Loss: 0.07848956435918808
Epoch 156, Training Loss: 0.07342585921287537, Validation Loss: 0.07803266495466232
Epoch 157, Training Loss: 0.07279496639966965, Validation Loss: 0.07766897976398468
Epoch 158, Training Loss: 0.07222746312618256, Validation Loss: 0.07733342796564102
Epoch 159, Training Loss: 0.07169366627931595, Validation Loss: 0.0770222544670105
Epoch 160, Training Loss: 0.07118835300207138, Validation Loss: 0.07672054320573807
Epoch 161, Training Loss: 0.0707225427031517, Validation Loss: 0.07643134891986847
Epoch 162, Training Loss: 0.07028862088918686, Validation Loss: 0.07615245878696442
Epoch 163, Training Loss: 0.06988082081079483, Validation Loss: 0.07591549307107925
Epoch 164, Training Loss: 0.06951037794351578, Validation Loss: 0.0756954699754715
Epoch 165, Training Loss: 0.06916423887014389, Validation Loss: 0.07548420876264572
Epoch 166, Training Loss: 0.06882704794406891, Validation Loss: 0.07526321709156036
Epoch 167, Training Loss: 0.06850149482488632, Validation Loss: 0.07501137256622314
Epoch 168, Training Loss: 0.0681767612695694, Validation Loss: 0.07473095506429672
Epoch 169, Training Loss: 0.06788263469934464, Validation Loss: 0.0744757428765297
Epoch 170, Training Loss: 0.06758461892604828, Validation Loss: 0.07426280528306961
Epoch 171, Training Loss: 0.06729556620121002, Validation Loss: 0.07404468208551407
Epoch 172, Training Loss: 0.06701629608869553, Validation Loss: 0.0738079771399498
Epoch 173, Training Loss: 0.06674891710281372, Validation Loss: 0.07350452989339828
Epoch 174, Training Loss: 0.0664759948849678, Validation Loss: 0.07315798848867416
Epoch 175, Training Loss: 0.06621094048023224, Validation Loss: 0.0728398859500885
Epoch 176, Training Loss: 0.06595619022846222, Validation Loss: 0.07252218574285507
Epoch 177, Training Loss: 0.06570426374673843, Validation Loss: 0.07219864428043365
Epoch 178, Training Loss: 0.06544593721628189, Validation Loss: 0.07191494107246399
Epoch 179, Training Loss: 0.06518521159887314, Validation Loss: 0.07168903201818466
Epoch 180, Training Loss: 0.06493036448955536, Validation Loss: 0.07146741449832916
Epoch 181, Training Loss: 0.06467782706022263, Validation Loss: 0.07124267518520355
Epoch 182, Training Loss: 0.06441991031169891, Validation Loss: 0.07096266001462936
Epoch 183, Training Loss: 0.06415489315986633, Validation Loss: 0.07065131515264511
Epoch 184, Training Loss: 0.06387979537248611, Validation Loss: 0.07039138674736023
Epoch 185, Training Loss: 0.06362112611532211, Validation Loss: 0.07018871605396271
Epoch 186, Training Loss: 0.06335626542568207, Validation Loss: 0.06999184936285019
Epoch 187, Training Loss: 0.06308387219905853, Validation Loss: 0.06979051232337952
Epoch 188, Training Loss: 0.06280706077814102, Validation Loss: 0.06956076622009277
Epoch 189, Training Loss: 0.06252960860729218, Validation Loss: 0.06933876127004623
Epoch 190, Training Loss: 0.06224968656897545, Validation Loss: 0.06912000477313995
Epoch 191, Training Loss: 0.06196882575750351, Validation Loss: 0.06887893378734589
Epoch 192, Training Loss: 0.06168936938047409, Validation Loss: 0.06858418881893158
Epoch 193, Training Loss: 0.06141073256731033, Validation Loss: 0.06833120435476303
Epoch 194, Training Loss: 0.06113246828317642, Validation Loss: 0.06810945272445679
Epoch 195, Training Loss: 0.060851726680994034, Validation Loss: 0.06786289066076279
Epoch 196, Training Loss: 0.06056628003716469, Validation Loss: 0.0675683468580246
Epoch 197, Training Loss: 0.06026383861899376, Validation Loss: 0.0672585740685463
Epoch 198, Training Loss: 0.05996686965227127, Validation Loss: 0.06697824597358704
Epoch 199, Training Loss: 0.05966044217348099, Validation Loss: 0.0667191818356514
Epoch 200, Training Loss: 0.05934006720781326, Validation Loss: 0.0664651170372963
Epoch 201, Training Loss: 0.0590086355805397, Validation Loss: 0.06619259715080261
Epoch 202, Training Loss: 0.05868499353528023, Validation Loss: 0.06586962193250656
Epoch 203, Training Loss: 0.058346621692180634, Validation Loss: 0.06550799310207367
Epoch 204, Training Loss: 0.05798127502202988, Validation Loss: 0.06512675434350967
Epoch 205, Training Loss: 0.05761559307575226, Validation Loss: 0.06478550285100937
Epoch 206, Training Loss: 0.05723060294985771, Validation Loss: 0.06451261043548584
Epoch 207, Training Loss: 0.05684668943285942, Validation Loss: 0.0642365962266922
Epoch 208, Training Loss: 0.05645923689007759, Validation Loss: 0.06389781087636948
Epoch 209, Training Loss: 0.05606478825211525, Validation Loss: 0.06354443728923798
Epoch 210, Training Loss: 0.05567057803273201, Validation Loss: 0.06320422887802124
Epoch 211, Training Loss: 0.055255141109228134, Validation Loss: 0.06284365803003311
Epoch 212, Training Loss: 0.05480528622865677, Validation Loss: 0.06248602643609047
Epoch 213, Training Loss: 0.054355282336473465, Validation Loss: 0.0621115006506443
Epoch 214, Training Loss: 0.053882498294115067, Validation Loss: 0.061691850423812866
Epoch 215, Training Loss: 0.05339183285832405, Validation Loss: 0.061251770704984665
Epoch 216, Training Loss: 0.05287781357765198, Validation Loss: 0.06076716631650925
Epoch 217, Training Loss: 0.05235343798995018, Validation Loss: 0.06024780124425888
Epoch 218, Training Loss: 0.05182241275906563, Validation Loss: 0.05972820147871971
Epoch 219, Training Loss: 0.051280874758958817, Validation Loss: 0.059200920164585114
Epoch 220, Training Loss: 0.05071893334388733, Validation Loss: 0.05868222564458847
Epoch 221, Training Loss: 0.05015111342072487, Validation Loss: 0.058154817670583725
Epoch 222, Training Loss: 0.049565620720386505, Validation Loss: 0.057648319751024246
Epoch 223, Training Loss: 0.04897313192486763, Validation Loss: 0.05716664344072342
Epoch 224, Training Loss: 0.04837867245078087, Validation Loss: 0.05666070058941841
Epoch 225, Training Loss: 0.04778098315000534, Validation Loss: 0.05608651414513588
Epoch 226, Training Loss: 0.04716605693101883, Validation Loss: 0.05552196875214577
Epoch 227, Training Loss: 0.04655430093407631, Validation Loss: 0.05499149486422539
Epoch 228, Training Loss: 0.04593796655535698, Validation Loss: 0.05447641760110855
Epoch 229, Training Loss: 0.04533768817782402, Validation Loss: 0.053908634930849075
Epoch 230, Training Loss: 0.04474308714270592, Validation Loss: 0.05331023409962654
Epoch 231, Training Loss: 0.04413282871246338, Validation Loss: 0.05274897441267967
Epoch 232, Training Loss: 0.04352850839495659, Validation Loss: 0.052234549075365067
Epoch 233, Training Loss: 0.04294262081384659, Validation Loss: 0.05168033391237259
Epoch 234, Training Loss: 0.04236067458987236, Validation Loss: 0.051114872097969055
Epoch 235, Training Loss: 0.04178144037723541, Validation Loss: 0.05051158368587494
Epoch 236, Training Loss: 0.04120899364352226, Validation Loss: 0.04992746561765671
Epoch 237, Training Loss: 0.04063865914940834, Validation Loss: 0.04936258867383003
Epoch 238, Training Loss: 0.040083110332489014, Validation Loss: 0.04872037097811699
Epoch 239, Training Loss: 0.03952149301767349, Validation Loss: 0.04796617105603218
Epoch 240, Training Loss: 0.038961224257946014, Validation Loss: 0.047251615673303604
Epoch 241, Training Loss: 0.03843003511428833, Validation Loss: 0.046578604727983475
Epoch 242, Training Loss: 0.037906330078840256, Validation Loss: 0.04603409767150879
Epoch 243, Training Loss: 0.03741871938109398, Validation Loss: 0.0454367995262146
Epoch 244, Training Loss: 0.03692632541060448, Validation Loss: 0.044810086488723755
Epoch 245, Training Loss: 0.03642673045396805, Validation Loss: 0.04411856085062027
Epoch 246, Training Loss: 0.03592836856842041, Validation Loss: 0.04347420483827591
Epoch 247, Training Loss: 0.03544284775853157, Validation Loss: 0.04290538281202316
Epoch 248, Training Loss: 0.03495050221681595, Validation Loss: 0.04234008863568306
Epoch 249, Training Loss: 0.03444408252835274, Validation Loss: 0.041742775589227676
Epoch 250, Training Loss: 0.03394078463315964, Validation Loss: 0.04106558486819267
Epoch 251, Training Loss: 0.03344542533159256, Validation Loss: 0.04036670923233032
Epoch 252, Training Loss: 0.03294970840215683, Validation Loss: 0.03971100598573685
Epoch 253, Training Loss: 0.032443828880786896, Validation Loss: 0.03914521262049675
Epoch 254, Training Loss: 0.03194504603743553, Validation Loss: 0.038553111255168915
Epoch 255, Training Loss: 0.031449031084775925, Validation Loss: 0.03786851093173027
Epoch 256, Training Loss: 0.03094574622809887, Validation Loss: 0.03718307986855507
Epoch 257, Training Loss: 0.03045959398150444, Validation Loss: 0.036590512841939926
Epoch 258, Training Loss: 0.029977712780237198, Validation Loss: 0.03608214110136032
Epoch 259, Training Loss: 0.02950238808989525, Validation Loss: 0.03547843545675278
Epoch 260, Training Loss: 0.02902212366461754, Validation Loss: 0.03481505438685417
Epoch 261, Training Loss: 0.02854231931269169, Validation Loss: 0.03419740870594978
Epoch 262, Training Loss: 0.028071416541934013, Validation Loss: 0.03363366052508354
Epoch 263, Training Loss: 0.027622349560260773, Validation Loss: 0.033026210963726044
Epoch 264, Training Loss: 0.02717256359755993, Validation Loss: 0.03236381337046623
Epoch 265, Training Loss: 0.026727065443992615, Validation Loss: 0.03179577738046646
Epoch 266, Training Loss: 0.02627899870276451, Validation Loss: 0.031283412128686905
Epoch 267, Training Loss: 0.025835661217570305, Validation Loss: 0.030731873586773872
Epoch 268, Training Loss: 0.025389518588781357, Validation Loss: 0.030180538073182106
Epoch 269, Training Loss: 0.02495698072016239, Validation Loss: 0.029646730050444603
Epoch 270, Training Loss: 0.024524910375475883, Validation Loss: 0.029142100363969803
Epoch 271, Training Loss: 0.024096664041280746, Validation Loss: 0.028605088591575623
Epoch 272, Training Loss: 0.02367105893790722, Validation Loss: 0.028074700385332108
Epoch 273, Training Loss: 0.02325921133160591, Validation Loss: 0.02752555161714554
Epoch 274, Training Loss: 0.022850334644317627, Validation Loss: 0.02700233645737171
Epoch 275, Training Loss: 0.022436516359448433, Validation Loss: 0.026454413309693336
Epoch 276, Training Loss: 0.022035913541913033, Validation Loss: 0.02591903880238533
Epoch 277, Training Loss: 0.02164214849472046, Validation Loss: 0.025439923629164696
Epoch 278, Training Loss: 0.021254125982522964, Validation Loss: 0.024979496374726295
Epoch 279, Training Loss: 0.020881248638033867, Validation Loss: 0.024467766284942627
Epoch 280, Training Loss: 0.020494934171438217, Validation Loss: 0.024007555097341537
Epoch 281, Training Loss: 0.020146159455180168, Validation Loss: 0.023579800501465797
Epoch 282, Training Loss: 0.019771017134189606, Validation Loss: 0.02325386367738247
Epoch 283, Training Loss: 0.019442925229668617, Validation Loss: 0.022806430235505104
Epoch 284, Training Loss: 0.019080040976405144, Validation Loss: 0.022350793704390526
Epoch 285, Training Loss: 0.018742911517620087, Validation Loss: 0.02194719761610031
Epoch 286, Training Loss: 0.01839783601462841, Validation Loss: 0.021627508103847504
Epoch 287, Training Loss: 0.01807468570768833, Validation Loss: 0.02125164307653904
Epoch 288, Training Loss: 0.017755404114723206, Validation Loss: 0.020856227725744247
Epoch 289, Training Loss: 0.01744087226688862, Validation Loss: 0.02049696445465088
Epoch 290, Training Loss: 0.01713200844824314, Validation Loss: 0.02014746703207493
Epoch 291, Training Loss: 0.016822418197989464, Validation Loss: 0.019800860434770584
Epoch 292, Training Loss: 0.016522089019417763, Validation Loss: 0.019435647875070572
Epoch 293, Training Loss: 0.0162228774279356, Validation Loss: 0.01904994249343872
Epoch 294, Training Loss: 0.0159262977540493, Validation Loss: 0.01869398169219494
Epoch 295, Training Loss: 0.015639789402484894, Validation Loss: 0.018382567912340164
Epoch 296, Training Loss: 0.015360993333160877, Validation Loss: 0.01805466040968895
Epoch 297, Training Loss: 0.015071677975356579, Validation Loss: 0.017751455307006836
Epoch 298, Training Loss: 0.014784111641347408, Validation Loss: 0.017465122044086456
Epoch 299, Training Loss: 0.014506373554468155, Validation Loss: 0.017137933522462845
Epoch 300, Training Loss: 0.014238073490560055, Validation Loss: 0.016816340386867523
Epoch 301, Training Loss: 0.013967621140182018, Validation Loss: 0.01650923863053322
Epoch 302, Training Loss: 0.013702945783734322, Validation Loss: 0.016196390613913536
Epoch 303, Training Loss: 0.013433057814836502, Validation Loss: 0.01589806005358696
Epoch 304, Training Loss: 0.013172892853617668, Validation Loss: 0.015587849542498589
Epoch 305, Training Loss: 0.012920347973704338, Validation Loss: 0.015289492905139923
Epoch 306, Training Loss: 0.012673788703978062, Validation Loss: 0.014982907101511955
Epoch 307, Training Loss: 0.012432962656021118, Validation Loss: 0.014611255377531052
Epoch 308, Training Loss: 0.012186061590909958, Validation Loss: 0.014267140068113804
Epoch 309, Training Loss: 0.011943482793867588, Validation Loss: 0.013954280875623226
Epoch 310, Training Loss: 0.011704075150191784, Validation Loss: 0.013656357303261757
Epoch 311, Training Loss: 0.01147298701107502, Validation Loss: 0.01336377952247858
Epoch 312, Training Loss: 0.011248655617237091, Validation Loss: 0.013052452355623245
Epoch 313, Training Loss: 0.011020388454198837, Validation Loss: 0.012750289402902126
Epoch 314, Training Loss: 0.01079812366515398, Validation Loss: 0.01243649609386921
Epoch 315, Training Loss: 0.010579006746411324, Validation Loss: 0.012127842754125595
Epoch 316, Training Loss: 0.010368049144744873, Validation Loss: 0.011840131133794785
Epoch 317, Training Loss: 0.010151895694434643, Validation Loss: 0.011583748273551464
Epoch 318, Training Loss: 0.009950608015060425, Validation Loss: 0.011318795382976532
Epoch 319, Training Loss: 0.009740161709487438, Validation Loss: 0.01109696738421917
Epoch 320, Training Loss: 0.009546162560582161, Validation Loss: 0.010862222872674465
Epoch 321, Training Loss: 0.009347262792289257, Validation Loss: 0.010656860657036304
Epoch 322, Training Loss: 0.009165297262370586, Validation Loss: 0.010393021628260612
Epoch 323, Training Loss: 0.008972156792879105, Validation Loss: 0.01013118028640747
Epoch 324, Training Loss: 0.00879403855651617, Validation Loss: 0.009895470924675465
Epoch 325, Training Loss: 0.008608615025877953, Validation Loss: 0.009661576710641384
Epoch 326, Training Loss: 0.00843371357768774, Validation Loss: 0.009374145418405533
Epoch 327, Training Loss: 0.008254317566752434, Validation Loss: 0.00912419706583023
Epoch 328, Training Loss: 0.008086055517196655, Validation Loss: 0.008905982598662376
Epoch 329, Training Loss: 0.00791691243648529, Validation Loss: 0.008682944811880589
Epoch 330, Training Loss: 0.00775172607973218, Validation Loss: 0.008481578901410103
Epoch 331, Training Loss: 0.007589283399283886, Validation Loss: 0.008274721913039684
Epoch 332, Training Loss: 0.007418896071612835, Validation Loss: 0.008116627112030983
Epoch 333, Training Loss: 0.007276357151567936, Validation Loss: 0.007909330539405346
Epoch 334, Training Loss: 0.00711664417758584, Validation Loss: 0.007726609241217375
Epoch 335, Training Loss: 0.006969640497118235, Validation Loss: 0.007549071218818426
Epoch 336, Training Loss: 0.006821077782660723, Validation Loss: 0.007358962669968605
Epoch 337, Training Loss: 0.006671408656984568, Validation Loss: 0.007168413605540991
Epoch 338, Training Loss: 0.006529342848807573, Validation Loss: 0.006951050832867622
Epoch 339, Training Loss: 0.006386857014149427, Validation Loss: 0.006769623141735792
Epoch 340, Training Loss: 0.006256022956222296, Validation Loss: 0.006559195462614298
Epoch 341, Training Loss: 0.006120520178228617, Validation Loss: 0.00634587649255991
Epoch 342, Training Loss: 0.00598672591149807, Validation Loss: 0.0061828382313251495
Epoch 343, Training Loss: 0.005854823626577854, Validation Loss: 0.006017865147441626
Epoch 344, Training Loss: 0.005724670365452766, Validation Loss: 0.005851749796420336
Epoch 345, Training Loss: 0.005597806069999933, Validation Loss: 0.005696211010217667
Epoch 346, Training Loss: 0.005476249847561121, Validation Loss: 0.005555339157581329
Epoch 347, Training Loss: 0.005354800261557102, Validation Loss: 0.0054316166788339615
Epoch 348, Training Loss: 0.005235905293375254, Validation Loss: 0.0052978964522480965
Epoch 349, Training Loss: 0.0051217833533883095, Validation Loss: 0.005167915020138025
Epoch 350, Training Loss: 0.005009999964386225, Validation Loss: 0.005037403665482998
Epoch 351, Training Loss: 0.004896337166428566, Validation Loss: 0.004924759268760681
Epoch 352, Training Loss: 0.004790059290826321, Validation Loss: 0.004813213367015123
Epoch 353, Training Loss: 0.004684119950979948, Validation Loss: 0.0046933675184845924
Epoch 354, Training Loss: 0.0045852819457650185, Validation Loss: 0.00454002246260643
Epoch 355, Training Loss: 0.004479505121707916, Validation Loss: 0.00439740065485239
Epoch 356, Training Loss: 0.004380059894174337, Validation Loss: 0.004276614636182785
Epoch 357, Training Loss: 0.004279670771211386, Validation Loss: 0.0041657802648842335
Epoch 358, Training Loss: 0.004183909390121698, Validation Loss: 0.004065766464918852
Epoch 359, Training Loss: 0.004090475849807262, Validation Loss: 0.003955896012485027
Epoch 360, Training Loss: 0.003995102364569902, Validation Loss: 0.003835471346974373
Epoch 361, Training Loss: 0.003899067174643278, Validation Loss: 0.003721546148881316
Epoch 362, Training Loss: 0.003805958665907383, Validation Loss: 0.003609939943999052
Epoch 363, Training Loss: 0.0037143914960324764, Validation Loss: 0.003513970645144582
Epoch 364, Training Loss: 0.003626491641625762, Validation Loss: 0.003415101207792759
Epoch 365, Training Loss: 0.003539853263646364, Validation Loss: 0.0033223300706595182
Epoch 366, Training Loss: 0.0034562069922685623, Validation Loss: 0.0032395999878644943
Epoch 367, Training Loss: 0.0033746184781193733, Validation Loss: 0.0031328427139669657
Epoch 368, Training Loss: 0.0032953647896647453, Validation Loss: 0.003040512092411518
Epoch 369, Training Loss: 0.003213459625840187, Validation Loss: 0.00295075005851686
Epoch 370, Training Loss: 0.003137734951451421, Validation Loss: 0.002857513725757599
Epoch 371, Training Loss: 0.0030642845667898655, Validation Loss: 0.002783149480819702
Epoch 372, Training Loss: 0.0029903785325586796, Validation Loss: 0.0027100653387606144
Epoch 373, Training Loss: 0.002919959370046854, Validation Loss: 0.002636699704453349
Epoch 374, Training Loss: 0.0028514601290225983, Validation Loss: 0.0025570490397512913
Epoch 375, Training Loss: 0.0027810479514300823, Validation Loss: 0.002469385741278529
Epoch 376, Training Loss: 0.0027109747752547264, Validation Loss: 0.002390594920143485
Epoch 377, Training Loss: 0.0026466555427759886, Validation Loss: 0.0023295991122722626
Epoch 378, Training Loss: 0.0025874320417642593, Validation Loss: 0.0022512231953442097
Epoch 379, Training Loss: 0.002518327673897147, Validation Loss: 0.002186741679906845
Epoch 380, Training Loss: 0.0024526515044271946, Validation Loss: 0.0021282832603901625
Epoch 381, Training Loss: 0.002392024965956807, Validation Loss: 0.00205941591411829
Epoch 382, Training Loss: 0.0023315362632274628, Validation Loss: 0.0020037684589624405
Epoch 383, Training Loss: 0.002274556318297982, Validation Loss: 0.0019391753012314439
Epoch 384, Training Loss: 0.002213686238974333, Validation Loss: 0.001884601661004126
Epoch 385, Training Loss: 0.00215703877620399, Validation Loss: 0.0018315183697268367
Epoch 386, Training Loss: 0.002098688157275319, Validation Loss: 0.001776224235072732
Epoch 387, Training Loss: 0.0020448346622288227, Validation Loss: 0.0017152221407741308
Epoch 388, Training Loss: 0.0019925374072045088, Validation Loss: 0.0016523330705240369
Epoch 389, Training Loss: 0.0019393537659198046, Validation Loss: 0.0015877116238698363
Epoch 390, Training Loss: 0.001885593868792057, Validation Loss: 0.001539014047011733
Epoch 391, Training Loss: 0.001835550065152347, Validation Loss: 0.001495090313255787
Epoch 392, Training Loss: 0.0017850743606686592, Validation Loss: 0.0014531082706525922
Epoch 393, Training Loss: 0.0017384618986397982, Validation Loss: 0.001407915260642767
Epoch 394, Training Loss: 0.001689466880634427, Validation Loss: 0.0013580811209976673
Epoch 395, Training Loss: 0.0016425714129582047, Validation Loss: 0.001310952939093113
Epoch 396, Training Loss: 0.00159965839702636, Validation Loss: 0.0012656645849347115
Epoch 397, Training Loss: 0.0015526883071288466, Validation Loss: 0.0012310174060985446
Epoch 398, Training Loss: 0.0015089379157871008, Validation Loss: 0.0012014256790280342
Epoch 399, Training Loss: 0.0014685860369354486, Validation Loss: 0.0011608405038714409
Epoch 400, Training Loss: 0.0014289793325588107, Validation Loss: 0.0011206800118088722
Epoch 401, Training Loss: 0.0013904145453125238, Validation Loss: 0.0010795763228088617
Epoch 402, Training Loss: 0.0013518270570784807, Validation Loss: 0.001041669282130897
Epoch 403, Training Loss: 0.0013139136135578156, Validation Loss: 0.0010056024184450507
Epoch 404, Training Loss: 0.001275935210287571, Validation Loss: 0.0009795973310247064
Epoch 405, Training Loss: 0.0012386266607791185, Validation Loss: 0.00095291284378618
Epoch 406, Training Loss: 0.0012034286046400666, Validation Loss: 0.0009251059382222593
Epoch 407, Training Loss: 0.0011708372039720416, Validation Loss: 0.0008922959095798433
Epoch 408, Training Loss: 0.0011375837493687868, Validation Loss: 0.0008594130631536245
Epoch 409, Training Loss: 0.0011048594024032354, Validation Loss: 0.0008332545403391123
Epoch 410, Training Loss: 0.0010718771954998374, Validation Loss: 0.0008156177937053144
Epoch 411, Training Loss: 0.0010409128153696656, Validation Loss: 0.0007961514056660235
Epoch 412, Training Loss: 0.0010121719678863883, Validation Loss: 0.000773894542362541
Epoch 413, Training Loss: 0.000983553472906351, Validation Loss: 0.0007465115049853921
Epoch 414, Training Loss: 0.0009528966038487852, Validation Loss: 0.0007184690912254155
Epoch 415, Training Loss: 0.0009243895765393972, Validation Loss: 0.0006919778534211218
Epoch 416, Training Loss: 0.0008976327953860164, Validation Loss: 0.0006715756026096642
Epoch 417, Training Loss: 0.000870484160259366, Validation Loss: 0.0006559747853316367
Epoch 418, Training Loss: 0.0008448912412859499, Validation Loss: 0.0006397446850314736
Epoch 419, Training Loss: 0.0008196541457436979, Validation Loss: 0.0006188556435517967
Epoch 420, Training Loss: 0.0007944763638079166, Validation Loss: 0.0005992496153339744
Epoch 421, Training Loss: 0.0007715090760029852, Validation Loss: 0.0005802171071991324
Epoch 422, Training Loss: 0.0007485149544663727, Validation Loss: 0.0005629683146253228
Epoch 423, Training Loss: 0.0007252194918692112, Validation Loss: 0.0005479882820509374
Epoch 424, Training Loss: 0.0007036956958472729, Validation Loss: 0.0005335601163096726
Epoch 425, Training Loss: 0.0006830759812146425, Validation Loss: 0.00051827821880579
Epoch 426, Training Loss: 0.0006631345604546368, Validation Loss: 0.0005005338462069631
Epoch 427, Training Loss: 0.0006423697341233492, Validation Loss: 0.0004859993059653789
Epoch 428, Training Loss: 0.0006232284940779209, Validation Loss: 0.00047406862722709775
Epoch 429, Training Loss: 0.0006053841789253056, Validation Loss: 0.00045987614430487156
Epoch 430, Training Loss: 0.0005872518522664905, Validation Loss: 0.00044645543675869703
Epoch 431, Training Loss: 0.0005687138182111084, Validation Loss: 0.0004335235571488738
Epoch 432, Training Loss: 0.0005506612360477448, Validation Loss: 0.00042379877413623035
Epoch 433, Training Loss: 0.0005348955746740103, Validation Loss: 0.0004129834705963731
Epoch 434, Training Loss: 0.0005185061017982662, Validation Loss: 0.0004010794509667903
Epoch 435, Training Loss: 0.0005026432918384671, Validation Loss: 0.0003875215188600123
Epoch 436, Training Loss: 0.000486826611449942, Validation Loss: 0.0003739139065146446
Epoch 437, Training Loss: 0.00047154296771623194, Validation Loss: 0.0003631488361861557
Epoch 438, Training Loss: 0.0004573954502120614, Validation Loss: 0.00035389242111705244
Epoch 439, Training Loss: 0.0004428397514857352, Validation Loss: 0.00034489211975596845
Epoch 440, Training Loss: 0.00042859616223722696, Validation Loss: 0.000335326069034636
Epoch 441, Training Loss: 0.00041473127203062177, Validation Loss: 0.0003256155760027468
Epoch 442, Training Loss: 0.00040208178688772023, Validation Loss: 0.0003161597123835236
Epoch 443, Training Loss: 0.0003900469746440649, Validation Loss: 0.0003063403710257262
Epoch 444, Training Loss: 0.00037723235436715186, Validation Loss: 0.00029751850524917245
Epoch 445, Training Loss: 0.0003646121476776898, Validation Loss: 0.00028855734854005277
Epoch 446, Training Loss: 0.00035243225283920765, Validation Loss: 0.00027897878317162395
Epoch 447, Training Loss: 0.0003407496551517397, Validation Loss: 0.0002695273724384606
Epoch 448, Training Loss: 0.00032951554749161005, Validation Loss: 0.0002606904017738998
Epoch 449, Training Loss: 0.00031911698170006275, Validation Loss: 0.0002524243318475783
Epoch 450, Training Loss: 0.00030837979284115136, Validation Loss: 0.00024459644919261336
Epoch 451, Training Loss: 0.0002978516567964107, Validation Loss: 0.00023662832973059267
Epoch 452, Training Loss: 0.00028741732239723206, Validation Loss: 0.0002286662202095613
Epoch 453, Training Loss: 0.0002776880864985287, Validation Loss: 0.0002204155462095514
Epoch 454, Training Loss: 0.00026838353369385004, Validation Loss: 0.00021265890973154455
Epoch 455, Training Loss: 0.00025913253193721175, Validation Loss: 0.00020537602540571243
Epoch 456, Training Loss: 0.00024957413552328944, Validation Loss: 0.00019899517064914107
Epoch 457, Training Loss: 0.0002408888831268996, Validation Loss: 0.00019252175115980208
Epoch 458, Training Loss: 0.00023229463840834796, Validation Loss: 0.0001853333378676325
Epoch 459, Training Loss: 0.0002233912964584306, Validation Loss: 0.00017832699813880026
Epoch 460, Training Loss: 0.00021513889078050852, Validation Loss: 0.00017150062194559723
Epoch 461, Training Loss: 0.0002074912772513926, Validation Loss: 0.0001646544988034293
Epoch 462, Training Loss: 0.00019968731794506311, Validation Loss: 0.00015898839046712965
Epoch 463, Training Loss: 0.00019194917695131153, Validation Loss: 0.0001536075578769669
Epoch 464, Training Loss: 0.00018461067520547658, Validation Loss: 0.00014841360098216683
Epoch 465, Training Loss: 0.00017752841813489795, Validation Loss: 0.00014288337843026966
Epoch 466, Training Loss: 0.00017079453391488642, Validation Loss: 0.0001373947161482647
Epoch 467, Training Loss: 0.00016426500224042684, Validation Loss: 0.00013189490709919482
Epoch 468, Training Loss: 0.00015785620780661702, Validation Loss: 0.0001264048187294975
Epoch 469, Training Loss: 0.00015175504086073488, Validation Loss: 0.0001214341536979191
Epoch 470, Training Loss: 0.00014556401583831757, Validation Loss: 0.00011718640598701313
Epoch 471, Training Loss: 0.00013991024752613157, Validation Loss: 0.00011280072794761509
Epoch 472, Training Loss: 0.0001341588795185089, Validation Loss: 0.00010804919293150306
Epoch 473, Training Loss: 0.0001286571059608832, Validation Loss: 0.00010371713869972154
Epoch 474, Training Loss: 0.00012338478700257838, Validation Loss: 9.938544098986313e-05
Epoch 475, Training Loss: 0.00011835757322842255, Validation Loss: 9.507802315056324e-05
Epoch 476, Training Loss: 0.00011313043796690181, Validation Loss: 9.15319615160115e-05
Epoch 477, Training Loss: 0.00010856126027647406, Validation Loss: 8.753680594963953e-05
Epoch 478, Training Loss: 0.00010341981396777555, Validation Loss: 8.400071237701923e-05
Epoch 479, Training Loss: 9.922296885633841e-05, Validation Loss: 8.027334843063727e-05
Epoch 480, Training Loss: 9.492448589298874e-05, Validation Loss: 7.680033741053194e-05
Epoch 481, Training Loss: 9.074332774616778e-05, Validation Loss: 7.324983016587794e-05
Epoch 482, Training Loss: 8.663949120091274e-05, Validation Loss: 6.984142237342894e-05
Epoch 483, Training Loss: 8.258788875536993e-05, Validation Loss: 6.700003723381087e-05
Epoch 484, Training Loss: 7.903767982497811e-05, Validation Loss: 6.419010605895892e-05
Epoch 485, Training Loss: 7.534860196756199e-05, Validation Loss: 6.134378054412082e-05
Epoch 486, Training Loss: 7.166300201788545e-05, Validation Loss: 5.861768659087829e-05
Epoch 487, Training Loss: 6.835571548435837e-05, Validation Loss: 5.57083185412921e-05
Epoch 488, Training Loss: 6.51232257951051e-05, Validation Loss: 5.3011070122011006e-05
Epoch 489, Training Loss: 6.21350045548752e-05, Validation Loss: 5.031198452343233e-05
Epoch 490, Training Loss: 5.9083806263515726e-05, Validation Loss: 4.78820875287056e-05
Epoch 491, Training Loss: 5.620629235636443e-05, Validation Loss: 4.5517575927078724e-05
Epoch 492, Training Loss: 5.343200245988555e-05, Validation Loss: 4.3333639041520655e-05
Epoch 493, Training Loss: 5.0734619435388595e-05, Validation Loss: 4.141046883887611e-05
Epoch 494, Training Loss: 4.8248843086184934e-05, Validation Loss: 3.9470105548389256e-05
Epoch 495, Training Loss: 4.576383071253076e-05, Validation Loss: 3.766873851418495e-05
Epoch 496, Training Loss: 4.349101800471544e-05, Validation Loss: 3.5765977372648194e-05
Epoch 497, Training Loss: 4.124207771383226e-05, Validation Loss: 3.382545037311502e-05
Epoch 498, Training Loss: 3.9048176404321566e-05, Validation Loss: 3.2107316656038165e-05
Epoch 499, Training Loss: 3.708504300448112e-05, Validation Loss: 3.0425349905272014e-05
Epoch 500, Training Loss: 3.516776268952526e-05, Validation Loss: 2.8850727176177315e-05
