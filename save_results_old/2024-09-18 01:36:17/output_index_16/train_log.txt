Epoch 1, Training Loss: 0.18043561279773712, Validation Loss: 0.1861754059791565
Epoch 2, Training Loss: 0.17983046174049377, Validation Loss: 0.18569855391979218
Epoch 3, Training Loss: 0.17804007232189178, Validation Loss: 0.1852298229932785
Epoch 4, Training Loss: 0.17895030975341797, Validation Loss: 0.18476243317127228
Epoch 5, Training Loss: 0.1773282289505005, Validation Loss: 0.18429771065711975
Epoch 6, Training Loss: 0.1774936467409134, Validation Loss: 0.18383072316646576
Epoch 7, Training Loss: 0.17706897854804993, Validation Loss: 0.1833634078502655
Epoch 8, Training Loss: 0.17551718652248383, Validation Loss: 0.18289698660373688
Epoch 9, Training Loss: 0.17523597180843353, Validation Loss: 0.18243570625782013
Epoch 10, Training Loss: 0.17443595826625824, Validation Loss: 0.1819709688425064
Epoch 11, Training Loss: 0.1748250126838684, Validation Loss: 0.1815013289451599
Epoch 12, Training Loss: 0.17356471717357635, Validation Loss: 0.18102741241455078
Epoch 13, Training Loss: 0.1736856997013092, Validation Loss: 0.18054482340812683
Epoch 14, Training Loss: 0.1738017201423645, Validation Loss: 0.18005385994911194
Epoch 15, Training Loss: 0.17183873057365417, Validation Loss: 0.1795583963394165
Epoch 16, Training Loss: 0.17089711129665375, Validation Loss: 0.1790558099746704
Epoch 17, Training Loss: 0.17170961201190948, Validation Loss: 0.17854951322078705
Epoch 18, Training Loss: 0.16970759630203247, Validation Loss: 0.17803728580474854
Epoch 19, Training Loss: 0.16858869791030884, Validation Loss: 0.17751574516296387
Epoch 20, Training Loss: 0.1684918850660324, Validation Loss: 0.1769835352897644
Epoch 21, Training Loss: 0.16796579957008362, Validation Loss: 0.17644204199314117
Epoch 22, Training Loss: 0.16727979481220245, Validation Loss: 0.1758868545293808
Epoch 23, Training Loss: 0.16747760772705078, Validation Loss: 0.17532210052013397
Epoch 24, Training Loss: 0.16687415540218353, Validation Loss: 0.17474666237831116
Epoch 25, Training Loss: 0.16803748905658722, Validation Loss: 0.17416095733642578
Epoch 26, Training Loss: 0.1668105572462082, Validation Loss: 0.17356956005096436
Epoch 27, Training Loss: 0.16669002175331116, Validation Loss: 0.17296487092971802
Epoch 28, Training Loss: 0.16539181768894196, Validation Loss: 0.1723456084728241
Epoch 29, Training Loss: 0.1641489714384079, Validation Loss: 0.17170892655849457
Epoch 30, Training Loss: 0.16330337524414062, Validation Loss: 0.1710568517446518
Epoch 31, Training Loss: 0.16218149662017822, Validation Loss: 0.17038539052009583
Epoch 32, Training Loss: 0.16105826199054718, Validation Loss: 0.16969266533851624
Epoch 33, Training Loss: 0.1607663631439209, Validation Loss: 0.16897383332252502
Epoch 34, Training Loss: 0.16024629771709442, Validation Loss: 0.16822563111782074
Epoch 35, Training Loss: 0.1602698564529419, Validation Loss: 0.16744334995746613
Epoch 36, Training Loss: 0.15852384269237518, Validation Loss: 0.16663014888763428
Epoch 37, Training Loss: 0.15671657025814056, Validation Loss: 0.16577422618865967
Epoch 38, Training Loss: 0.1555371880531311, Validation Loss: 0.16487745940685272
Epoch 39, Training Loss: 0.15626299381256104, Validation Loss: 0.16393405199050903
Epoch 40, Training Loss: 0.15270806849002838, Validation Loss: 0.1629425287246704
Epoch 41, Training Loss: 0.15263088047504425, Validation Loss: 0.16190233826637268
Epoch 42, Training Loss: 0.1553560048341751, Validation Loss: 0.1608022004365921
Epoch 43, Training Loss: 0.1516731232404709, Validation Loss: 0.15965478122234344
Epoch 44, Training Loss: 0.15131764113903046, Validation Loss: 0.15846724808216095
Epoch 45, Training Loss: 0.15019814670085907, Validation Loss: 0.15722748637199402
Epoch 46, Training Loss: 0.14420826733112335, Validation Loss: 0.15589416027069092
Epoch 47, Training Loss: 0.14559876918792725, Validation Loss: 0.1544725000858307
Epoch 48, Training Loss: 0.14467546343803406, Validation Loss: 0.15296123921871185
Epoch 49, Training Loss: 0.13862566649913788, Validation Loss: 0.15135975182056427
Epoch 50, Training Loss: 0.14423438906669617, Validation Loss: 0.1496707648038864
Epoch 51, Training Loss: 0.13914328813552856, Validation Loss: 0.14788615703582764
Epoch 52, Training Loss: 0.1378507912158966, Validation Loss: 0.14599955081939697
Epoch 53, Training Loss: 0.13600236177444458, Validation Loss: 0.14402449131011963
Epoch 54, Training Loss: 0.13378776609897614, Validation Loss: 0.1419365257024765
Epoch 55, Training Loss: 0.12919624149799347, Validation Loss: 0.13973376154899597
Epoch 56, Training Loss: 0.1281810998916626, Validation Loss: 0.13745050132274628
Epoch 57, Training Loss: 0.12704190611839294, Validation Loss: 0.13508863747119904
Epoch 58, Training Loss: 0.12428465485572815, Validation Loss: 0.13267052173614502
Epoch 59, Training Loss: 0.12242879718542099, Validation Loss: 0.1302545964717865
Epoch 60, Training Loss: 0.12083087116479874, Validation Loss: 0.1278037130832672
Epoch 61, Training Loss: 0.12034572660923004, Validation Loss: 0.12534549832344055
Epoch 62, Training Loss: 0.12026044726371765, Validation Loss: 0.12294591963291168
Epoch 63, Training Loss: 0.11764322221279144, Validation Loss: 0.12058265507221222
Epoch 64, Training Loss: 0.11571346968412399, Validation Loss: 0.11822874844074249
Epoch 65, Training Loss: 0.11110016703605652, Validation Loss: 0.11604344099760056
Epoch 66, Training Loss: 0.1131785660982132, Validation Loss: 0.1139722466468811
Epoch 67, Training Loss: 0.11838656663894653, Validation Loss: 0.11205711960792542
Epoch 68, Training Loss: 0.0988357812166214, Validation Loss: 0.11030582338571548
Epoch 69, Training Loss: 0.10882368683815002, Validation Loss: 0.10871268063783646
Epoch 70, Training Loss: 0.11093635112047195, Validation Loss: 0.10732566565275192
Epoch 71, Training Loss: 0.10748428851366043, Validation Loss: 0.10616753995418549
Epoch 72, Training Loss: 0.10691694170236588, Validation Loss: 0.10526658594608307
Epoch 73, Training Loss: 0.11725679039955139, Validation Loss: 0.10451290011405945
Epoch 74, Training Loss: 0.10638672113418579, Validation Loss: 0.10391929745674133
Epoch 75, Training Loss: 0.10591653734445572, Validation Loss: 0.10348687320947647
Epoch 76, Training Loss: 0.10817020386457443, Validation Loss: 0.10319150984287262
Epoch 77, Training Loss: 0.10476690530776978, Validation Loss: 0.10296168923377991
Epoch 78, Training Loss: 0.10601342469453812, Validation Loss: 0.10285701602697372
Epoch 79, Training Loss: 0.10967372357845306, Validation Loss: 0.10278667509555817
Epoch 80, Training Loss: 0.1081911101937294, Validation Loss: 0.10277273505926132
Epoch 81, Training Loss: 0.1095360666513443, Validation Loss: 0.10286679863929749
Epoch 82, Training Loss: 0.11765513569116592, Validation Loss: 0.10317054390907288
Epoch 83, Training Loss: 0.1026097908616066, Validation Loss: 0.10345365852117538
Epoch 84, Training Loss: 0.10278484225273132, Validation Loss: 0.10385633260011673
Epoch 85, Training Loss: 0.10167031735181808, Validation Loss: 0.1042538434267044
Epoch 86, Training Loss: 0.11405839025974274, Validation Loss: 0.1047726646065712
Epoch 87, Training Loss: 0.11004605889320374, Validation Loss: 0.10526294261217117
Epoch 88, Training Loss: 0.11183122545480728, Validation Loss: 0.1057419627904892
Epoch 89, Training Loss: 0.10101296752691269, Validation Loss: 0.10612775385379791
Epoch 90, Training Loss: 0.10097043961286545, Validation Loss: 0.10642889887094498
Epoch 91, Training Loss: 0.11227330565452576, Validation Loss: 0.10676942020654678
Epoch 92, Training Loss: 0.10546153783798218, Validation Loss: 0.10711437463760376
Epoch 93, Training Loss: 0.10114721208810806, Validation Loss: 0.10736005753278732
Epoch 94, Training Loss: 0.10217038542032242, Validation Loss: 0.10757771134376526
Epoch 95, Training Loss: 0.0982862114906311, Validation Loss: 0.10767434537410736
Epoch 96, Training Loss: 0.10838351398706436, Validation Loss: 0.10777570307254791
Epoch 97, Training Loss: 0.10738049447536469, Validation Loss: 0.10784739255905151
Epoch 98, Training Loss: 0.10687092691659927, Validation Loss: 0.10780781507492065
Epoch 99, Training Loss: 0.10356295853853226, Validation Loss: 0.10768847912549973
Epoch 100, Training Loss: 0.10391777753829956, Validation Loss: 0.10758975148200989
Epoch 101, Training Loss: 0.10275878012180328, Validation Loss: 0.10741076618432999
Epoch 102, Training Loss: 0.09732428193092346, Validation Loss: 0.10723866522312164
Epoch 103, Training Loss: 0.10452226549386978, Validation Loss: 0.10711275786161423
Epoch 104, Training Loss: 0.10347311943769455, Validation Loss: 0.10706961899995804
Epoch 105, Training Loss: 0.09912146627902985, Validation Loss: 0.10695286095142365
Epoch 106, Training Loss: 0.10897460579872131, Validation Loss: 0.10681699961423874
Epoch 107, Training Loss: 0.10222213715314865, Validation Loss: 0.10662879049777985
Epoch 108, Training Loss: 0.10145270079374313, Validation Loss: 0.10637383908033371
Epoch 109, Training Loss: 0.10255411267280579, Validation Loss: 0.10618744790554047
Epoch 110, Training Loss: 0.102720245718956, Validation Loss: 0.10603136569261551
Epoch 111, Training Loss: 0.09917110949754715, Validation Loss: 0.10592910647392273
Epoch 112, Training Loss: 0.09929180145263672, Validation Loss: 0.10581082850694656
Epoch 113, Training Loss: 0.10252132266759872, Validation Loss: 0.10567118972539902
Epoch 114, Training Loss: 0.10059595853090286, Validation Loss: 0.1055646613240242
Epoch 115, Training Loss: 0.09931836277246475, Validation Loss: 0.10546234995126724
Epoch 116, Training Loss: 0.0988493338227272, Validation Loss: 0.10531582683324814
Epoch 117, Training Loss: 0.09825045615434647, Validation Loss: 0.10516268014907837
Epoch 118, Training Loss: 0.1087406650185585, Validation Loss: 0.10521294921636581
Epoch 119, Training Loss: 0.10022154450416565, Validation Loss: 0.1052110567688942
Epoch 120, Training Loss: 0.10506746172904968, Validation Loss: 0.10518241673707962
Epoch 121, Training Loss: 0.10514522343873978, Validation Loss: 0.105156809091568
Epoch 122, Training Loss: 0.10411283373832703, Validation Loss: 0.10513406246900558
Epoch 123, Training Loss: 0.1019517257809639, Validation Loss: 0.1052047610282898
Epoch 124, Training Loss: 0.10440415143966675, Validation Loss: 0.10532420873641968
Epoch 125, Training Loss: 0.10549617558717728, Validation Loss: 0.1054430902004242
Epoch 126, Training Loss: 0.10500148683786392, Validation Loss: 0.10552168637514114
Epoch 127, Training Loss: 0.09904530644416809, Validation Loss: 0.10556160658597946
Epoch 128, Training Loss: 0.09660814702510834, Validation Loss: 0.1055087000131607
Epoch 129, Training Loss: 0.09803646057844162, Validation Loss: 0.10546345263719559
Epoch 130, Training Loss: 0.09746012836694717, Validation Loss: 0.10549808293581009
Epoch 131, Training Loss: 0.10529230535030365, Validation Loss: 0.1055489331483841
Epoch 132, Training Loss: 0.1059742346405983, Validation Loss: 0.10564079135656357
Epoch 133, Training Loss: 0.09987711906433105, Validation Loss: 0.10574910044670105
Epoch 134, Training Loss: 0.1014215424656868, Validation Loss: 0.10589638352394104
Epoch 135, Training Loss: 0.09908808767795563, Validation Loss: 0.10610800981521606
Epoch 136, Training Loss: 0.10440479964017868, Validation Loss: 0.1062537133693695
Epoch 137, Training Loss: 0.09861377626657486, Validation Loss: 0.10635921359062195
Epoch 138, Training Loss: 0.10404738783836365, Validation Loss: 0.1064448207616806
Epoch 139, Training Loss: 0.09690427780151367, Validation Loss: 0.10645252466201782
Epoch 140, Training Loss: 0.08856210857629776, Validation Loss: 0.1063297912478447
Epoch 141, Training Loss: 0.10103420168161392, Validation Loss: 0.10622061789035797
Epoch 142, Training Loss: 0.10097280144691467, Validation Loss: 0.10607217997312546
Epoch 143, Training Loss: 0.10140202939510345, Validation Loss: 0.10590342432260513
Epoch 144, Training Loss: 0.10297388583421707, Validation Loss: 0.1057855412364006
Epoch 145, Training Loss: 0.09235090762376785, Validation Loss: 0.10561145842075348
Epoch 146, Training Loss: 0.09590812027454376, Validation Loss: 0.10540393739938736
Epoch 147, Training Loss: 0.0991838350892067, Validation Loss: 0.10521414875984192
Epoch 148, Training Loss: 0.09593076258897781, Validation Loss: 0.10501588135957718
Epoch 149, Training Loss: 0.0969747006893158, Validation Loss: 0.10479004681110382
Epoch 150, Training Loss: 0.09489446878433228, Validation Loss: 0.10455084592103958
Epoch 151, Training Loss: 0.10090948641300201, Validation Loss: 0.10432146489620209
Epoch 152, Training Loss: 0.09606849402189255, Validation Loss: 0.10412894189357758
Epoch 153, Training Loss: 0.09564445167779922, Validation Loss: 0.1039016842842102
Epoch 154, Training Loss: 0.10418294370174408, Validation Loss: 0.10371324419975281
Epoch 155, Training Loss: 0.09588177502155304, Validation Loss: 0.10360689461231232
Epoch 156, Training Loss: 0.10809570550918579, Validation Loss: 0.10367971658706665
Epoch 157, Training Loss: 0.1070762574672699, Validation Loss: 0.10388081520795822
Epoch 158, Training Loss: 0.0979750007390976, Validation Loss: 0.10407022386789322
Epoch 159, Training Loss: 0.10083745419979095, Validation Loss: 0.10424219071865082
Epoch 160, Training Loss: 0.10271332412958145, Validation Loss: 0.10439754277467728
Epoch 161, Training Loss: 0.09876121580600739, Validation Loss: 0.10452121496200562
Epoch 162, Training Loss: 0.09882518649101257, Validation Loss: 0.1046631932258606
Epoch 163, Training Loss: 0.09397859126329422, Validation Loss: 0.10484272986650467
Epoch 164, Training Loss: 0.09376516193151474, Validation Loss: 0.10494024306535721
Epoch 165, Training Loss: 0.09613827615976334, Validation Loss: 0.10503975301980972
Epoch 166, Training Loss: 0.10150645673274994, Validation Loss: 0.10515036433935165
Epoch 167, Training Loss: 0.09743504971265793, Validation Loss: 0.10524845868349075
Epoch 168, Training Loss: 0.09829745441675186, Validation Loss: 0.10534802824258804
Epoch 169, Training Loss: 0.1004905179142952, Validation Loss: 0.10536792874336243
Epoch 170, Training Loss: 0.09547004848718643, Validation Loss: 0.10534782707691193
Epoch 171, Training Loss: 0.09714430570602417, Validation Loss: 0.10531289130449295
Epoch 172, Training Loss: 0.09396975487470627, Validation Loss: 0.10534325987100601
Epoch 173, Training Loss: 0.10086390376091003, Validation Loss: 0.10535497218370438
Epoch 174, Training Loss: 0.10041969269514084, Validation Loss: 0.10535023361444473
Epoch 175, Training Loss: 0.0979556068778038, Validation Loss: 0.10533491522073746
Epoch 176, Training Loss: 0.0972781777381897, Validation Loss: 0.1053658053278923
Epoch 177, Training Loss: 0.09511452913284302, Validation Loss: 0.10539639741182327
Epoch 178, Training Loss: 0.0955297127366066, Validation Loss: 0.10539557784795761
Epoch 179, Training Loss: 0.09694110602140427, Validation Loss: 0.10539299249649048
Epoch 180, Training Loss: 0.09621728956699371, Validation Loss: 0.10535792261362076
Epoch 181, Training Loss: 0.09454727172851562, Validation Loss: 0.1053772047162056
Epoch 182, Training Loss: 0.09750325977802277, Validation Loss: 0.10539006441831589
Epoch 183, Training Loss: 0.09516514837741852, Validation Loss: 0.10538646578788757
Epoch 184, Training Loss: 0.0983293205499649, Validation Loss: 0.10540993511676788
Epoch 185, Training Loss: 0.10385690629482269, Validation Loss: 0.10546854138374329
Epoch 186, Training Loss: 0.09106940776109695, Validation Loss: 0.10550644248723984
Epoch 187, Training Loss: 0.095893494784832, Validation Loss: 0.1055213138461113
Epoch 188, Training Loss: 0.09799697250127792, Validation Loss: 0.10558026283979416
Epoch 189, Training Loss: 0.09336414933204651, Validation Loss: 0.1055828258395195
Epoch 190, Training Loss: 0.10185954719781876, Validation Loss: 0.10558158159255981
Epoch 191, Training Loss: 0.09694118052721024, Validation Loss: 0.10551827400922775
Epoch 192, Training Loss: 0.10464780777692795, Validation Loss: 0.10549572110176086
Epoch 193, Training Loss: 0.09530317038297653, Validation Loss: 0.10545793175697327
Epoch 194, Training Loss: 0.09634548425674438, Validation Loss: 0.10541989654302597
Epoch 195, Training Loss: 0.10118741542100906, Validation Loss: 0.10542800277471542
Epoch 196, Training Loss: 0.10058732330799103, Validation Loss: 0.10539016872644424
Epoch 197, Training Loss: 0.09859314560890198, Validation Loss: 0.10536713153123856
Epoch 198, Training Loss: 0.09944700449705124, Validation Loss: 0.10537351667881012
Epoch 199, Training Loss: 0.10098269581794739, Validation Loss: 0.10545764118432999
Epoch 200, Training Loss: 0.09998995065689087, Validation Loss: 0.10550334304571152
Epoch 201, Training Loss: 0.09680759161710739, Validation Loss: 0.10552628338336945
Epoch 202, Training Loss: 0.09415298700332642, Validation Loss: 0.1055302694439888
Epoch 203, Training Loss: 0.09464088082313538, Validation Loss: 0.1055288165807724
Epoch 204, Training Loss: 0.10019301623106003, Validation Loss: 0.10549896210432053
Epoch 205, Training Loss: 0.0949108824133873, Validation Loss: 0.10546658933162689
Epoch 206, Training Loss: 0.09728701412677765, Validation Loss: 0.10546129941940308
Epoch 207, Training Loss: 0.10041116923093796, Validation Loss: 0.10548681765794754
Epoch 208, Training Loss: 0.10035616159439087, Validation Loss: 0.10554150491952896
Epoch 209, Training Loss: 0.10488594323396683, Validation Loss: 0.10565851628780365
Epoch 210, Training Loss: 0.09801553189754486, Validation Loss: 0.10570717602968216
Epoch 211, Training Loss: 0.10138966888189316, Validation Loss: 0.10575118660926819
Epoch 212, Training Loss: 0.09615826606750488, Validation Loss: 0.10574665665626526
Epoch 213, Training Loss: 0.09535864740610123, Validation Loss: 0.1056402325630188
Epoch 214, Training Loss: 0.0968320220708847, Validation Loss: 0.10551378130912781
Epoch 215, Training Loss: 0.10285308212041855, Validation Loss: 0.10534198582172394
Epoch 216, Training Loss: 0.0930803120136261, Validation Loss: 0.105171337723732
Epoch 217, Training Loss: 0.09669903665781021, Validation Loss: 0.10502173751592636
Epoch 218, Training Loss: 0.10249172151088715, Validation Loss: 0.10493183881044388
Epoch 219, Training Loss: 0.09263152629137039, Validation Loss: 0.1048172116279602
Epoch 220, Training Loss: 0.09826415777206421, Validation Loss: 0.10468555241823196
Epoch 221, Training Loss: 0.09950553625822067, Validation Loss: 0.10457107424736023
Epoch 222, Training Loss: 0.09413491189479828, Validation Loss: 0.10449841618537903
Epoch 223, Training Loss: 0.09866693615913391, Validation Loss: 0.1045350506901741
Epoch 224, Training Loss: 0.09822183102369308, Validation Loss: 0.10458018630743027
Epoch 225, Training Loss: 0.09235189110040665, Validation Loss: 0.10462686419487
Epoch 226, Training Loss: 0.096783846616745, Validation Loss: 0.10474814474582672
Epoch 227, Training Loss: 0.096539206802845, Validation Loss: 0.10485658794641495
Epoch 228, Training Loss: 0.09138236939907074, Validation Loss: 0.1049380674958229
Epoch 229, Training Loss: 0.0924144759774208, Validation Loss: 0.10500684380531311
Epoch 230, Training Loss: 0.0934462919831276, Validation Loss: 0.10502130538225174
Epoch 231, Training Loss: 0.09865818172693253, Validation Loss: 0.10497578978538513
Epoch 232, Training Loss: 0.09405578672885895, Validation Loss: 0.1050550788640976
Epoch 233, Training Loss: 0.09582996368408203, Validation Loss: 0.10510025173425674
Epoch 234, Training Loss: 0.09575807303190231, Validation Loss: 0.10509907454252243
Epoch 235, Training Loss: 0.10088943690061569, Validation Loss: 0.10511718690395355
Epoch 236, Training Loss: 0.09720450639724731, Validation Loss: 0.10510559380054474
Epoch 237, Training Loss: 0.09704665094614029, Validation Loss: 0.1050792783498764
Epoch 238, Training Loss: 0.10254799574613571, Validation Loss: 0.10506180673837662
Epoch 239, Training Loss: 0.09784431010484695, Validation Loss: 0.1050352081656456
Epoch 240, Training Loss: 0.09106055647134781, Validation Loss: 0.10506349802017212
Epoch 241, Training Loss: 0.0985507071018219, Validation Loss: 0.10507870465517044
Epoch 242, Training Loss: 0.09603506326675415, Validation Loss: 0.10511697828769684
Epoch 243, Training Loss: 0.09181516617536545, Validation Loss: 0.10516677051782608
Epoch 244, Training Loss: 0.09787795692682266, Validation Loss: 0.10522666573524475
Epoch 245, Training Loss: 0.09671804308891296, Validation Loss: 0.10525450855493546
Epoch 246, Training Loss: 0.09452056884765625, Validation Loss: 0.10526546835899353
Epoch 247, Training Loss: 0.09137143939733505, Validation Loss: 0.105255626142025
Epoch 248, Training Loss: 0.10108020156621933, Validation Loss: 0.1052478775382042
Epoch 249, Training Loss: 0.0997805967926979, Validation Loss: 0.10527409613132477
Epoch 250, Training Loss: 0.09477674961090088, Validation Loss: 0.10525733977556229
Epoch 251, Training Loss: 0.09860459715127945, Validation Loss: 0.10523631423711777
Epoch 252, Training Loss: 0.09554494917392731, Validation Loss: 0.10520657896995544
Epoch 253, Training Loss: 0.09564158320426941, Validation Loss: 0.10517533123493195
Epoch 254, Training Loss: 0.09015548229217529, Validation Loss: 0.10516964644193649
Epoch 255, Training Loss: 0.09140919148921967, Validation Loss: 0.10509131848812103
Epoch 256, Training Loss: 0.09471477568149567, Validation Loss: 0.105011947453022
Epoch 257, Training Loss: 0.10020122677087784, Validation Loss: 0.10498795658349991
Epoch 258, Training Loss: 0.0991932675242424, Validation Loss: 0.10501185059547424
Epoch 259, Training Loss: 0.1008375808596611, Validation Loss: 0.10508085042238235
Epoch 260, Training Loss: 0.09415630251169205, Validation Loss: 0.10517524182796478
Epoch 261, Training Loss: 0.10071804374456406, Validation Loss: 0.10532227158546448
Epoch 262, Training Loss: 0.09376125782728195, Validation Loss: 0.10546079277992249
Epoch 263, Training Loss: 0.09724429994821548, Validation Loss: 0.1055961325764656
Epoch 264, Training Loss: 0.09492617845535278, Validation Loss: 0.10580213367938995
Epoch 265, Training Loss: 0.09602750837802887, Validation Loss: 0.10599149018526077
Epoch 266, Training Loss: 0.09450767934322357, Validation Loss: 0.10607761889696121
Epoch 267, Training Loss: 0.10167434066534042, Validation Loss: 0.10618776828050613
Epoch 268, Training Loss: 0.09675976634025574, Validation Loss: 0.10629528760910034
Epoch 269, Training Loss: 0.09321778267621994, Validation Loss: 0.10634952783584595
Epoch 270, Training Loss: 0.09704199433326721, Validation Loss: 0.10631308704614639
Epoch 271, Training Loss: 0.09751538187265396, Validation Loss: 0.10626162588596344
Epoch 272, Training Loss: 0.09669799357652664, Validation Loss: 0.10622628033161163
Epoch 273, Training Loss: 0.09324242919683456, Validation Loss: 0.10616058856248856
Epoch 274, Training Loss: 0.0962967649102211, Validation Loss: 0.10608642548322678
Epoch 275, Training Loss: 0.09670187532901764, Validation Loss: 0.10598956793546677
Epoch 276, Training Loss: 0.09293102473020554, Validation Loss: 0.10591095685958862
Epoch 277, Training Loss: 0.09812986105680466, Validation Loss: 0.10582182556390762
Epoch 278, Training Loss: 0.09975086897611618, Validation Loss: 0.10569272190332413
Epoch 279, Training Loss: 0.09527137130498886, Validation Loss: 0.10558261722326279
Epoch 280, Training Loss: 0.09851180762052536, Validation Loss: 0.10552270710468292
Epoch 281, Training Loss: 0.09991470724344254, Validation Loss: 0.10546602308750153
Epoch 282, Training Loss: 0.1005219891667366, Validation Loss: 0.10542124509811401
Epoch 283, Training Loss: 0.09232631325721741, Validation Loss: 0.10532738268375397
Epoch 284, Training Loss: 0.09441719204187393, Validation Loss: 0.10523071885108948
Epoch 285, Training Loss: 0.09483351558446884, Validation Loss: 0.10508997738361359
Epoch 286, Training Loss: 0.096370168030262, Validation Loss: 0.10492236912250519
Epoch 287, Training Loss: 0.09259132295846939, Validation Loss: 0.10473837703466415
Epoch 288, Training Loss: 0.08965758234262466, Validation Loss: 0.10454944521188736
Epoch 289, Training Loss: 0.09468233585357666, Validation Loss: 0.10439112037420273
Epoch 290, Training Loss: 0.09067665785551071, Validation Loss: 0.10428860783576965
Epoch 291, Training Loss: 0.09258697181940079, Validation Loss: 0.10418678820133209
Epoch 292, Training Loss: 0.10005389899015427, Validation Loss: 0.10415557026863098
Epoch 293, Training Loss: 0.097056083381176, Validation Loss: 0.10417724400758743
Epoch 294, Training Loss: 0.09142615646123886, Validation Loss: 0.1041552871465683
Epoch 295, Training Loss: 0.09767460823059082, Validation Loss: 0.10418213903903961
Epoch 296, Training Loss: 0.09520208090543747, Validation Loss: 0.10416045784950256
Epoch 297, Training Loss: 0.08938088268041611, Validation Loss: 0.10418564081192017
Epoch 298, Training Loss: 0.08920448273420334, Validation Loss: 0.10419227927923203
Epoch 299, Training Loss: 0.09167486429214478, Validation Loss: 0.1041630282998085
Epoch 300, Training Loss: 0.09472314268350601, Validation Loss: 0.10416869074106216
Epoch 301, Training Loss: 0.09310204535722733, Validation Loss: 0.10420392453670502
Epoch 302, Training Loss: 0.08983222395181656, Validation Loss: 0.10417837649583817
Epoch 303, Training Loss: 0.09710400551557541, Validation Loss: 0.10416959971189499
Epoch 304, Training Loss: 0.0959399864077568, Validation Loss: 0.10418488085269928
Epoch 305, Training Loss: 0.09265325218439102, Validation Loss: 0.10420284420251846
Epoch 306, Training Loss: 0.09725300222635269, Validation Loss: 0.10428126156330109
Epoch 307, Training Loss: 0.09675939381122589, Validation Loss: 0.10435598343610764
Epoch 308, Training Loss: 0.09366853535175323, Validation Loss: 0.10440326482057571
Epoch 309, Training Loss: 0.09540103375911713, Validation Loss: 0.1044781282544136
Epoch 310, Training Loss: 0.09395360946655273, Validation Loss: 0.1046118214726448
Epoch 311, Training Loss: 0.09737588465213776, Validation Loss: 0.10476083308458328
Epoch 312, Training Loss: 0.08933458477258682, Validation Loss: 0.10487283021211624
Epoch 313, Training Loss: 0.09629266709089279, Validation Loss: 0.10505001991987228
Epoch 314, Training Loss: 0.09452464431524277, Validation Loss: 0.10518176108598709
Epoch 315, Training Loss: 0.0960550531744957, Validation Loss: 0.10529951006174088
Epoch 316, Training Loss: 0.09100241214036942, Validation Loss: 0.10536525398492813
Epoch 317, Training Loss: 0.09578989446163177, Validation Loss: 0.10538455843925476
Epoch 318, Training Loss: 0.09075706452131271, Validation Loss: 0.10537490248680115
Epoch 319, Training Loss: 0.09238062798976898, Validation Loss: 0.10529404878616333
Epoch 320, Training Loss: 0.09940637648105621, Validation Loss: 0.1053289920091629
Epoch 321, Training Loss: 0.09402626752853394, Validation Loss: 0.10536383837461472
Epoch 322, Training Loss: 0.097682423889637, Validation Loss: 0.10536859929561615
Epoch 323, Training Loss: 0.10526615381240845, Validation Loss: 0.10545188188552856
Epoch 324, Training Loss: 0.09415749460458755, Validation Loss: 0.10545375198125839
Epoch 325, Training Loss: 0.09355340152978897, Validation Loss: 0.10543908178806305
Epoch 326, Training Loss: 0.09547998756170273, Validation Loss: 0.10546495765447617
Epoch 327, Training Loss: 0.09249260276556015, Validation Loss: 0.105440154671669
Epoch 328, Training Loss: 0.09416547417640686, Validation Loss: 0.10540458559989929
Epoch 329, Training Loss: 0.09742254763841629, Validation Loss: 0.10530314594507217
Epoch 330, Training Loss: 0.09508966654539108, Validation Loss: 0.10516596585512161
Epoch 331, Training Loss: 0.09904970228672028, Validation Loss: 0.10507362335920334
Epoch 332, Training Loss: 0.09256687760353088, Validation Loss: 0.10496801882982254
Epoch 333, Training Loss: 0.09191713482141495, Validation Loss: 0.10485218465328217
Epoch 334, Training Loss: 0.09674489498138428, Validation Loss: 0.1047583743929863
Epoch 335, Training Loss: 0.09390037506818771, Validation Loss: 0.10467063635587692
Epoch 336, Training Loss: 0.09543583542108536, Validation Loss: 0.1045951321721077
Epoch 337, Training Loss: 0.09309311211109161, Validation Loss: 0.10455047339200974
Epoch 338, Training Loss: 0.09436754137277603, Validation Loss: 0.1045648381114006
Epoch 339, Training Loss: 0.09469441324472427, Validation Loss: 0.10452578961849213
Epoch 340, Training Loss: 0.09716708958148956, Validation Loss: 0.10451671481132507
Epoch 341, Training Loss: 0.09308293461799622, Validation Loss: 0.10452509671449661
Epoch 342, Training Loss: 0.0963398888707161, Validation Loss: 0.10454429686069489
Epoch 343, Training Loss: 0.09780137985944748, Validation Loss: 0.10457757860422134
Epoch 344, Training Loss: 0.09611713886260986, Validation Loss: 0.10462172329425812
Epoch 345, Training Loss: 0.099455825984478, Validation Loss: 0.10476584732532501
Epoch 346, Training Loss: 0.09364528208971024, Validation Loss: 0.10489387065172195
Epoch 347, Training Loss: 0.09116893261671066, Validation Loss: 0.10502364486455917
Epoch 348, Training Loss: 0.0935896784067154, Validation Loss: 0.10513929277658463
Epoch 349, Training Loss: 0.08812647312879562, Validation Loss: 0.10519660264253616
Epoch 350, Training Loss: 0.09273859858512878, Validation Loss: 0.10520424693822861
Epoch 351, Training Loss: 0.09137097746133804, Validation Loss: 0.10517146438360214
Epoch 352, Training Loss: 0.09608633816242218, Validation Loss: 0.10509025305509567
Epoch 353, Training Loss: 0.09138431400060654, Validation Loss: 0.10501641035079956
Epoch 354, Training Loss: 0.0969306156039238, Validation Loss: 0.10497885942459106
Epoch 355, Training Loss: 0.09792040288448334, Validation Loss: 0.10492327064275742
Epoch 356, Training Loss: 0.09396719932556152, Validation Loss: 0.10485421866178513
Epoch 357, Training Loss: 0.09380543231964111, Validation Loss: 0.10480528324842453
Epoch 358, Training Loss: 0.09617799520492554, Validation Loss: 0.10476956516504288
Epoch 359, Training Loss: 0.09796418249607086, Validation Loss: 0.10477526485919952
Epoch 360, Training Loss: 0.09215628355741501, Validation Loss: 0.1047072559595108
Epoch 361, Training Loss: 0.09633617848157883, Validation Loss: 0.10465937852859497
Epoch 362, Training Loss: 0.09633228927850723, Validation Loss: 0.10462409257888794
Epoch 363, Training Loss: 0.09137743711471558, Validation Loss: 0.10465086996555328
Epoch 364, Training Loss: 0.09218332916498184, Validation Loss: 0.10470665991306305
Epoch 365, Training Loss: 0.09566351771354675, Validation Loss: 0.10475608706474304
Epoch 366, Training Loss: 0.09573454409837723, Validation Loss: 0.104822538793087
Epoch 367, Training Loss: 0.09306126832962036, Validation Loss: 0.1048273891210556
Epoch 368, Training Loss: 0.0918312668800354, Validation Loss: 0.10479103773832321
Epoch 369, Training Loss: 0.09728097915649414, Validation Loss: 0.10475087910890579
Epoch 370, Training Loss: 0.090777188539505, Validation Loss: 0.10465563088655472
Epoch 371, Training Loss: 0.09228815138339996, Validation Loss: 0.10459662228822708
Epoch 372, Training Loss: 0.08929615467786789, Validation Loss: 0.10450099408626556
Epoch 373, Training Loss: 0.09541969746351242, Validation Loss: 0.10446877032518387
Epoch 374, Training Loss: 0.09514044225215912, Validation Loss: 0.10443443804979324
Epoch 375, Training Loss: 0.09637846797704697, Validation Loss: 0.10442563891410828
Epoch 376, Training Loss: 0.09342920035123825, Validation Loss: 0.10441576689481735
Epoch 377, Training Loss: 0.09290705621242523, Validation Loss: 0.10436498373746872
Epoch 378, Training Loss: 0.09498336166143417, Validation Loss: 0.1043294221162796
Epoch 379, Training Loss: 0.09116225689649582, Validation Loss: 0.10431525856256485
Epoch 380, Training Loss: 0.0971933901309967, Validation Loss: 0.10433593392372131
Epoch 381, Training Loss: 0.09697289764881134, Validation Loss: 0.10436346381902695
Epoch 382, Training Loss: 0.09456385672092438, Validation Loss: 0.10434876382350922
Epoch 383, Training Loss: 0.09251517802476883, Validation Loss: 0.10440602898597717
Epoch 384, Training Loss: 0.09039793908596039, Validation Loss: 0.10445448756217957
Epoch 385, Training Loss: 0.09319180995225906, Validation Loss: 0.10449634492397308
Epoch 386, Training Loss: 0.09186803549528122, Validation Loss: 0.10451306402683258
Epoch 387, Training Loss: 0.09627900272607803, Validation Loss: 0.10459389537572861
Epoch 388, Training Loss: 0.0926118791103363, Validation Loss: 0.10461048036813736
Epoch 389, Training Loss: 0.09600881487131119, Validation Loss: 0.1045876145362854
Epoch 390, Training Loss: 0.09404905140399933, Validation Loss: 0.1045047715306282
Epoch 391, Training Loss: 0.09294547140598297, Validation Loss: 0.10437804460525513
Epoch 392, Training Loss: 0.09437596797943115, Validation Loss: 0.1042092889547348
Epoch 393, Training Loss: 0.0948701947927475, Validation Loss: 0.10405535250902176
Epoch 394, Training Loss: 0.09238512814044952, Validation Loss: 0.10394926369190216
Epoch 395, Training Loss: 0.08887399733066559, Validation Loss: 0.10386351495981216
Epoch 396, Training Loss: 0.09539289027452469, Validation Loss: 0.10384046286344528
Epoch 397, Training Loss: 0.09540659934282303, Validation Loss: 0.1038547232747078
Epoch 398, Training Loss: 0.09185134619474411, Validation Loss: 0.10383795946836472
Epoch 399, Training Loss: 0.09852167963981628, Validation Loss: 0.10385594516992569
Epoch 400, Training Loss: 0.09516894072294235, Validation Loss: 0.1039077639579773
Epoch 401, Training Loss: 0.09058789163827896, Validation Loss: 0.10395336896181107
Epoch 402, Training Loss: 0.09557487815618515, Validation Loss: 0.10399941354990005
Epoch 403, Training Loss: 0.09334590286016464, Validation Loss: 0.10405601561069489
Epoch 404, Training Loss: 0.09152344614267349, Validation Loss: 0.10410426557064056
Epoch 405, Training Loss: 0.09625180065631866, Validation Loss: 0.1042063981294632
Epoch 406, Training Loss: 0.09395420551300049, Validation Loss: 0.10428661853075027
Epoch 407, Training Loss: 0.08845529705286026, Validation Loss: 0.10429777204990387
Epoch 408, Training Loss: 0.0939607173204422, Validation Loss: 0.10442748665809631
Epoch 409, Training Loss: 0.09168335795402527, Validation Loss: 0.10454822331666946
Epoch 410, Training Loss: 0.09345612674951553, Validation Loss: 0.10460648685693741
Epoch 411, Training Loss: 0.09263876080513, Validation Loss: 0.10465548932552338
Epoch 412, Training Loss: 0.09479391574859619, Validation Loss: 0.10464237630367279
Epoch 413, Training Loss: 0.0926203653216362, Validation Loss: 0.10463834553956985
Epoch 414, Training Loss: 0.09557551890611649, Validation Loss: 0.10471771657466888
Epoch 415, Training Loss: 0.09417252987623215, Validation Loss: 0.10477996617555618
Epoch 416, Training Loss: 0.09266017377376556, Validation Loss: 0.10482806712388992
Epoch 417, Training Loss: 0.09062758088111877, Validation Loss: 0.10484444350004196
Epoch 418, Training Loss: 0.09370072185993195, Validation Loss: 0.10480636358261108
Epoch 419, Training Loss: 0.09430898725986481, Validation Loss: 0.1047482043504715
Epoch 420, Training Loss: 0.09196271002292633, Validation Loss: 0.10466642677783966
Epoch 421, Training Loss: 0.09447338432073593, Validation Loss: 0.1045493483543396
Epoch 422, Training Loss: 0.0922868475317955, Validation Loss: 0.1044325903058052
Epoch 423, Training Loss: 0.09419432282447815, Validation Loss: 0.10432485491037369
Epoch 424, Training Loss: 0.09367666393518448, Validation Loss: 0.10426674038171768
Epoch 425, Training Loss: 0.09568364918231964, Validation Loss: 0.10425775498151779
Epoch 426, Training Loss: 0.09292963892221451, Validation Loss: 0.10424114018678665
Epoch 427, Training Loss: 0.09701762348413467, Validation Loss: 0.10423117130994797
Epoch 428, Training Loss: 0.09411249309778214, Validation Loss: 0.10423622280359268
Epoch 429, Training Loss: 0.09449826180934906, Validation Loss: 0.10422874987125397
Epoch 430, Training Loss: 0.09610588848590851, Validation Loss: 0.10420603305101395
Epoch 431, Training Loss: 0.09482941776514053, Validation Loss: 0.1041736975312233
Epoch 432, Training Loss: 0.09993872046470642, Validation Loss: 0.10418335348367691
Epoch 433, Training Loss: 0.09613851457834244, Validation Loss: 0.10423066467046738
Epoch 434, Training Loss: 0.09487992525100708, Validation Loss: 0.10429389774799347
Epoch 435, Training Loss: 0.09019655734300613, Validation Loss: 0.10432187467813492
Epoch 436, Training Loss: 0.09587495774030685, Validation Loss: 0.1043870821595192
Epoch 437, Training Loss: 0.09021313488483429, Validation Loss: 0.10442470014095306
Epoch 438, Training Loss: 0.09059452265501022, Validation Loss: 0.10447333753108978
Epoch 439, Training Loss: 0.09446985274553299, Validation Loss: 0.10454075783491135
Epoch 440, Training Loss: 0.0916811004281044, Validation Loss: 0.1046033501625061
Epoch 441, Training Loss: 0.0945691466331482, Validation Loss: 0.10463022440671921
Epoch 442, Training Loss: 0.0887177363038063, Validation Loss: 0.1046188473701477
Epoch 443, Training Loss: 0.09476004540920258, Validation Loss: 0.10467220097780228
Epoch 444, Training Loss: 0.09008561819791794, Validation Loss: 0.10464734584093094
Epoch 445, Training Loss: 0.09636799246072769, Validation Loss: 0.10458432137966156
Epoch 446, Training Loss: 0.0945361852645874, Validation Loss: 0.10451995581388474
Epoch 447, Training Loss: 0.09144670516252518, Validation Loss: 0.10450290143489838
Epoch 448, Training Loss: 0.09212854504585266, Validation Loss: 0.1045399084687233
Epoch 449, Training Loss: 0.09304285049438477, Validation Loss: 0.10451053082942963
Epoch 450, Training Loss: 0.08976949751377106, Validation Loss: 0.10443728417158127
Epoch 451, Training Loss: 0.09569880366325378, Validation Loss: 0.10433096438646317
Epoch 452, Training Loss: 0.09085681289434433, Validation Loss: 0.10425402969121933
Epoch 453, Training Loss: 0.08953212201595306, Validation Loss: 0.10413531213998795
Epoch 454, Training Loss: 0.09644317626953125, Validation Loss: 0.10412456840276718
Epoch 455, Training Loss: 0.09612838178873062, Validation Loss: 0.10410212725400925
Epoch 456, Training Loss: 0.09616762399673462, Validation Loss: 0.10413254052400589
Epoch 457, Training Loss: 0.09182894229888916, Validation Loss: 0.10414593666791916
Epoch 458, Training Loss: 0.09434682130813599, Validation Loss: 0.10412226617336273
Epoch 459, Training Loss: 0.09160821884870529, Validation Loss: 0.10414780676364899
Epoch 460, Training Loss: 0.09669472277164459, Validation Loss: 0.10414760559797287
Epoch 461, Training Loss: 0.09415163099765778, Validation Loss: 0.10417843610048294
Epoch 462, Training Loss: 0.09558439254760742, Validation Loss: 0.10419455170631409
Epoch 463, Training Loss: 0.09429671615362167, Validation Loss: 0.10422703623771667
Epoch 464, Training Loss: 0.09521204233169556, Validation Loss: 0.10422703623771667
Epoch 465, Training Loss: 0.09283025562763214, Validation Loss: 0.10419116169214249
Epoch 466, Training Loss: 0.09155048429965973, Validation Loss: 0.10416243225336075
Epoch 467, Training Loss: 0.09391067922115326, Validation Loss: 0.10416019707918167
Epoch 468, Training Loss: 0.09439490735530853, Validation Loss: 0.10416864603757858
Epoch 469, Training Loss: 0.09108252078294754, Validation Loss: 0.10416623950004578
Epoch 470, Training Loss: 0.09259466081857681, Validation Loss: 0.1041250005364418
Epoch 471, Training Loss: 0.0962885394692421, Validation Loss: 0.10405100882053375
Epoch 472, Training Loss: 0.09181809425354004, Validation Loss: 0.10398087650537491
Epoch 473, Training Loss: 0.09181152284145355, Validation Loss: 0.10390619188547134
Epoch 474, Training Loss: 0.09218630939722061, Validation Loss: 0.10381926596164703
Epoch 475, Training Loss: 0.09183309227228165, Validation Loss: 0.10376117378473282
Epoch 476, Training Loss: 0.09365639835596085, Validation Loss: 0.10369136184453964
Epoch 477, Training Loss: 0.09208539873361588, Validation Loss: 0.10362798720598221
Epoch 478, Training Loss: 0.09212813526391983, Validation Loss: 0.10353083163499832
Epoch 479, Training Loss: 0.09757409244775772, Validation Loss: 0.10347197949886322
Epoch 480, Training Loss: 0.09503260999917984, Validation Loss: 0.10350391268730164
Epoch 481, Training Loss: 0.09328120201826096, Validation Loss: 0.10354442149400711
Epoch 482, Training Loss: 0.09249338507652283, Validation Loss: 0.10360891371965408
Epoch 483, Training Loss: 0.0954800620675087, Validation Loss: 0.10363826900720596
Epoch 484, Training Loss: 0.09110190719366074, Validation Loss: 0.10369178652763367
Epoch 485, Training Loss: 0.09230021387338638, Validation Loss: 0.10375115275382996
Epoch 486, Training Loss: 0.08978600054979324, Validation Loss: 0.1038142666220665
Epoch 487, Training Loss: 0.09319908916950226, Validation Loss: 0.10385934263467789
Epoch 488, Training Loss: 0.09307654201984406, Validation Loss: 0.10387483239173889
Epoch 489, Training Loss: 0.09298411756753922, Validation Loss: 0.1038542091846466
Epoch 490, Training Loss: 0.09203335642814636, Validation Loss: 0.1038409024477005
Epoch 491, Training Loss: 0.09405030310153961, Validation Loss: 0.10383132100105286
Epoch 492, Training Loss: 0.0923696905374527, Validation Loss: 0.10383151471614838
Epoch 493, Training Loss: 0.09181469678878784, Validation Loss: 0.10377396643161774
Epoch 494, Training Loss: 0.0983070358633995, Validation Loss: 0.10369326919317245
Epoch 495, Training Loss: 0.09533216804265976, Validation Loss: 0.10363972932100296
Epoch 496, Training Loss: 0.09280052781105042, Validation Loss: 0.1036461666226387
Epoch 497, Training Loss: 0.09548800438642502, Validation Loss: 0.10365723818540573
Epoch 498, Training Loss: 0.09196074306964874, Validation Loss: 0.10365945845842361
Epoch 499, Training Loss: 0.09426585584878922, Validation Loss: 0.10371802747249603
Epoch 500, Training Loss: 0.09221302717924118, Validation Loss: 0.1037549301981926
