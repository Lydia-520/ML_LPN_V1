Epoch 1, Training Loss: 0.19350460171699524, Validation Loss: 0.19805625081062317
Epoch 2, Training Loss: 0.19253338873386383, Validation Loss: 0.19747239351272583
Epoch 3, Training Loss: 0.1921072006225586, Validation Loss: 0.19689986109733582
Epoch 4, Training Loss: 0.1923087239265442, Validation Loss: 0.19632971286773682
Epoch 5, Training Loss: 0.18929210305213928, Validation Loss: 0.19575472176074982
Epoch 6, Training Loss: 0.191179558634758, Validation Loss: 0.19518505036830902
Epoch 7, Training Loss: 0.1897086203098297, Validation Loss: 0.1946106255054474
Epoch 8, Training Loss: 0.19026967883110046, Validation Loss: 0.1940358281135559
Epoch 9, Training Loss: 0.1900329887866974, Validation Loss: 0.1934625208377838
Epoch 10, Training Loss: 0.18851031363010406, Validation Loss: 0.19289521872997284
Epoch 11, Training Loss: 0.1874658614397049, Validation Loss: 0.19233261048793793
Epoch 12, Training Loss: 0.1884295642375946, Validation Loss: 0.19177599251270294
Epoch 13, Training Loss: 0.18508301675319672, Validation Loss: 0.1912180483341217
Epoch 14, Training Loss: 0.18436530232429504, Validation Loss: 0.19066715240478516
Epoch 15, Training Loss: 0.1859283298254013, Validation Loss: 0.19012004137039185
Epoch 16, Training Loss: 0.18521404266357422, Validation Loss: 0.18957026302814484
Epoch 17, Training Loss: 0.18456248939037323, Validation Loss: 0.1890171766281128
Epoch 18, Training Loss: 0.18454255163669586, Validation Loss: 0.18845896422863007
Epoch 19, Training Loss: 0.18230056762695312, Validation Loss: 0.18789079785346985
Epoch 20, Training Loss: 0.1803152859210968, Validation Loss: 0.18731072545051575
Epoch 21, Training Loss: 0.18033787608146667, Validation Loss: 0.18672628700733185
Epoch 22, Training Loss: 0.17924322187900543, Validation Loss: 0.18613533675670624
Epoch 23, Training Loss: 0.18015015125274658, Validation Loss: 0.18553601205348969
Epoch 24, Training Loss: 0.17782467603683472, Validation Loss: 0.18491673469543457
Epoch 25, Training Loss: 0.1781305968761444, Validation Loss: 0.1842799186706543
Epoch 26, Training Loss: 0.17673486471176147, Validation Loss: 0.18363256752490997
Epoch 27, Training Loss: 0.17672862112522125, Validation Loss: 0.18297386169433594
Epoch 28, Training Loss: 0.17663827538490295, Validation Loss: 0.18230277299880981
Epoch 29, Training Loss: 0.1757386177778244, Validation Loss: 0.1816118061542511
Epoch 30, Training Loss: 0.17174501717090607, Validation Loss: 0.1808975487947464
Epoch 31, Training Loss: 0.1727827787399292, Validation Loss: 0.1801632046699524
Epoch 32, Training Loss: 0.1752985119819641, Validation Loss: 0.17940525710582733
Epoch 33, Training Loss: 0.17258450388908386, Validation Loss: 0.17862753570079803
Epoch 34, Training Loss: 0.16929733753204346, Validation Loss: 0.1778210997581482
Epoch 35, Training Loss: 0.16914549469947815, Validation Loss: 0.1769844889640808
Epoch 36, Training Loss: 0.16717706620693207, Validation Loss: 0.17611263692378998
Epoch 37, Training Loss: 0.16833101212978363, Validation Loss: 0.17520320415496826
Epoch 38, Training Loss: 0.16523614525794983, Validation Loss: 0.17424936592578888
Epoch 39, Training Loss: 0.1637146770954132, Validation Loss: 0.17322993278503418
Epoch 40, Training Loss: 0.16355623304843903, Validation Loss: 0.1721525639295578
Epoch 41, Training Loss: 0.1614937037229538, Validation Loss: 0.17102625966072083
Epoch 42, Training Loss: 0.16191034018993378, Validation Loss: 0.16984176635742188
Epoch 43, Training Loss: 0.1565447598695755, Validation Loss: 0.16859307885169983
Epoch 44, Training Loss: 0.1592005342245102, Validation Loss: 0.16728918254375458
Epoch 45, Training Loss: 0.15672926604747772, Validation Loss: 0.16592587530612946
Epoch 46, Training Loss: 0.1560010015964508, Validation Loss: 0.16451340913772583
Epoch 47, Training Loss: 0.15482322871685028, Validation Loss: 0.1630483865737915
Epoch 48, Training Loss: 0.153177872300148, Validation Loss: 0.1615319848060608
Epoch 49, Training Loss: 0.14937478303909302, Validation Loss: 0.15992818772792816
Epoch 50, Training Loss: 0.15051965415477753, Validation Loss: 0.15823888778686523
Epoch 51, Training Loss: 0.14496321976184845, Validation Loss: 0.1564432680606842
Epoch 52, Training Loss: 0.1449265331029892, Validation Loss: 0.15456950664520264
Epoch 53, Training Loss: 0.1410975456237793, Validation Loss: 0.1525915563106537
Epoch 54, Training Loss: 0.13836224377155304, Validation Loss: 0.15050575137138367
Epoch 55, Training Loss: 0.14429818093776703, Validation Loss: 0.14833128452301025
Epoch 56, Training Loss: 0.1335410624742508, Validation Loss: 0.14603324234485626
Epoch 57, Training Loss: 0.1298971027135849, Validation Loss: 0.14361925423145294
Epoch 58, Training Loss: 0.1323716640472412, Validation Loss: 0.141119122505188
Epoch 59, Training Loss: 0.1332814246416092, Validation Loss: 0.1385289877653122
Epoch 60, Training Loss: 0.12817084789276123, Validation Loss: 0.13588161766529083
Epoch 61, Training Loss: 0.12140055000782013, Validation Loss: 0.13321730494499207
Epoch 62, Training Loss: 0.11706449836492538, Validation Loss: 0.13051922619342804
Epoch 63, Training Loss: 0.11770329624414444, Validation Loss: 0.12776601314544678
Epoch 64, Training Loss: 0.11612905561923981, Validation Loss: 0.12503327429294586
Epoch 65, Training Loss: 0.12066176533699036, Validation Loss: 0.12241384387016296
Epoch 66, Training Loss: 0.12216000258922577, Validation Loss: 0.11990827322006226
Epoch 67, Training Loss: 0.11269010603427887, Validation Loss: 0.11756373196840286
Epoch 68, Training Loss: 0.11366769671440125, Validation Loss: 0.11546030640602112
Epoch 69, Training Loss: 0.10337510704994202, Validation Loss: 0.11356369405984879
Epoch 70, Training Loss: 0.10800186544656754, Validation Loss: 0.11180222779512405
Epoch 71, Training Loss: 0.11991307139396667, Validation Loss: 0.11050776392221451
Epoch 72, Training Loss: 0.1126679852604866, Validation Loss: 0.10943697392940521
Epoch 73, Training Loss: 0.11113334447145462, Validation Loss: 0.1086384728550911
Epoch 74, Training Loss: 0.10713407397270203, Validation Loss: 0.1080055981874466
Epoch 75, Training Loss: 0.11062804609537125, Validation Loss: 0.10748997330665588
Epoch 76, Training Loss: 0.11155558377504349, Validation Loss: 0.10707062482833862
Epoch 77, Training Loss: 0.10433881729841232, Validation Loss: 0.10669397562742233
Epoch 78, Training Loss: 0.11618024110794067, Validation Loss: 0.10644097626209259
Epoch 79, Training Loss: 0.10923100262880325, Validation Loss: 0.10639724880456924
Epoch 80, Training Loss: 0.10407975316047668, Validation Loss: 0.10639417916536331
Epoch 81, Training Loss: 0.11011439561843872, Validation Loss: 0.10643798112869263
Epoch 82, Training Loss: 0.11187146604061127, Validation Loss: 0.1066453754901886
Epoch 83, Training Loss: 0.10858116298913956, Validation Loss: 0.10690262913703918
Epoch 84, Training Loss: 0.10751194506883621, Validation Loss: 0.10723897814750671
Epoch 85, Training Loss: 0.10932303220033646, Validation Loss: 0.10760276764631271
Epoch 86, Training Loss: 0.10860796272754669, Validation Loss: 0.10805141180753708
Epoch 87, Training Loss: 0.1072593405842781, Validation Loss: 0.10848505795001984
Epoch 88, Training Loss: 0.09615883976221085, Validation Loss: 0.10888055711984634
Epoch 89, Training Loss: 0.10413883626461029, Validation Loss: 0.10921940207481384
Epoch 90, Training Loss: 0.10510804504156113, Validation Loss: 0.10947329550981522
Epoch 91, Training Loss: 0.10419400036334991, Validation Loss: 0.10979768633842468
Epoch 92, Training Loss: 0.10815835744142532, Validation Loss: 0.11001521348953247
Epoch 93, Training Loss: 0.1009921208024025, Validation Loss: 0.11015135049819946
Epoch 94, Training Loss: 0.10779105871915817, Validation Loss: 0.11019397526979446
Epoch 95, Training Loss: 0.11054213345050812, Validation Loss: 0.11017588526010513
Epoch 96, Training Loss: 0.09972948580980301, Validation Loss: 0.11008130013942719
Epoch 97, Training Loss: 0.10804670304059982, Validation Loss: 0.10995007306337357
Epoch 98, Training Loss: 0.10733918100595474, Validation Loss: 0.10988452285528183
Epoch 99, Training Loss: 0.10537248849868774, Validation Loss: 0.10976053029298782
Epoch 100, Training Loss: 0.10165367275476456, Validation Loss: 0.10951314866542816
Epoch 101, Training Loss: 0.10435131192207336, Validation Loss: 0.10941611230373383
Epoch 102, Training Loss: 0.10806138813495636, Validation Loss: 0.10936553031206131
Epoch 103, Training Loss: 0.11490543186664581, Validation Loss: 0.10941488295793533
Epoch 104, Training Loss: 0.09574563056230545, Validation Loss: 0.10937311500310898
Epoch 105, Training Loss: 0.106901615858078, Validation Loss: 0.10927306115627289
Epoch 106, Training Loss: 0.09922178089618683, Validation Loss: 0.10918384790420532
Epoch 107, Training Loss: 0.11244011670351028, Validation Loss: 0.1091218888759613
Epoch 108, Training Loss: 0.10535106807947159, Validation Loss: 0.10904739052057266
Epoch 109, Training Loss: 0.10400404036045074, Validation Loss: 0.10892330855131149
Epoch 110, Training Loss: 0.10331139713525772, Validation Loss: 0.10879438370466232
Epoch 111, Training Loss: 0.10409928858280182, Validation Loss: 0.1086450144648552
Epoch 112, Training Loss: 0.10364824533462524, Validation Loss: 0.10854818671941757
Epoch 113, Training Loss: 0.1071084514260292, Validation Loss: 0.10846806317567825
Epoch 114, Training Loss: 0.10666490346193314, Validation Loss: 0.10848047584295273
Epoch 115, Training Loss: 0.10878852754831314, Validation Loss: 0.10849844664335251
Epoch 116, Training Loss: 0.10013305395841599, Validation Loss: 0.10850311815738678
Epoch 117, Training Loss: 0.09660497307777405, Validation Loss: 0.10843880474567413
Epoch 118, Training Loss: 0.10553576052188873, Validation Loss: 0.10846679657697678
Epoch 119, Training Loss: 0.10602167248725891, Validation Loss: 0.10854682326316833
Epoch 120, Training Loss: 0.09794609993696213, Validation Loss: 0.10858757793903351
Epoch 121, Training Loss: 0.10736753791570663, Validation Loss: 0.10861019045114517
Epoch 122, Training Loss: 0.1079670712351799, Validation Loss: 0.1086604967713356
Epoch 123, Training Loss: 0.10535655170679092, Validation Loss: 0.1086939349770546
Epoch 124, Training Loss: 0.10572778433561325, Validation Loss: 0.10873103886842728
Epoch 125, Training Loss: 0.10089944303035736, Validation Loss: 0.10877794772386551
Epoch 126, Training Loss: 0.10271773487329483, Validation Loss: 0.1087508574128151
Epoch 127, Training Loss: 0.10201634466648102, Validation Loss: 0.10864179581403732
Epoch 128, Training Loss: 0.10735910385847092, Validation Loss: 0.10854080319404602
Epoch 129, Training Loss: 0.10231144726276398, Validation Loss: 0.10848360508680344
Epoch 130, Training Loss: 0.0946166068315506, Validation Loss: 0.10839340090751648
Epoch 131, Training Loss: 0.10098912566900253, Validation Loss: 0.1082155629992485
Epoch 132, Training Loss: 0.10396609455347061, Validation Loss: 0.1081077829003334
Epoch 133, Training Loss: 0.10693445801734924, Validation Loss: 0.10803209990262985
Epoch 134, Training Loss: 0.10346127301454544, Validation Loss: 0.10795632004737854
Epoch 135, Training Loss: 0.1064077839255333, Validation Loss: 0.10787314921617508
Epoch 136, Training Loss: 0.10302231460809708, Validation Loss: 0.10777480900287628
Epoch 137, Training Loss: 0.10802076011896133, Validation Loss: 0.10776955634355545
Epoch 138, Training Loss: 0.09799807518720627, Validation Loss: 0.10775164514780045
Epoch 139, Training Loss: 0.09947089105844498, Validation Loss: 0.10765789449214935
Epoch 140, Training Loss: 0.10079112648963928, Validation Loss: 0.10758178681135178
Epoch 141, Training Loss: 0.10375320166349411, Validation Loss: 0.10758036375045776
Epoch 142, Training Loss: 0.09597864747047424, Validation Loss: 0.10762673616409302
Epoch 143, Training Loss: 0.10410227626562119, Validation Loss: 0.10771647095680237
Epoch 144, Training Loss: 0.09942889213562012, Validation Loss: 0.10773030668497086
Epoch 145, Training Loss: 0.10078565031290054, Validation Loss: 0.10777528584003448
Epoch 146, Training Loss: 0.0986805185675621, Validation Loss: 0.10778795927762985
Epoch 147, Training Loss: 0.09896176308393478, Validation Loss: 0.10775557160377502
Epoch 148, Training Loss: 0.10755570232868195, Validation Loss: 0.107770636677742
Epoch 149, Training Loss: 0.09946856647729874, Validation Loss: 0.10778625309467316
Epoch 150, Training Loss: 0.0979926809668541, Validation Loss: 0.107742540538311
Epoch 151, Training Loss: 0.10182006657123566, Validation Loss: 0.10771665722131729
Epoch 152, Training Loss: 0.10031319409608841, Validation Loss: 0.10767152160406113
Epoch 153, Training Loss: 0.1019827276468277, Validation Loss: 0.10757245123386383
Epoch 154, Training Loss: 0.09987765550613403, Validation Loss: 0.10748812556266785
Epoch 155, Training Loss: 0.10968667268753052, Validation Loss: 0.1075356975197792
Epoch 156, Training Loss: 0.10993152856826782, Validation Loss: 0.10767628997564316
Epoch 157, Training Loss: 0.09702486544847488, Validation Loss: 0.10782478749752045
Epoch 158, Training Loss: 0.09771756082773209, Validation Loss: 0.10792543739080429
Epoch 159, Training Loss: 0.09303945302963257, Validation Loss: 0.10795719921588898
Epoch 160, Training Loss: 0.10196330398321152, Validation Loss: 0.10803761333227158
Epoch 161, Training Loss: 0.10535295307636261, Validation Loss: 0.10820332169532776
Epoch 162, Training Loss: 0.10195044428110123, Validation Loss: 0.10834677517414093
Epoch 163, Training Loss: 0.10379714518785477, Validation Loss: 0.10844585299491882
Epoch 164, Training Loss: 0.10294069349765778, Validation Loss: 0.10856478661298752
Epoch 165, Training Loss: 0.09978853911161423, Validation Loss: 0.10862722992897034
Epoch 166, Training Loss: 0.09620816260576248, Validation Loss: 0.1086772233247757
Epoch 167, Training Loss: 0.10090986639261246, Validation Loss: 0.10868233442306519
Epoch 168, Training Loss: 0.10121625661849976, Validation Loss: 0.1086786761879921
Epoch 169, Training Loss: 0.10560549050569534, Validation Loss: 0.10862196981906891
Epoch 170, Training Loss: 0.09789763391017914, Validation Loss: 0.10854543745517731
Epoch 171, Training Loss: 0.10226541757583618, Validation Loss: 0.1085294634103775
Epoch 172, Training Loss: 0.10439794510602951, Validation Loss: 0.10850121080875397
Epoch 173, Training Loss: 0.10327845811843872, Validation Loss: 0.10850685089826584
Epoch 174, Training Loss: 0.1048160269856453, Validation Loss: 0.10855481028556824
Epoch 175, Training Loss: 0.09980547428131104, Validation Loss: 0.10859821736812592
Epoch 176, Training Loss: 0.1031159833073616, Validation Loss: 0.10858386009931564
Epoch 177, Training Loss: 0.10399007052183151, Validation Loss: 0.10857918113470078
Epoch 178, Training Loss: 0.09837949275970459, Validation Loss: 0.10853630304336548
Epoch 179, Training Loss: 0.10444199293851852, Validation Loss: 0.10853829979896545
Epoch 180, Training Loss: 0.09965772926807404, Validation Loss: 0.10849076509475708
Epoch 181, Training Loss: 0.10326726734638214, Validation Loss: 0.10839896649122238
Epoch 182, Training Loss: 0.09608060121536255, Validation Loss: 0.10832195729017258
Epoch 183, Training Loss: 0.1004113107919693, Validation Loss: 0.10815843939781189
Epoch 184, Training Loss: 0.09850790351629257, Validation Loss: 0.1080007404088974
Epoch 185, Training Loss: 0.09574197232723236, Validation Loss: 0.10786997526884079
Epoch 186, Training Loss: 0.10135918110609055, Validation Loss: 0.1077355369925499
Epoch 187, Training Loss: 0.10048497468233109, Validation Loss: 0.10767289996147156
Epoch 188, Training Loss: 0.09774047881364822, Validation Loss: 0.1076136901974678
Epoch 189, Training Loss: 0.09983167052268982, Validation Loss: 0.10754626244306564
Epoch 190, Training Loss: 0.10184789448976517, Validation Loss: 0.10749679803848267
Epoch 191, Training Loss: 0.10366052389144897, Validation Loss: 0.10752136260271072
Epoch 192, Training Loss: 0.09883059561252594, Validation Loss: 0.10753346979618073
Epoch 193, Training Loss: 0.0969589427113533, Validation Loss: 0.10754340142011642
Epoch 194, Training Loss: 0.10135343670845032, Validation Loss: 0.10757651925086975
Epoch 195, Training Loss: 0.10543940216302872, Validation Loss: 0.10760928690433502
Epoch 196, Training Loss: 0.10055166482925415, Validation Loss: 0.10773852467536926
Epoch 197, Training Loss: 0.10227657109498978, Validation Loss: 0.10789915919303894
Epoch 198, Training Loss: 0.10112892836332321, Validation Loss: 0.10799885541200638
Epoch 199, Training Loss: 0.10025046765804291, Validation Loss: 0.10812295973300934
Epoch 200, Training Loss: 0.0984729528427124, Validation Loss: 0.10824009776115417
Epoch 201, Training Loss: 0.09798844158649445, Validation Loss: 0.1082843765616417
Epoch 202, Training Loss: 0.10121086239814758, Validation Loss: 0.10833790153265
Epoch 203, Training Loss: 0.10196768492460251, Validation Loss: 0.10837476700544357
Epoch 204, Training Loss: 0.0933937206864357, Validation Loss: 0.10837206244468689
Epoch 205, Training Loss: 0.10110481083393097, Validation Loss: 0.10831847786903381
Epoch 206, Training Loss: 0.09952158480882645, Validation Loss: 0.10820290446281433
Epoch 207, Training Loss: 0.09922069311141968, Validation Loss: 0.10807894170284271
Epoch 208, Training Loss: 0.10090284794569016, Validation Loss: 0.10796668380498886
Epoch 209, Training Loss: 0.09385867416858673, Validation Loss: 0.10784456133842468
Epoch 210, Training Loss: 0.09377196431159973, Validation Loss: 0.1077163964509964
Epoch 211, Training Loss: 0.09909351170063019, Validation Loss: 0.1076008677482605
Epoch 212, Training Loss: 0.10534287244081497, Validation Loss: 0.1076202541589737
Epoch 213, Training Loss: 0.09879294037818909, Validation Loss: 0.10772392898797989
Epoch 214, Training Loss: 0.10060738027095795, Validation Loss: 0.10781119018793106
Epoch 215, Training Loss: 0.10592243820428848, Validation Loss: 0.10798914730548859
Epoch 216, Training Loss: 0.10056959837675095, Validation Loss: 0.10810647904872894
Epoch 217, Training Loss: 0.09856488555669785, Validation Loss: 0.10819413512945175
Epoch 218, Training Loss: 0.09885600954294205, Validation Loss: 0.10826708376407623
Epoch 219, Training Loss: 0.09807831048965454, Validation Loss: 0.1082569882273674
Epoch 220, Training Loss: 0.1029491126537323, Validation Loss: 0.10826709121465683
Epoch 221, Training Loss: 0.09695108234882355, Validation Loss: 0.10824066400527954
Epoch 222, Training Loss: 0.09725276380777359, Validation Loss: 0.10822208225727081
Epoch 223, Training Loss: 0.0943194031715393, Validation Loss: 0.1081354022026062
Epoch 224, Training Loss: 0.09906044602394104, Validation Loss: 0.10799112170934677
Epoch 225, Training Loss: 0.10511446744203568, Validation Loss: 0.10789181292057037
Epoch 226, Training Loss: 0.09699711948633194, Validation Loss: 0.10783074796199799
Epoch 227, Training Loss: 0.09458567947149277, Validation Loss: 0.10776520520448685
Epoch 228, Training Loss: 0.09886085242033005, Validation Loss: 0.10776928067207336
Epoch 229, Training Loss: 0.095290407538414, Validation Loss: 0.10772211849689484
Epoch 230, Training Loss: 0.09896818548440933, Validation Loss: 0.10768131166696548
Epoch 231, Training Loss: 0.10386557132005692, Validation Loss: 0.10770784318447113
Epoch 232, Training Loss: 0.09401217103004456, Validation Loss: 0.10764151811599731
Epoch 233, Training Loss: 0.09845595806837082, Validation Loss: 0.10760007053613663
Epoch 234, Training Loss: 0.102309450507164, Validation Loss: 0.10750972479581833
Epoch 235, Training Loss: 0.09923979640007019, Validation Loss: 0.10745690762996674
Epoch 236, Training Loss: 0.09890376776456833, Validation Loss: 0.10746767371892929
Epoch 237, Training Loss: 0.10128317028284073, Validation Loss: 0.10749071836471558
Epoch 238, Training Loss: 0.09406719356775284, Validation Loss: 0.10753076523542404
Epoch 239, Training Loss: 0.09753439575433731, Validation Loss: 0.10766401886940002
Epoch 240, Training Loss: 0.09286151081323624, Validation Loss: 0.10768987983465195
Epoch 241, Training Loss: 0.10022035241127014, Validation Loss: 0.10770383477210999
Epoch 242, Training Loss: 0.09891457110643387, Validation Loss: 0.10778698325157166
Epoch 243, Training Loss: 0.10098075121641159, Validation Loss: 0.10790875554084778
Epoch 244, Training Loss: 0.0933675616979599, Validation Loss: 0.10804091393947601
Epoch 245, Training Loss: 0.09400695562362671, Validation Loss: 0.10811112076044083
Epoch 246, Training Loss: 0.10012272745370865, Validation Loss: 0.10812333971261978
Epoch 247, Training Loss: 0.10158590227365494, Validation Loss: 0.1081104502081871
Epoch 248, Training Loss: 0.09948451817035675, Validation Loss: 0.10809244960546494
Epoch 249, Training Loss: 0.09987550973892212, Validation Loss: 0.10802027583122253
Epoch 250, Training Loss: 0.10049282014369965, Validation Loss: 0.10793782770633698
Epoch 251, Training Loss: 0.09858912974596024, Validation Loss: 0.10789286345243454
Epoch 252, Training Loss: 0.09777190536260605, Validation Loss: 0.10787095129489899
Epoch 253, Training Loss: 0.09238595515489578, Validation Loss: 0.10787254571914673
Epoch 254, Training Loss: 0.09908212721347809, Validation Loss: 0.10790727287530899
Epoch 255, Training Loss: 0.09843740612268448, Validation Loss: 0.10788829624652863
Epoch 256, Training Loss: 0.09915253520011902, Validation Loss: 0.10785827785730362
Epoch 257, Training Loss: 0.09477867186069489, Validation Loss: 0.10773216933012009
Epoch 258, Training Loss: 0.09770931303501129, Validation Loss: 0.10761121660470963
Epoch 259, Training Loss: 0.09731092303991318, Validation Loss: 0.10756636410951614
Epoch 260, Training Loss: 0.09473886340856552, Validation Loss: 0.10752159357070923
Epoch 261, Training Loss: 0.09579279273748398, Validation Loss: 0.10743723064661026
Epoch 262, Training Loss: 0.09833389520645142, Validation Loss: 0.10731745511293411
Epoch 263, Training Loss: 0.09550629556179047, Validation Loss: 0.10723331570625305
Epoch 264, Training Loss: 0.09893485903739929, Validation Loss: 0.10714195668697357
Epoch 265, Training Loss: 0.09781867265701294, Validation Loss: 0.107045479118824
Epoch 266, Training Loss: 0.09823121130466461, Validation Loss: 0.10700328648090363
Epoch 267, Training Loss: 0.09710010886192322, Validation Loss: 0.1069733276963234
Epoch 268, Training Loss: 0.0953444391489029, Validation Loss: 0.10693130642175674
Epoch 269, Training Loss: 0.09922712296247482, Validation Loss: 0.10685379803180695
Epoch 270, Training Loss: 0.09786830097436905, Validation Loss: 0.10675767809152603
Epoch 271, Training Loss: 0.0955721065402031, Validation Loss: 0.1067505031824112
Epoch 272, Training Loss: 0.09288766235113144, Validation Loss: 0.10675443708896637
Epoch 273, Training Loss: 0.09796983003616333, Validation Loss: 0.10676444321870804
Epoch 274, Training Loss: 0.10079112648963928, Validation Loss: 0.10684067010879517
Epoch 275, Training Loss: 0.0962309017777443, Validation Loss: 0.10695482790470123
Epoch 276, Training Loss: 0.09744774550199509, Validation Loss: 0.10708818584680557
Epoch 277, Training Loss: 0.09977944195270538, Validation Loss: 0.10717327892780304
Epoch 278, Training Loss: 0.10073429346084595, Validation Loss: 0.10718315094709396
Epoch 279, Training Loss: 0.09305118024349213, Validation Loss: 0.10720301419496536
Epoch 280, Training Loss: 0.1022888571023941, Validation Loss: 0.10728234797716141
Epoch 281, Training Loss: 0.10642383992671967, Validation Loss: 0.10736820846796036
Epoch 282, Training Loss: 0.09389231353998184, Validation Loss: 0.1074451357126236
Epoch 283, Training Loss: 0.10076303035020828, Validation Loss: 0.10757587850093842
Epoch 284, Training Loss: 0.09828092157840729, Validation Loss: 0.10769923031330109
Epoch 285, Training Loss: 0.09284410625696182, Validation Loss: 0.1077776849269867
Epoch 286, Training Loss: 0.09622054547071457, Validation Loss: 0.10785046964883804
Epoch 287, Training Loss: 0.09499962627887726, Validation Loss: 0.10790415108203888
Epoch 288, Training Loss: 0.09671138972043991, Validation Loss: 0.10790934413671494
Epoch 289, Training Loss: 0.09463440626859665, Validation Loss: 0.10793481022119522
Epoch 290, Training Loss: 0.09316901117563248, Validation Loss: 0.10792353004217148
Epoch 291, Training Loss: 0.09375039488077164, Validation Loss: 0.1078600212931633
Epoch 292, Training Loss: 0.09762551635503769, Validation Loss: 0.10778317600488663
Epoch 293, Training Loss: 0.091074638068676, Validation Loss: 0.10764124244451523
Epoch 294, Training Loss: 0.09779905527830124, Validation Loss: 0.10748733580112457
Epoch 295, Training Loss: 0.09698031842708588, Validation Loss: 0.1073804646730423
Epoch 296, Training Loss: 0.09702068567276001, Validation Loss: 0.10724403709173203
Epoch 297, Training Loss: 0.09430485963821411, Validation Loss: 0.10711830109357834
Epoch 298, Training Loss: 0.09791532158851624, Validation Loss: 0.10702988505363464
Epoch 299, Training Loss: 0.09779484570026398, Validation Loss: 0.10694745928049088
Epoch 300, Training Loss: 0.09960874915122986, Validation Loss: 0.10685000568628311
Epoch 301, Training Loss: 0.09701090306043625, Validation Loss: 0.1067374050617218
Epoch 302, Training Loss: 0.09937606006860733, Validation Loss: 0.10663647204637527
Epoch 303, Training Loss: 0.10233600437641144, Validation Loss: 0.1066017746925354
Epoch 304, Training Loss: 0.09417566657066345, Validation Loss: 0.10659025609493256
Epoch 305, Training Loss: 0.09937877207994461, Validation Loss: 0.10659617930650711
Epoch 306, Training Loss: 0.09557154029607773, Validation Loss: 0.10660713911056519
Epoch 307, Training Loss: 0.09927326440811157, Validation Loss: 0.10668914765119553
Epoch 308, Training Loss: 0.095919169485569, Validation Loss: 0.10673226416110992
Epoch 309, Training Loss: 0.0918147936463356, Validation Loss: 0.1067686453461647
Epoch 310, Training Loss: 0.09399059414863586, Validation Loss: 0.10679230839014053
Epoch 311, Training Loss: 0.09369175881147385, Validation Loss: 0.10684185475111008
Epoch 312, Training Loss: 0.09892000257968903, Validation Loss: 0.10694463551044464
Epoch 313, Training Loss: 0.09468302875757217, Validation Loss: 0.10703608393669128
Epoch 314, Training Loss: 0.09641662985086441, Validation Loss: 0.10710714757442474
Epoch 315, Training Loss: 0.09559259563684464, Validation Loss: 0.10715712606906891
Epoch 316, Training Loss: 0.09971167892217636, Validation Loss: 0.10725945234298706
Epoch 317, Training Loss: 0.09759191423654556, Validation Loss: 0.10736030340194702
Epoch 318, Training Loss: 0.1015707403421402, Validation Loss: 0.10745960474014282
Epoch 319, Training Loss: 0.09557594358921051, Validation Loss: 0.10752566158771515
Epoch 320, Training Loss: 0.09326893091201782, Validation Loss: 0.10760531574487686
Epoch 321, Training Loss: 0.09596041589975357, Validation Loss: 0.10767493396997452
Epoch 322, Training Loss: 0.09208869934082031, Validation Loss: 0.10766912251710892
Epoch 323, Training Loss: 0.09435376524925232, Validation Loss: 0.10760372132062912
Epoch 324, Training Loss: 0.09600860625505447, Validation Loss: 0.10747204720973969
Epoch 325, Training Loss: 0.09594987332820892, Validation Loss: 0.10730034857988358
Epoch 326, Training Loss: 0.09731954336166382, Validation Loss: 0.1071414053440094
Epoch 327, Training Loss: 0.09469082951545715, Validation Loss: 0.1069815382361412
Epoch 328, Training Loss: 0.1002877876162529, Validation Loss: 0.10678650438785553
Epoch 329, Training Loss: 0.09200358390808105, Validation Loss: 0.10662282258272171
Epoch 330, Training Loss: 0.09195612370967865, Validation Loss: 0.10646937787532806
Epoch 331, Training Loss: 0.09622807055711746, Validation Loss: 0.10640431940555573
Epoch 332, Training Loss: 0.09575547277927399, Validation Loss: 0.10633836686611176
Epoch 333, Training Loss: 0.09982576966285706, Validation Loss: 0.10627934336662292
Epoch 334, Training Loss: 0.09535948187112808, Validation Loss: 0.1062203049659729
Epoch 335, Training Loss: 0.0963965654373169, Validation Loss: 0.10621378570795059
Epoch 336, Training Loss: 0.09566094726324081, Validation Loss: 0.10622958093881607
Epoch 337, Training Loss: 0.09990397095680237, Validation Loss: 0.10628961026668549
Epoch 338, Training Loss: 0.09794134646654129, Validation Loss: 0.10638806968927383
Epoch 339, Training Loss: 0.09631824493408203, Validation Loss: 0.106483593583107
Epoch 340, Training Loss: 0.09859465062618256, Validation Loss: 0.10661563277244568
Epoch 341, Training Loss: 0.09785313159227371, Validation Loss: 0.10677661746740341
Epoch 342, Training Loss: 0.09678415209054947, Validation Loss: 0.10692732781171799
Epoch 343, Training Loss: 0.09498055279254913, Validation Loss: 0.10700613260269165
Epoch 344, Training Loss: 0.09658866375684738, Validation Loss: 0.10704915970563889
Epoch 345, Training Loss: 0.09577896445989609, Validation Loss: 0.10703085362911224
Epoch 346, Training Loss: 0.09612452238798141, Validation Loss: 0.10702584683895111
Epoch 347, Training Loss: 0.09800922125577927, Validation Loss: 0.1070621982216835
Epoch 348, Training Loss: 0.0899757668375969, Validation Loss: 0.10703098028898239
Epoch 349, Training Loss: 0.09449293464422226, Validation Loss: 0.1069774404168129
Epoch 350, Training Loss: 0.09594732522964478, Validation Loss: 0.10690943151712418
Epoch 351, Training Loss: 0.09337697178125381, Validation Loss: 0.10683676600456238
Epoch 352, Training Loss: 0.09857654571533203, Validation Loss: 0.10678143054246902
Epoch 353, Training Loss: 0.09792894870042801, Validation Loss: 0.10672412067651749
Epoch 354, Training Loss: 0.10274925827980042, Validation Loss: 0.10676772892475128
Epoch 355, Training Loss: 0.096478670835495, Validation Loss: 0.10677280277013779
Epoch 356, Training Loss: 0.09456183016300201, Validation Loss: 0.1068066656589508
Epoch 357, Training Loss: 0.0966920256614685, Validation Loss: 0.1067802757024765
Epoch 358, Training Loss: 0.0982300266623497, Validation Loss: 0.10679079592227936
Epoch 359, Training Loss: 0.09604546427726746, Validation Loss: 0.10677757114171982
Epoch 360, Training Loss: 0.09559836983680725, Validation Loss: 0.10673628002405167
Epoch 361, Training Loss: 0.09528243541717529, Validation Loss: 0.10666847974061966
Epoch 362, Training Loss: 0.09548479318618774, Validation Loss: 0.106547050178051
Epoch 363, Training Loss: 0.09161972999572754, Validation Loss: 0.10641156882047653
Epoch 364, Training Loss: 0.0947442352771759, Validation Loss: 0.10628106445074081
Epoch 365, Training Loss: 0.09685276448726654, Validation Loss: 0.10619611293077469
Epoch 366, Training Loss: 0.09687206149101257, Validation Loss: 0.10613063722848892
Epoch 367, Training Loss: 0.09346793591976166, Validation Loss: 0.10608765482902527
Epoch 368, Training Loss: 0.09559763967990875, Validation Loss: 0.10603732615709305
Epoch 369, Training Loss: 0.09696009010076523, Validation Loss: 0.10600083321332932
Epoch 370, Training Loss: 0.09780897200107574, Validation Loss: 0.10601196438074112
Epoch 371, Training Loss: 0.09625748544931412, Validation Loss: 0.10603564232587814
Epoch 372, Training Loss: 0.09704194962978363, Validation Loss: 0.10604231804609299
Epoch 373, Training Loss: 0.09260965883731842, Validation Loss: 0.10603096336126328
Epoch 374, Training Loss: 0.10090133547782898, Validation Loss: 0.10603969544172287
Epoch 375, Training Loss: 0.09923427551984787, Validation Loss: 0.10612001270055771
Epoch 376, Training Loss: 0.09174174815416336, Validation Loss: 0.10617292672395706
Epoch 377, Training Loss: 0.09053373336791992, Validation Loss: 0.10620807111263275
Epoch 378, Training Loss: 0.09425303339958191, Validation Loss: 0.10619906336069107
Epoch 379, Training Loss: 0.0992501750588417, Validation Loss: 0.10627295821905136
Epoch 380, Training Loss: 0.09677137434482574, Validation Loss: 0.10630900412797928
Epoch 381, Training Loss: 0.0923643708229065, Validation Loss: 0.10638473927974701
Epoch 382, Training Loss: 0.09269716590642929, Validation Loss: 0.10648949444293976
Epoch 383, Training Loss: 0.0962657779455185, Validation Loss: 0.10658915340900421
Epoch 384, Training Loss: 0.09708239883184433, Validation Loss: 0.10665462911128998
Epoch 385, Training Loss: 0.09909073263406754, Validation Loss: 0.10673171281814575
Epoch 386, Training Loss: 0.0922950729727745, Validation Loss: 0.10676995664834976
Epoch 387, Training Loss: 0.095955990254879, Validation Loss: 0.10680752247571945
Epoch 388, Training Loss: 0.09387801587581635, Validation Loss: 0.10684234648942947
Epoch 389, Training Loss: 0.09298842400312424, Validation Loss: 0.10685695707798004
Epoch 390, Training Loss: 0.09549102932214737, Validation Loss: 0.10689157992601395
Epoch 391, Training Loss: 0.0931396335363388, Validation Loss: 0.10690949857234955
Epoch 392, Training Loss: 0.09415977448225021, Validation Loss: 0.10684008151292801
Epoch 393, Training Loss: 0.09758692234754562, Validation Loss: 0.10680551081895828
Epoch 394, Training Loss: 0.09508895128965378, Validation Loss: 0.10674462467432022
Epoch 395, Training Loss: 0.09323252737522125, Validation Loss: 0.1066424772143364
Epoch 396, Training Loss: 0.09290994703769684, Validation Loss: 0.10657768696546555
Epoch 397, Training Loss: 0.09676645696163177, Validation Loss: 0.10655727237462997
Epoch 398, Training Loss: 0.09474396705627441, Validation Loss: 0.10656032711267471
Epoch 399, Training Loss: 0.09613257646560669, Validation Loss: 0.10652314126491547
Epoch 400, Training Loss: 0.09882098436355591, Validation Loss: 0.10644391179084778
Epoch 401, Training Loss: 0.0930793285369873, Validation Loss: 0.1063479483127594
Epoch 402, Training Loss: 0.09054730832576752, Validation Loss: 0.10627556592226028
Epoch 403, Training Loss: 0.09190700948238373, Validation Loss: 0.10622122138738632
Epoch 404, Training Loss: 0.09572476893663406, Validation Loss: 0.10615437477827072
Epoch 405, Training Loss: 0.09423112124204636, Validation Loss: 0.1060665026307106
Epoch 406, Training Loss: 0.09329413622617722, Validation Loss: 0.10597549378871918
Epoch 407, Training Loss: 0.09237843751907349, Validation Loss: 0.10584893077611923
Epoch 408, Training Loss: 0.09940505027770996, Validation Loss: 0.10575587302446365
Epoch 409, Training Loss: 0.09702916443347931, Validation Loss: 0.10568604618310928
Epoch 410, Training Loss: 0.09774082154035568, Validation Loss: 0.105656698346138
Epoch 411, Training Loss: 0.09627361595630646, Validation Loss: 0.10559477657079697
Epoch 412, Training Loss: 0.09753616154193878, Validation Loss: 0.10554899275302887
Epoch 413, Training Loss: 0.09444937855005264, Validation Loss: 0.10556748509407043
Epoch 414, Training Loss: 0.10047926008701324, Validation Loss: 0.10559288412332535
Epoch 415, Training Loss: 0.08910080790519714, Validation Loss: 0.10563065856695175
Epoch 416, Training Loss: 0.09730131924152374, Validation Loss: 0.10568125545978546
Epoch 417, Training Loss: 0.09196875989437103, Validation Loss: 0.10573356598615646
Epoch 418, Training Loss: 0.09616587311029434, Validation Loss: 0.10580846667289734
Epoch 419, Training Loss: 0.08986268192529678, Validation Loss: 0.10587940365076065
Epoch 420, Training Loss: 0.09145883470773697, Validation Loss: 0.105929434299469
Epoch 421, Training Loss: 0.09793601930141449, Validation Loss: 0.10598007589578629
Epoch 422, Training Loss: 0.09663942456245422, Validation Loss: 0.10601667314767838
Epoch 423, Training Loss: 0.09445979446172714, Validation Loss: 0.10606221109628677
Epoch 424, Training Loss: 0.09538030624389648, Validation Loss: 0.10610679537057877
Epoch 425, Training Loss: 0.09378456324338913, Validation Loss: 0.10610773414373398
Epoch 426, Training Loss: 0.09522298723459244, Validation Loss: 0.10612460970878601
Epoch 427, Training Loss: 0.09379890561103821, Validation Loss: 0.10612963885068893
Epoch 428, Training Loss: 0.09520590305328369, Validation Loss: 0.10615783929824829
Epoch 429, Training Loss: 0.09390638768672943, Validation Loss: 0.10615628957748413
Epoch 430, Training Loss: 0.09762366116046906, Validation Loss: 0.10617449879646301
Epoch 431, Training Loss: 0.09613867104053497, Validation Loss: 0.10622494667768478
Epoch 432, Training Loss: 0.0922032818198204, Validation Loss: 0.1063113585114479
Epoch 433, Training Loss: 0.09985175728797913, Validation Loss: 0.10641628503799438
Epoch 434, Training Loss: 0.09365357458591461, Validation Loss: 0.10647370666265488
Epoch 435, Training Loss: 0.09341368824243546, Validation Loss: 0.10648012906312943
Epoch 436, Training Loss: 0.09835313260555267, Validation Loss: 0.10648579895496368
Epoch 437, Training Loss: 0.09182075411081314, Validation Loss: 0.1064392477273941
Epoch 438, Training Loss: 0.0954081118106842, Validation Loss: 0.10635588318109512
Epoch 439, Training Loss: 0.09602228552103043, Validation Loss: 0.10623987019062042
Epoch 440, Training Loss: 0.09588050842285156, Validation Loss: 0.10611072182655334
Epoch 441, Training Loss: 0.09377437084913254, Validation Loss: 0.10595019161701202
Epoch 442, Training Loss: 0.09149855375289917, Validation Loss: 0.1057821661233902
Epoch 443, Training Loss: 0.09130525588989258, Validation Loss: 0.10566271841526031
Epoch 444, Training Loss: 0.09498996287584305, Validation Loss: 0.10553888231515884
Epoch 445, Training Loss: 0.09802187979221344, Validation Loss: 0.10542849451303482
Epoch 446, Training Loss: 0.09133865684270859, Validation Loss: 0.1053256094455719
Epoch 447, Training Loss: 0.09366466850042343, Validation Loss: 0.10524168610572815
Epoch 448, Training Loss: 0.09122544527053833, Validation Loss: 0.10516507178544998
Epoch 449, Training Loss: 0.09415692836046219, Validation Loss: 0.10508204251527786
Epoch 450, Training Loss: 0.09575515240430832, Validation Loss: 0.10499928891658783
Epoch 451, Training Loss: 0.09327493607997894, Validation Loss: 0.1048893854022026
Epoch 452, Training Loss: 0.0972573459148407, Validation Loss: 0.10490746051073074
Epoch 453, Training Loss: 0.09526631236076355, Validation Loss: 0.10494687408208847
Epoch 454, Training Loss: 0.09552066773176193, Validation Loss: 0.10499518364667892
Epoch 455, Training Loss: 0.09191416203975677, Validation Loss: 0.10503362119197845
Epoch 456, Training Loss: 0.09400974959135056, Validation Loss: 0.1050867810845375
Epoch 457, Training Loss: 0.09577462822198868, Validation Loss: 0.1051354631781578
Epoch 458, Training Loss: 0.09428930282592773, Validation Loss: 0.10518857836723328
Epoch 459, Training Loss: 0.09658272564411163, Validation Loss: 0.10523389279842377
Epoch 460, Training Loss: 0.09665103256702423, Validation Loss: 0.10524719208478928
Epoch 461, Training Loss: 0.09420262277126312, Validation Loss: 0.10526540130376816
Epoch 462, Training Loss: 0.09110115468502045, Validation Loss: 0.10524880141019821
Epoch 463, Training Loss: 0.09235338121652603, Validation Loss: 0.10524815320968628
Epoch 464, Training Loss: 0.0957711711525917, Validation Loss: 0.10522221028804779
Epoch 465, Training Loss: 0.08990080654621124, Validation Loss: 0.10517888516187668
Epoch 466, Training Loss: 0.09354370087385178, Validation Loss: 0.10516157746315002
Epoch 467, Training Loss: 0.09246648848056793, Validation Loss: 0.10516209155321121
Epoch 468, Training Loss: 0.09290120750665665, Validation Loss: 0.10511722415685654
Epoch 469, Training Loss: 0.09114579111337662, Validation Loss: 0.1050896942615509
Epoch 470, Training Loss: 0.09603607654571533, Validation Loss: 0.10506337881088257
Epoch 471, Training Loss: 0.09388384968042374, Validation Loss: 0.10499297827482224
Epoch 472, Training Loss: 0.09428481012582779, Validation Loss: 0.10491759330034256
Epoch 473, Training Loss: 0.09442196786403656, Validation Loss: 0.10489240288734436
Epoch 474, Training Loss: 0.09164010733366013, Validation Loss: 0.10487903654575348
Epoch 475, Training Loss: 0.09196482598781586, Validation Loss: 0.10489065200090408
Epoch 476, Training Loss: 0.09292326122522354, Validation Loss: 0.10494079440832138
Epoch 477, Training Loss: 0.09296800941228867, Validation Loss: 0.10500016808509827
Epoch 478, Training Loss: 0.0907459482550621, Validation Loss: 0.10508973896503448
Epoch 479, Training Loss: 0.09600779414176941, Validation Loss: 0.10517892986536026
Epoch 480, Training Loss: 0.09485824406147003, Validation Loss: 0.10528997331857681
Epoch 481, Training Loss: 0.0904015600681305, Validation Loss: 0.10539867728948593
Epoch 482, Training Loss: 0.09254950284957886, Validation Loss: 0.10549575090408325
Epoch 483, Training Loss: 0.09586383402347565, Validation Loss: 0.10561157763004303
Epoch 484, Training Loss: 0.09280020743608475, Validation Loss: 0.10569773614406586
Epoch 485, Training Loss: 0.09479760378599167, Validation Loss: 0.10574577748775482
Epoch 486, Training Loss: 0.09078747034072876, Validation Loss: 0.10573267191648483
Epoch 487, Training Loss: 0.09437977522611618, Validation Loss: 0.10571951419115067
Epoch 488, Training Loss: 0.09499652683734894, Validation Loss: 0.10574236512184143
Epoch 489, Training Loss: 0.09627306461334229, Validation Loss: 0.10576370358467102
Epoch 490, Training Loss: 0.09577467292547226, Validation Loss: 0.10574804991483688
Epoch 491, Training Loss: 0.09327730536460876, Validation Loss: 0.10569027811288834
Epoch 492, Training Loss: 0.09244629740715027, Validation Loss: 0.10561682283878326
Epoch 493, Training Loss: 0.0943126380443573, Validation Loss: 0.10554189234972
Epoch 494, Training Loss: 0.09143628925085068, Validation Loss: 0.10548458248376846
Epoch 495, Training Loss: 0.09497866779565811, Validation Loss: 0.10543157905340195
Epoch 496, Training Loss: 0.09416627883911133, Validation Loss: 0.1053587943315506
Epoch 497, Training Loss: 0.09561482071876526, Validation Loss: 0.10525267571210861
Epoch 498, Training Loss: 0.09192005544900894, Validation Loss: 0.10518147796392441
Epoch 499, Training Loss: 0.09339958429336548, Validation Loss: 0.10511543601751328
Epoch 500, Training Loss: 0.09432389587163925, Validation Loss: 0.10501181334257126
