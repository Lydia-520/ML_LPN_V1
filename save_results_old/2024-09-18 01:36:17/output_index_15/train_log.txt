Epoch 1, Training Loss: 0.17965775728225708, Validation Loss: 0.17997092008590698
Epoch 2, Training Loss: 0.17643821239471436, Validation Loss: 0.17940984666347504
Epoch 3, Training Loss: 0.1765664666891098, Validation Loss: 0.1788584589958191
Epoch 4, Training Loss: 0.17663611471652985, Validation Loss: 0.17830917239189148
Epoch 5, Training Loss: 0.1759345382452011, Validation Loss: 0.17776449024677277
Epoch 6, Training Loss: 0.17590560019016266, Validation Loss: 0.17721961438655853
Epoch 7, Training Loss: 0.17484338581562042, Validation Loss: 0.1766844391822815
Epoch 8, Training Loss: 0.1737556904554367, Validation Loss: 0.1761535406112671
Epoch 9, Training Loss: 0.1754903495311737, Validation Loss: 0.17563262581825256
Epoch 10, Training Loss: 0.1733337789773941, Validation Loss: 0.17511315643787384
Epoch 11, Training Loss: 0.1721072942018509, Validation Loss: 0.17459291219711304
Epoch 12, Training Loss: 0.17163489758968353, Validation Loss: 0.17406831681728363
Epoch 13, Training Loss: 0.16991253197193146, Validation Loss: 0.1735447496175766
Epoch 14, Training Loss: 0.17093133926391602, Validation Loss: 0.17302407324314117
Epoch 15, Training Loss: 0.16982896625995636, Validation Loss: 0.17250216007232666
Epoch 16, Training Loss: 0.17025016248226166, Validation Loss: 0.17197374999523163
Epoch 17, Training Loss: 0.16790154576301575, Validation Loss: 0.17143844068050385
Epoch 18, Training Loss: 0.17011378705501556, Validation Loss: 0.1708970069885254
Epoch 19, Training Loss: 0.16727736592292786, Validation Loss: 0.17034989595413208
Epoch 20, Training Loss: 0.16547958552837372, Validation Loss: 0.16980241239070892
Epoch 21, Training Loss: 0.1670006364583969, Validation Loss: 0.1692531853914261
Epoch 22, Training Loss: 0.16550028324127197, Validation Loss: 0.16869452595710754
Epoch 23, Training Loss: 0.16455702483654022, Validation Loss: 0.16812658309936523
Epoch 24, Training Loss: 0.16485650837421417, Validation Loss: 0.16754737496376038
Epoch 25, Training Loss: 0.1634550839662552, Validation Loss: 0.16695213317871094
Epoch 26, Training Loss: 0.1621863842010498, Validation Loss: 0.16634120047092438
Epoch 27, Training Loss: 0.1617877036333084, Validation Loss: 0.16570763289928436
Epoch 28, Training Loss: 0.16140100359916687, Validation Loss: 0.16505467891693115
Epoch 29, Training Loss: 0.16119082272052765, Validation Loss: 0.1643802374601364
Epoch 30, Training Loss: 0.15923424065113068, Validation Loss: 0.16368554532527924
Epoch 31, Training Loss: 0.15937817096710205, Validation Loss: 0.16296948492527008
Epoch 32, Training Loss: 0.15738366544246674, Validation Loss: 0.16222964227199554
Epoch 33, Training Loss: 0.15564559400081635, Validation Loss: 0.16146011650562286
Epoch 34, Training Loss: 0.1567726582288742, Validation Loss: 0.1606588363647461
Epoch 35, Training Loss: 0.15480820834636688, Validation Loss: 0.1598304957151413
Epoch 36, Training Loss: 0.1555161029100418, Validation Loss: 0.15898068249225616
Epoch 37, Training Loss: 0.15247990190982819, Validation Loss: 0.15808501839637756
Epoch 38, Training Loss: 0.15127907693386078, Validation Loss: 0.1571512520313263
Epoch 39, Training Loss: 0.1524117887020111, Validation Loss: 0.15618424117565155
Epoch 40, Training Loss: 0.148243248462677, Validation Loss: 0.1551705151796341
Epoch 41, Training Loss: 0.14999254047870636, Validation Loss: 0.15411929786205292
Epoch 42, Training Loss: 0.14840789139270782, Validation Loss: 0.15301625430583954
Epoch 43, Training Loss: 0.1452576071023941, Validation Loss: 0.15185976028442383
Epoch 44, Training Loss: 0.14172911643981934, Validation Loss: 0.1506449431180954
Epoch 45, Training Loss: 0.14198923110961914, Validation Loss: 0.1493874043226242
Epoch 46, Training Loss: 0.14396372437477112, Validation Loss: 0.14808444678783417
Epoch 47, Training Loss: 0.14031486213207245, Validation Loss: 0.14671733975410461
Epoch 48, Training Loss: 0.13826104998588562, Validation Loss: 0.14529035985469818
Epoch 49, Training Loss: 0.13402540981769562, Validation Loss: 0.14379934966564178
Epoch 50, Training Loss: 0.13565219938755035, Validation Loss: 0.14224962890148163
Epoch 51, Training Loss: 0.1328681856393814, Validation Loss: 0.140640527009964
Epoch 52, Training Loss: 0.12971800565719604, Validation Loss: 0.13897067308425903
Epoch 53, Training Loss: 0.13127943873405457, Validation Loss: 0.13722200691699982
Epoch 54, Training Loss: 0.13021723926067352, Validation Loss: 0.1354372352361679
Epoch 55, Training Loss: 0.12718167901039124, Validation Loss: 0.13358691334724426
Epoch 56, Training Loss: 0.12563057243824005, Validation Loss: 0.1317082941532135
Epoch 57, Training Loss: 0.12554652988910675, Validation Loss: 0.12979936599731445
Epoch 58, Training Loss: 0.12109081447124481, Validation Loss: 0.1278887540102005
Epoch 59, Training Loss: 0.12116320431232452, Validation Loss: 0.12600640952587128
Epoch 60, Training Loss: 0.11622659862041473, Validation Loss: 0.12415477633476257
Epoch 61, Training Loss: 0.11000186204910278, Validation Loss: 0.12236551940441132
Epoch 62, Training Loss: 0.11598546802997589, Validation Loss: 0.12063544243574142
Epoch 63, Training Loss: 0.1131967231631279, Validation Loss: 0.11898782849311829
Epoch 64, Training Loss: 0.11040691286325455, Validation Loss: 0.11745990812778473
Epoch 65, Training Loss: 0.1132846251130104, Validation Loss: 0.11604975163936615
Epoch 66, Training Loss: 0.11012653261423111, Validation Loss: 0.11478782445192337
Epoch 67, Training Loss: 0.11209531128406525, Validation Loss: 0.11367558687925339
Epoch 68, Training Loss: 0.10301019996404648, Validation Loss: 0.11267811059951782
Epoch 69, Training Loss: 0.11197751760482788, Validation Loss: 0.11183835566043854
Epoch 70, Training Loss: 0.10759203881025314, Validation Loss: 0.11109286546707153
Epoch 71, Training Loss: 0.1082727238535881, Validation Loss: 0.11047285050153732
Epoch 72, Training Loss: 0.11013645678758621, Validation Loss: 0.1099676564335823
Epoch 73, Training Loss: 0.11357386410236359, Validation Loss: 0.1095304861664772
Epoch 74, Training Loss: 0.11475396901369095, Validation Loss: 0.10917315632104874
Epoch 75, Training Loss: 0.10681010037660599, Validation Loss: 0.1088423952460289
Epoch 76, Training Loss: 0.11340676993131638, Validation Loss: 0.10860282182693481
Epoch 77, Training Loss: 0.11596652865409851, Validation Loss: 0.1084546372294426
Epoch 78, Training Loss: 0.10710401087999344, Validation Loss: 0.10839349031448364
Epoch 79, Training Loss: 0.11149352043867111, Validation Loss: 0.10841509699821472
Epoch 80, Training Loss: 0.11262791603803635, Validation Loss: 0.10856464505195618
Epoch 81, Training Loss: 0.1104290708899498, Validation Loss: 0.10873792320489883
Epoch 82, Training Loss: 0.09837290644645691, Validation Loss: 0.10889972746372223
Epoch 83, Training Loss: 0.09990321844816208, Validation Loss: 0.10907052457332611
Epoch 84, Training Loss: 0.10126394778490067, Validation Loss: 0.10926307737827301
Epoch 85, Training Loss: 0.1036110669374466, Validation Loss: 0.10942742228507996
Epoch 86, Training Loss: 0.10752847045660019, Validation Loss: 0.10956241935491562
Epoch 87, Training Loss: 0.1091887503862381, Validation Loss: 0.10969693213701248
Epoch 88, Training Loss: 0.10879597812891006, Validation Loss: 0.10983257740736008
Epoch 89, Training Loss: 0.11008630692958832, Validation Loss: 0.10997011512517929
Epoch 90, Training Loss: 0.10124852508306503, Validation Loss: 0.11010535061359406
Epoch 91, Training Loss: 0.10763171315193176, Validation Loss: 0.11020303517580032
Epoch 92, Training Loss: 0.09466756880283356, Validation Loss: 0.11028305441141129
Epoch 93, Training Loss: 0.10535696893930435, Validation Loss: 0.11036967486143112
Epoch 94, Training Loss: 0.10798881202936172, Validation Loss: 0.11039917916059494
Epoch 95, Training Loss: 0.10453718155622482, Validation Loss: 0.1103808730840683
Epoch 96, Training Loss: 0.10360091179609299, Validation Loss: 0.11035961657762527
Epoch 97, Training Loss: 0.10501670092344284, Validation Loss: 0.11030331999063492
Epoch 98, Training Loss: 0.1056036651134491, Validation Loss: 0.11021381616592407
Epoch 99, Training Loss: 0.10254515707492828, Validation Loss: 0.11007621139287949
Epoch 100, Training Loss: 0.10440835356712341, Validation Loss: 0.10989228636026382
Epoch 101, Training Loss: 0.09710779786109924, Validation Loss: 0.10967156291007996
Epoch 102, Training Loss: 0.10072050988674164, Validation Loss: 0.10939821600914001
Epoch 103, Training Loss: 0.10214357823133469, Validation Loss: 0.10909835249185562
Epoch 104, Training Loss: 0.10465468466281891, Validation Loss: 0.1088486984372139
Epoch 105, Training Loss: 0.10175611823797226, Validation Loss: 0.10859193652868271
Epoch 106, Training Loss: 0.10299231857061386, Validation Loss: 0.1083550825715065
Epoch 107, Training Loss: 0.10102814435958862, Validation Loss: 0.10810346156358719
Epoch 108, Training Loss: 0.1049361526966095, Validation Loss: 0.10784934461116791
Epoch 109, Training Loss: 0.10452540218830109, Validation Loss: 0.10770057886838913
Epoch 110, Training Loss: 0.09924757480621338, Validation Loss: 0.10757546871900558
Epoch 111, Training Loss: 0.10503202676773071, Validation Loss: 0.10750533640384674
Epoch 112, Training Loss: 0.10234270244836807, Validation Loss: 0.10742294043302536
Epoch 113, Training Loss: 0.10008908808231354, Validation Loss: 0.10735467076301575
Epoch 114, Training Loss: 0.10079783946275711, Validation Loss: 0.10730145871639252
Epoch 115, Training Loss: 0.09970593452453613, Validation Loss: 0.1072065681219101
Epoch 116, Training Loss: 0.10409316420555115, Validation Loss: 0.10712108761072159
Epoch 117, Training Loss: 0.10627264529466629, Validation Loss: 0.10713843256235123
Epoch 118, Training Loss: 0.0908435732126236, Validation Loss: 0.10715008527040482
Epoch 119, Training Loss: 0.10332182794809341, Validation Loss: 0.1071254163980484
Epoch 120, Training Loss: 0.10026070475578308, Validation Loss: 0.10703899711370468
Epoch 121, Training Loss: 0.10261844098567963, Validation Loss: 0.10696534067392349
Epoch 122, Training Loss: 0.09947962313890457, Validation Loss: 0.10698913037776947
Epoch 123, Training Loss: 0.10282248258590698, Validation Loss: 0.10705579817295074
Epoch 124, Training Loss: 0.10103200376033783, Validation Loss: 0.10717073827981949
Epoch 125, Training Loss: 0.10100524872541428, Validation Loss: 0.10725241154432297
Epoch 126, Training Loss: 0.10325916111469269, Validation Loss: 0.10741286724805832
Epoch 127, Training Loss: 0.1001213863492012, Validation Loss: 0.10752438008785248
Epoch 128, Training Loss: 0.10538819432258606, Validation Loss: 0.10763458162546158
Epoch 129, Training Loss: 0.10520803183317184, Validation Loss: 0.10778921097517014
Epoch 130, Training Loss: 0.09649989008903503, Validation Loss: 0.1078840047121048
Epoch 131, Training Loss: 0.10026201605796814, Validation Loss: 0.10794386267662048
Epoch 132, Training Loss: 0.09881173819303513, Validation Loss: 0.10799264162778854
Epoch 133, Training Loss: 0.10102996975183487, Validation Loss: 0.10796145349740982
Epoch 134, Training Loss: 0.09799811244010925, Validation Loss: 0.10796580463647842
Epoch 135, Training Loss: 0.09321317821741104, Validation Loss: 0.10791785269975662
Epoch 136, Training Loss: 0.10359501093626022, Validation Loss: 0.10786435008049011
Epoch 137, Training Loss: 0.10187483578920364, Validation Loss: 0.10772571712732315
Epoch 138, Training Loss: 0.09959391504526138, Validation Loss: 0.10754583030939102
Epoch 139, Training Loss: 0.09945745766162872, Validation Loss: 0.1074434444308281
Epoch 140, Training Loss: 0.10047334432601929, Validation Loss: 0.10730667412281036
Epoch 141, Training Loss: 0.096614770591259, Validation Loss: 0.10711498558521271
Epoch 142, Training Loss: 0.09998463094234467, Validation Loss: 0.106918565928936
Epoch 143, Training Loss: 0.0946541428565979, Validation Loss: 0.1067095398902893
Epoch 144, Training Loss: 0.1016552746295929, Validation Loss: 0.10648797452449799
Epoch 145, Training Loss: 0.10500724613666534, Validation Loss: 0.10626186430454254
Epoch 146, Training Loss: 0.09830228239297867, Validation Loss: 0.10604704916477203
Epoch 147, Training Loss: 0.10023007541894913, Validation Loss: 0.1058395653963089
Epoch 148, Training Loss: 0.09867750853300095, Validation Loss: 0.10567094385623932
Epoch 149, Training Loss: 0.0981442779302597, Validation Loss: 0.10553561896085739
Epoch 150, Training Loss: 0.10559342801570892, Validation Loss: 0.10547911375761032
Epoch 151, Training Loss: 0.10070054978132248, Validation Loss: 0.10543035715818405
Epoch 152, Training Loss: 0.0980452224612236, Validation Loss: 0.1053585484623909
Epoch 153, Training Loss: 0.10149098187685013, Validation Loss: 0.10529439896345139
Epoch 154, Training Loss: 0.10168368369340897, Validation Loss: 0.10531392693519592
Epoch 155, Training Loss: 0.09807389229536057, Validation Loss: 0.10529173165559769
Epoch 156, Training Loss: 0.09960509836673737, Validation Loss: 0.10527055710554123
Epoch 157, Training Loss: 0.09468907117843628, Validation Loss: 0.10524259507656097
Epoch 158, Training Loss: 0.09849825501441956, Validation Loss: 0.10521373152732849
Epoch 159, Training Loss: 0.09449898451566696, Validation Loss: 0.10518241673707962
Epoch 160, Training Loss: 0.09407256543636322, Validation Loss: 0.10519500076770782
Epoch 161, Training Loss: 0.10344734787940979, Validation Loss: 0.10523013025522232
Epoch 162, Training Loss: 0.09925597161054611, Validation Loss: 0.10529360175132751
Epoch 163, Training Loss: 0.10079019516706467, Validation Loss: 0.10535719245672226
Epoch 164, Training Loss: 0.09951803833246231, Validation Loss: 0.10544351488351822
Epoch 165, Training Loss: 0.10317721962928772, Validation Loss: 0.10555492341518402
Epoch 166, Training Loss: 0.09710311889648438, Validation Loss: 0.10568074136972427
Epoch 167, Training Loss: 0.10380861908197403, Validation Loss: 0.10582461208105087
Epoch 168, Training Loss: 0.09792493283748627, Validation Loss: 0.10590069741010666
Epoch 169, Training Loss: 0.0970647931098938, Validation Loss: 0.10596133023500443
Epoch 170, Training Loss: 0.09751534461975098, Validation Loss: 0.10595901310443878
Epoch 171, Training Loss: 0.09755778312683105, Validation Loss: 0.10593920201063156
Epoch 172, Training Loss: 0.10232169926166534, Validation Loss: 0.1059236228466034
Epoch 173, Training Loss: 0.09973166137933731, Validation Loss: 0.10591106861829758
Epoch 174, Training Loss: 0.10155656188726425, Validation Loss: 0.10585134476423264
Epoch 175, Training Loss: 0.09817402809858322, Validation Loss: 0.10578077286481857
Epoch 176, Training Loss: 0.09799027442932129, Validation Loss: 0.10572262108325958
Epoch 177, Training Loss: 0.10222727805376053, Validation Loss: 0.10579299181699753
Epoch 178, Training Loss: 0.09695537388324738, Validation Loss: 0.10581253468990326
Epoch 179, Training Loss: 0.09864139556884766, Validation Loss: 0.1057676374912262
Epoch 180, Training Loss: 0.09977569431066513, Validation Loss: 0.10567185282707214
Epoch 181, Training Loss: 0.09702152758836746, Validation Loss: 0.10559804737567902
Epoch 182, Training Loss: 0.10256437212228775, Validation Loss: 0.10548430681228638
Epoch 183, Training Loss: 0.09641396254301071, Validation Loss: 0.10542017221450806
Epoch 184, Training Loss: 0.10232143849134445, Validation Loss: 0.10537443310022354
Epoch 185, Training Loss: 0.0981699526309967, Validation Loss: 0.1053353026509285
Epoch 186, Training Loss: 0.09094591438770294, Validation Loss: 0.10526527464389801
Epoch 187, Training Loss: 0.10367356985807419, Validation Loss: 0.10524696111679077
Epoch 188, Training Loss: 0.10423620045185089, Validation Loss: 0.10522822290658951
Epoch 189, Training Loss: 0.09583914279937744, Validation Loss: 0.10519396513700485
Epoch 190, Training Loss: 0.10083149373531342, Validation Loss: 0.10518462210893631
Epoch 191, Training Loss: 0.10166610032320023, Validation Loss: 0.10523481667041779
Epoch 192, Training Loss: 0.09548189491033554, Validation Loss: 0.105241559445858
Epoch 193, Training Loss: 0.09323181211948395, Validation Loss: 0.10526347905397415
Epoch 194, Training Loss: 0.0978216826915741, Validation Loss: 0.10524918138980865
Epoch 195, Training Loss: 0.09742236137390137, Validation Loss: 0.10527055710554123
Epoch 196, Training Loss: 0.1024729534983635, Validation Loss: 0.10536473244428635
Epoch 197, Training Loss: 0.09781751036643982, Validation Loss: 0.10543765127658844
Epoch 198, Training Loss: 0.10022816807031631, Validation Loss: 0.10545556992292404
Epoch 199, Training Loss: 0.09629449248313904, Validation Loss: 0.10545660555362701
Epoch 200, Training Loss: 0.10325808078050613, Validation Loss: 0.10548225045204163
Epoch 201, Training Loss: 0.0943358838558197, Validation Loss: 0.1054491400718689
Epoch 202, Training Loss: 0.0959286093711853, Validation Loss: 0.10538123548030853
Epoch 203, Training Loss: 0.0978744775056839, Validation Loss: 0.10526031255722046
Epoch 204, Training Loss: 0.0993795245885849, Validation Loss: 0.10520075261592865
Epoch 205, Training Loss: 0.10024287551641464, Validation Loss: 0.1052054837346077
Epoch 206, Training Loss: 0.09780700504779816, Validation Loss: 0.10516783595085144
Epoch 207, Training Loss: 0.10164748132228851, Validation Loss: 0.10511228442192078
Epoch 208, Training Loss: 0.0980973094701767, Validation Loss: 0.1050720065832138
Epoch 209, Training Loss: 0.09850181639194489, Validation Loss: 0.1050061285495758
Epoch 210, Training Loss: 0.09864649921655655, Validation Loss: 0.1049656793475151
Epoch 211, Training Loss: 0.09539269655942917, Validation Loss: 0.10492224246263504
Epoch 212, Training Loss: 0.09698136150836945, Validation Loss: 0.10492014139890671
Epoch 213, Training Loss: 0.09703788161277771, Validation Loss: 0.10481768101453781
Epoch 214, Training Loss: 0.09803488105535507, Validation Loss: 0.10475674271583557
Epoch 215, Training Loss: 0.09500501304864883, Validation Loss: 0.10468853265047073
Epoch 216, Training Loss: 0.0954243466258049, Validation Loss: 0.10464926064014435
Epoch 217, Training Loss: 0.09477631002664566, Validation Loss: 0.10463815927505493
Epoch 218, Training Loss: 0.10505102574825287, Validation Loss: 0.10471159964799881
Epoch 219, Training Loss: 0.09803333878517151, Validation Loss: 0.10476323962211609
Epoch 220, Training Loss: 0.10047788918018341, Validation Loss: 0.10479596257209778
Epoch 221, Training Loss: 0.10234753042459488, Validation Loss: 0.10487194359302521
Epoch 222, Training Loss: 0.10267995297908783, Validation Loss: 0.10495111346244812
Epoch 223, Training Loss: 0.09494876861572266, Validation Loss: 0.10499159246683121
Epoch 224, Training Loss: 0.10215745121240616, Validation Loss: 0.10510140657424927
Epoch 225, Training Loss: 0.09150813519954681, Validation Loss: 0.1051301658153534
Epoch 226, Training Loss: 0.09386450797319412, Validation Loss: 0.10517289489507675
Epoch 227, Training Loss: 0.09961599856615067, Validation Loss: 0.105226069688797
Epoch 228, Training Loss: 0.09416335076093674, Validation Loss: 0.1052667647600174
Epoch 229, Training Loss: 0.09644338488578796, Validation Loss: 0.10527220368385315
Epoch 230, Training Loss: 0.0952485203742981, Validation Loss: 0.10525348037481308
Epoch 231, Training Loss: 0.09757556021213531, Validation Loss: 0.1051667109131813
Epoch 232, Training Loss: 0.09614932537078857, Validation Loss: 0.10506198555231094
Epoch 233, Training Loss: 0.1008489727973938, Validation Loss: 0.10498396307229996
Epoch 234, Training Loss: 0.09334442019462585, Validation Loss: 0.10491453856229782
Epoch 235, Training Loss: 0.10082691162824631, Validation Loss: 0.1048576682806015
Epoch 236, Training Loss: 0.10143273323774338, Validation Loss: 0.10480879247188568
Epoch 237, Training Loss: 0.0949053168296814, Validation Loss: 0.10472322255373001
Epoch 238, Training Loss: 0.0954178124666214, Validation Loss: 0.10466092079877853
Epoch 239, Training Loss: 0.0960938036441803, Validation Loss: 0.10456281900405884
Epoch 240, Training Loss: 0.0977025032043457, Validation Loss: 0.10452491790056229
Epoch 241, Training Loss: 0.09876670688390732, Validation Loss: 0.10444427281618118
Epoch 242, Training Loss: 0.09450113773345947, Validation Loss: 0.10432233661413193
Epoch 243, Training Loss: 0.09115511178970337, Validation Loss: 0.10420908033847809
Epoch 244, Training Loss: 0.09366264939308167, Validation Loss: 0.1040332168340683
Epoch 245, Training Loss: 0.09761308133602142, Validation Loss: 0.10387837141752243
Epoch 246, Training Loss: 0.09689779579639435, Validation Loss: 0.10370758175849915
Epoch 247, Training Loss: 0.10041629523038864, Validation Loss: 0.10363627970218658
Epoch 248, Training Loss: 0.0925413966178894, Validation Loss: 0.10357798635959625
Epoch 249, Training Loss: 0.09509056806564331, Validation Loss: 0.10352261364459991
Epoch 250, Training Loss: 0.09592826664447784, Validation Loss: 0.10342328995466232
Epoch 251, Training Loss: 0.09798890352249146, Validation Loss: 0.10328115522861481
Epoch 252, Training Loss: 0.0929025337100029, Validation Loss: 0.10315347462892532
Epoch 253, Training Loss: 0.09573421627283096, Validation Loss: 0.1030787006020546
Epoch 254, Training Loss: 0.09597219526767731, Validation Loss: 0.10308457165956497
Epoch 255, Training Loss: 0.09733150899410248, Validation Loss: 0.103129543364048
Epoch 256, Training Loss: 0.09732308983802795, Validation Loss: 0.1031508818268776
Epoch 257, Training Loss: 0.09274840354919434, Validation Loss: 0.10318709164857864
Epoch 258, Training Loss: 0.09670101851224899, Validation Loss: 0.10325387120246887
Epoch 259, Training Loss: 0.09570489078760147, Validation Loss: 0.10331185162067413
Epoch 260, Training Loss: 0.09993437677621841, Validation Loss: 0.10335841774940491
Epoch 261, Training Loss: 0.09425213187932968, Validation Loss: 0.10341209918260574
Epoch 262, Training Loss: 0.09687609225511551, Validation Loss: 0.1034565269947052
Epoch 263, Training Loss: 0.0974498763680458, Validation Loss: 0.10351502150297165
Epoch 264, Training Loss: 0.09443399310112, Validation Loss: 0.10358589887619019
Epoch 265, Training Loss: 0.09887632727622986, Validation Loss: 0.10370300710201263
Epoch 266, Training Loss: 0.09594987332820892, Validation Loss: 0.10381168127059937
Epoch 267, Training Loss: 0.09609708189964294, Validation Loss: 0.10389086604118347
Epoch 268, Training Loss: 0.0978463813662529, Validation Loss: 0.10397051274776459
Epoch 269, Training Loss: 0.1022539734840393, Validation Loss: 0.10404449701309204
Epoch 270, Training Loss: 0.09614009410142899, Validation Loss: 0.10409972071647644
Epoch 271, Training Loss: 0.1013253778219223, Validation Loss: 0.10423965752124786
Epoch 272, Training Loss: 0.09273293614387512, Validation Loss: 0.10437264293432236
Epoch 273, Training Loss: 0.09518289566040039, Validation Loss: 0.10451731830835342
Epoch 274, Training Loss: 0.09560775756835938, Validation Loss: 0.10462775081396103
Epoch 275, Training Loss: 0.09537804126739502, Validation Loss: 0.10469864308834076
Epoch 276, Training Loss: 0.09522979706525803, Validation Loss: 0.10475964099168777
Epoch 277, Training Loss: 0.09801122546195984, Validation Loss: 0.10483831912279129
Epoch 278, Training Loss: 0.092879518866539, Validation Loss: 0.10484407097101212
Epoch 279, Training Loss: 0.0927153006196022, Validation Loss: 0.10480418801307678
Epoch 280, Training Loss: 0.09747492522001266, Validation Loss: 0.10477255284786224
Epoch 281, Training Loss: 0.09790759533643723, Validation Loss: 0.10474595427513123
Epoch 282, Training Loss: 0.09919550269842148, Validation Loss: 0.10472092777490616
Epoch 283, Training Loss: 0.09758210182189941, Validation Loss: 0.10469552874565125
Epoch 284, Training Loss: 0.09555492550134659, Validation Loss: 0.1046861931681633
Epoch 285, Training Loss: 0.09554441273212433, Validation Loss: 0.1046251729130745
Epoch 286, Training Loss: 0.09620434045791626, Validation Loss: 0.10464269667863846
Epoch 287, Training Loss: 0.09261155128479004, Validation Loss: 0.1046861782670021
Epoch 288, Training Loss: 0.09646405279636383, Validation Loss: 0.10469618439674377
Epoch 289, Training Loss: 0.09476152062416077, Validation Loss: 0.10465353727340698
Epoch 290, Training Loss: 0.0934533029794693, Validation Loss: 0.10457815229892731
Epoch 291, Training Loss: 0.09701187908649445, Validation Loss: 0.10449197888374329
Epoch 292, Training Loss: 0.10059044510126114, Validation Loss: 0.10448279976844788
Epoch 293, Training Loss: 0.09901360422372818, Validation Loss: 0.10442882776260376
Epoch 294, Training Loss: 0.09473834186792374, Validation Loss: 0.10438119620084763
Epoch 295, Training Loss: 0.09667991101741791, Validation Loss: 0.10435537248849869
Epoch 296, Training Loss: 0.09638891369104385, Validation Loss: 0.10428355634212494
Epoch 297, Training Loss: 0.09089650958776474, Validation Loss: 0.10423547029495239
Epoch 298, Training Loss: 0.09452631324529648, Validation Loss: 0.10420380532741547
Epoch 299, Training Loss: 0.0926537737250328, Validation Loss: 0.10418570786714554
Epoch 300, Training Loss: 0.09594200551509857, Validation Loss: 0.10414863377809525
Epoch 301, Training Loss: 0.09268124401569366, Validation Loss: 0.10414287447929382
Epoch 302, Training Loss: 0.09790390729904175, Validation Loss: 0.10417504608631134
Epoch 303, Training Loss: 0.0933099314570427, Validation Loss: 0.10421635955572128
Epoch 304, Training Loss: 0.09759809821844101, Validation Loss: 0.10424188524484634
Epoch 305, Training Loss: 0.09383231401443481, Validation Loss: 0.10421700030565262
Epoch 306, Training Loss: 0.09906303137540817, Validation Loss: 0.10424275696277618
Epoch 307, Training Loss: 0.09391412883996964, Validation Loss: 0.10429404675960541
Epoch 308, Training Loss: 0.09704601019620895, Validation Loss: 0.10434924811124802
Epoch 309, Training Loss: 0.09137588739395142, Validation Loss: 0.10436341166496277
Epoch 310, Training Loss: 0.0982607826590538, Validation Loss: 0.10444430261850357
Epoch 311, Training Loss: 0.09595926105976105, Validation Loss: 0.10449574887752533
Epoch 312, Training Loss: 0.09324077516794205, Validation Loss: 0.10453460365533829
Epoch 313, Training Loss: 0.09216979891061783, Validation Loss: 0.10458319634199142
Epoch 314, Training Loss: 0.09560027718544006, Validation Loss: 0.10459086298942566
Epoch 315, Training Loss: 0.09434802830219269, Validation Loss: 0.10456997901201248
Epoch 316, Training Loss: 0.09666960686445236, Validation Loss: 0.10453837364912033
Epoch 317, Training Loss: 0.09495887905359268, Validation Loss: 0.10451691597700119
Epoch 318, Training Loss: 0.09823882579803467, Validation Loss: 0.10454300045967102
Epoch 319, Training Loss: 0.09700467437505722, Validation Loss: 0.10453818738460541
Epoch 320, Training Loss: 0.09357573837041855, Validation Loss: 0.10445895791053772
Epoch 321, Training Loss: 0.09743918478488922, Validation Loss: 0.10441917181015015
Epoch 322, Training Loss: 0.09237494319677353, Validation Loss: 0.10439244657754898
Epoch 323, Training Loss: 0.09615086019039154, Validation Loss: 0.10435618460178375
Epoch 324, Training Loss: 0.09348569065332413, Validation Loss: 0.10435723513364792
Epoch 325, Training Loss: 0.09819518774747849, Validation Loss: 0.10433750599622726
Epoch 326, Training Loss: 0.09962227940559387, Validation Loss: 0.1043357327580452
Epoch 327, Training Loss: 0.09663837403059006, Validation Loss: 0.10435142368078232
Epoch 328, Training Loss: 0.09083841741085052, Validation Loss: 0.10433734208345413
Epoch 329, Training Loss: 0.09389698505401611, Validation Loss: 0.10435441881418228
Epoch 330, Training Loss: 0.09341341257095337, Validation Loss: 0.10434593260288239
Epoch 331, Training Loss: 0.09316276013851166, Validation Loss: 0.10435404628515244
Epoch 332, Training Loss: 0.09514306485652924, Validation Loss: 0.10437599569559097
Epoch 333, Training Loss: 0.09645889699459076, Validation Loss: 0.10437443107366562
Epoch 334, Training Loss: 0.09592117369174957, Validation Loss: 0.1044265553355217
Epoch 335, Training Loss: 0.09211276471614838, Validation Loss: 0.1044270321726799
Epoch 336, Training Loss: 0.0951252207159996, Validation Loss: 0.1044454425573349
Epoch 337, Training Loss: 0.09490646421909332, Validation Loss: 0.10446285456418991
Epoch 338, Training Loss: 0.09400742501020432, Validation Loss: 0.10443798452615738
Epoch 339, Training Loss: 0.09461775422096252, Validation Loss: 0.10440173745155334
Epoch 340, Training Loss: 0.09378202259540558, Validation Loss: 0.10432078689336777
Epoch 341, Training Loss: 0.09580492973327637, Validation Loss: 0.10424593091011047
Epoch 342, Training Loss: 0.09622926265001297, Validation Loss: 0.10411573946475983
Epoch 343, Training Loss: 0.09219000488519669, Validation Loss: 0.10394230484962463
Epoch 344, Training Loss: 0.09500245004892349, Validation Loss: 0.10381653904914856
Epoch 345, Training Loss: 0.09352995455265045, Validation Loss: 0.10368040949106216
Epoch 346, Training Loss: 0.09359945356845856, Validation Loss: 0.10356305539608002
Epoch 347, Training Loss: 0.099943146109581, Validation Loss: 0.10346590727567673
Epoch 348, Training Loss: 0.09570334106683731, Validation Loss: 0.10333771258592606
Epoch 349, Training Loss: 0.09050366282463074, Validation Loss: 0.10321622341871262
Epoch 350, Training Loss: 0.08985251933336258, Validation Loss: 0.10310275852680206
Epoch 351, Training Loss: 0.0980304405093193, Validation Loss: 0.1030287966132164
Epoch 352, Training Loss: 0.09464249759912491, Validation Loss: 0.10296086221933365
Epoch 353, Training Loss: 0.09631150215864182, Validation Loss: 0.10290851444005966
Epoch 354, Training Loss: 0.09565949440002441, Validation Loss: 0.10289647430181503
Epoch 355, Training Loss: 0.09566453844308853, Validation Loss: 0.1028752401471138
Epoch 356, Training Loss: 0.09317611157894135, Validation Loss: 0.10289233922958374
Epoch 357, Training Loss: 0.09697778522968292, Validation Loss: 0.10291138291358948
Epoch 358, Training Loss: 0.09586773067712784, Validation Loss: 0.10296006500720978
Epoch 359, Training Loss: 0.09744641184806824, Validation Loss: 0.10301592200994492
Epoch 360, Training Loss: 0.09300076216459274, Validation Loss: 0.10307145863771439
Epoch 361, Training Loss: 0.09549552202224731, Validation Loss: 0.10310474783182144
Epoch 362, Training Loss: 0.09517882764339447, Validation Loss: 0.10314792394638062
Epoch 363, Training Loss: 0.089396633207798, Validation Loss: 0.10316217690706253
Epoch 364, Training Loss: 0.0956113263964653, Validation Loss: 0.10315049439668655
Epoch 365, Training Loss: 0.09740236401557922, Validation Loss: 0.10314169526100159
Epoch 366, Training Loss: 0.09534990787506104, Validation Loss: 0.10316108167171478
Epoch 367, Training Loss: 0.09306774288415909, Validation Loss: 0.10319999605417252
Epoch 368, Training Loss: 0.09437087178230286, Validation Loss: 0.10320950299501419
Epoch 369, Training Loss: 0.09398484230041504, Validation Loss: 0.10321396589279175
Epoch 370, Training Loss: 0.09828522056341171, Validation Loss: 0.10321126133203506
Epoch 371, Training Loss: 0.09443354606628418, Validation Loss: 0.1031879335641861
Epoch 372, Training Loss: 0.09372766315937042, Validation Loss: 0.10314412415027618
Epoch 373, Training Loss: 0.091035857796669, Validation Loss: 0.10305538773536682
Epoch 374, Training Loss: 0.09481596201658249, Validation Loss: 0.10298088937997818
Epoch 375, Training Loss: 0.09426587074995041, Validation Loss: 0.10295134782791138
Epoch 376, Training Loss: 0.09227842092514038, Validation Loss: 0.10291697829961777
Epoch 377, Training Loss: 0.09458688646554947, Validation Loss: 0.102849081158638
Epoch 378, Training Loss: 0.09277892112731934, Validation Loss: 0.10281375050544739
Epoch 379, Training Loss: 0.09641988575458527, Validation Loss: 0.10283280909061432
Epoch 380, Training Loss: 0.09165439754724503, Validation Loss: 0.10289434343576431
Epoch 381, Training Loss: 0.09396190941333771, Validation Loss: 0.10295035690069199
Epoch 382, Training Loss: 0.0983547642827034, Validation Loss: 0.10301373898983002
Epoch 383, Training Loss: 0.09635237604379654, Validation Loss: 0.10309115052223206
Epoch 384, Training Loss: 0.09391150623559952, Validation Loss: 0.1031607985496521
Epoch 385, Training Loss: 0.09426434338092804, Validation Loss: 0.10324090719223022
Epoch 386, Training Loss: 0.09132325649261475, Validation Loss: 0.10329136252403259
Epoch 387, Training Loss: 0.09705799072980881, Validation Loss: 0.10333884507417679
Epoch 388, Training Loss: 0.09368760883808136, Validation Loss: 0.1033543273806572
Epoch 389, Training Loss: 0.09915244579315186, Validation Loss: 0.10340066254138947
Epoch 390, Training Loss: 0.0937826856970787, Validation Loss: 0.10345576703548431
Epoch 391, Training Loss: 0.09218454360961914, Validation Loss: 0.10344628244638443
Epoch 392, Training Loss: 0.09471026062965393, Validation Loss: 0.10341484844684601
Epoch 393, Training Loss: 0.09338653087615967, Validation Loss: 0.10334935039281845
Epoch 394, Training Loss: 0.09261384606361389, Validation Loss: 0.1032499447464943
Epoch 395, Training Loss: 0.09381498396396637, Validation Loss: 0.10314825922250748
Epoch 396, Training Loss: 0.09187335520982742, Validation Loss: 0.10303205251693726
Epoch 397, Training Loss: 0.09463530778884888, Validation Loss: 0.10295894742012024
Epoch 398, Training Loss: 0.09491638094186783, Validation Loss: 0.102907195687294
Epoch 399, Training Loss: 0.09506485611200333, Validation Loss: 0.10287446528673172
Epoch 400, Training Loss: 0.09517792612314224, Validation Loss: 0.10284072905778885
Epoch 401, Training Loss: 0.09627380967140198, Validation Loss: 0.10279504209756851
Epoch 402, Training Loss: 0.10053807497024536, Validation Loss: 0.10279085487127304
Epoch 403, Training Loss: 0.09771759808063507, Validation Loss: 0.10281988978385925
Epoch 404, Training Loss: 0.09074398875236511, Validation Loss: 0.10283952951431274
Epoch 405, Training Loss: 0.09230470657348633, Validation Loss: 0.10283089429140091
Epoch 406, Training Loss: 0.0918341800570488, Validation Loss: 0.10282371938228607
Epoch 407, Training Loss: 0.09371329843997955, Validation Loss: 0.10280334204435349
Epoch 408, Training Loss: 0.09157879650592804, Validation Loss: 0.10279650241136551
Epoch 409, Training Loss: 0.09853062778711319, Validation Loss: 0.10284505039453506
Epoch 410, Training Loss: 0.09512117505073547, Validation Loss: 0.10286100208759308
Epoch 411, Training Loss: 0.09625919163227081, Validation Loss: 0.10289933532476425
Epoch 412, Training Loss: 0.09424924105405807, Validation Loss: 0.10290445387363434
Epoch 413, Training Loss: 0.09321720898151398, Validation Loss: 0.10291782021522522
Epoch 414, Training Loss: 0.09405635297298431, Validation Loss: 0.1029285416007042
Epoch 415, Training Loss: 0.09536916017532349, Validation Loss: 0.10287623852491379
Epoch 416, Training Loss: 0.09185852110385895, Validation Loss: 0.10279206186532974
Epoch 417, Training Loss: 0.08882509917020798, Validation Loss: 0.10270360857248306
Epoch 418, Training Loss: 0.08892589062452316, Validation Loss: 0.10260365158319473
Epoch 419, Training Loss: 0.09505796432495117, Validation Loss: 0.10259167104959488
Epoch 420, Training Loss: 0.09081575274467468, Validation Loss: 0.102530337870121
Epoch 421, Training Loss: 0.09742866456508636, Validation Loss: 0.10248211771249771
Epoch 422, Training Loss: 0.09416160732507706, Validation Loss: 0.10244259983301163
Epoch 423, Training Loss: 0.08980758488178253, Validation Loss: 0.10242433100938797
Epoch 424, Training Loss: 0.08971506357192993, Validation Loss: 0.10240935534238815
Epoch 425, Training Loss: 0.08889085799455643, Validation Loss: 0.10237108916044235
Epoch 426, Training Loss: 0.09176884591579437, Validation Loss: 0.10229228436946869
Epoch 427, Training Loss: 0.0927300676703453, Validation Loss: 0.1022336557507515
Epoch 428, Training Loss: 0.09860128909349442, Validation Loss: 0.1021668016910553
Epoch 429, Training Loss: 0.09457244724035263, Validation Loss: 0.10214022547006607
Epoch 430, Training Loss: 0.09330210834741592, Validation Loss: 0.10219954699277878
Epoch 431, Training Loss: 0.09624816477298737, Validation Loss: 0.10222177952528
Epoch 432, Training Loss: 0.09407520294189453, Validation Loss: 0.10226239264011383
Epoch 433, Training Loss: 0.0958472266793251, Validation Loss: 0.10233523696660995
Epoch 434, Training Loss: 0.09237036108970642, Validation Loss: 0.10236087441444397
Epoch 435, Training Loss: 0.09245425462722778, Validation Loss: 0.10239029675722122
Epoch 436, Training Loss: 0.09348931908607483, Validation Loss: 0.10241559147834778
Epoch 437, Training Loss: 0.09302180260419846, Validation Loss: 0.10241864621639252
Epoch 438, Training Loss: 0.08971097320318222, Validation Loss: 0.102384552359581
Epoch 439, Training Loss: 0.09300904721021652, Validation Loss: 0.1023559644818306
Epoch 440, Training Loss: 0.09362893551588058, Validation Loss: 0.10235943645238876
Epoch 441, Training Loss: 0.08942602574825287, Validation Loss: 0.10235732048749924
Epoch 442, Training Loss: 0.09485083818435669, Validation Loss: 0.10236872732639313
Epoch 443, Training Loss: 0.09368608891963959, Validation Loss: 0.10238376259803772
Epoch 444, Training Loss: 0.09426505118608475, Validation Loss: 0.10239390283823013
Epoch 445, Training Loss: 0.09176585078239441, Validation Loss: 0.10238519310951233
Epoch 446, Training Loss: 0.09508419036865234, Validation Loss: 0.10240890085697174
Epoch 447, Training Loss: 0.09016422182321548, Validation Loss: 0.10241370648145676
Epoch 448, Training Loss: 0.09173140674829483, Validation Loss: 0.10237693041563034
Epoch 449, Training Loss: 0.09473530203104019, Validation Loss: 0.10235684365034103
Epoch 450, Training Loss: 0.09363513439893723, Validation Loss: 0.10236793756484985
Epoch 451, Training Loss: 0.0967138335108757, Validation Loss: 0.10239429026842117
Epoch 452, Training Loss: 0.09296684712171555, Validation Loss: 0.10241255164146423
Epoch 453, Training Loss: 0.09189169853925705, Validation Loss: 0.1023998111486435
Epoch 454, Training Loss: 0.09335052222013474, Validation Loss: 0.10237345099449158
Epoch 455, Training Loss: 0.09511518478393555, Validation Loss: 0.10237675905227661
Epoch 456, Training Loss: 0.09032458811998367, Validation Loss: 0.10234738141298294
Epoch 457, Training Loss: 0.09674008190631866, Validation Loss: 0.10231687873601913
Epoch 458, Training Loss: 0.0959392637014389, Validation Loss: 0.10229776799678802
Epoch 459, Training Loss: 0.08955935388803482, Validation Loss: 0.10227373242378235
Epoch 460, Training Loss: 0.09101888537406921, Validation Loss: 0.10223923623561859
Epoch 461, Training Loss: 0.09286604821681976, Validation Loss: 0.10221032053232193
Epoch 462, Training Loss: 0.0950079932808876, Validation Loss: 0.1021762490272522
Epoch 463, Training Loss: 0.08967871218919754, Validation Loss: 0.10210005193948746
Epoch 464, Training Loss: 0.09638018161058426, Validation Loss: 0.10200179368257523
Epoch 465, Training Loss: 0.09259462356567383, Validation Loss: 0.10194138437509537
Epoch 466, Training Loss: 0.09380289912223816, Validation Loss: 0.1019371971487999
Epoch 467, Training Loss: 0.09527118504047394, Validation Loss: 0.10197398066520691
Epoch 468, Training Loss: 0.09338922798633575, Validation Loss: 0.10200855135917664
Epoch 469, Training Loss: 0.09328188002109528, Validation Loss: 0.10204575210809708
Epoch 470, Training Loss: 0.09506457298994064, Validation Loss: 0.10211256891489029
Epoch 471, Training Loss: 0.0885358527302742, Validation Loss: 0.10217031836509705
Epoch 472, Training Loss: 0.09025680273771286, Validation Loss: 0.10222788155078888
Epoch 473, Training Loss: 0.09182387590408325, Validation Loss: 0.10225187242031097
Epoch 474, Training Loss: 0.09146983921527863, Validation Loss: 0.10224422812461853
Epoch 475, Training Loss: 0.09289379417896271, Validation Loss: 0.10217520594596863
Epoch 476, Training Loss: 0.09279167652130127, Validation Loss: 0.10212015360593796
Epoch 477, Training Loss: 0.09317568689584732, Validation Loss: 0.10206048935651779
Epoch 478, Training Loss: 0.09534835070371628, Validation Loss: 0.10204725712537766
Epoch 479, Training Loss: 0.09300294518470764, Validation Loss: 0.10203978419303894
Epoch 480, Training Loss: 0.09522734582424164, Validation Loss: 0.10203554481267929
Epoch 481, Training Loss: 0.08880910277366638, Validation Loss: 0.10201627761125565
Epoch 482, Training Loss: 0.09483000636100769, Validation Loss: 0.10200417786836624
Epoch 483, Training Loss: 0.09220809489488602, Validation Loss: 0.10202518105506897
Epoch 484, Training Loss: 0.09105950593948364, Validation Loss: 0.1020510122179985
Epoch 485, Training Loss: 0.09288568049669266, Validation Loss: 0.10204853117465973
Epoch 486, Training Loss: 0.09595616161823273, Validation Loss: 0.10207171738147736
Epoch 487, Training Loss: 0.09623295068740845, Validation Loss: 0.10207910090684891
Epoch 488, Training Loss: 0.09342922270298004, Validation Loss: 0.10205196589231491
Epoch 489, Training Loss: 0.09329161792993546, Validation Loss: 0.1019914448261261
Epoch 490, Training Loss: 0.09122269600629807, Validation Loss: 0.10191379487514496
Epoch 491, Training Loss: 0.09090464562177658, Validation Loss: 0.10186146199703217
Epoch 492, Training Loss: 0.09200432896614075, Validation Loss: 0.10176471620798111
Epoch 493, Training Loss: 0.09524764120578766, Validation Loss: 0.10172508656978607
Epoch 494, Training Loss: 0.09213747084140778, Validation Loss: 0.1016988679766655
Epoch 495, Training Loss: 0.0964871421456337, Validation Loss: 0.1016949936747551
Epoch 496, Training Loss: 0.09272592514753342, Validation Loss: 0.10168281197547913
Epoch 497, Training Loss: 0.0946492925286293, Validation Loss: 0.10166198015213013
Epoch 498, Training Loss: 0.08973222970962524, Validation Loss: 0.1016385480761528
Epoch 499, Training Loss: 0.08839435130357742, Validation Loss: 0.10157837718725204
Epoch 500, Training Loss: 0.09284988045692444, Validation Loss: 0.10154654085636139
