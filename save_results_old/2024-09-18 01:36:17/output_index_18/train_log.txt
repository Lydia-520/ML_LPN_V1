Epoch 1, Training Loss: 0.18371203541755676, Validation Loss: 0.19226427376270294
Epoch 2, Training Loss: 0.1828434020280838, Validation Loss: 0.19171734154224396
Epoch 3, Training Loss: 0.18323107063770294, Validation Loss: 0.191179096698761
Epoch 4, Training Loss: 0.1808437705039978, Validation Loss: 0.19065409898757935
Epoch 5, Training Loss: 0.1817781925201416, Validation Loss: 0.19013354182243347
Epoch 6, Training Loss: 0.1799866110086441, Validation Loss: 0.1896090805530548
Epoch 7, Training Loss: 0.18041570484638214, Validation Loss: 0.18908153474330902
Epoch 8, Training Loss: 0.1797291785478592, Validation Loss: 0.18855395913124084
Epoch 9, Training Loss: 0.17850983142852783, Validation Loss: 0.188022181391716
Epoch 10, Training Loss: 0.1779949963092804, Validation Loss: 0.18748372793197632
Epoch 11, Training Loss: 0.1762535125017166, Validation Loss: 0.1869383454322815
Epoch 12, Training Loss: 0.17809796333312988, Validation Loss: 0.1863945871591568
Epoch 13, Training Loss: 0.17450709640979767, Validation Loss: 0.18584656715393066
Epoch 14, Training Loss: 0.17525020241737366, Validation Loss: 0.18529412150382996
Epoch 15, Training Loss: 0.17480558156967163, Validation Loss: 0.18474069237709045
Epoch 16, Training Loss: 0.17455120384693146, Validation Loss: 0.18417850136756897
Epoch 17, Training Loss: 0.1736173927783966, Validation Loss: 0.18360809981822968
Epoch 18, Training Loss: 0.17130811512470245, Validation Loss: 0.18302945792675018
Epoch 19, Training Loss: 0.1715095341205597, Validation Loss: 0.18244916200637817
Epoch 20, Training Loss: 0.1724812090396881, Validation Loss: 0.1818658858537674
Epoch 21, Training Loss: 0.17151418328285217, Validation Loss: 0.18127332627773285
Epoch 22, Training Loss: 0.17049284279346466, Validation Loss: 0.18066911399364471
Epoch 23, Training Loss: 0.17159776389598846, Validation Loss: 0.1800619512796402
Epoch 24, Training Loss: 0.16792000830173492, Validation Loss: 0.17944450676441193
Epoch 25, Training Loss: 0.16797220706939697, Validation Loss: 0.17881222069263458
Epoch 26, Training Loss: 0.16691389679908752, Validation Loss: 0.17816442251205444
Epoch 27, Training Loss: 0.1662103235721588, Validation Loss: 0.177496075630188
Epoch 28, Training Loss: 0.16657011210918427, Validation Loss: 0.17681708931922913
Epoch 29, Training Loss: 0.16236595809459686, Validation Loss: 0.17610356211662292
Epoch 30, Training Loss: 0.16511981189250946, Validation Loss: 0.17535510659217834
Epoch 31, Training Loss: 0.16193149983882904, Validation Loss: 0.1745738685131073
Epoch 32, Training Loss: 0.16173917055130005, Validation Loss: 0.1737522929906845
Epoch 33, Training Loss: 0.1607854664325714, Validation Loss: 0.17289836704730988
Epoch 34, Training Loss: 0.15853996574878693, Validation Loss: 0.17202135920524597
Epoch 35, Training Loss: 0.15989667177200317, Validation Loss: 0.17111758887767792
Epoch 36, Training Loss: 0.1599469631910324, Validation Loss: 0.17017196118831635
Epoch 37, Training Loss: 0.15513354539871216, Validation Loss: 0.16917455196380615
Epoch 38, Training Loss: 0.15629535913467407, Validation Loss: 0.16812185943126678
Epoch 39, Training Loss: 0.1512744128704071, Validation Loss: 0.16700033843517303
Epoch 40, Training Loss: 0.15220116078853607, Validation Loss: 0.1658073514699936
Epoch 41, Training Loss: 0.152666375041008, Validation Loss: 0.16453973948955536
Epoch 42, Training Loss: 0.14728489518165588, Validation Loss: 0.1631939709186554
Epoch 43, Training Loss: 0.15174420177936554, Validation Loss: 0.1617938131093979
Epoch 44, Training Loss: 0.14615905284881592, Validation Loss: 0.16030685603618622
Epoch 45, Training Loss: 0.14465327560901642, Validation Loss: 0.15872783958911896
Epoch 46, Training Loss: 0.14333057403564453, Validation Loss: 0.15706519782543182
Epoch 47, Training Loss: 0.14180894196033478, Validation Loss: 0.15531566739082336
Epoch 48, Training Loss: 0.13929636776447296, Validation Loss: 0.15346761047840118
Epoch 49, Training Loss: 0.13460803031921387, Validation Loss: 0.15151037275791168
Epoch 50, Training Loss: 0.13574974238872528, Validation Loss: 0.14946317672729492
Epoch 51, Training Loss: 0.13571766018867493, Validation Loss: 0.14732256531715393
Epoch 52, Training Loss: 0.13231071829795837, Validation Loss: 0.1450852006673813
Epoch 53, Training Loss: 0.12853382527828217, Validation Loss: 0.14272785186767578
Epoch 54, Training Loss: 0.12874722480773926, Validation Loss: 0.14026843011379242
Epoch 55, Training Loss: 0.12838158011436462, Validation Loss: 0.13773736357688904
Epoch 56, Training Loss: 0.11881555616855621, Validation Loss: 0.1351090669631958
Epoch 57, Training Loss: 0.12385445833206177, Validation Loss: 0.13243244588375092
Epoch 58, Training Loss: 0.12042619287967682, Validation Loss: 0.12967868149280548
Epoch 59, Training Loss: 0.11225656419992447, Validation Loss: 0.12686479091644287
Epoch 60, Training Loss: 0.11370983719825745, Validation Loss: 0.12404419481754303
Epoch 61, Training Loss: 0.11263395845890045, Validation Loss: 0.12127106636762619
Epoch 62, Training Loss: 0.1093086525797844, Validation Loss: 0.11862016469240189
Epoch 63, Training Loss: 0.1106436550617218, Validation Loss: 0.11610562354326248
Epoch 64, Training Loss: 0.11287642270326614, Validation Loss: 0.11379904299974442
Epoch 65, Training Loss: 0.10272539407014847, Validation Loss: 0.11178774386644363
Epoch 66, Training Loss: 0.11123286932706833, Validation Loss: 0.1100456565618515
Epoch 67, Training Loss: 0.10709546506404877, Validation Loss: 0.108580082654953
Epoch 68, Training Loss: 0.09998161345720291, Validation Loss: 0.10728596895933151
Epoch 69, Training Loss: 0.10674787312746048, Validation Loss: 0.10623817890882492
Epoch 70, Training Loss: 0.10150143504142761, Validation Loss: 0.1053585559129715
Epoch 71, Training Loss: 0.10773036628961563, Validation Loss: 0.1047404333949089
Epoch 72, Training Loss: 0.1085151731967926, Validation Loss: 0.10433899611234665
Epoch 73, Training Loss: 0.11068997532129288, Validation Loss: 0.10408837348222733
Epoch 74, Training Loss: 0.10337083786725998, Validation Loss: 0.10404188930988312
Epoch 75, Training Loss: 0.11716853827238083, Validation Loss: 0.10421623289585114
Epoch 76, Training Loss: 0.10813339054584503, Validation Loss: 0.10462314635515213
Epoch 77, Training Loss: 0.10545499622821808, Validation Loss: 0.10516829043626785
Epoch 78, Training Loss: 0.10175984352827072, Validation Loss: 0.10574737191200256
Epoch 79, Training Loss: 0.105161651968956, Validation Loss: 0.10637965053319931
Epoch 80, Training Loss: 0.10254275053739548, Validation Loss: 0.10702511668205261
Epoch 81, Training Loss: 0.09838270395994186, Validation Loss: 0.10752441734075546
Epoch 82, Training Loss: 0.10124944150447845, Validation Loss: 0.10802419483661652
Epoch 83, Training Loss: 0.1021580919623375, Validation Loss: 0.10850848257541656
Epoch 84, Training Loss: 0.10553552210330963, Validation Loss: 0.10891051590442657
Epoch 85, Training Loss: 0.10479290783405304, Validation Loss: 0.10931679606437683
Epoch 86, Training Loss: 0.09497816115617752, Validation Loss: 0.1096157506108284
Epoch 87, Training Loss: 0.1079823449254036, Validation Loss: 0.10990241169929504
Epoch 88, Training Loss: 0.10463044792413712, Validation Loss: 0.11018118262290955
Epoch 89, Training Loss: 0.10365752130746841, Validation Loss: 0.11042169481515884
Epoch 90, Training Loss: 0.10727881640195847, Validation Loss: 0.11060028523206711
Epoch 91, Training Loss: 0.10719595104455948, Validation Loss: 0.11071185022592545
Epoch 92, Training Loss: 0.10116425901651382, Validation Loss: 0.11076699197292328
Epoch 93, Training Loss: 0.10615815222263336, Validation Loss: 0.11082178354263306
Epoch 94, Training Loss: 0.1026533767580986, Validation Loss: 0.11081820726394653
Epoch 95, Training Loss: 0.10243097692728043, Validation Loss: 0.1107671931385994
Epoch 96, Training Loss: 0.09452464431524277, Validation Loss: 0.11061658710241318
Epoch 97, Training Loss: 0.1023416817188263, Validation Loss: 0.11038828641176224
Epoch 98, Training Loss: 0.10371722280979156, Validation Loss: 0.11006909608840942
Epoch 99, Training Loss: 0.1012929379940033, Validation Loss: 0.10973888635635376
Epoch 100, Training Loss: 0.09916986525058746, Validation Loss: 0.10944188386201859
Epoch 101, Training Loss: 0.10337895900011063, Validation Loss: 0.10923703014850616
Epoch 102, Training Loss: 0.10276177525520325, Validation Loss: 0.10911645740270615
Epoch 103, Training Loss: 0.09945494681596756, Validation Loss: 0.10903500020503998
Epoch 104, Training Loss: 0.09984423965215683, Validation Loss: 0.10893756151199341
Epoch 105, Training Loss: 0.09966814517974854, Validation Loss: 0.10884054005146027
Epoch 106, Training Loss: 0.10098046809434891, Validation Loss: 0.10864134132862091
Epoch 107, Training Loss: 0.1013287603855133, Validation Loss: 0.10838209837675095
Epoch 108, Training Loss: 0.09629589319229126, Validation Loss: 0.10812923312187195
Epoch 109, Training Loss: 0.10442100465297699, Validation Loss: 0.10785356909036636
Epoch 110, Training Loss: 0.10207933932542801, Validation Loss: 0.10760322958230972
Epoch 111, Training Loss: 0.10121982544660568, Validation Loss: 0.10740580409765244
Epoch 112, Training Loss: 0.0982707291841507, Validation Loss: 0.1072898879647255
Epoch 113, Training Loss: 0.10486645251512527, Validation Loss: 0.10722363740205765
Epoch 114, Training Loss: 0.10555239021778107, Validation Loss: 0.10716734081506729
Epoch 115, Training Loss: 0.10146992653608322, Validation Loss: 0.10718945413827896
Epoch 116, Training Loss: 0.10169073939323425, Validation Loss: 0.10720473527908325
Epoch 117, Training Loss: 0.0998074933886528, Validation Loss: 0.10727666318416595
Epoch 118, Training Loss: 0.09654161334037781, Validation Loss: 0.10730989277362823
Epoch 119, Training Loss: 0.1035648062825203, Validation Loss: 0.1073441356420517
Epoch 120, Training Loss: 0.10627385973930359, Validation Loss: 0.10740727931261063
Epoch 121, Training Loss: 0.10530673712491989, Validation Loss: 0.10748888552188873
Epoch 122, Training Loss: 0.10481230169534683, Validation Loss: 0.10758117586374283
Epoch 123, Training Loss: 0.0971384271979332, Validation Loss: 0.10759875178337097
Epoch 124, Training Loss: 0.10079801827669144, Validation Loss: 0.10755502432584763
Epoch 125, Training Loss: 0.09898107498884201, Validation Loss: 0.10755816847085953
Epoch 126, Training Loss: 0.09839826822280884, Validation Loss: 0.10757718235254288
Epoch 127, Training Loss: 0.10172221064567566, Validation Loss: 0.10757455229759216
Epoch 128, Training Loss: 0.0967993512749672, Validation Loss: 0.10752478241920471
Epoch 129, Training Loss: 0.09822859615087509, Validation Loss: 0.10741528868675232
Epoch 130, Training Loss: 0.10636535286903381, Validation Loss: 0.10730069875717163
Epoch 131, Training Loss: 0.100262850522995, Validation Loss: 0.10717297345399857
Epoch 132, Training Loss: 0.10274127870798111, Validation Loss: 0.10710890591144562
Epoch 133, Training Loss: 0.09987391531467438, Validation Loss: 0.10711268335580826
Epoch 134, Training Loss: 0.09952519834041595, Validation Loss: 0.10708358138799667
Epoch 135, Training Loss: 0.10507386177778244, Validation Loss: 0.10723915696144104
Epoch 136, Training Loss: 0.10028884559869766, Validation Loss: 0.10732898861169815
Epoch 137, Training Loss: 0.1038285419344902, Validation Loss: 0.1073666587471962
Epoch 138, Training Loss: 0.10062771290540695, Validation Loss: 0.10736040025949478
Epoch 139, Training Loss: 0.1007653996348381, Validation Loss: 0.10736902058124542
Epoch 140, Training Loss: 0.0998251810669899, Validation Loss: 0.1074075773358345
Epoch 141, Training Loss: 0.09577559679746628, Validation Loss: 0.1073894202709198
Epoch 142, Training Loss: 0.09838637709617615, Validation Loss: 0.1073431670665741
Epoch 143, Training Loss: 0.09866590052843094, Validation Loss: 0.10725608468055725
Epoch 144, Training Loss: 0.0965619757771492, Validation Loss: 0.10717179626226425
Epoch 145, Training Loss: 0.09532036632299423, Validation Loss: 0.10707742720842361
Epoch 146, Training Loss: 0.1023923009634018, Validation Loss: 0.10696134716272354
Epoch 147, Training Loss: 0.09959840774536133, Validation Loss: 0.10682739317417145
Epoch 148, Training Loss: 0.10519038885831833, Validation Loss: 0.10674936324357986
Epoch 149, Training Loss: 0.10158291459083557, Validation Loss: 0.10672862827777863
Epoch 150, Training Loss: 0.100262850522995, Validation Loss: 0.1067957952618599
Epoch 151, Training Loss: 0.10066153109073639, Validation Loss: 0.10682085901498795
Epoch 152, Training Loss: 0.10080600529909134, Validation Loss: 0.10685846209526062
Epoch 153, Training Loss: 0.10256292670965195, Validation Loss: 0.10694971680641174
Epoch 154, Training Loss: 0.10087846219539642, Validation Loss: 0.10701535642147064
Epoch 155, Training Loss: 0.0953841581940651, Validation Loss: 0.10702759027481079
Epoch 156, Training Loss: 0.10112911462783813, Validation Loss: 0.10711442679166794
Epoch 157, Training Loss: 0.09713970869779587, Validation Loss: 0.10724332183599472
Epoch 158, Training Loss: 0.09555023163557053, Validation Loss: 0.107342429459095
Epoch 159, Training Loss: 0.10197458416223526, Validation Loss: 0.10744235664606094
Epoch 160, Training Loss: 0.09633753448724747, Validation Loss: 0.10747803747653961
Epoch 161, Training Loss: 0.10297659784555435, Validation Loss: 0.10757419466972351
Epoch 162, Training Loss: 0.10281025618314743, Validation Loss: 0.10763182491064072
Epoch 163, Training Loss: 0.09804221987724304, Validation Loss: 0.10766858607530594
Epoch 164, Training Loss: 0.09947890788316727, Validation Loss: 0.10766826570034027
Epoch 165, Training Loss: 0.0970548540353775, Validation Loss: 0.10763330012559891
Epoch 166, Training Loss: 0.10250888764858246, Validation Loss: 0.10771331936120987
Epoch 167, Training Loss: 0.09592202305793762, Validation Loss: 0.10775059461593628
Epoch 168, Training Loss: 0.09654342383146286, Validation Loss: 0.1077198013663292
Epoch 169, Training Loss: 0.09976532310247421, Validation Loss: 0.10770629346370697
Epoch 170, Training Loss: 0.09776537865400314, Validation Loss: 0.10764433443546295
Epoch 171, Training Loss: 0.09395904093980789, Validation Loss: 0.10758710652589798
Epoch 172, Training Loss: 0.09547776728868484, Validation Loss: 0.10750128328800201
Epoch 173, Training Loss: 0.09745090454816818, Validation Loss: 0.10747216641902924
Epoch 174, Training Loss: 0.1023155003786087, Validation Loss: 0.10739181190729141
Epoch 175, Training Loss: 0.09647760540246964, Validation Loss: 0.10722872614860535
Epoch 176, Training Loss: 0.0922965407371521, Validation Loss: 0.10702664405107498
Epoch 177, Training Loss: 0.10073386132717133, Validation Loss: 0.10692372918128967
Epoch 178, Training Loss: 0.0951976627111435, Validation Loss: 0.10677924007177353
Epoch 179, Training Loss: 0.10052340477705002, Validation Loss: 0.10668855160474777
Epoch 180, Training Loss: 0.09896667301654816, Validation Loss: 0.10666794329881668
Epoch 181, Training Loss: 0.10215666890144348, Validation Loss: 0.10673195123672485
Epoch 182, Training Loss: 0.10237430036067963, Validation Loss: 0.10684318095445633
Epoch 183, Training Loss: 0.09641937166452408, Validation Loss: 0.10701919347047806
Epoch 184, Training Loss: 0.09950095415115356, Validation Loss: 0.10715536028146744
Epoch 185, Training Loss: 0.09622551500797272, Validation Loss: 0.10721376538276672
Epoch 186, Training Loss: 0.09812302142381668, Validation Loss: 0.10728354007005692
Epoch 187, Training Loss: 0.09975212067365646, Validation Loss: 0.10738972574472427
Epoch 188, Training Loss: 0.09286901354789734, Validation Loss: 0.10739196836948395
Epoch 189, Training Loss: 0.10042442381381989, Validation Loss: 0.10739590972661972
Epoch 190, Training Loss: 0.0960194543004036, Validation Loss: 0.1074029803276062
Epoch 191, Training Loss: 0.09604564309120178, Validation Loss: 0.1074594035744667
Epoch 192, Training Loss: 0.09176518768072128, Validation Loss: 0.10743221640586853
Epoch 193, Training Loss: 0.10156859457492828, Validation Loss: 0.1074843481183052
Epoch 194, Training Loss: 0.09896758943796158, Validation Loss: 0.10747118294239044
Epoch 195, Training Loss: 0.09623213112354279, Validation Loss: 0.10747569054365158
Epoch 196, Training Loss: 0.09527745097875595, Validation Loss: 0.1074385866522789
Epoch 197, Training Loss: 0.10140032321214676, Validation Loss: 0.10739429295063019
Epoch 198, Training Loss: 0.09529871493577957, Validation Loss: 0.10731447488069534
Epoch 199, Training Loss: 0.09394233673810959, Validation Loss: 0.10721994191408157
Epoch 200, Training Loss: 0.09523509442806244, Validation Loss: 0.10710224509239197
Epoch 201, Training Loss: 0.09527824819087982, Validation Loss: 0.10696103423833847
Epoch 202, Training Loss: 0.096672922372818, Validation Loss: 0.10679669678211212
Epoch 203, Training Loss: 0.09654877334833145, Validation Loss: 0.10666146129369736
Epoch 204, Training Loss: 0.10322041809558868, Validation Loss: 0.10654447972774506
Epoch 205, Training Loss: 0.09856492280960083, Validation Loss: 0.10642648488283157
Epoch 206, Training Loss: 0.09733887016773224, Validation Loss: 0.10639416426420212
Epoch 207, Training Loss: 0.0959194228053093, Validation Loss: 0.10637078434228897
Epoch 208, Training Loss: 0.0960719957947731, Validation Loss: 0.10632822662591934
Epoch 209, Training Loss: 0.09542013704776764, Validation Loss: 0.10628929734230042
Epoch 210, Training Loss: 0.09630054980516434, Validation Loss: 0.10629718750715256
Epoch 211, Training Loss: 0.10156437754631042, Validation Loss: 0.10630851238965988
Epoch 212, Training Loss: 0.10183244943618774, Validation Loss: 0.10635301470756531
Epoch 213, Training Loss: 0.09518297016620636, Validation Loss: 0.106472909450531
Epoch 214, Training Loss: 0.09719271957874298, Validation Loss: 0.10662541538476944
Epoch 215, Training Loss: 0.09855478256940842, Validation Loss: 0.10683973133563995
Epoch 216, Training Loss: 0.09742075204849243, Validation Loss: 0.10702504962682724
Epoch 217, Training Loss: 0.09797850251197815, Validation Loss: 0.10714206844568253
Epoch 218, Training Loss: 0.09440220892429352, Validation Loss: 0.107206329703331
Epoch 219, Training Loss: 0.10072179138660431, Validation Loss: 0.10729075223207474
Epoch 220, Training Loss: 0.09446199238300323, Validation Loss: 0.10729239881038666
Epoch 221, Training Loss: 0.09709551930427551, Validation Loss: 0.10730798542499542
Epoch 222, Training Loss: 0.09251727163791656, Validation Loss: 0.10732000321149826
Epoch 223, Training Loss: 0.09851621091365814, Validation Loss: 0.10728628933429718
Epoch 224, Training Loss: 0.10280083119869232, Validation Loss: 0.1072365939617157
Epoch 225, Training Loss: 0.09571443498134613, Validation Loss: 0.10715124756097794
Epoch 226, Training Loss: 0.09486527740955353, Validation Loss: 0.10702699422836304
Epoch 227, Training Loss: 0.09888684004545212, Validation Loss: 0.10688804090023041
Epoch 228, Training Loss: 0.09438546001911163, Validation Loss: 0.10678869485855103
Epoch 229, Training Loss: 0.10070636123418808, Validation Loss: 0.106743723154068
Epoch 230, Training Loss: 0.10157757997512817, Validation Loss: 0.10676433145999908
Epoch 231, Training Loss: 0.09933438152074814, Validation Loss: 0.10681694000959396
Epoch 232, Training Loss: 0.09463924914598465, Validation Loss: 0.1068793460726738
Epoch 233, Training Loss: 0.09864231944084167, Validation Loss: 0.1069369912147522
Epoch 234, Training Loss: 0.0943240225315094, Validation Loss: 0.10697024315595627
Epoch 235, Training Loss: 0.09798434376716614, Validation Loss: 0.10697805136442184
Epoch 236, Training Loss: 0.09615518897771835, Validation Loss: 0.10692670196294785
Epoch 237, Training Loss: 0.09635844826698303, Validation Loss: 0.10686062276363373
Epoch 238, Training Loss: 0.09551089257001877, Validation Loss: 0.10675454884767532
Epoch 239, Training Loss: 0.09839865565299988, Validation Loss: 0.10661470144987106
Epoch 240, Training Loss: 0.09698960185050964, Validation Loss: 0.10647180676460266
Epoch 241, Training Loss: 0.09469502419233322, Validation Loss: 0.10631396621465683
Epoch 242, Training Loss: 0.10147863626480103, Validation Loss: 0.10610877722501755
Epoch 243, Training Loss: 0.09281547367572784, Validation Loss: 0.10589595139026642
Epoch 244, Training Loss: 0.09978586435317993, Validation Loss: 0.10573437064886093
Epoch 245, Training Loss: 0.09369086474180222, Validation Loss: 0.1055438444018364
Epoch 246, Training Loss: 0.09707723557949066, Validation Loss: 0.10538697987794876
Epoch 247, Training Loss: 0.0931529700756073, Validation Loss: 0.10525564104318619
Epoch 248, Training Loss: 0.09971169382333755, Validation Loss: 0.10513412207365036
Epoch 249, Training Loss: 0.09864027053117752, Validation Loss: 0.10508064180612564
Epoch 250, Training Loss: 0.09823936969041824, Validation Loss: 0.10513830929994583
Epoch 251, Training Loss: 0.09554687142372131, Validation Loss: 0.1052541434764862
Epoch 252, Training Loss: 0.09781821072101593, Validation Loss: 0.10542947798967361
Epoch 253, Training Loss: 0.0970328226685524, Validation Loss: 0.1055777296423912
Epoch 254, Training Loss: 0.09705351293087006, Validation Loss: 0.10574295371770859
Epoch 255, Training Loss: 0.10146726667881012, Validation Loss: 0.10593381524085999
Epoch 256, Training Loss: 0.09230335056781769, Validation Loss: 0.10608488321304321
Epoch 257, Training Loss: 0.09888020157814026, Validation Loss: 0.10624409466981888
Epoch 258, Training Loss: 0.09669052064418793, Validation Loss: 0.10638365149497986
Epoch 259, Training Loss: 0.09981109946966171, Validation Loss: 0.10644335299730301
Epoch 260, Training Loss: 0.09212324023246765, Validation Loss: 0.10648833960294724
Epoch 261, Training Loss: 0.10020619630813599, Validation Loss: 0.10650883615016937
Epoch 262, Training Loss: 0.10005400329828262, Validation Loss: 0.10662970691919327
Epoch 263, Training Loss: 0.09709307551383972, Validation Loss: 0.10675860196352005
Epoch 264, Training Loss: 0.09911300241947174, Validation Loss: 0.10685215145349503
Epoch 265, Training Loss: 0.0914921760559082, Validation Loss: 0.10686466097831726
Epoch 266, Training Loss: 0.09564390778541565, Validation Loss: 0.10686466097831726
Epoch 267, Training Loss: 0.096168652176857, Validation Loss: 0.10683790594339371
Epoch 268, Training Loss: 0.09544941782951355, Validation Loss: 0.10680835694074631
Epoch 269, Training Loss: 0.09987286478281021, Validation Loss: 0.10680929571390152
Epoch 270, Training Loss: 0.08927855640649796, Validation Loss: 0.10679756104946136
Epoch 271, Training Loss: 0.09455302357673645, Validation Loss: 0.10675733536481857
Epoch 272, Training Loss: 0.09530551731586456, Validation Loss: 0.10673478245735168
Epoch 273, Training Loss: 0.0938127264380455, Validation Loss: 0.10671474784612656
Epoch 274, Training Loss: 0.09598618745803833, Validation Loss: 0.10664347559213638
Epoch 275, Training Loss: 0.0958697721362114, Validation Loss: 0.10659299045801163
Epoch 276, Training Loss: 0.09607051312923431, Validation Loss: 0.10657680779695511
Epoch 277, Training Loss: 0.09499885141849518, Validation Loss: 0.10648925602436066
Epoch 278, Training Loss: 0.09439802169799805, Validation Loss: 0.1063980758190155
Epoch 279, Training Loss: 0.0939902737736702, Validation Loss: 0.10635464638471603
Epoch 280, Training Loss: 0.09532777220010757, Validation Loss: 0.10625580698251724
Epoch 281, Training Loss: 0.09316787868738174, Validation Loss: 0.10613182932138443
Epoch 282, Training Loss: 0.09374954551458359, Validation Loss: 0.10607659071683884
Epoch 283, Training Loss: 0.09140974283218384, Validation Loss: 0.1060287281870842
Epoch 284, Training Loss: 0.09454204142093658, Validation Loss: 0.10592948645353317
Epoch 285, Training Loss: 0.09440825134515762, Validation Loss: 0.10577846318483353
Epoch 286, Training Loss: 0.09391412883996964, Validation Loss: 0.1055886298418045
Epoch 287, Training Loss: 0.09631112962961197, Validation Loss: 0.105424664914608
Epoch 288, Training Loss: 0.09840431064367294, Validation Loss: 0.10525737702846527
Epoch 289, Training Loss: 0.09539525955915451, Validation Loss: 0.1051008477807045
Epoch 290, Training Loss: 0.09503819048404694, Validation Loss: 0.10497280955314636
Epoch 291, Training Loss: 0.09446791559457779, Validation Loss: 0.10479411482810974
Epoch 292, Training Loss: 0.09551884979009628, Validation Loss: 0.1046881154179573
Epoch 293, Training Loss: 0.0944029688835144, Validation Loss: 0.10459575057029724
Epoch 294, Training Loss: 0.09756731986999512, Validation Loss: 0.10454154759645462
Epoch 295, Training Loss: 0.09804867953062057, Validation Loss: 0.10450750589370728
Epoch 296, Training Loss: 0.09882181882858276, Validation Loss: 0.10451026260852814
Epoch 297, Training Loss: 0.09913952648639679, Validation Loss: 0.10453206300735474
Epoch 298, Training Loss: 0.09455756098031998, Validation Loss: 0.10455222427845001
Epoch 299, Training Loss: 0.09257233142852783, Validation Loss: 0.10457422584295273
Epoch 300, Training Loss: 0.08850782364606857, Validation Loss: 0.10462764650583267
Epoch 301, Training Loss: 0.09897535294294357, Validation Loss: 0.10465305298566818
Epoch 302, Training Loss: 0.09359268099069595, Validation Loss: 0.1046881452202797
Epoch 303, Training Loss: 0.10079430043697357, Validation Loss: 0.10476046800613403
Epoch 304, Training Loss: 0.09393762797117233, Validation Loss: 0.10487077385187149
Epoch 305, Training Loss: 0.0916997492313385, Validation Loss: 0.10501104593276978
Epoch 306, Training Loss: 0.09682965278625488, Validation Loss: 0.1051555648446083
Epoch 307, Training Loss: 0.09581685066223145, Validation Loss: 0.10529758781194687
Epoch 308, Training Loss: 0.09376248717308044, Validation Loss: 0.10538334399461746
Epoch 309, Training Loss: 0.09664210677146912, Validation Loss: 0.10541903227567673
Epoch 310, Training Loss: 0.09392815828323364, Validation Loss: 0.10541446506977081
Epoch 311, Training Loss: 0.0965794026851654, Validation Loss: 0.10539799183607101
Epoch 312, Training Loss: 0.09524527192115784, Validation Loss: 0.10539612174034119
Epoch 313, Training Loss: 0.09345213323831558, Validation Loss: 0.10540322214365005
Epoch 314, Training Loss: 0.09636706858873367, Validation Loss: 0.10540857911109924
Epoch 315, Training Loss: 0.09225820004940033, Validation Loss: 0.10545182973146439
Epoch 316, Training Loss: 0.09553255140781403, Validation Loss: 0.10554631054401398
Epoch 317, Training Loss: 0.0928579717874527, Validation Loss: 0.10564693808555603
Epoch 318, Training Loss: 0.09987831115722656, Validation Loss: 0.10574402660131454
Epoch 319, Training Loss: 0.09012884646654129, Validation Loss: 0.10581463575363159
Epoch 320, Training Loss: 0.09263202548027039, Validation Loss: 0.10587955266237259
Epoch 321, Training Loss: 0.09757955372333527, Validation Loss: 0.1058959811925888
Epoch 322, Training Loss: 0.09613239765167236, Validation Loss: 0.10583898425102234
Epoch 323, Training Loss: 0.0951431542634964, Validation Loss: 0.10574620217084885
Epoch 324, Training Loss: 0.09337332099676132, Validation Loss: 0.10567665845155716
Epoch 325, Training Loss: 0.09983892738819122, Validation Loss: 0.10560281574726105
Epoch 326, Training Loss: 0.08946989476680756, Validation Loss: 0.10548368096351624
Epoch 327, Training Loss: 0.09906691312789917, Validation Loss: 0.10541393607854843
Epoch 328, Training Loss: 0.09523596614599228, Validation Loss: 0.10539282858371735
Epoch 329, Training Loss: 0.09654795378446579, Validation Loss: 0.1054261326789856
Epoch 330, Training Loss: 0.09368453919887543, Validation Loss: 0.10544648766517639
Epoch 331, Training Loss: 0.09331512451171875, Validation Loss: 0.10546329617500305
Epoch 332, Training Loss: 0.09079665690660477, Validation Loss: 0.10547001659870148
Epoch 333, Training Loss: 0.09411352872848511, Validation Loss: 0.10550528764724731
Epoch 334, Training Loss: 0.09553185105323792, Validation Loss: 0.10552483797073364
Epoch 335, Training Loss: 0.09794951975345612, Validation Loss: 0.10551616549491882
Epoch 336, Training Loss: 0.09508518129587173, Validation Loss: 0.10554356873035431
Epoch 337, Training Loss: 0.09398167580366135, Validation Loss: 0.10559990257024765
Epoch 338, Training Loss: 0.09299516677856445, Validation Loss: 0.10560233891010284
Epoch 339, Training Loss: 0.09525022655725479, Validation Loss: 0.10559526085853577
Epoch 340, Training Loss: 0.0976189523935318, Validation Loss: 0.10555470734834671
Epoch 341, Training Loss: 0.0936983972787857, Validation Loss: 0.10547564923763275
Epoch 342, Training Loss: 0.0984935313463211, Validation Loss: 0.10542751103639603
Epoch 343, Training Loss: 0.09279298037290573, Validation Loss: 0.1053476482629776
Epoch 344, Training Loss: 0.09194210916757584, Validation Loss: 0.10521822422742844
Epoch 345, Training Loss: 0.09389495104551315, Validation Loss: 0.10509388893842697
Epoch 346, Training Loss: 0.09512697905302048, Validation Loss: 0.10495258122682571
Epoch 347, Training Loss: 0.09508632123470306, Validation Loss: 0.10485993325710297
Epoch 348, Training Loss: 0.09476707875728607, Validation Loss: 0.10477259755134583
Epoch 349, Training Loss: 0.09673476219177246, Validation Loss: 0.1047201082110405
Epoch 350, Training Loss: 0.09696883708238602, Validation Loss: 0.10472232103347778
Epoch 351, Training Loss: 0.09379924833774567, Validation Loss: 0.10472096502780914
Epoch 352, Training Loss: 0.09619718790054321, Validation Loss: 0.10473229736089706
Epoch 353, Training Loss: 0.09581763297319412, Validation Loss: 0.10471045225858688
Epoch 354, Training Loss: 0.09600280970335007, Validation Loss: 0.10473524779081345
Epoch 355, Training Loss: 0.09249705821275711, Validation Loss: 0.10476604104042053
Epoch 356, Training Loss: 0.0913509801030159, Validation Loss: 0.10479818284511566
Epoch 357, Training Loss: 0.0963820070028305, Validation Loss: 0.10482028871774673
Epoch 358, Training Loss: 0.09820877015590668, Validation Loss: 0.10482972860336304
Epoch 359, Training Loss: 0.09631013870239258, Validation Loss: 0.10485167056322098
Epoch 360, Training Loss: 0.09092607349157333, Validation Loss: 0.10491464287042618
Epoch 361, Training Loss: 0.09586651623249054, Validation Loss: 0.10497080534696579
Epoch 362, Training Loss: 0.09971806406974792, Validation Loss: 0.10506507754325867
Epoch 363, Training Loss: 0.0930728018283844, Validation Loss: 0.10520979762077332
Epoch 364, Training Loss: 0.0940733328461647, Validation Loss: 0.10530213266611099
Epoch 365, Training Loss: 0.09624774754047394, Validation Loss: 0.10539107769727707
Epoch 366, Training Loss: 0.09334634244441986, Validation Loss: 0.10543642193078995
Epoch 367, Training Loss: 0.09366916120052338, Validation Loss: 0.10542506724596024
Epoch 368, Training Loss: 0.09383319318294525, Validation Loss: 0.10541854053735733
Epoch 369, Training Loss: 0.09574327617883682, Validation Loss: 0.10540025681257248
Epoch 370, Training Loss: 0.09485224634408951, Validation Loss: 0.10533593595027924
Epoch 371, Training Loss: 0.09400442242622375, Validation Loss: 0.10530983656644821
Epoch 372, Training Loss: 0.09586655348539352, Validation Loss: 0.10527211427688599
Epoch 373, Training Loss: 0.09526112675666809, Validation Loss: 0.10525872558355331
Epoch 374, Training Loss: 0.09260502457618713, Validation Loss: 0.10525478422641754
Epoch 375, Training Loss: 0.09133706986904144, Validation Loss: 0.10522329062223434
Epoch 376, Training Loss: 0.09104374796152115, Validation Loss: 0.10518179088830948
Epoch 377, Training Loss: 0.0999860092997551, Validation Loss: 0.10511988401412964
Epoch 378, Training Loss: 0.09179559350013733, Validation Loss: 0.1050528883934021
Epoch 379, Training Loss: 0.09437458962202072, Validation Loss: 0.10499268025159836
Epoch 380, Training Loss: 0.09085288643836975, Validation Loss: 0.104938805103302
Epoch 381, Training Loss: 0.09552869200706482, Validation Loss: 0.10485503822565079
Epoch 382, Training Loss: 0.09505389630794525, Validation Loss: 0.1047748252749443
Epoch 383, Training Loss: 0.09347006678581238, Validation Loss: 0.10473937541246414
Epoch 384, Training Loss: 0.08873283863067627, Validation Loss: 0.10466951876878738
Epoch 385, Training Loss: 0.0954020619392395, Validation Loss: 0.10462170839309692
Epoch 386, Training Loss: 0.09348110109567642, Validation Loss: 0.10459724813699722
Epoch 387, Training Loss: 0.09431476145982742, Validation Loss: 0.10456174612045288
Epoch 388, Training Loss: 0.09003248810768127, Validation Loss: 0.10451226681470871
Epoch 389, Training Loss: 0.09619608521461487, Validation Loss: 0.10450822860002518
Epoch 390, Training Loss: 0.0938635841012001, Validation Loss: 0.10451648384332657
Epoch 391, Training Loss: 0.09320495277643204, Validation Loss: 0.10455755144357681
Epoch 392, Training Loss: 0.0959063321352005, Validation Loss: 0.10459140688180923
Epoch 393, Training Loss: 0.09122824668884277, Validation Loss: 0.10463009029626846
Epoch 394, Training Loss: 0.09353888034820557, Validation Loss: 0.10472716391086578
Epoch 395, Training Loss: 0.094874806702137, Validation Loss: 0.10483554005622864
Epoch 396, Training Loss: 0.0950208231806755, Validation Loss: 0.10494256764650345
Epoch 397, Training Loss: 0.09554632008075714, Validation Loss: 0.10504717379808426
Epoch 398, Training Loss: 0.09696705639362335, Validation Loss: 0.10514617711305618
Epoch 399, Training Loss: 0.0922781452536583, Validation Loss: 0.10522844642400742
Epoch 400, Training Loss: 0.08899173885583878, Validation Loss: 0.10527240484952927
Epoch 401, Training Loss: 0.09526032954454422, Validation Loss: 0.10526756197214127
Epoch 402, Training Loss: 0.09383942931890488, Validation Loss: 0.10531178116798401
Epoch 403, Training Loss: 0.09282252192497253, Validation Loss: 0.1053156778216362
Epoch 404, Training Loss: 0.09401645511388779, Validation Loss: 0.10533920675516129
Epoch 405, Training Loss: 0.0911216139793396, Validation Loss: 0.10535666346549988
Epoch 406, Training Loss: 0.09509354084730148, Validation Loss: 0.10531748086214066
Epoch 407, Training Loss: 0.09527729451656342, Validation Loss: 0.10527948290109634
Epoch 408, Training Loss: 0.09168773889541626, Validation Loss: 0.10523659735918045
Epoch 409, Training Loss: 0.09501169621944427, Validation Loss: 0.10521995276212692
Epoch 410, Training Loss: 0.0910235047340393, Validation Loss: 0.1051715537905693
Epoch 411, Training Loss: 0.09304267168045044, Validation Loss: 0.10514617711305618
Epoch 412, Training Loss: 0.09439487010240555, Validation Loss: 0.10519257187843323
Epoch 413, Training Loss: 0.0974457636475563, Validation Loss: 0.10521162301301956
Epoch 414, Training Loss: 0.0974789634346962, Validation Loss: 0.10523202270269394
Epoch 415, Training Loss: 0.09508481621742249, Validation Loss: 0.10524500906467438
Epoch 416, Training Loss: 0.09298563003540039, Validation Loss: 0.1052342876791954
Epoch 417, Training Loss: 0.098126120865345, Validation Loss: 0.10525412857532501
Epoch 418, Training Loss: 0.09027688950300217, Validation Loss: 0.10525363683700562
Epoch 419, Training Loss: 0.09429196268320084, Validation Loss: 0.10522308945655823
Epoch 420, Training Loss: 0.094850555062294, Validation Loss: 0.10520781576633453
Epoch 421, Training Loss: 0.09012435376644135, Validation Loss: 0.10519426316022873
Epoch 422, Training Loss: 0.08835889399051666, Validation Loss: 0.10515011847019196
Epoch 423, Training Loss: 0.09394942969083786, Validation Loss: 0.10511273890733719
Epoch 424, Training Loss: 0.09009521454572678, Validation Loss: 0.10505230724811554
Epoch 425, Training Loss: 0.09325342625379562, Validation Loss: 0.10499868541955948
Epoch 426, Training Loss: 0.09958106279373169, Validation Loss: 0.10491670668125153
Epoch 427, Training Loss: 0.09400457888841629, Validation Loss: 0.10482817888259888
Epoch 428, Training Loss: 0.09452365338802338, Validation Loss: 0.10471663624048233
Epoch 429, Training Loss: 0.09425018727779388, Validation Loss: 0.10456831753253937
Epoch 430, Training Loss: 0.09335286170244217, Validation Loss: 0.10442580282688141
Epoch 431, Training Loss: 0.08941183239221573, Validation Loss: 0.10434780269861221
Epoch 432, Training Loss: 0.09351791441440582, Validation Loss: 0.10424982011318207
Epoch 433, Training Loss: 0.09251134842634201, Validation Loss: 0.10411888360977173
Epoch 434, Training Loss: 0.09098992496728897, Validation Loss: 0.10404562205076218
Epoch 435, Training Loss: 0.09535226225852966, Validation Loss: 0.10402236133813858
Epoch 436, Training Loss: 0.088286392390728, Validation Loss: 0.10403255373239517
Epoch 437, Training Loss: 0.09520910680294037, Validation Loss: 0.10410302132368088
Epoch 438, Training Loss: 0.09353077411651611, Validation Loss: 0.10416840016841888
Epoch 439, Training Loss: 0.09028811007738113, Validation Loss: 0.10420796275138855
Epoch 440, Training Loss: 0.09335850924253464, Validation Loss: 0.10424769669771194
Epoch 441, Training Loss: 0.09204822033643723, Validation Loss: 0.10430262982845306
Epoch 442, Training Loss: 0.09188754856586456, Validation Loss: 0.1043686717748642
Epoch 443, Training Loss: 0.09620156139135361, Validation Loss: 0.10443916916847229
Epoch 444, Training Loss: 0.09092595428228378, Validation Loss: 0.1044994443655014
Epoch 445, Training Loss: 0.09721642732620239, Validation Loss: 0.1045762225985527
Epoch 446, Training Loss: 0.09537079930305481, Validation Loss: 0.10465246438980103
Epoch 447, Training Loss: 0.09465694427490234, Validation Loss: 0.10472530871629715
Epoch 448, Training Loss: 0.09744635224342346, Validation Loss: 0.1048019528388977
Epoch 449, Training Loss: 0.09220079332590103, Validation Loss: 0.10480540245771408
Epoch 450, Training Loss: 0.09395474195480347, Validation Loss: 0.10487616807222366
Epoch 451, Training Loss: 0.08874001353979111, Validation Loss: 0.10493717342615128
Epoch 452, Training Loss: 0.09286737442016602, Validation Loss: 0.10498612374067307
Epoch 453, Training Loss: 0.09732094407081604, Validation Loss: 0.1050410121679306
Epoch 454, Training Loss: 0.09306873381137848, Validation Loss: 0.1051425114274025
Epoch 455, Training Loss: 0.0953570008277893, Validation Loss: 0.1052410826086998
Epoch 456, Training Loss: 0.09583258628845215, Validation Loss: 0.10525920987129211
Epoch 457, Training Loss: 0.09162647277116776, Validation Loss: 0.10520988702774048
Epoch 458, Training Loss: 0.09772497415542603, Validation Loss: 0.1051192507147789
Epoch 459, Training Loss: 0.09021634608507156, Validation Loss: 0.10500877350568771
Epoch 460, Training Loss: 0.09166216850280762, Validation Loss: 0.10489191114902496
Epoch 461, Training Loss: 0.08995229005813599, Validation Loss: 0.10481900721788406
Epoch 462, Training Loss: 0.09237287938594818, Validation Loss: 0.10467575490474701
Epoch 463, Training Loss: 0.09212969988584518, Validation Loss: 0.10457083582878113
Epoch 464, Training Loss: 0.09344761818647385, Validation Loss: 0.10444604605436325
Epoch 465, Training Loss: 0.09418658167123795, Validation Loss: 0.10432074218988419
Epoch 466, Training Loss: 0.0929514542222023, Validation Loss: 0.10418404638767242
Epoch 467, Training Loss: 0.08826667070388794, Validation Loss: 0.10402056574821472
Epoch 468, Training Loss: 0.09389641135931015, Validation Loss: 0.10388090461492538
Epoch 469, Training Loss: 0.09084875136613846, Validation Loss: 0.10373132675886154
Epoch 470, Training Loss: 0.09308083355426788, Validation Loss: 0.10359817743301392
Epoch 471, Training Loss: 0.09475162625312805, Validation Loss: 0.10352707654237747
Epoch 472, Training Loss: 0.09243658930063248, Validation Loss: 0.10349064320325851
Epoch 473, Training Loss: 0.09221257269382477, Validation Loss: 0.10348159074783325
Epoch 474, Training Loss: 0.09205963462591171, Validation Loss: 0.10348958522081375
Epoch 475, Training Loss: 0.08947679400444031, Validation Loss: 0.10346294194459915
Epoch 476, Training Loss: 0.09328579902648926, Validation Loss: 0.10345501452684402
Epoch 477, Training Loss: 0.09401807934045792, Validation Loss: 0.10352005064487457
Epoch 478, Training Loss: 0.09712371975183487, Validation Loss: 0.10358349233865738
Epoch 479, Training Loss: 0.0939677506685257, Validation Loss: 0.10370118170976639
Epoch 480, Training Loss: 0.09537767618894577, Validation Loss: 0.1038680300116539
Epoch 481, Training Loss: 0.09007775783538818, Validation Loss: 0.10404372960329056
Epoch 482, Training Loss: 0.09534221887588501, Validation Loss: 0.10423816740512848
Epoch 483, Training Loss: 0.09403452277183533, Validation Loss: 0.10441110283136368
Epoch 484, Training Loss: 0.09667066484689713, Validation Loss: 0.10461989045143127
Epoch 485, Training Loss: 0.0900368019938469, Validation Loss: 0.10475729405879974
Epoch 486, Training Loss: 0.09705165773630142, Validation Loss: 0.10493682324886322
Epoch 487, Training Loss: 0.08811024576425552, Validation Loss: 0.10503095388412476
Epoch 488, Training Loss: 0.0918334573507309, Validation Loss: 0.10508805513381958
Epoch 489, Training Loss: 0.08846798539161682, Validation Loss: 0.10506118834018707
Epoch 490, Training Loss: 0.09126404672861099, Validation Loss: 0.10503476113080978
Epoch 491, Training Loss: 0.09194077551364899, Validation Loss: 0.10502278059720993
Epoch 492, Training Loss: 0.09918490052223206, Validation Loss: 0.10507316142320633
Epoch 493, Training Loss: 0.0896332636475563, Validation Loss: 0.10509494692087173
Epoch 494, Training Loss: 0.09045230597257614, Validation Loss: 0.10507968068122864
Epoch 495, Training Loss: 0.09417278319597244, Validation Loss: 0.10506085306406021
Epoch 496, Training Loss: 0.09415871649980545, Validation Loss: 0.10507040470838547
Epoch 497, Training Loss: 0.09533331543207169, Validation Loss: 0.10506384819746017
Epoch 498, Training Loss: 0.08793260902166367, Validation Loss: 0.1050296500325203
Epoch 499, Training Loss: 0.09440567344427109, Validation Loss: 0.1049736887216568
Epoch 500, Training Loss: 0.09508607536554337, Validation Loss: 0.10491760075092316
