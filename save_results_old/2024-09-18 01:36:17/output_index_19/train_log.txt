Epoch 1, Training Loss: 0.18348903954029083, Validation Loss: 0.1846059411764145
Epoch 2, Training Loss: 0.1829795241355896, Validation Loss: 0.18416650593280792
Epoch 3, Training Loss: 0.18169407546520233, Validation Loss: 0.18372617661952972
Epoch 4, Training Loss: 0.18168435990810394, Validation Loss: 0.18328970670700073
Epoch 5, Training Loss: 0.1793789267539978, Validation Loss: 0.18285472691059113
Epoch 6, Training Loss: 0.1798088401556015, Validation Loss: 0.18241743743419647
Epoch 7, Training Loss: 0.1791107952594757, Validation Loss: 0.18197841942310333
Epoch 8, Training Loss: 0.178449347615242, Validation Loss: 0.18153776228427887
Epoch 9, Training Loss: 0.17910748720169067, Validation Loss: 0.18109732866287231
Epoch 10, Training Loss: 0.17825931310653687, Validation Loss: 0.18065956234931946
Epoch 11, Training Loss: 0.17822164297103882, Validation Loss: 0.1802244484424591
Epoch 12, Training Loss: 0.17635639011859894, Validation Loss: 0.17979465425014496
Epoch 13, Training Loss: 0.1775761842727661, Validation Loss: 0.1793690174818039
Epoch 14, Training Loss: 0.17581863701343536, Validation Loss: 0.17893917858600616
Epoch 15, Training Loss: 0.1751573383808136, Validation Loss: 0.1785116046667099
Epoch 16, Training Loss: 0.17475935816764832, Validation Loss: 0.17808593809604645
Epoch 17, Training Loss: 0.17381328344345093, Validation Loss: 0.17765608429908752
Epoch 18, Training Loss: 0.17223648726940155, Validation Loss: 0.17722167074680328
Epoch 19, Training Loss: 0.17199309170246124, Validation Loss: 0.17677955329418182
Epoch 20, Training Loss: 0.17303434014320374, Validation Loss: 0.17633889615535736
Epoch 21, Training Loss: 0.1726170778274536, Validation Loss: 0.17589424550533295
Epoch 22, Training Loss: 0.17260859906673431, Validation Loss: 0.17544442415237427
Epoch 23, Training Loss: 0.17020446062088013, Validation Loss: 0.17498698830604553
Epoch 24, Training Loss: 0.1703789234161377, Validation Loss: 0.17452454566955566
Epoch 25, Training Loss: 0.16853339970111847, Validation Loss: 0.17405307292938232
Epoch 26, Training Loss: 0.1681150496006012, Validation Loss: 0.17357280850410461
Epoch 27, Training Loss: 0.16844013333320618, Validation Loss: 0.17308375239372253
Epoch 28, Training Loss: 0.16793446242809296, Validation Loss: 0.17259107530117035
Epoch 29, Training Loss: 0.16731950640678406, Validation Loss: 0.17208844423294067
Epoch 30, Training Loss: 0.16605685651302338, Validation Loss: 0.1715736836194992
Epoch 31, Training Loss: 0.1652487963438034, Validation Loss: 0.17104612290859222
Epoch 32, Training Loss: 0.16294683516025543, Validation Loss: 0.1705024242401123
Epoch 33, Training Loss: 0.16485874354839325, Validation Loss: 0.16994629800319672
Epoch 34, Training Loss: 0.164723739027977, Validation Loss: 0.16937237977981567
Epoch 35, Training Loss: 0.16511814296245575, Validation Loss: 0.16877737641334534
Epoch 36, Training Loss: 0.16270290315151215, Validation Loss: 0.1681591421365738
Epoch 37, Training Loss: 0.1621255874633789, Validation Loss: 0.16751210391521454
Epoch 38, Training Loss: 0.16010890901088715, Validation Loss: 0.16684125363826752
Epoch 39, Training Loss: 0.15848053991794586, Validation Loss: 0.16614492237567902
Epoch 40, Training Loss: 0.1590488702058792, Validation Loss: 0.16541749238967896
Epoch 41, Training Loss: 0.1575135439634323, Validation Loss: 0.16465488076210022
Epoch 42, Training Loss: 0.1560416966676712, Validation Loss: 0.16384775936603546
Epoch 43, Training Loss: 0.1565680205821991, Validation Loss: 0.16297398507595062
Epoch 44, Training Loss: 0.15519608557224274, Validation Loss: 0.16203825175762177
Epoch 45, Training Loss: 0.15379564464092255, Validation Loss: 0.16104833781719208
Epoch 46, Training Loss: 0.1534292995929718, Validation Loss: 0.16000548005104065
Epoch 47, Training Loss: 0.14920265972614288, Validation Loss: 0.15888512134552002
Epoch 48, Training Loss: 0.14898675680160522, Validation Loss: 0.15766650438308716
Epoch 49, Training Loss: 0.14811918139457703, Validation Loss: 0.15635167062282562
Epoch 50, Training Loss: 0.1476890593767166, Validation Loss: 0.15495000779628754
Epoch 51, Training Loss: 0.14919771254062653, Validation Loss: 0.15347686409950256
Epoch 52, Training Loss: 0.1434037685394287, Validation Loss: 0.15191367268562317
Epoch 53, Training Loss: 0.13865910470485687, Validation Loss: 0.1502368301153183
Epoch 54, Training Loss: 0.14101286232471466, Validation Loss: 0.14844198524951935
Epoch 55, Training Loss: 0.13546597957611084, Validation Loss: 0.14649860560894012
Epoch 56, Training Loss: 0.1349492073059082, Validation Loss: 0.14444807171821594
Epoch 57, Training Loss: 0.13013772666454315, Validation Loss: 0.1422959417104721
Epoch 58, Training Loss: 0.131083145737648, Validation Loss: 0.14004038274288177
Epoch 59, Training Loss: 0.13251157104969025, Validation Loss: 0.13769666850566864
Epoch 60, Training Loss: 0.12368979305028915, Validation Loss: 0.13523566722869873
Epoch 61, Training Loss: 0.12673814594745636, Validation Loss: 0.13267144560813904
Epoch 62, Training Loss: 0.12294940650463104, Validation Loss: 0.13002729415893555
Epoch 63, Training Loss: 0.11954815685749054, Validation Loss: 0.12734799087047577
Epoch 64, Training Loss: 0.11781157553195953, Validation Loss: 0.12464023381471634
Epoch 65, Training Loss: 0.1176477000117302, Validation Loss: 0.12195634096860886
Epoch 66, Training Loss: 0.11179688572883606, Validation Loss: 0.11929871886968613
Epoch 67, Training Loss: 0.11257078498601913, Validation Loss: 0.11671945452690125
Epoch 68, Training Loss: 0.11233258992433548, Validation Loss: 0.11431578546762466
Epoch 69, Training Loss: 0.10891393572092056, Validation Loss: 0.11215652525424957
Epoch 70, Training Loss: 0.10894431173801422, Validation Loss: 0.11021275073289871
Epoch 71, Training Loss: 0.11373037099838257, Validation Loss: 0.10862813889980316
Epoch 72, Training Loss: 0.10824519395828247, Validation Loss: 0.10730037838220596
Epoch 73, Training Loss: 0.10860425233840942, Validation Loss: 0.10626355558633804
Epoch 74, Training Loss: 0.11094466596841812, Validation Loss: 0.10548732429742813
Epoch 75, Training Loss: 0.11279859393835068, Validation Loss: 0.10489685833454132
Epoch 76, Training Loss: 0.10986848175525665, Validation Loss: 0.10463479161262512
Epoch 77, Training Loss: 0.11960320174694061, Validation Loss: 0.10461943596601486
Epoch 78, Training Loss: 0.10773256421089172, Validation Loss: 0.10465656965970993
Epoch 79, Training Loss: 0.11034747958183289, Validation Loss: 0.10482024401426315
Epoch 80, Training Loss: 0.10871678590774536, Validation Loss: 0.10508033633232117
Epoch 81, Training Loss: 0.10978206992149353, Validation Loss: 0.10548397898674011
Epoch 82, Training Loss: 0.1081671193242073, Validation Loss: 0.10592278838157654
Epoch 83, Training Loss: 0.10455694794654846, Validation Loss: 0.10642706602811813
Epoch 84, Training Loss: 0.10802271217107773, Validation Loss: 0.10694020241498947
Epoch 85, Training Loss: 0.10466574877500534, Validation Loss: 0.10737870633602142
Epoch 86, Training Loss: 0.10712897032499313, Validation Loss: 0.10787388682365417
Epoch 87, Training Loss: 0.10254361480474472, Validation Loss: 0.10830029845237732
Epoch 88, Training Loss: 0.10650978982448578, Validation Loss: 0.10872674733400345
Epoch 89, Training Loss: 0.10682588815689087, Validation Loss: 0.109080471098423
Epoch 90, Training Loss: 0.10840035229921341, Validation Loss: 0.10943412035703659
Epoch 91, Training Loss: 0.11302326619625092, Validation Loss: 0.10981415212154388
Epoch 92, Training Loss: 0.10457669943571091, Validation Loss: 0.11009020358324051
Epoch 93, Training Loss: 0.1078825369477272, Validation Loss: 0.11028836667537689
Epoch 94, Training Loss: 0.10649602860212326, Validation Loss: 0.11041729897260666
Epoch 95, Training Loss: 0.10435579717159271, Validation Loss: 0.11042279750108719
Epoch 96, Training Loss: 0.10267681628465652, Validation Loss: 0.11033548414707184
Epoch 97, Training Loss: 0.10193612426519394, Validation Loss: 0.1101902648806572
Epoch 98, Training Loss: 0.10231385380029678, Validation Loss: 0.11002960056066513
Epoch 99, Training Loss: 0.1030319482088089, Validation Loss: 0.10984120517969131
Epoch 100, Training Loss: 0.10492156445980072, Validation Loss: 0.10968748480081558
Epoch 101, Training Loss: 0.10732170939445496, Validation Loss: 0.10942266881465912
Epoch 102, Training Loss: 0.0996057465672493, Validation Loss: 0.10914956778287888
Epoch 103, Training Loss: 0.09813925623893738, Validation Loss: 0.10885017365217209
Epoch 104, Training Loss: 0.09632045030593872, Validation Loss: 0.10846545547246933
Epoch 105, Training Loss: 0.10586343705654144, Validation Loss: 0.10814442485570908
Epoch 106, Training Loss: 0.10197032988071442, Validation Loss: 0.1078316941857338
Epoch 107, Training Loss: 0.10446184128522873, Validation Loss: 0.107594795525074
Epoch 108, Training Loss: 0.0973396897315979, Validation Loss: 0.10738562047481537
Epoch 109, Training Loss: 0.10190130025148392, Validation Loss: 0.10722249746322632
Epoch 110, Training Loss: 0.09869705885648727, Validation Loss: 0.1070510670542717
Epoch 111, Training Loss: 0.0985313430428505, Validation Loss: 0.1068616509437561
Epoch 112, Training Loss: 0.10491682589054108, Validation Loss: 0.1067088395357132
Epoch 113, Training Loss: 0.09836149215698242, Validation Loss: 0.10660675913095474
Epoch 114, Training Loss: 0.10656827688217163, Validation Loss: 0.10659370571374893
Epoch 115, Training Loss: 0.09625289589166641, Validation Loss: 0.1065700426697731
Epoch 116, Training Loss: 0.09713035821914673, Validation Loss: 0.10661298036575317
Epoch 117, Training Loss: 0.1020505279302597, Validation Loss: 0.10667938739061356
Epoch 118, Training Loss: 0.10054399818181992, Validation Loss: 0.10674536973237991
Epoch 119, Training Loss: 0.10026941448450089, Validation Loss: 0.10683884471654892
Epoch 120, Training Loss: 0.10314133018255234, Validation Loss: 0.10691066086292267
Epoch 121, Training Loss: 0.09768719226121902, Validation Loss: 0.10688319802284241
Epoch 122, Training Loss: 0.10157538205385208, Validation Loss: 0.10698504000902176
Epoch 123, Training Loss: 0.10065871477127075, Validation Loss: 0.10703983902931213
Epoch 124, Training Loss: 0.1025942862033844, Validation Loss: 0.10704562813043594
Epoch 125, Training Loss: 0.09796575456857681, Validation Loss: 0.1070069968700409
Epoch 126, Training Loss: 0.09637851268053055, Validation Loss: 0.10696721822023392
Epoch 127, Training Loss: 0.10159831494092941, Validation Loss: 0.10688145458698273
Epoch 128, Training Loss: 0.09683354198932648, Validation Loss: 0.10685241967439651
Epoch 129, Training Loss: 0.1015864908695221, Validation Loss: 0.1068035215139389
Epoch 130, Training Loss: 0.09769196063280106, Validation Loss: 0.10671968013048172
Epoch 131, Training Loss: 0.09552991390228271, Validation Loss: 0.10658980906009674
Epoch 132, Training Loss: 0.1013508215546608, Validation Loss: 0.10647275298833847
Epoch 133, Training Loss: 0.09356389194726944, Validation Loss: 0.10636097937822342
Epoch 134, Training Loss: 0.10230174660682678, Validation Loss: 0.10634361952543259
Epoch 135, Training Loss: 0.10485593229532242, Validation Loss: 0.10648901760578156
Epoch 136, Training Loss: 0.09797646105289459, Validation Loss: 0.1066603809595108
Epoch 137, Training Loss: 0.10012562572956085, Validation Loss: 0.10689979791641235
Epoch 138, Training Loss: 0.09466645121574402, Validation Loss: 0.10707046836614609
Epoch 139, Training Loss: 0.10056751221418381, Validation Loss: 0.10721597820520401
Epoch 140, Training Loss: 0.1005101278424263, Validation Loss: 0.10733591765165329
Epoch 141, Training Loss: 0.10177963227033615, Validation Loss: 0.10746679455041885
Epoch 142, Training Loss: 0.10105706751346588, Validation Loss: 0.10758785158395767
Epoch 143, Training Loss: 0.10062295198440552, Validation Loss: 0.1076904833316803
Epoch 144, Training Loss: 0.0983654111623764, Validation Loss: 0.10778829455375671
Epoch 145, Training Loss: 0.09534352272748947, Validation Loss: 0.10783559083938599
Epoch 146, Training Loss: 0.10191374272108078, Validation Loss: 0.10798969119787216
Epoch 147, Training Loss: 0.09667932242155075, Validation Loss: 0.10809806734323502
Epoch 148, Training Loss: 0.09981925040483475, Validation Loss: 0.10816257447004318
Epoch 149, Training Loss: 0.10017654299736023, Validation Loss: 0.10822409391403198
Epoch 150, Training Loss: 0.10356738418340683, Validation Loss: 0.10825873166322708
Epoch 151, Training Loss: 0.10234494507312775, Validation Loss: 0.1083509773015976
Epoch 152, Training Loss: 0.09933914244174957, Validation Loss: 0.10840297490358353
Epoch 153, Training Loss: 0.10227189213037491, Validation Loss: 0.10832975804805756
Epoch 154, Training Loss: 0.09983622282743454, Validation Loss: 0.10830089449882507
Epoch 155, Training Loss: 0.10051645338535309, Validation Loss: 0.10825399309396744
Epoch 156, Training Loss: 0.10076043754816055, Validation Loss: 0.10821796208620071
Epoch 157, Training Loss: 0.10281656682491302, Validation Loss: 0.1082334816455841
Epoch 158, Training Loss: 0.09428589791059494, Validation Loss: 0.10817115753889084
Epoch 159, Training Loss: 0.09753916412591934, Validation Loss: 0.1081095039844513
Epoch 160, Training Loss: 0.09853615611791611, Validation Loss: 0.10802429169416428
Epoch 161, Training Loss: 0.09551479667425156, Validation Loss: 0.1079743504524231
Epoch 162, Training Loss: 0.10181883722543716, Validation Loss: 0.10805955529212952
Epoch 163, Training Loss: 0.09394452720880508, Validation Loss: 0.10814069211483002
Epoch 164, Training Loss: 0.10380822420120239, Validation Loss: 0.10822410136461258
Epoch 165, Training Loss: 0.09506429731845856, Validation Loss: 0.10823672264814377
Epoch 166, Training Loss: 0.10514558851718903, Validation Loss: 0.10830206423997879
Epoch 167, Training Loss: 0.09823116660118103, Validation Loss: 0.10834310203790665
Epoch 168, Training Loss: 0.1003124862909317, Validation Loss: 0.1084330677986145
Epoch 169, Training Loss: 0.10045427829027176, Validation Loss: 0.10853677988052368
Epoch 170, Training Loss: 0.10047538578510284, Validation Loss: 0.10858400166034698
Epoch 171, Training Loss: 0.10082437843084335, Validation Loss: 0.1085924431681633
Epoch 172, Training Loss: 0.1009780690073967, Validation Loss: 0.10865234583616257
Epoch 173, Training Loss: 0.10066882520914078, Validation Loss: 0.1087283045053482
Epoch 174, Training Loss: 0.09886602312326431, Validation Loss: 0.10879939049482346
Epoch 175, Training Loss: 0.09623859822750092, Validation Loss: 0.10886246711015701
Epoch 176, Training Loss: 0.09756484627723694, Validation Loss: 0.10889773815870285
Epoch 177, Training Loss: 0.09357084333896637, Validation Loss: 0.10892291367053986
Epoch 178, Training Loss: 0.09912009537220001, Validation Loss: 0.1089235320687294
Epoch 179, Training Loss: 0.09603137522935867, Validation Loss: 0.1089039072394371
Epoch 180, Training Loss: 0.09674303978681564, Validation Loss: 0.108858622610569
Epoch 181, Training Loss: 0.1022716537117958, Validation Loss: 0.10890001803636551
Epoch 182, Training Loss: 0.10012931376695633, Validation Loss: 0.10889068990945816
Epoch 183, Training Loss: 0.0982707291841507, Validation Loss: 0.10881558060646057
Epoch 184, Training Loss: 0.09535399079322815, Validation Loss: 0.10874034464359283
Epoch 185, Training Loss: 0.10212277621030807, Validation Loss: 0.10872913897037506
Epoch 186, Training Loss: 0.09405983984470367, Validation Loss: 0.10869358479976654
Epoch 187, Training Loss: 0.1023612767457962, Validation Loss: 0.10858672857284546
Epoch 188, Training Loss: 0.0989493876695633, Validation Loss: 0.10842468589544296
Epoch 189, Training Loss: 0.10368846356868744, Validation Loss: 0.10834341496229172
Epoch 190, Training Loss: 0.09937470406293869, Validation Loss: 0.10823408514261246
Epoch 191, Training Loss: 0.09418339282274246, Validation Loss: 0.1081426814198494
Epoch 192, Training Loss: 0.10004303604364395, Validation Loss: 0.10797327011823654
Epoch 193, Training Loss: 0.1011766716837883, Validation Loss: 0.1078251376748085
Epoch 194, Training Loss: 0.09953632950782776, Validation Loss: 0.10767701268196106
Epoch 195, Training Loss: 0.09658875316381454, Validation Loss: 0.10754610598087311
Epoch 196, Training Loss: 0.09858524054288864, Validation Loss: 0.107400082051754
Epoch 197, Training Loss: 0.1003585234284401, Validation Loss: 0.1073467805981636
Epoch 198, Training Loss: 0.09812166541814804, Validation Loss: 0.10729003697633743
Epoch 199, Training Loss: 0.10113552957773209, Validation Loss: 0.10725865513086319
Epoch 200, Training Loss: 0.09840843826532364, Validation Loss: 0.10722135007381439
Epoch 201, Training Loss: 0.10055230557918549, Validation Loss: 0.10724052786827087
Epoch 202, Training Loss: 0.09619535505771637, Validation Loss: 0.10721733421087265
Epoch 203, Training Loss: 0.09439003467559814, Validation Loss: 0.10715221613645554
Epoch 204, Training Loss: 0.09135937690734863, Validation Loss: 0.10711309313774109
Epoch 205, Training Loss: 0.09767041355371475, Validation Loss: 0.10714417695999146
Epoch 206, Training Loss: 0.09264440834522247, Validation Loss: 0.10714761167764664
Epoch 207, Training Loss: 0.09704457968473434, Validation Loss: 0.10715744644403458
Epoch 208, Training Loss: 0.09299905598163605, Validation Loss: 0.10725665837526321
Epoch 209, Training Loss: 0.09466896206140518, Validation Loss: 0.10730545967817307
Epoch 210, Training Loss: 0.09644057601690292, Validation Loss: 0.10732284188270569
Epoch 211, Training Loss: 0.10028023272752762, Validation Loss: 0.10735829174518585
Epoch 212, Training Loss: 0.09560176730155945, Validation Loss: 0.10740507394075394
Epoch 213, Training Loss: 0.09701235592365265, Validation Loss: 0.10752031207084656
Epoch 214, Training Loss: 0.09265485405921936, Validation Loss: 0.10755143314599991
Epoch 215, Training Loss: 0.09440381079912186, Validation Loss: 0.10752708464860916
Epoch 216, Training Loss: 0.10058706998825073, Validation Loss: 0.10760296136140823
Epoch 217, Training Loss: 0.09778789430856705, Validation Loss: 0.10766488313674927
Epoch 218, Training Loss: 0.09740129113197327, Validation Loss: 0.10768653452396393
Epoch 219, Training Loss: 0.0943494588136673, Validation Loss: 0.10767162591218948
Epoch 220, Training Loss: 0.09687405824661255, Validation Loss: 0.10763850808143616
Epoch 221, Training Loss: 0.094114750623703, Validation Loss: 0.10757098346948624
Epoch 222, Training Loss: 0.0985790491104126, Validation Loss: 0.10752247273921967
Epoch 223, Training Loss: 0.09572603553533554, Validation Loss: 0.10744433850049973
Epoch 224, Training Loss: 0.09364227205514908, Validation Loss: 0.10730792582035065
Epoch 225, Training Loss: 0.09842656552791595, Validation Loss: 0.10721123963594437
Epoch 226, Training Loss: 0.09949292242527008, Validation Loss: 0.10714632272720337
Epoch 227, Training Loss: 0.09922681748867035, Validation Loss: 0.10709241777658463
Epoch 228, Training Loss: 0.09952890127897263, Validation Loss: 0.10702890902757645
Epoch 229, Training Loss: 0.10160945355892181, Validation Loss: 0.10701213032007217
Epoch 230, Training Loss: 0.09899497032165527, Validation Loss: 0.1069725900888443
Epoch 231, Training Loss: 0.09570598602294922, Validation Loss: 0.1069624274969101
Epoch 232, Training Loss: 0.09289287030696869, Validation Loss: 0.10694573819637299
Epoch 233, Training Loss: 0.09655395150184631, Validation Loss: 0.10687988251447678
Epoch 234, Training Loss: 0.09522601962089539, Validation Loss: 0.10684402287006378
Epoch 235, Training Loss: 0.0979514792561531, Validation Loss: 0.10680089890956879
Epoch 236, Training Loss: 0.09979332983493805, Validation Loss: 0.1068577840924263
Epoch 237, Training Loss: 0.09852520376443863, Validation Loss: 0.10695149749517441
Epoch 238, Training Loss: 0.09601318091154099, Validation Loss: 0.1070745512843132
Epoch 239, Training Loss: 0.09518606960773468, Validation Loss: 0.10720911622047424
Epoch 240, Training Loss: 0.09551944583654404, Validation Loss: 0.107277050614357
Epoch 241, Training Loss: 0.0924064964056015, Validation Loss: 0.10732574015855789
Epoch 242, Training Loss: 0.09960475564002991, Validation Loss: 0.10737298429012299
Epoch 243, Training Loss: 0.09706202149391174, Validation Loss: 0.10733114928007126
Epoch 244, Training Loss: 0.10118722170591354, Validation Loss: 0.1073821559548378
Epoch 245, Training Loss: 0.09509462863206863, Validation Loss: 0.10740722715854645
Epoch 246, Training Loss: 0.09485307335853577, Validation Loss: 0.10737206041812897
Epoch 247, Training Loss: 0.09464877098798752, Validation Loss: 0.10731814801692963
Epoch 248, Training Loss: 0.10226565599441528, Validation Loss: 0.1073378473520279
Epoch 249, Training Loss: 0.09515266865491867, Validation Loss: 0.1073729544878006
Epoch 250, Training Loss: 0.09728989750146866, Validation Loss: 0.10739602148532867
Epoch 251, Training Loss: 0.09670358896255493, Validation Loss: 0.10740549862384796
Epoch 252, Training Loss: 0.09790200740098953, Validation Loss: 0.10737381130456924
Epoch 253, Training Loss: 0.09596198797225952, Validation Loss: 0.10736197978258133
Epoch 254, Training Loss: 0.09519171714782715, Validation Loss: 0.10727070271968842
Epoch 255, Training Loss: 0.09341830760240555, Validation Loss: 0.10715349018573761
Epoch 256, Training Loss: 0.0986301600933075, Validation Loss: 0.10701437294483185
Epoch 257, Training Loss: 0.09368203580379486, Validation Loss: 0.10685659945011139
Epoch 258, Training Loss: 0.09538821130990982, Validation Loss: 0.10669849812984467
Epoch 259, Training Loss: 0.0952988862991333, Validation Loss: 0.10656828433275223
Epoch 260, Training Loss: 0.09790076315402985, Validation Loss: 0.10650668293237686
Epoch 261, Training Loss: 0.09907863289117813, Validation Loss: 0.10645631700754166
Epoch 262, Training Loss: 0.09502361714839935, Validation Loss: 0.10653187334537506
Epoch 263, Training Loss: 0.09444323927164078, Validation Loss: 0.10659955441951752
Epoch 264, Training Loss: 0.09664249420166016, Validation Loss: 0.10670842975378036
Epoch 265, Training Loss: 0.0983869731426239, Validation Loss: 0.10678869485855103
Epoch 266, Training Loss: 0.09721671044826508, Validation Loss: 0.10693128407001495
Epoch 267, Training Loss: 0.09513862431049347, Validation Loss: 0.10704851895570755
Epoch 268, Training Loss: 0.09768259525299072, Validation Loss: 0.10718036442995071
Epoch 269, Training Loss: 0.09498925507068634, Validation Loss: 0.10731860995292664
Epoch 270, Training Loss: 0.09382183104753494, Validation Loss: 0.10745760798454285
Epoch 271, Training Loss: 0.09044144302606583, Validation Loss: 0.10758049786090851
Epoch 272, Training Loss: 0.09230298548936844, Validation Loss: 0.107615165412426
Epoch 273, Training Loss: 0.0977766290307045, Validation Loss: 0.1075516790151596
Epoch 274, Training Loss: 0.09488945454359055, Validation Loss: 0.10744128376245499
Epoch 275, Training Loss: 0.09608906507492065, Validation Loss: 0.10730905085802078
Epoch 276, Training Loss: 0.094609335064888, Validation Loss: 0.10716840624809265
Epoch 277, Training Loss: 0.09735417366027832, Validation Loss: 0.10713650286197662
Epoch 278, Training Loss: 0.09696163237094879, Validation Loss: 0.10705863684415817
Epoch 279, Training Loss: 0.09551197290420532, Validation Loss: 0.10692144185304642
Epoch 280, Training Loss: 0.09359867870807648, Validation Loss: 0.1067759320139885
Epoch 281, Training Loss: 0.09088070690631866, Validation Loss: 0.10659733414649963
Epoch 282, Training Loss: 0.09627822786569595, Validation Loss: 0.10644087940454483
Epoch 283, Training Loss: 0.09606391191482544, Validation Loss: 0.10628111660480499
Epoch 284, Training Loss: 0.09576959908008575, Validation Loss: 0.106107696890831
Epoch 285, Training Loss: 0.09695179015398026, Validation Loss: 0.10591524839401245
Epoch 286, Training Loss: 0.09483634680509567, Validation Loss: 0.10575293004512787
Epoch 287, Training Loss: 0.09956393390893936, Validation Loss: 0.10556565970182419
Epoch 288, Training Loss: 0.09520120918750763, Validation Loss: 0.1054241880774498
Epoch 289, Training Loss: 0.09976298362016678, Validation Loss: 0.10539545863866806
Epoch 290, Training Loss: 0.09345029294490814, Validation Loss: 0.10539322346448898
Epoch 291, Training Loss: 0.09919828176498413, Validation Loss: 0.10552062094211578
Epoch 292, Training Loss: 0.09252288192510605, Validation Loss: 0.10569608956575394
Epoch 293, Training Loss: 0.09367237240076065, Validation Loss: 0.10580462962388992
Epoch 294, Training Loss: 0.09567153453826904, Validation Loss: 0.10593482851982117
Epoch 295, Training Loss: 0.09335989505052567, Validation Loss: 0.10602221637964249
Epoch 296, Training Loss: 0.09458480775356293, Validation Loss: 0.10613683611154556
Epoch 297, Training Loss: 0.09541748464107513, Validation Loss: 0.10624181479215622
Epoch 298, Training Loss: 0.09135518223047256, Validation Loss: 0.10634637624025345
Epoch 299, Training Loss: 0.09730060398578644, Validation Loss: 0.10647904127836227
Epoch 300, Training Loss: 0.09762286394834518, Validation Loss: 0.10659561306238174
Epoch 301, Training Loss: 0.09578356891870499, Validation Loss: 0.10663870722055435
Epoch 302, Training Loss: 0.09742271900177002, Validation Loss: 0.10670270770788193
Epoch 303, Training Loss: 0.09761592745780945, Validation Loss: 0.10673639923334122
Epoch 304, Training Loss: 0.09379342943429947, Validation Loss: 0.10675069689750671
Epoch 305, Training Loss: 0.09585316479206085, Validation Loss: 0.10675428062677383
Epoch 306, Training Loss: 0.09408054500818253, Validation Loss: 0.10671165585517883
Epoch 307, Training Loss: 0.09327813982963562, Validation Loss: 0.10661345720291138
Epoch 308, Training Loss: 0.09619321674108505, Validation Loss: 0.10654892772436142
Epoch 309, Training Loss: 0.0999646782875061, Validation Loss: 0.10646174103021622
Epoch 310, Training Loss: 0.09750054031610489, Validation Loss: 0.10643482953310013
Epoch 311, Training Loss: 0.09392663836479187, Validation Loss: 0.1063970997929573
Epoch 312, Training Loss: 0.09810443222522736, Validation Loss: 0.10634659975767136
Epoch 313, Training Loss: 0.09433319419622421, Validation Loss: 0.10635554045438766
Epoch 314, Training Loss: 0.09704983234405518, Validation Loss: 0.10632139444351196
Epoch 315, Training Loss: 0.09892046451568604, Validation Loss: 0.10632706433534622
Epoch 316, Training Loss: 0.09120204299688339, Validation Loss: 0.10628014802932739
Epoch 317, Training Loss: 0.09530839323997498, Validation Loss: 0.1062287762761116
Epoch 318, Training Loss: 0.09815452247858047, Validation Loss: 0.10618119686841965
Epoch 319, Training Loss: 0.09282734990119934, Validation Loss: 0.10617779195308685
Epoch 320, Training Loss: 0.09740283340215683, Validation Loss: 0.10624467581510544
Epoch 321, Training Loss: 0.09403251111507416, Validation Loss: 0.10625133663415909
Epoch 322, Training Loss: 0.09226451069116592, Validation Loss: 0.10619989782571793
Epoch 323, Training Loss: 0.09839886426925659, Validation Loss: 0.10616037994623184
Epoch 324, Training Loss: 0.0944480299949646, Validation Loss: 0.10608986765146255
Epoch 325, Training Loss: 0.09961508959531784, Validation Loss: 0.10604073852300644
Epoch 326, Training Loss: 0.09439904987812042, Validation Loss: 0.10594579577445984
Epoch 327, Training Loss: 0.09498617798089981, Validation Loss: 0.10592515766620636
Epoch 328, Training Loss: 0.09543358534574509, Validation Loss: 0.10591162741184235
Epoch 329, Training Loss: 0.09835828840732574, Validation Loss: 0.10591183602809906
Epoch 330, Training Loss: 0.09188050776720047, Validation Loss: 0.10591162741184235
Epoch 331, Training Loss: 0.09560428559780121, Validation Loss: 0.10588950663805008
Epoch 332, Training Loss: 0.09023785591125488, Validation Loss: 0.10583335906267166
Epoch 333, Training Loss: 0.09133205562829971, Validation Loss: 0.10578355938196182
Epoch 334, Training Loss: 0.09631511569023132, Validation Loss: 0.10574366897344589
Epoch 335, Training Loss: 0.09568264335393906, Validation Loss: 0.10572697222232819
Epoch 336, Training Loss: 0.09378137439489365, Validation Loss: 0.10580513626337051
Epoch 337, Training Loss: 0.09644702821969986, Validation Loss: 0.10588628053665161
Epoch 338, Training Loss: 0.09419718384742737, Validation Loss: 0.10596403479576111
Epoch 339, Training Loss: 0.09407839179039001, Validation Loss: 0.10603947192430496
Epoch 340, Training Loss: 0.09388253092765808, Validation Loss: 0.10615348070859909
Epoch 341, Training Loss: 0.09527134150266647, Validation Loss: 0.10623274743556976
Epoch 342, Training Loss: 0.095490001142025, Validation Loss: 0.10631405562162399
Epoch 343, Training Loss: 0.09223499894142151, Validation Loss: 0.10646139830350876
Epoch 344, Training Loss: 0.09432452917098999, Validation Loss: 0.10659614950418472
Epoch 345, Training Loss: 0.09497659653425217, Validation Loss: 0.1066688820719719
Epoch 346, Training Loss: 0.09373390674591064, Validation Loss: 0.10667242109775543
Epoch 347, Training Loss: 0.09751188009977341, Validation Loss: 0.10668328404426575
Epoch 348, Training Loss: 0.09109042584896088, Validation Loss: 0.10666528344154358
Epoch 349, Training Loss: 0.09303896874189377, Validation Loss: 0.10661002993583679
Epoch 350, Training Loss: 0.09645765274763107, Validation Loss: 0.10652881860733032
Epoch 351, Training Loss: 0.09184709936380386, Validation Loss: 0.10644998401403427
Epoch 352, Training Loss: 0.08895304054021835, Validation Loss: 0.10638108849525452
Epoch 353, Training Loss: 0.09216897934675217, Validation Loss: 0.1063445582985878
Epoch 354, Training Loss: 0.09250519424676895, Validation Loss: 0.10625436902046204
Epoch 355, Training Loss: 0.09267861396074295, Validation Loss: 0.10618072748184204
Epoch 356, Training Loss: 0.09390731155872345, Validation Loss: 0.1060807928442955
Epoch 357, Training Loss: 0.09237832576036453, Validation Loss: 0.10599900782108307
Epoch 358, Training Loss: 0.09475371241569519, Validation Loss: 0.10595645010471344
Epoch 359, Training Loss: 0.09261713922023773, Validation Loss: 0.10584816336631775
Epoch 360, Training Loss: 0.09639417380094528, Validation Loss: 0.10577482730150223
Epoch 361, Training Loss: 0.09404466301202774, Validation Loss: 0.10571066290140152
Epoch 362, Training Loss: 0.08858708292245865, Validation Loss: 0.10565151274204254
Epoch 363, Training Loss: 0.09407808631658554, Validation Loss: 0.1055980697274208
Epoch 364, Training Loss: 0.0932534858584404, Validation Loss: 0.10556124150753021
Epoch 365, Training Loss: 0.099528968334198, Validation Loss: 0.10559593141078949
Epoch 366, Training Loss: 0.09293816983699799, Validation Loss: 0.10561086237430573
Epoch 367, Training Loss: 0.0960785523056984, Validation Loss: 0.10563213378190994
Epoch 368, Training Loss: 0.09418069571256638, Validation Loss: 0.10562730580568314
Epoch 369, Training Loss: 0.08989138156175613, Validation Loss: 0.10562398284673691
Epoch 370, Training Loss: 0.09299333393573761, Validation Loss: 0.10559120029211044
Epoch 371, Training Loss: 0.09245722740888596, Validation Loss: 0.10556139796972275
Epoch 372, Training Loss: 0.09272614866495132, Validation Loss: 0.10552699863910675
Epoch 373, Training Loss: 0.0915520042181015, Validation Loss: 0.1054568886756897
Epoch 374, Training Loss: 0.09562072902917862, Validation Loss: 0.10547803342342377
Epoch 375, Training Loss: 0.09083008766174316, Validation Loss: 0.10547091066837311
Epoch 376, Training Loss: 0.09367301315069199, Validation Loss: 0.10546432435512543
Epoch 377, Training Loss: 0.0932551771402359, Validation Loss: 0.10549736768007278
Epoch 378, Training Loss: 0.09860018640756607, Validation Loss: 0.10558163374662399
Epoch 379, Training Loss: 0.09285549074411392, Validation Loss: 0.10566280782222748
Epoch 380, Training Loss: 0.09198102355003357, Validation Loss: 0.10576090961694717
Epoch 381, Training Loss: 0.09421054273843765, Validation Loss: 0.10584093630313873
Epoch 382, Training Loss: 0.09335941821336746, Validation Loss: 0.10588492453098297
Epoch 383, Training Loss: 0.09494327008724213, Validation Loss: 0.1058933287858963
Epoch 384, Training Loss: 0.09276403486728668, Validation Loss: 0.10591132938861847
Epoch 385, Training Loss: 0.08842414617538452, Validation Loss: 0.10588349401950836
Epoch 386, Training Loss: 0.09439301490783691, Validation Loss: 0.1058712750673294
Epoch 387, Training Loss: 0.0934092327952385, Validation Loss: 0.1058541014790535
Epoch 388, Training Loss: 0.09174259006977081, Validation Loss: 0.10581900924444199
Epoch 389, Training Loss: 0.09542575478553772, Validation Loss: 0.10572252422571182
Epoch 390, Training Loss: 0.09805666655302048, Validation Loss: 0.10569987446069717
Epoch 391, Training Loss: 0.09574872255325317, Validation Loss: 0.10569191724061966
Epoch 392, Training Loss: 0.0938836857676506, Validation Loss: 0.10563968122005463
Epoch 393, Training Loss: 0.09596224129199982, Validation Loss: 0.10559118539094925
Epoch 394, Training Loss: 0.09533132612705231, Validation Loss: 0.10550270229578018
Epoch 395, Training Loss: 0.09557634592056274, Validation Loss: 0.10547883808612823
Epoch 396, Training Loss: 0.09356383234262466, Validation Loss: 0.10545358806848526
Epoch 397, Training Loss: 0.094049371778965, Validation Loss: 0.10544656217098236
Epoch 398, Training Loss: 0.09228943288326263, Validation Loss: 0.1054476648569107
Epoch 399, Training Loss: 0.0929969847202301, Validation Loss: 0.10545618832111359
Epoch 400, Training Loss: 0.09332763403654099, Validation Loss: 0.10545848309993744
Epoch 401, Training Loss: 0.09330597519874573, Validation Loss: 0.10541512817144394
Epoch 402, Training Loss: 0.09286914020776749, Validation Loss: 0.1054001897573471
Epoch 403, Training Loss: 0.09574883431196213, Validation Loss: 0.10539857298135757
Epoch 404, Training Loss: 0.09575961530208588, Validation Loss: 0.10542917996644974
Epoch 405, Training Loss: 0.09426513314247131, Validation Loss: 0.1054539903998375
Epoch 406, Training Loss: 0.0889890193939209, Validation Loss: 0.10546576231718063
Epoch 407, Training Loss: 0.09387025982141495, Validation Loss: 0.10545197129249573
Epoch 408, Training Loss: 0.09061234444379807, Validation Loss: 0.10543126612901688
Epoch 409, Training Loss: 0.09589266777038574, Validation Loss: 0.105434350669384
Epoch 410, Training Loss: 0.09614862501621246, Validation Loss: 0.10547317564487457
Epoch 411, Training Loss: 0.0924629494547844, Validation Loss: 0.10553549230098724
Epoch 412, Training Loss: 0.09604042023420334, Validation Loss: 0.10564006865024567
Epoch 413, Training Loss: 0.09149054437875748, Validation Loss: 0.10568287968635559
Epoch 414, Training Loss: 0.09291253983974457, Validation Loss: 0.105664923787117
Epoch 415, Training Loss: 0.09332042932510376, Validation Loss: 0.10561051219701767
Epoch 416, Training Loss: 0.09545466303825378, Validation Loss: 0.10556554049253464
Epoch 417, Training Loss: 0.09429723024368286, Validation Loss: 0.1055237203836441
Epoch 418, Training Loss: 0.09620010107755661, Validation Loss: 0.10545986145734787
Epoch 419, Training Loss: 0.09447497874498367, Validation Loss: 0.10547146946191788
Epoch 420, Training Loss: 0.09462600946426392, Validation Loss: 0.10549743473529816
Epoch 421, Training Loss: 0.09137196838855743, Validation Loss: 0.10551108419895172
Epoch 422, Training Loss: 0.09475783258676529, Validation Loss: 0.10554419457912445
Epoch 423, Training Loss: 0.09564526379108429, Validation Loss: 0.10558415949344635
Epoch 424, Training Loss: 0.09325653314590454, Validation Loss: 0.1056223064661026
Epoch 425, Training Loss: 0.09554669260978699, Validation Loss: 0.10564905405044556
Epoch 426, Training Loss: 0.09301312267780304, Validation Loss: 0.10567960888147354
Epoch 427, Training Loss: 0.09111393988132477, Validation Loss: 0.10571426898241043
Epoch 428, Training Loss: 0.09710005670785904, Validation Loss: 0.1057567298412323
Epoch 429, Training Loss: 0.09293185919523239, Validation Loss: 0.10577300935983658
Epoch 430, Training Loss: 0.09554234892129898, Validation Loss: 0.10578017681837082
Epoch 431, Training Loss: 0.08574656397104263, Validation Loss: 0.10570414364337921
Epoch 432, Training Loss: 0.09541985392570496, Validation Loss: 0.1055905893445015
Epoch 433, Training Loss: 0.09723362326622009, Validation Loss: 0.10548491030931473
Epoch 434, Training Loss: 0.0933433473110199, Validation Loss: 0.10536817461252213
Epoch 435, Training Loss: 0.09336156398057938, Validation Loss: 0.10524038225412369
Epoch 436, Training Loss: 0.09041966497898102, Validation Loss: 0.10508861392736435
Epoch 437, Training Loss: 0.09349451959133148, Validation Loss: 0.10496494919061661
Epoch 438, Training Loss: 0.09390997886657715, Validation Loss: 0.10488266497850418
Epoch 439, Training Loss: 0.09459373354911804, Validation Loss: 0.10483518242835999
Epoch 440, Training Loss: 0.09408885985612869, Validation Loss: 0.10476142168045044
Epoch 441, Training Loss: 0.0936354547739029, Validation Loss: 0.10470455884933472
Epoch 442, Training Loss: 0.09307213127613068, Validation Loss: 0.10469544678926468
Epoch 443, Training Loss: 0.09281450510025024, Validation Loss: 0.10472360253334045
Epoch 444, Training Loss: 0.09221445024013519, Validation Loss: 0.10470496863126755
Epoch 445, Training Loss: 0.09586460888385773, Validation Loss: 0.10464625805616379
Epoch 446, Training Loss: 0.0939013659954071, Validation Loss: 0.10457012057304382
Epoch 447, Training Loss: 0.09405862540006638, Validation Loss: 0.104560986161232
Epoch 448, Training Loss: 0.08894969522953033, Validation Loss: 0.1045466735959053
Epoch 449, Training Loss: 0.09531227499246597, Validation Loss: 0.10454060137271881
Epoch 450, Training Loss: 0.09430469572544098, Validation Loss: 0.10460898280143738
Epoch 451, Training Loss: 0.09278853237628937, Validation Loss: 0.10465507954359055
Epoch 452, Training Loss: 0.09475396573543549, Validation Loss: 0.10470983386039734
Epoch 453, Training Loss: 0.08870285749435425, Validation Loss: 0.1047583743929863
Epoch 454, Training Loss: 0.09411755204200745, Validation Loss: 0.1047944501042366
Epoch 455, Training Loss: 0.09266899526119232, Validation Loss: 0.10484426468610764
Epoch 456, Training Loss: 0.09239056706428528, Validation Loss: 0.1048501655459404
Epoch 457, Training Loss: 0.09145254641771317, Validation Loss: 0.10486752539873123
Epoch 458, Training Loss: 0.0931267961859703, Validation Loss: 0.10488703101873398
Epoch 459, Training Loss: 0.09554731100797653, Validation Loss: 0.10499519854784012
Epoch 460, Training Loss: 0.09344511479139328, Validation Loss: 0.10508673638105392
Epoch 461, Training Loss: 0.09428039938211441, Validation Loss: 0.10509838163852692
Epoch 462, Training Loss: 0.09491870552301407, Validation Loss: 0.10509199649095535
Epoch 463, Training Loss: 0.09677249193191528, Validation Loss: 0.10506969690322876
Epoch 464, Training Loss: 0.09627503901720047, Validation Loss: 0.10513214021921158
Epoch 465, Training Loss: 0.092180036008358, Validation Loss: 0.10519015043973923
Epoch 466, Training Loss: 0.09199897199869156, Validation Loss: 0.10526488721370697
Epoch 467, Training Loss: 0.09521584957838058, Validation Loss: 0.10533065348863602
Epoch 468, Training Loss: 0.09059307724237442, Validation Loss: 0.10541316866874695
Epoch 469, Training Loss: 0.09388208389282227, Validation Loss: 0.10542789846658707
Epoch 470, Training Loss: 0.0952099859714508, Validation Loss: 0.10543466359376907
Epoch 471, Training Loss: 0.0945986807346344, Validation Loss: 0.1054086908698082
Epoch 472, Training Loss: 0.09306561201810837, Validation Loss: 0.10541370511054993
Epoch 473, Training Loss: 0.09295942634344101, Validation Loss: 0.10541648417711258
Epoch 474, Training Loss: 0.0918099582195282, Validation Loss: 0.1053638607263565
Epoch 475, Training Loss: 0.09283086657524109, Validation Loss: 0.10524379462003708
Epoch 476, Training Loss: 0.09088074415922165, Validation Loss: 0.10512194782495499
Epoch 477, Training Loss: 0.09635084122419357, Validation Loss: 0.10498224943876266
Epoch 478, Training Loss: 0.09156445413827896, Validation Loss: 0.10485997796058655
Epoch 479, Training Loss: 0.09382428228855133, Validation Loss: 0.10473662614822388
Epoch 480, Training Loss: 0.08861998468637466, Validation Loss: 0.10463208705186844
Epoch 481, Training Loss: 0.0914846658706665, Validation Loss: 0.10453285276889801
Epoch 482, Training Loss: 0.09407244622707367, Validation Loss: 0.10445521026849747
Epoch 483, Training Loss: 0.09069424867630005, Validation Loss: 0.10436214506626129
Epoch 484, Training Loss: 0.09287726134061813, Validation Loss: 0.10424023866653442
Epoch 485, Training Loss: 0.09389638155698776, Validation Loss: 0.10413751751184464
Epoch 486, Training Loss: 0.09070765972137451, Validation Loss: 0.10407446324825287
Epoch 487, Training Loss: 0.09342973679304123, Validation Loss: 0.10403350740671158
Epoch 488, Training Loss: 0.09760064631700516, Validation Loss: 0.10400721430778503
Epoch 489, Training Loss: 0.09040359407663345, Validation Loss: 0.10396678745746613
Epoch 490, Training Loss: 0.09234777837991714, Validation Loss: 0.10392778366804123
Epoch 491, Training Loss: 0.09746306389570236, Validation Loss: 0.1039527952671051
Epoch 492, Training Loss: 0.08988595008850098, Validation Loss: 0.10396217554807663
Epoch 493, Training Loss: 0.09195569902658463, Validation Loss: 0.10393733531236649
Epoch 494, Training Loss: 0.08952976763248444, Validation Loss: 0.10391397774219513
Epoch 495, Training Loss: 0.09227211028337479, Validation Loss: 0.10392660647630692
Epoch 496, Training Loss: 0.09119049459695816, Validation Loss: 0.1039571613073349
Epoch 497, Training Loss: 0.0912976861000061, Validation Loss: 0.10399512201547623
Epoch 498, Training Loss: 0.0948752909898758, Validation Loss: 0.10406846553087234
Epoch 499, Training Loss: 0.0906197726726532, Validation Loss: 0.10411956906318665
Epoch 500, Training Loss: 0.08866095542907715, Validation Loss: 0.10421120375394821
