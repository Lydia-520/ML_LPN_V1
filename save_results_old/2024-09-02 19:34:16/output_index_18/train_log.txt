Epoch 1, Training Loss: 0.47257453203201294, Validation Loss: 0.4713493585586548
Epoch 2, Training Loss: 0.4713493585586548, Validation Loss: 0.47013816237449646
Epoch 3, Training Loss: 0.47013819217681885, Validation Loss: 0.46894192695617676
Epoch 4, Training Loss: 0.46894192695617676, Validation Loss: 0.46777161955833435
Epoch 5, Training Loss: 0.46777161955833435, Validation Loss: 0.46661967039108276
Epoch 6, Training Loss: 0.46661967039108276, Validation Loss: 0.4654756486415863
Epoch 7, Training Loss: 0.4654756784439087, Validation Loss: 0.46434253454208374
Epoch 8, Training Loss: 0.46434250473976135, Validation Loss: 0.463207483291626
Epoch 9, Training Loss: 0.463207483291626, Validation Loss: 0.4620988070964813
Epoch 10, Training Loss: 0.4620988070964813, Validation Loss: 0.46099841594696045
Epoch 11, Training Loss: 0.46099841594696045, Validation Loss: 0.45991185307502747
Epoch 12, Training Loss: 0.45991188287734985, Validation Loss: 0.45882871747016907
Epoch 13, Training Loss: 0.4588286876678467, Validation Loss: 0.4577195644378662
Epoch 14, Training Loss: 0.4577195346355438, Validation Loss: 0.45657798647880554
Epoch 15, Training Loss: 0.4565780460834503, Validation Loss: 0.45542699098587036
Epoch 16, Training Loss: 0.45542699098587036, Validation Loss: 0.45427003502845764
Epoch 17, Training Loss: 0.4542700946331024, Validation Loss: 0.4531104862689972
Epoch 18, Training Loss: 0.4531104862689972, Validation Loss: 0.45191964507102966
Epoch 19, Training Loss: 0.45191964507102966, Validation Loss: 0.45067888498306274
Epoch 20, Training Loss: 0.45067885518074036, Validation Loss: 0.449398934841156
Epoch 21, Training Loss: 0.449398934841156, Validation Loss: 0.44807156920433044
Epoch 22, Training Loss: 0.44807156920433044, Validation Loss: 0.4467358887195587
Epoch 23, Training Loss: 0.44673582911491394, Validation Loss: 0.44537097215652466
Epoch 24, Training Loss: 0.44537097215652466, Validation Loss: 0.44395044445991516
Epoch 25, Training Loss: 0.44395044445991516, Validation Loss: 0.4424850046634674
Epoch 26, Training Loss: 0.4424850642681122, Validation Loss: 0.44096294045448303
Epoch 27, Training Loss: 0.44096294045448303, Validation Loss: 0.4393746554851532
Epoch 28, Training Loss: 0.4393746554851532, Validation Loss: 0.43770238757133484
Epoch 29, Training Loss: 0.43770232796669006, Validation Loss: 0.4359199106693268
Epoch 30, Training Loss: 0.4359199106693268, Validation Loss: 0.4340226948261261
Epoch 31, Training Loss: 0.4340226948261261, Validation Loss: 0.43207627534866333
Epoch 32, Training Loss: 0.4320763349533081, Validation Loss: 0.43012839555740356
Epoch 33, Training Loss: 0.43012839555740356, Validation Loss: 0.42808377742767334
Epoch 34, Training Loss: 0.42808377742767334, Validation Loss: 0.4259468615055084
Epoch 35, Training Loss: 0.4259468615055084, Validation Loss: 0.42373189330101013
Epoch 36, Training Loss: 0.4237319231033325, Validation Loss: 0.4213704466819763
Epoch 37, Training Loss: 0.4213704466819763, Validation Loss: 0.4188348948955536
Epoch 38, Training Loss: 0.4188348948955536, Validation Loss: 0.41618677973747253
Epoch 39, Training Loss: 0.4161868393421173, Validation Loss: 0.4133969247341156
Epoch 40, Training Loss: 0.413396954536438, Validation Loss: 0.4104230999946594
Epoch 41, Training Loss: 0.4104230999946594, Validation Loss: 0.40726739168167114
Epoch 42, Training Loss: 0.4072674512863159, Validation Loss: 0.40389326214790344
Epoch 43, Training Loss: 0.40389326214790344, Validation Loss: 0.4002796411514282
Epoch 44, Training Loss: 0.4002796411514282, Validation Loss: 0.3963749408721924
Epoch 45, Training Loss: 0.39637497067451477, Validation Loss: 0.39213505387306213
Epoch 46, Training Loss: 0.39213505387306213, Validation Loss: 0.387542724609375
Epoch 47, Training Loss: 0.3875426948070526, Validation Loss: 0.38260629773139954
Epoch 48, Training Loss: 0.38260629773139954, Validation Loss: 0.3773021101951599
Epoch 49, Training Loss: 0.3773021101951599, Validation Loss: 0.371624231338501
Epoch 50, Training Loss: 0.371624231338501, Validation Loss: 0.3655245304107666
Epoch 51, Training Loss: 0.3655245304107666, Validation Loss: 0.35895171761512756
Epoch 52, Training Loss: 0.3589516878128052, Validation Loss: 0.3519013226032257
Epoch 53, Training Loss: 0.3519013524055481, Validation Loss: 0.34431129693984985
Epoch 54, Training Loss: 0.34431132674217224, Validation Loss: 0.3362210690975189
Epoch 55, Training Loss: 0.3362210690975189, Validation Loss: 0.3276699185371399
Epoch 56, Training Loss: 0.3276699185371399, Validation Loss: 0.31862568855285645
Epoch 57, Training Loss: 0.31862571835517883, Validation Loss: 0.309041291475296
Epoch 58, Training Loss: 0.309041291475296, Validation Loss: 0.29895275831222534
Epoch 59, Training Loss: 0.29895278811454773, Validation Loss: 0.28839269280433655
Epoch 60, Training Loss: 0.28839269280433655, Validation Loss: 0.277361661195755
Epoch 61, Training Loss: 0.277361661195755, Validation Loss: 0.26592352986335754
Epoch 62, Training Loss: 0.26592350006103516, Validation Loss: 0.25408291816711426
Epoch 63, Training Loss: 0.25408288836479187, Validation Loss: 0.24193228781223297
Epoch 64, Training Loss: 0.24193227291107178, Validation Loss: 0.22961445152759552
Epoch 65, Training Loss: 0.22961445152759552, Validation Loss: 0.21720482409000397
Epoch 66, Training Loss: 0.21720479428768158, Validation Loss: 0.20483726263046265
Epoch 67, Training Loss: 0.20483729243278503, Validation Loss: 0.19267362356185913
Epoch 68, Training Loss: 0.19267362356185913, Validation Loss: 0.1809139996767044
Epoch 69, Training Loss: 0.1809139996767044, Validation Loss: 0.16958583891391754
Epoch 70, Training Loss: 0.16958583891391754, Validation Loss: 0.1587812751531601
Epoch 71, Training Loss: 0.1587812900543213, Validation Loss: 0.14859746396541595
Epoch 72, Training Loss: 0.14859747886657715, Validation Loss: 0.13903088867664337
Epoch 73, Training Loss: 0.13903090357780457, Validation Loss: 0.13000449538230896
Epoch 74, Training Loss: 0.13000448048114777, Validation Loss: 0.12146024405956268
Epoch 75, Training Loss: 0.12146024405956268, Validation Loss: 0.11328347027301788
Epoch 76, Training Loss: 0.11328347027301788, Validation Loss: 0.10537949949502945
Epoch 77, Training Loss: 0.10537949204444885, Validation Loss: 0.09763028472661972
Epoch 78, Training Loss: 0.09763029217720032, Validation Loss: 0.08999349176883698
Epoch 79, Training Loss: 0.08999349921941757, Validation Loss: 0.08249655365943909
Epoch 80, Training Loss: 0.08249654620885849, Validation Loss: 0.07510478794574738
Epoch 81, Training Loss: 0.07510478049516678, Validation Loss: 0.06779207289218903
Epoch 82, Training Loss: 0.06779207289218903, Validation Loss: 0.060798898339271545
Epoch 83, Training Loss: 0.06079889461398125, Validation Loss: 0.05432153865695
Epoch 84, Training Loss: 0.05432153865695, Validation Loss: 0.048229873180389404
Epoch 85, Training Loss: 0.048229873180389404, Validation Loss: 0.04273286089301109
Epoch 86, Training Loss: 0.042732853442430496, Validation Loss: 0.037907928228378296
Epoch 87, Training Loss: 0.037907931953668594, Validation Loss: 0.033549826592206955
Epoch 88, Training Loss: 0.03354983404278755, Validation Loss: 0.029656263068318367
Epoch 89, Training Loss: 0.02965625934302807, Validation Loss: 0.026210390031337738
Epoch 90, Training Loss: 0.026210391893982887, Validation Loss: 0.023242823779582977
Epoch 91, Training Loss: 0.023242823779582977, Validation Loss: 0.020706314593553543
Epoch 92, Training Loss: 0.020706316456198692, Validation Loss: 0.018479760736227036
Epoch 93, Training Loss: 0.01847975142300129, Validation Loss: 0.016498589888215065
Epoch 94, Training Loss: 0.016498584300279617, Validation Loss: 0.014728189446032047
Epoch 95, Training Loss: 0.014728189446032047, Validation Loss: 0.013165337033569813
Epoch 96, Training Loss: 0.013165338896214962, Validation Loss: 0.011785074137151241
Epoch 97, Training Loss: 0.011785074137151241, Validation Loss: 0.010529307648539543
Epoch 98, Training Loss: 0.01052930485457182, Validation Loss: 0.009382905438542366
Epoch 99, Training Loss: 0.009382910095155239, Validation Loss: 0.008320659399032593
Epoch 100, Training Loss: 0.008320661261677742, Validation Loss: 0.007357193157076836
Epoch 101, Training Loss: 0.007357190828770399, Validation Loss: 0.006469688378274441
Epoch 102, Training Loss: 0.00646969024091959, Validation Loss: 0.005669912323355675
Epoch 103, Training Loss: 0.0056699104607105255, Validation Loss: 0.004949002526700497
Epoch 104, Training Loss: 0.004949003458023071, Validation Loss: 0.004289968870580196
Epoch 105, Training Loss: 0.004289969801902771, Validation Loss: 0.003692065831273794
Epoch 106, Training Loss: 0.0036920648999512196, Validation Loss: 0.003144670045003295
Epoch 107, Training Loss: 0.003144672140479088, Validation Loss: 0.0026545082218945026
Epoch 108, Training Loss: 0.002654507290571928, Validation Loss: 0.0022239508107304573
Epoch 109, Training Loss: 0.002223949646577239, Validation Loss: 0.0018456581747159362
Epoch 110, Training Loss: 0.0018456581747159362, Validation Loss: 0.0015212208963930607
Epoch 111, Training Loss: 0.001521220081485808, Validation Loss: 0.001248450018465519
Epoch 112, Training Loss: 0.0012484502512961626, Validation Loss: 0.0010248692706227303
Epoch 113, Training Loss: 0.0010248690377920866, Validation Loss: 0.0008458267548121512
Epoch 114, Training Loss: 0.0008458270458504558, Validation Loss: 0.0007056667236611247
Epoch 115, Training Loss: 0.0007056675385683775, Validation Loss: 0.0005982156144455075
Epoch 116, Training Loss: 0.0005982163711450994, Validation Loss: 0.0005170597578398883
Epoch 117, Training Loss: 0.0005170584190636873, Validation Loss: 0.00045605789637193084
Epoch 118, Training Loss: 0.0004560591478366405, Validation Loss: 0.00040963050560094416
Epoch 119, Training Loss: 0.0004096300108358264, Validation Loss: 0.00037333305226638913
Epoch 120, Training Loss: 0.00037333223735913634, Validation Loss: 0.0003438546264078468
Epoch 121, Training Loss: 0.00034385520848445594, Validation Loss: 0.0003186892718076706
Epoch 122, Training Loss: 0.0003186890680808574, Validation Loss: 0.00029622315196320415
Epoch 123, Training Loss: 0.00029622326837852597, Validation Loss: 0.00027574479463510215
Epoch 124, Training Loss: 0.0002757445618044585, Validation Loss: 0.0002571185177657753
Epoch 125, Training Loss: 0.0002571187214925885, Validation Loss: 0.00024027089239098132
Epoch 126, Training Loss: 0.00024027109611779451, Validation Loss: 0.00022522405197378248
Epoch 127, Training Loss: 0.00022522434301208705, Validation Loss: 0.0002119295095326379
Epoch 128, Training Loss: 0.00021192958229221404, Validation Loss: 0.00020024528203066438
Epoch 129, Training Loss: 0.00020024526747874916, Validation Loss: 0.00018978628213517368
Epoch 130, Training Loss: 0.00018978625303134322, Validation Loss: 0.00018016592366620898
Epoch 131, Training Loss: 0.00018016515241470188, Validation Loss: 0.00017099322576541454
Epoch 132, Training Loss: 0.0001709934149403125, Validation Loss: 0.00016148753638844937
Epoch 133, Training Loss: 0.00016148733266163617, Validation Loss: 0.00015186847303994
Epoch 134, Training Loss: 0.00015186819655355066, Validation Loss: 0.00014207135245669633
Epoch 135, Training Loss: 0.0001420713815605268, Validation Loss: 0.0001319902075920254
Epoch 136, Training Loss: 0.00013198971282690763, Validation Loss: 0.00012174937000963837
Epoch 137, Training Loss: 0.00012174922449048609, Validation Loss: 0.00011148464545840397
Epoch 138, Training Loss: 0.00011148465273436159, Validation Loss: 0.00010132743773283437
Epoch 139, Training Loss: 0.00010132743773283437, Validation Loss: 9.142752969637513e-05
Epoch 140, Training Loss: 9.142760245595127e-05, Validation Loss: 8.19066190160811e-05
Epoch 141, Training Loss: 8.190643711714074e-05, Validation Loss: 7.285266474355012e-05
Epoch 142, Training Loss: 7.285246829269454e-05, Validation Loss: 6.432736699935049e-05
Epoch 143, Training Loss: 6.432789086829871e-05, Validation Loss: 5.637628783006221e-05
Epoch 144, Training Loss: 5.637610229314305e-05, Validation Loss: 4.9036698328563944e-05
Epoch 145, Training Loss: 4.903695298708044e-05, Validation Loss: 4.2344137909822166e-05
Epoch 146, Training Loss: 4.234441803419031e-05, Validation Loss: 3.633066444308497e-05
Epoch 147, Training Loss: 3.6330584407551214e-05, Validation Loss: 3.1019972084322944e-05
Epoch 148, Training Loss: 3.101971378782764e-05, Validation Loss: 2.6420666472404264e-05
Epoch 149, Training Loss: 2.6420682843308896e-05, Validation Loss: 2.2521629944094457e-05
Epoch 150, Training Loss: 2.2521706341649406e-05, Validation Loss: 1.9285302187199704e-05
Epoch 151, Training Loss: 1.928518759086728e-05, Validation Loss: 1.66508907568641e-05
Epoch 152, Training Loss: 1.6650994439260103e-05, Validation Loss: 1.4538399227603804e-05
Epoch 153, Training Loss: 1.4538522009388544e-05, Validation Loss: 1.2856981811637525e-05
Epoch 154, Training Loss: 1.2856959983764682e-05, Validation Loss: 1.1513944627949968e-05
Epoch 155, Training Loss: 1.1513903700688388e-05, Validation Loss: 1.0424610081827268e-05
Epoch 156, Training Loss: 1.0424540050735231e-05, Validation Loss: 9.518674232822377e-06
Epoch 157, Training Loss: 9.5187369879568e-06, Validation Loss: 8.743695616431069e-06
Epoch 158, Training Loss: 8.743853868509177e-06, Validation Loss: 8.064839676080737e-06
Epoch 159, Training Loss: 8.064843314059544e-06, Validation Loss: 7.462081157427747e-06
Epoch 160, Training Loss: 7.462051598849939e-06, Validation Loss: 6.925184152350994e-06
Epoch 161, Training Loss: 6.925219622644363e-06, Validation Loss: 6.448918611567933e-06
Epoch 162, Training Loss: 6.448925432778196e-06, Validation Loss: 6.028073585184757e-06
Epoch 163, Training Loss: 6.028057669027476e-06, Validation Loss: 5.65494156035129e-06
Epoch 164, Training Loss: 5.654958386003273e-06, Validation Loss: 5.318086095940089e-06
Epoch 165, Training Loss: 5.318033345247386e-06, Validation Loss: 5.003431851946516e-06
Epoch 166, Training Loss: 5.003482783649815e-06, Validation Loss: 4.69594760943437e-06
Epoch 167, Training Loss: 4.695992174674757e-06, Validation Loss: 4.382676706882194e-06
Epoch 168, Training Loss: 4.382643055578228e-06, Validation Loss: 4.054473265568959e-06
Epoch 169, Training Loss: 4.054480086779222e-06, Validation Loss: 3.7077995784784434e-06
Epoch 170, Training Loss: 3.7078048080729786e-06, Validation Loss: 3.3450689898018027e-06
Epoch 171, Training Loss: 3.3450849059590837e-06, Validation Loss: 2.9735485895798774e-06
Epoch 172, Training Loss: 2.9734953841398237e-06, Validation Loss: 2.604030896691256e-06
Epoch 173, Training Loss: 2.6041577712021535e-06, Validation Loss: 2.2491572053695563e-06
Epoch 174, Training Loss: 2.2491444724437315e-06, Validation Loss: 1.9203157535230275e-06
Epoch 175, Training Loss: 1.9202925614081323e-06, Validation Loss: 1.6266968714262475e-06
Epoch 176, Training Loss: 1.6267315459117526e-06, Validation Loss: 1.3744850093644345e-06
Epoch 177, Training Loss: 1.3744634088652674e-06, Validation Loss: 1.1655188245640602e-06
Epoch 178, Training Loss: 1.1655573644020478e-06, Validation Loss: 9.987246585296816e-07
Epoch 179, Training Loss: 9.987146540879621e-07, Validation Loss: 8.698522151462384e-07
Epoch 180, Training Loss: 8.698416991137492e-07, Validation Loss: 7.730896527391451e-07
Epoch 181, Training Loss: 7.730905622338469e-07, Validation Loss: 7.018600172159495e-07
Epoch 182, Training Loss: 7.018729775154497e-07, Validation Loss: 6.495503157566418e-07
Epoch 183, Training Loss: 6.49550656817155e-07, Validation Loss: 6.103121563683089e-07
Epoch 184, Training Loss: 6.103214786890021e-07, Validation Loss: 5.79188565552613e-07
Epoch 185, Training Loss: 5.791885087091941e-07, Validation Loss: 5.523471600099583e-07
Epoch 186, Training Loss: 5.523417030417477e-07, Validation Loss: 5.269549774311599e-07
Epoch 187, Training Loss: 5.269602070256951e-07, Validation Loss: 5.011152666156704e-07
Epoch 188, Training Loss: 5.011038979318982e-07, Validation Loss: 4.7359333166241413e-07
Epoch 189, Training Loss: 4.736059224796918e-07, Validation Loss: 4.4382562691680505e-07
Epoch 190, Training Loss: 4.43831766006042e-07, Validation Loss: 4.117210323784093e-07
Epoch 191, Training Loss: 4.1172631881636335e-07, Validation Loss: 3.7763112459288095e-07
Epoch 192, Training Loss: 3.776384858156234e-07, Validation Loss: 3.422737790970132e-07
Epoch 193, Training Loss: 3.4226749789922906e-07, Validation Loss: 3.065770783905464e-07
Epoch 194, Training Loss: 3.065719624828489e-07, Validation Loss: 2.715838434141915e-07
Epoch 195, Training Loss: 2.715702009936649e-07, Validation Loss: 2.3833904094772151e-07
Epoch 196, Training Loss: 2.3836705054236518e-07, Validation Loss: 2.0777640941105346e-07
Epoch 197, Training Loss: 2.0777362408352928e-07, Validation Loss: 1.8039281712844968e-07
Epoch 198, Training Loss: 1.8040334737179364e-07, Validation Loss: 1.5658538643492648e-07
Epoch 199, Training Loss: 1.5657012397696235e-07, Validation Loss: 1.361871966309991e-07
Epoch 200, Training Loss: 1.3622285166547954e-07, Validation Loss: 1.1903379970590322e-07
Epoch 201, Training Loss: 1.1902517371709109e-07, Validation Loss: 1.0452471599364799e-07
Epoch 202, Training Loss: 1.0453158694190279e-07, Validation Loss: 9.219854035791286e-08
Epoch 203, Training Loss: 9.218833696422735e-08, Validation Loss: 8.149004315782804e-08
Epoch 204, Training Loss: 8.149196872864195e-08, Validation Loss: 7.204648966308014e-08
Epoch 205, Training Loss: 7.204842944474876e-08, Validation Loss: 6.359666571142952e-08
Epoch 206, Training Loss: 6.360361481938526e-08, Validation Loss: 5.6021541183781665e-08
Epoch 207, Training Loss: 5.6023409911176714e-08, Validation Loss: 4.930636876565586e-08
Epoch 208, Training Loss: 4.930196340069415e-08, Validation Loss: 4.3470901545106244e-08
Epoch 209, Training Loss: 4.345853454879034e-08, Validation Loss: 3.8533226387471586e-08
Epoch 210, Training Loss: 3.8527009138533685e-08, Validation Loss: 3.449112284670264e-08
Epoch 211, Training Loss: 3.449463648053097e-08, Validation Loss: 3.126574554812578e-08
Epoch 212, Training Loss: 3.1263532207503886e-08, Validation Loss: 2.8727475509526812e-08
Epoch 213, Training Loss: 2.8728923240350923e-08, Validation Loss: 2.6743434133891242e-08
Epoch 214, Training Loss: 2.6746082681938788e-08, Validation Loss: 2.5131058123406547e-08
Epoch 215, Training Loss: 2.51282337160319e-08, Validation Loss: 2.375365149021036e-08
Epoch 216, Training Loss: 2.375290719669465e-08, Validation Loss: 2.2507890662382124e-08
Epoch 217, Training Loss: 2.250645536605589e-08, Validation Loss: 2.1318957266203142e-08
Epoch 218, Training Loss: 2.131185716791606e-08, Validation Loss: 2.0138665846047843e-08
Epoch 219, Training Loss: 2.0138543277425924e-08, Validation Loss: 1.8962575509817725e-08
Epoch 220, Training Loss: 1.89624707047642e-08, Validation Loss: 1.7790720008292737e-08
Epoch 221, Training Loss: 1.779252301048473e-08, Validation Loss: 1.6614315256902046e-08
Epoch 222, Training Loss: 1.661276627373809e-08, Validation Loss: 1.5423250232515784e-08
Epoch 223, Training Loss: 1.5421644405932966e-08, Validation Loss: 1.420396422702197e-08
Epoch 224, Training Loss: 1.4205589593530021e-08, Validation Loss: 1.2951993255683192e-08
Epoch 225, Training Loss: 1.2957664274892977e-08, Validation Loss: 1.1670638677685474e-08
Epoch 226, Training Loss: 1.1669486710275123e-08, Validation Loss: 1.0357396718063683e-08
Epoch 227, Training Loss: 1.0362951385900487e-08, Validation Loss: 9.048820359680576e-09
Epoch 228, Training Loss: 9.051929872327946e-09, Validation Loss: 7.775887489458455e-09
Epoch 229, Training Loss: 7.775560639800005e-09, Validation Loss: 6.5677259186713854e-09
Epoch 230, Training Loss: 6.568656285566021e-09, Validation Loss: 5.472122754923703e-09
Epoch 231, Training Loss: 5.473946185219347e-09, Validation Loss: 4.514354667861653e-09
Epoch 232, Training Loss: 4.514975948666233e-09, Validation Loss: 3.7056901991405766e-09
Epoch 233, Training Loss: 3.706429163585767e-09, Validation Loss: 3.0570204145874413e-09
Epoch 234, Training Loss: 3.0552465002386953e-09, Validation Loss: 2.5491404542776763e-09
Epoch 235, Training Loss: 2.5491635469165885e-09, Validation Loss: 2.1678925321566567e-09
Epoch 236, Training Loss: 2.1704160690916297e-09, Validation Loss: 1.890086753775222e-09
Epoch 237, Training Loss: 1.8911403554255912e-09, Validation Loss: 1.695429130421644e-09
Epoch 238, Training Loss: 1.697275764378503e-09, Validation Loss: 1.5622211302357414e-09
Epoch 239, Training Loss: 1.5626354654685315e-09, Validation Loss: 1.4722620900187167e-09
Epoch 240, Training Loss: 1.4707721707196697e-09, Validation Loss: 1.4134429182632857e-09
Epoch 241, Training Loss: 1.41224565375353e-09, Validation Loss: 1.3735571569029048e-09
Epoch 242, Training Loss: 1.3732756043438599e-09, Validation Loss: 1.3456734615502342e-09
Epoch 243, Training Loss: 1.344299893624168e-09, Validation Loss: 1.3178261815127712e-09
Epoch 244, Training Loss: 1.3182530622657396e-09, Validation Loss: 1.2867640286629012e-09
Epoch 245, Training Loss: 1.2877461319504846e-09, Validation Loss: 1.2450613873227212e-09
Epoch 246, Training Loss: 1.2455054765325713e-09, Validation Loss: 1.189819465174935e-09
Epoch 247, Training Loss: 1.1900203045200897e-09, Validation Loss: 1.1189600357397467e-09
Epoch 248, Training Loss: 1.1165968150095296e-09, Validation Loss: 1.0338027101042258e-09
Epoch 249, Training Loss: 1.0337611877631048e-09, Validation Loss: 9.400005218651586e-10
Epoch 250, Training Loss: 9.387962629503477e-10, Validation Loss: 8.416141672462629e-10
Epoch 251, Training Loss: 8.409736795833567e-10, Validation Loss: 7.451853023532351e-10
Epoch 252, Training Loss: 7.448947014765395e-10, Validation Loss: 6.536323704509073e-10
Epoch 253, Training Loss: 6.535944563346163e-10, Validation Loss: 5.713190476264174e-10
Epoch 254, Training Loss: 5.713888806546663e-10, Validation Loss: 4.985074575358794e-10
Epoch 255, Training Loss: 4.996247859878622e-10, Validation Loss: 4.372412987230234e-10
Epoch 256, Training Loss: 4.377127826860061e-10, Validation Loss: 3.845165297278186e-10
Epoch 257, Training Loss: 3.8420727710430924e-10, Validation Loss: 3.3865457660375853e-10
Epoch 258, Training Loss: 3.382961133446827e-10, Validation Loss: 2.9703345338916165e-10
Epoch 259, Training Loss: 2.9751245911313617e-10, Validation Loss: 2.601548143577048e-10
Epoch 260, Training Loss: 2.604301774233875e-10, Validation Loss: 2.2641366559383869e-10
Epoch 261, Training Loss: 2.2599516702470623e-10, Validation Loss: 1.952078776401578e-10
Epoch 262, Training Loss: 1.950270916983854e-10, Validation Loss: 1.6789619694534963e-10
Epoch 263, Training Loss: 1.677492589280405e-10, Validation Loss: 1.428181461982092e-10
Epoch 264, Training Loss: 1.426993245789987e-10, Validation Loss: 1.2165113361106705e-10
Epoch 265, Training Loss: 1.2165647655937306e-10, Validation Loss: 1.0418790136190736e-10
Epoch 266, Training Loss: 1.0444747844395863e-10, Validation Loss: 9.078537227535932e-11
Epoch 267, Training Loss: 9.042054605057359e-11, Validation Loss: 8.003707419046435e-11
Epoch 268, Training Loss: 7.988663203173374e-11, Validation Loss: 7.197632767574902e-11
Epoch 269, Training Loss: 7.186059386432575e-11, Validation Loss: 6.665097640468076e-11
Epoch 270, Training Loss: 6.624784054665156e-11, Validation Loss: 6.231092031239172e-11
Epoch 271, Training Loss: 6.217494574745075e-11, Validation Loss: 5.94328405933986e-11
Epoch 272, Training Loss: 5.948651293774532e-11, Validation Loss: 5.718507958829555e-11
Epoch 273, Training Loss: 5.7186561042144035e-11, Validation Loss: 5.525009616480503e-11
Epoch 274, Training Loss: 5.5409923177540676e-11, Validation Loss: 5.3778547587368664e-11
Epoch 275, Training Loss: 5.3799912441698794e-11, Validation Loss: 5.233389416270384e-11
Epoch 276, Training Loss: 5.215956486170903e-11, Validation Loss: 5.0163043857631706e-11
Epoch 277, Training Loss: 5.014374679368494e-11, Validation Loss: 4.769913630742195e-11
Epoch 278, Training Loss: 4.759410920929241e-11, Validation Loss: 4.4720848552115555e-11
Epoch 279, Training Loss: 4.4672845284088325e-11, Validation Loss: 4.1573577913567306e-11
Epoch 280, Training Loss: 4.1545874379655956e-11, Validation Loss: 3.799423275996361e-11
Epoch 281, Training Loss: 3.8028802329392875e-11, Validation Loss: 3.453940952691248e-11
Epoch 282, Training Loss: 3.435722192857149e-11, Validation Loss: 3.0567555431293414e-11
Epoch 283, Training Loss: 3.0614705215370464e-11, Validation Loss: 2.696326148465822e-11
Epoch 284, Training Loss: 2.6993044952017264e-11, Validation Loss: 2.3511446262114433e-11
Epoch 285, Training Loss: 2.3377339994357094e-11, Validation Loss: 2.029746509757402e-11
Epoch 286, Training Loss: 2.020836969984785e-11, Validation Loss: 1.734584177681686e-11
Epoch 287, Training Loss: 1.729928353344512e-11, Validation Loss: 1.4653167568212666e-11
Epoch 288, Training Loss: 1.4698894879039415e-11, Validation Loss: 1.2296907415942915e-11
Epoch 289, Training Loss: 1.2342074411086923e-11, Validation Loss: 1.0407018996572148e-11
Epoch 290, Training Loss: 1.0505799355464696e-11, Validation Loss: 8.788226223133133e-12
Epoch 291, Training Loss: 8.872783584246147e-12, Validation Loss: 7.437488125372482e-12
Epoch 292, Training Loss: 7.419259651086918e-12, Validation Loss: 6.2567446883210476e-12
Epoch 293, Training Loss: 6.258115987228807e-12, Validation Loss: 5.265534102488756e-12
Epoch 294, Training Loss: 5.225157979904527e-12, Validation Loss: 4.520484247344525e-12
Epoch 295, Training Loss: 4.529782365175761e-12, Validation Loss: 3.9315837911668705e-12
Epoch 296, Training Loss: 3.954345097895162e-12, Validation Loss: 3.5422697761133826e-12
Epoch 297, Training Loss: 3.5990912940903064e-12, Validation Loss: 3.2723157950692583e-12
Epoch 298, Training Loss: 3.32043051907982e-12, Validation Loss: 3.1381791696510897e-12
Epoch 299, Training Loss: 3.1420701544077057e-12, Validation Loss: 3.0443516631228906e-12
Epoch 300, Training Loss: 3.0592442641641515e-12, Validation Loss: 2.9629237431605393e-12
Epoch 301, Training Loss: 2.92606173665777e-12, Validation Loss: 2.943130114618775e-12
Epoch 302, Training Loss: 2.947800207056539e-12, Validation Loss: 2.8555699471688456e-12
Epoch 303, Training Loss: 2.843271191405039e-12, Validation Loss: 2.7186614504765005e-12
Epoch 304, Training Loss: 2.7173942349772995e-12, Validation Loss: 2.6091923760462876e-12
Epoch 305, Training Loss: 2.635955689833658e-12, Validation Loss: 2.464936024390574e-12
Epoch 306, Training Loss: 2.430191898411538e-12, Validation Loss: 2.3127133888523055e-12
Epoch 307, Training Loss: 2.2378314479265526e-12, Validation Loss: 2.0586113109316573e-12
Epoch 308, Training Loss: 2.010209273345387e-12, Validation Loss: 1.7909157230128203e-12
Epoch 309, Training Loss: 1.7838486764121253e-12, Validation Loss: 1.6144647467866702e-12
Epoch 310, Training Loss: 1.5927493698941753e-12, Validation Loss: 1.4457705865833503e-12
Epoch 311, Training Loss: 1.4353379595988258e-12, Validation Loss: 1.2602059153155043e-12
Epoch 312, Training Loss: 1.290444313906125e-12, Validation Loss: 1.1396166128829766e-12
Epoch 313, Training Loss: 1.1306650060660672e-12, Validation Loss: 9.608604059976877e-13
Epoch 314, Training Loss: 9.850809404299277e-13, Validation Loss: 8.743907290928443e-13
Epoch 315, Training Loss: 8.643073236280774e-13, Validation Loss: 7.61591690320168e-13
Epoch 316, Training Loss: 7.64148076412563e-13, Validation Loss: 6.658781599028218e-13
Epoch 317, Training Loss: 6.771722397234947e-13, Validation Loss: 5.847057863925254e-13
Epoch 318, Training Loss: 6.051499904478896e-13, Validation Loss: 5.042223149426261e-13
Epoch 319, Training Loss: 5.385579135430696e-13, Validation Loss: 4.579247137731501e-13
Epoch 320, Training Loss: 4.755218029235675e-13, Validation Loss: 3.9678544195946575e-13
Epoch 321, Training Loss: 4.4040994267267874e-13, Validation Loss: 3.780094726818506e-13
Epoch 322, Training Loss: 3.939231211190497e-13, Validation Loss: 3.2848693925537076e-13
Epoch 323, Training Loss: 3.485982661387277e-13, Validation Loss: 2.9487805426609004e-13
Epoch 324, Training Loss: 3.012125596689452e-13, Validation Loss: 2.7549821148345477e-13
Epoch 325, Training Loss: 2.6618128274452646e-13, Validation Loss: 2.2565657025255814e-13
Epoch 326, Training Loss: 2.328740499046855e-13, Validation Loss: 1.919168627186399e-13
Epoch 327, Training Loss: 2.0606403410873553e-13, Validation Loss: 1.898028717702005e-13
Epoch 328, Training Loss: 1.9090496327853201e-13, Validation Loss: 1.550630690473273e-13
Epoch 329, Training Loss: 1.5901406439419036e-13, Validation Loss: 1.4343811782866617e-13
Epoch 330, Training Loss: 1.5590518242722395e-13, Validation Loss: 1.2509919044677992e-13
Epoch 331, Training Loss: 1.439892313454677e-13, Validation Loss: 1.2461329169065338e-13
Epoch 332, Training Loss: 1.1863023042200938e-13, Validation Loss: 9.181514598090301e-14
Epoch 333, Training Loss: 1.0598516693178378e-13, Validation Loss: 9.875967773610717e-14
Epoch 334, Training Loss: 9.74887623969925e-14, Validation Loss: 7.678406521716141e-14
Epoch 335, Training Loss: 8.950956295605828e-14, Validation Loss: 7.456798985791893e-14
Epoch 336, Training Loss: 7.571104387957966e-14, Validation Loss: 6.042655796307389e-14
Epoch 337, Training Loss: 6.307424743091927e-14, Validation Loss: 6.085206665819298e-14
Epoch 338, Training Loss: 5.744626915002785e-14, Validation Loss: 5.202512615046055e-14
Epoch 339, Training Loss: 5.30374050613288e-14, Validation Loss: 4.236004654141999e-14
Epoch 340, Training Loss: 4.2877529462083744e-14, Validation Loss: 4.461815845176881e-14
Epoch 341, Training Loss: 3.21617427514239e-14, Validation Loss: 3.5248249496055636e-14
Epoch 342, Training Loss: 2.9688826673783184e-14, Validation Loss: 2.8511115452052593e-14
Epoch 343, Training Loss: 2.977422792365715e-14, Validation Loss: 2.0447820886049066e-14
Epoch 344, Training Loss: 2.507285964134867e-14, Validation Loss: 2.1822521478124905e-14
Epoch 345, Training Loss: 1.960848069202173e-14, Validation Loss: 1.996169681915856e-14
Epoch 346, Training Loss: 1.90789902322977e-14, Validation Loss: 1.8747390385974796e-14
Epoch 347, Training Loss: 1.5624220667254107e-14, Validation Loss: 1.5710023410745073e-14
Epoch 348, Training Loss: 1.6711760149551794e-14, Validation Loss: 1.8754596942290036e-14
Epoch 349, Training Loss: 1.1452878169492323e-14, Validation Loss: 1.510397133698462e-14
Epoch 350, Training Loss: 9.837984444563581e-15, Validation Loss: 1.3040984477464147e-14
Epoch 351, Training Loss: 1.3164650440730327e-14, Validation Loss: 1.438175885890361e-14
Epoch 352, Training Loss: 1.2877219974474947e-14, Validation Loss: 1.8669995291518277e-14
Epoch 353, Training Loss: 1.2041083259054126e-14, Validation Loss: 1.5600901850216196e-14
Epoch 354, Training Loss: 9.553489794503385e-15, Validation Loss: 1.2971028026350414e-14
Epoch 355, Training Loss: 8.980764232052654e-15, Validation Loss: 1.1811165482884366e-14
Epoch 356, Training Loss: 1.2930328940267792e-14, Validation Loss: 1.1825177101897847e-14
Epoch 357, Training Loss: 8.961548442611243e-15, Validation Loss: 1.1942337005096167e-14
Epoch 358, Training Loss: 9.525467403509371e-15, Validation Loss: 1.1388827232086847e-14
Epoch 359, Training Loss: 7.90336712226539e-15, Validation Loss: 1.100878895964226e-14
Epoch 360, Training Loss: 7.431522336799699e-15, Validation Loss: 9.419381609063453e-15
Epoch 361, Training Loss: 7.068564907252968e-15, Validation Loss: 8.810527550313484e-15
Epoch 362, Training Loss: 7.761386612613677e-15, Validation Loss: 8.482264166769816e-15
Epoch 363, Training Loss: 5.493435567549554e-15, Validation Loss: 9.196136758452163e-15
Epoch 364, Training Loss: 5.3058186167656736e-15, Validation Loss: 8.824371456803409e-15
Epoch 365, Training Loss: 5.2268222065223694e-15, Validation Loss: 9.37254407521208e-15
Epoch 366, Training Loss: 5.189458736186035e-15, Validation Loss: 7.643158600868869e-15
Epoch 367, Training Loss: 3.919107521014242e-15, Validation Loss: 5.639719851606266e-15
Epoch 368, Training Loss: 4.148891465978336e-15, Validation Loss: 8.294480350495327e-15
Epoch 369, Training Loss: 5.129410876489283e-15, Validation Loss: 8.096588890061252e-15
Epoch 370, Training Loss: 4.255110244596972e-15, Validation Loss: 6.293543736558913e-15
Epoch 371, Training Loss: 3.958872753272516e-15, Validation Loss: 6.397627145117522e-15
Epoch 372, Training Loss: 4.620736251444027e-15, Validation Loss: 8.263122343755026e-15
Epoch 373, Training Loss: 3.3066165145469997e-15, Validation Loss: 7.869206283502624e-15
Epoch 374, Training Loss: 3.043739204091917e-15, Validation Loss: 8.150498301989252e-15
Epoch 375, Training Loss: 3.1483564551655326e-15, Validation Loss: 1.0800656023842933e-14
Epoch 376, Training Loss: 3.9449949654647015e-15, Validation Loss: 6.5326687608653275e-15
Epoch 377, Training Loss: 2.352785418138141e-15, Validation Loss: 7.976525357919744e-15
Epoch 378, Training Loss: 4.433652931416917e-15, Validation Loss: 7.238567384382222e-15
Epoch 379, Training Loss: 3.851319897761954e-15, Validation Loss: 7.160671693453875e-15
Epoch 380, Training Loss: 5.089645644231009e-15, Validation Loss: 6.773294727554276e-15
Epoch 381, Training Loss: 5.915107203417584e-15, Validation Loss: 5.097418442071488e-15
Epoch 382, Training Loss: 3.654095052257368e-15, Validation Loss: 4.953669751142382e-15
Epoch 383, Training Loss: 3.641551764857953e-15, Validation Loss: 3.751106159222877e-15
Epoch 384, Training Loss: 3.555616037194268e-15, Validation Loss: 4.670543059292001e-15
Epoch 385, Training Loss: 1.981821621415726e-15, Validation Loss: 5.057886567390183e-15
Epoch 386, Training Loss: 2.5823027594820865e-15, Validation Loss: 6.716182260536234e-15
Epoch 387, Training Loss: 2.325029842522512e-15, Validation Loss: 6.196832902773206e-15
Epoch 388, Training Loss: 2.9660770824987753e-15, Validation Loss: 4.4943682530761055e-15
Epoch 389, Training Loss: 4.59911912359715e-15, Validation Loss: 2.3517514026677802e-15
Epoch 390, Training Loss: 4.106457656419737e-15, Validation Loss: 5.2548445975163834e-15
Epoch 391, Training Loss: 5.222551889918787e-15, Validation Loss: 5.18855791664663e-15
Epoch 392, Training Loss: 5.305018170630518e-15, Validation Loss: 4.763817903927171e-15
Epoch 393, Training Loss: 3.898024023924135e-15, Validation Loss: 4.816259831274053e-15
Epoch 394, Training Loss: 3.0005045248816895e-15, Validation Loss: 4.586075239725908e-15
Epoch 395, Training Loss: 2.1990622789804046e-15, Validation Loss: 5.538138154857373e-15
Epoch 396, Training Loss: 1.7392271501573582e-15, Validation Loss: 3.81208829626045e-15
Epoch 397, Training Loss: 3.917773020605843e-15, Validation Loss: 3.908965995536766e-15
Epoch 398, Training Loss: 3.217211551689598e-15, Validation Loss: 4.032264770020312e-15
Epoch 399, Training Loss: 1.6935906031460726e-15, Validation Loss: 4.1159317199347765e-15
Epoch 400, Training Loss: 3.274857861222647e-15, Validation Loss: 5.388818528234175e-15
Epoch 401, Training Loss: 3.619133767359447e-15, Validation Loss: 4.780464218923086e-15
Epoch 402, Training Loss: 2.569759472082671e-15, Validation Loss: 4.74523611864678e-15
Epoch 403, Training Loss: 3.4232434222632602e-15, Validation Loss: 4.784734535526669e-15
Epoch 404, Training Loss: 2.614862282458068e-15, Validation Loss: 3.4887624795245644e-15
Epoch 405, Training Loss: 2.546274001312388e-15, Validation Loss: 4.205470302239608e-15
Epoch 406, Training Loss: 2.257242219270224e-15, Validation Loss: 4.207605248783162e-15
Epoch 407, Training Loss: 2.2532391415615e-15, Validation Loss: 3.7214824524420785e-15
Epoch 408, Training Loss: 1.912966313133424e-15, Validation Loss: 3.3098191461205682e-15
Epoch 409, Training Loss: 2.1358115759518475e-15, Validation Loss: 2.9094982462375034e-15
Epoch 410, Training Loss: 2.174242519559959e-15, Validation Loss: 2.9831572901219214e-15
Epoch 411, Training Loss: 2.7581770807599435e-15, Validation Loss: 2.8978890244206728e-15
Epoch 412, Training Loss: 2.2652487982041452e-15, Validation Loss: 3.0552150182195552e-15
Epoch 413, Training Loss: 2.122200815280655e-15, Validation Loss: 3.084038278865198e-15
Epoch 414, Training Loss: 2.1350109180584553e-15, Validation Loss: 2.981556186093374e-15
Epoch 415, Training Loss: 1.8780050282355028e-15, Validation Loss: 3.3578575609329118e-15
Epoch 416, Training Loss: 1.800609722020746e-15, Validation Loss: 3.3578575609329118e-15
Epoch 417, Training Loss: 1.4931633378261551e-15, Validation Loss: 3.3071503570620067e-15
Epoch 418, Training Loss: 1.66236558057849e-15, Validation Loss: 3.2430989961400574e-15
Epoch 419, Training Loss: 2.4400554344519883e-15, Validation Loss: 2.6270053467899058e-15
Epoch 420, Training Loss: 2.3973545977567677e-15, Validation Loss: 2.6079566345973406e-15
Epoch 421, Training Loss: 1.0597492842103384e-15, Validation Loss: 3.4589052034085608e-15
Epoch 422, Training Loss: 3.1600990846715558e-15, Validation Loss: 2.4999700982177844e-15
Epoch 423, Training Loss: 1.7923363277084397e-15, Validation Loss: 4.383079135235205e-15
Epoch 424, Training Loss: 2.4934316391396916e-15, Validation Loss: 3.556416906845897e-15
Epoch 425, Training Loss: 2.1971941478152353e-15, Validation Loss: 2.4963672435766382e-15
Epoch 426, Training Loss: 2.3842774678423453e-15, Validation Loss: 4.018820663081492e-15
Epoch 427, Training Loss: 1.664500633001163e-15, Validation Loss: 3.200297997798824e-15
Epoch 428, Training Loss: 3.099250355323175e-15, Validation Loss: 3.1818832897672787e-15
Epoch 429, Training Loss: 2.3010107409954586e-15, Validation Loss: 3.159698861603978e-15
Epoch 430, Training Loss: 2.2556409034834397e-15, Validation Loss: 3.147689204961333e-15
Epoch 431, Training Loss: 1.845712532396143e-15, Validation Loss: 3.121401537443296e-15
Epoch 432, Training Loss: 2.0165160909352622e-15, Validation Loss: 3.23028868160402e-15
Epoch 433, Training Loss: 2.2166765408767946e-15, Validation Loss: 3.2736567685034404e-15
Epoch 434, Training Loss: 2.18465086041582e-15, Validation Loss: 3.702567359696943e-15
Epoch 435, Training Loss: 1.4880925750874172e-15, Validation Loss: 3.657731364699931e-15
Epoch 436, Training Loss: 1.3642599580888644e-15, Validation Loss: 3.744200723120386e-15
Epoch 437, Training Loss: 7.181421671321e-16, Validation Loss: 4.205370352351832e-15
Epoch 438, Training Loss: 7.397595067372138e-16, Validation Loss: 3.6225032644236245e-15
Epoch 439, Training Loss: 7.397595067372138e-16, Validation Loss: 3.704568898551305e-15
Epoch 440, Training Loss: 1.5924427990244108e-15, Validation Loss: 3.823063725674498e-15
Epoch 441, Training Loss: 1.5644204080303968e-15, Validation Loss: 3.768620259473254e-15
Epoch 442, Training Loss: 1.823027719519252e-15, Validation Loss: 3.682684531809569e-15
Epoch 443, Training Loss: 1.2105368189311281e-15, Validation Loss: 3.682551124120376e-15
Epoch 444, Training Loss: 1.2105368189311281e-15, Validation Loss: 3.599784993745317e-15
Epoch 445, Training Loss: 1.1262025129333457e-15, Validation Loss: 3.4844923746792187e-15
Epoch 446, Training Loss: 1.13687777504671e-15, Validation Loss: 3.3884155450545315e-15
Epoch 447, Training Loss: 6.829139609766752e-16, Validation Loss: 3.695861823370004e-15
Epoch 448, Training Loss: 6.829139609766752e-16, Validation Loss: 3.695861823370004e-15
Epoch 449, Training Loss: 1.4499286586159275e-15, Validation Loss: 3.747103081514153e-15
Epoch 450, Training Loss: 1.4499286586159275e-15, Validation Loss: 3.6536948291897905e-15
Epoch 451, Training Loss: 1.5532114092811438e-15, Validation Loss: 5.1108625490103084e-15
Epoch 452, Training Loss: 1.873468108011772e-15, Validation Loss: 5.121537705244554e-15
Epoch 453, Training Loss: 1.873468108011772e-15, Validation Loss: 3.289669714613046e-15
Epoch 454, Training Loss: 1.788066222863094e-15, Validation Loss: 3.289669714613046e-15
Epoch 455, Training Loss: 1.7848638030477622e-15, Validation Loss: 3.289669714613046e-15
Epoch 456, Training Loss: 1.8043459843510848e-15, Validation Loss: 1.965942082995313e-15
Epoch 457, Training Loss: 2.1982616210870125e-15, Validation Loss: 1.965942082995313e-15
Epoch 458, Training Loss: 2.1982616210870125e-15, Validation Loss: 2.0097106047205476e-15
Epoch 459, Training Loss: 2.5673574984024948e-15, Validation Loss: 2.3091505158603356e-15
Epoch 460, Training Loss: 2.0122459860899165e-15, Validation Loss: 2.719079098705869e-15
Epoch 461, Training Loss: 2.026123773897731e-15, Validation Loss: 2.005040276807624e-15
Epoch 462, Training Loss: 2.450196959929464e-15, Validation Loss: 2.850517648054292e-15
Epoch 463, Training Loss: 2.0955127129368032e-15, Validation Loss: 1.6175295855814782e-15
Epoch 464, Training Loss: 1.2868646518741076e-15, Validation Loss: 1.536931647793153e-15
Epoch 465, Training Loss: 1.8144875098285605e-15, Validation Loss: 1.5476069099065173e-15
Epoch 466, Training Loss: 1.5513432781159744e-15, Validation Loss: 1.591642247010137e-15
Epoch 467, Training Loss: 1.4979671793073895e-15, Validation Loss: 2.4114992009429672e-15
Epoch 468, Training Loss: 1.4349832916572174e-15, Validation Loss: 1.5566808562330974e-15
Epoch 469, Training Loss: 1.9850240412310578e-15, Validation Loss: 1.5534783305386473e-15
Epoch 470, Training Loss: 2.105921053792664e-15, Validation Loss: 1.6335424258119655e-15
Epoch 471, Training Loss: 2.9497973210107845e-15, Validation Loss: 1.636745057385534e-15
Epoch 472, Training Loss: 2.8473152282389603e-15, Validation Loss: 1.594044114811195e-15
Epoch 473, Training Loss: 2.6570292766382817e-15, Validation Loss: 1.3244948317097088e-15
Epoch 474, Training Loss: 1.3383726195175232e-15, Validation Loss: 2.6055214148739845e-15
Epoch 475, Training Loss: 1.95940362391722e-15, Validation Loss: 3.4736838107557802e-15
Epoch 476, Training Loss: 1.4504623952518161e-15, Validation Loss: 4.004776009783068e-15
Epoch 477, Training Loss: 2.3164898445900573e-15, Validation Loss: 3.701599624554705e-15
Epoch 478, Training Loss: 2.4627402473288793e-15, Validation Loss: 3.2820635705049393e-15
Epoch 479, Training Loss: 1.3258292262389895e-15, Validation Loss: 3.3679990864103875e-15
Epoch 480, Training Loss: 1.2628453385888174e-15, Validation Loss: 5.38094578050592e-15
Epoch 481, Training Loss: 2.4088304118844057e-15, Validation Loss: 4.59391495316922e-15
Epoch 482, Training Loss: 1.9735482271034197e-15, Validation Loss: 4.222950944688568e-15
Epoch 483, Training Loss: 1.627137268543947e-15, Validation Loss: 4.48075770416315e-15
Epoch 484, Training Loss: 1.9159021293286074e-15, Validation Loss: 4.029195546135936e-15
Epoch 485, Training Loss: 8.166211292556411e-16, Validation Loss: 4.080436804280085e-15
Epoch 486, Training Loss: 2.6914569307794328e-15, Validation Loss: 4.297544054155571e-15
Epoch 487, Training Loss: 1.0813666238154523e-15, Validation Loss: 4.665839061819424e-15
Epoch 488, Training Loss: 1.2249483433748312e-15, Validation Loss: 4.665839061819424e-15
Epoch 489, Training Loss: 1.2249483433748312e-15, Validation Loss: 4.665839061819424e-15
Epoch 490, Training Loss: 1.8649278983210804e-15, Validation Loss: 4.665839061819424e-15
Epoch 491, Training Loss: 1.8032785110793075e-15, Validation Loss: 4.4584731143538364e-15
Epoch 492, Training Loss: 1.8481145060763194e-15, Validation Loss: 3.867065816734938e-15
Epoch 493, Training Loss: 1.1376784329401022e-15, Validation Loss: 4.03079686192272e-15
Epoch 494, Training Loss: 7.982063682845366e-16, Validation Loss: 3.803414678880566e-15
Epoch 495, Training Loss: 2.149689363759662e-15, Validation Loss: 3.944327503502265e-15
Epoch 496, Training Loss: 1.0928424379430903e-15, Validation Loss: 3.84558167306078e-15
Epoch 497, Training Loss: 1.3004755184244186e-15, Validation Loss: 4.290738567940856e-15
Epoch 498, Training Loss: 1.148086773795963e-15, Validation Loss: 4.290738567940856e-15
Epoch 499, Training Loss: 9.879583714910898e-16, Validation Loss: 4.271523202015919e-15
Epoch 500, Training Loss: 1.1929226629138565e-15, Validation Loss: 4.271523202015919e-15
