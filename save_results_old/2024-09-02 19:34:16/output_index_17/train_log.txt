Epoch 1, Training Loss: 0.4422585964202881, Validation Loss: 0.44100987911224365
Epoch 2, Training Loss: 0.44100990891456604, Validation Loss: 0.43978801369667053
Epoch 3, Training Loss: 0.43978801369667053, Validation Loss: 0.43859851360321045
Epoch 4, Training Loss: 0.43859851360321045, Validation Loss: 0.43744003772735596
Epoch 5, Training Loss: 0.43744003772735596, Validation Loss: 0.4362969994544983
Epoch 6, Training Loss: 0.4362969994544983, Validation Loss: 0.43516042828559875
Epoch 7, Training Loss: 0.43516042828559875, Validation Loss: 0.43400487303733826
Epoch 8, Training Loss: 0.43400487303733826, Validation Loss: 0.43285807967185974
Epoch 9, Training Loss: 0.43285804986953735, Validation Loss: 0.43170827627182007
Epoch 10, Training Loss: 0.43170827627182007, Validation Loss: 0.43054714798927307
Epoch 11, Training Loss: 0.43054714798927307, Validation Loss: 0.4294280409812927
Epoch 12, Training Loss: 0.4294280409812927, Validation Loss: 0.42828670144081116
Epoch 13, Training Loss: 0.4282867908477783, Validation Loss: 0.4271067678928375
Epoch 14, Training Loss: 0.4271067678928375, Validation Loss: 0.42588165402412415
Epoch 15, Training Loss: 0.42588168382644653, Validation Loss: 0.4246249794960022
Epoch 16, Training Loss: 0.4246249794960022, Validation Loss: 0.4233417809009552
Epoch 17, Training Loss: 0.4233417809009552, Validation Loss: 0.42199885845184326
Epoch 18, Training Loss: 0.42199885845184326, Validation Loss: 0.42061641812324524
Epoch 19, Training Loss: 0.42061638832092285, Validation Loss: 0.4192037880420685
Epoch 20, Training Loss: 0.4192037284374237, Validation Loss: 0.4177393615245819
Epoch 21, Training Loss: 0.4177393615245819, Validation Loss: 0.4161975085735321
Epoch 22, Training Loss: 0.4161975085735321, Validation Loss: 0.41459181904792786
Epoch 23, Training Loss: 0.41459181904792786, Validation Loss: 0.41291385889053345
Epoch 24, Training Loss: 0.41291385889053345, Validation Loss: 0.4111732542514801
Epoch 25, Training Loss: 0.4111732542514801, Validation Loss: 0.4094211161136627
Epoch 26, Training Loss: 0.4094211161136627, Validation Loss: 0.4075968861579895
Epoch 27, Training Loss: 0.4075968861579895, Validation Loss: 0.40567678213119507
Epoch 28, Training Loss: 0.40567678213119507, Validation Loss: 0.4036560356616974
Epoch 29, Training Loss: 0.4036559760570526, Validation Loss: 0.401520311832428
Epoch 30, Training Loss: 0.401520311832428, Validation Loss: 0.39925628900527954
Epoch 31, Training Loss: 0.39925628900527954, Validation Loss: 0.3968573808670044
Epoch 32, Training Loss: 0.3968573808670044, Validation Loss: 0.3943023681640625
Epoch 33, Training Loss: 0.3943023681640625, Validation Loss: 0.3915845453739166
Epoch 34, Training Loss: 0.39158451557159424, Validation Loss: 0.3886864483356476
Epoch 35, Training Loss: 0.3886864483356476, Validation Loss: 0.3855951130390167
Epoch 36, Training Loss: 0.3855951130390167, Validation Loss: 0.38225996494293213
Epoch 37, Training Loss: 0.38225996494293213, Validation Loss: 0.37873172760009766
Epoch 38, Training Loss: 0.37873172760009766, Validation Loss: 0.37500134110450745
Epoch 39, Training Loss: 0.37500134110450745, Validation Loss: 0.37098944187164307
Epoch 40, Training Loss: 0.37098944187164307, Validation Loss: 0.3666779696941376
Epoch 41, Training Loss: 0.36667799949645996, Validation Loss: 0.3620629906654358
Epoch 42, Training Loss: 0.3620629906654358, Validation Loss: 0.35714268684387207
Epoch 43, Training Loss: 0.35714268684387207, Validation Loss: 0.35194912552833557
Epoch 44, Training Loss: 0.35194912552833557, Validation Loss: 0.3464362621307373
Epoch 45, Training Loss: 0.3464362919330597, Validation Loss: 0.3405533730983734
Epoch 46, Training Loss: 0.3405533730983734, Validation Loss: 0.3343023955821991
Epoch 47, Training Loss: 0.3343024253845215, Validation Loss: 0.3276754319667816
Epoch 48, Training Loss: 0.3276754319667816, Validation Loss: 0.32064324617385864
Epoch 49, Training Loss: 0.32064321637153625, Validation Loss: 0.31320545077323914
Epoch 50, Training Loss: 0.31320545077323914, Validation Loss: 0.305364191532135
Epoch 51, Training Loss: 0.3053642213344574, Validation Loss: 0.2971402108669281
Epoch 52, Training Loss: 0.2971402406692505, Validation Loss: 0.2885594069957733
Epoch 53, Training Loss: 0.2885593771934509, Validation Loss: 0.27964454889297485
Epoch 54, Training Loss: 0.27964451909065247, Validation Loss: 0.27047058939933777
Epoch 55, Training Loss: 0.2704705595970154, Validation Loss: 0.26111388206481934
Epoch 56, Training Loss: 0.26111388206481934, Validation Loss: 0.25163084268569946
Epoch 57, Training Loss: 0.25163084268569946, Validation Loss: 0.24212470650672913
Epoch 58, Training Loss: 0.24212470650672913, Validation Loss: 0.23273590207099915
Epoch 59, Training Loss: 0.23273590207099915, Validation Loss: 0.22358064353466034
Epoch 60, Training Loss: 0.22358062863349915, Validation Loss: 0.21480931341648102
Epoch 61, Training Loss: 0.21480931341648102, Validation Loss: 0.2065768539905548
Epoch 62, Training Loss: 0.20657683908939362, Validation Loss: 0.1988716572523117
Epoch 63, Training Loss: 0.1988716572523117, Validation Loss: 0.19163835048675537
Epoch 64, Training Loss: 0.19163835048675537, Validation Loss: 0.18483462929725647
Epoch 65, Training Loss: 0.18483465909957886, Validation Loss: 0.1783684641122818
Epoch 66, Training Loss: 0.1783684492111206, Validation Loss: 0.17221218347549438
Epoch 67, Training Loss: 0.1722121685743332, Validation Loss: 0.16617584228515625
Epoch 68, Training Loss: 0.16617584228515625, Validation Loss: 0.16012294590473175
Epoch 69, Training Loss: 0.16012293100357056, Validation Loss: 0.153806671500206
Epoch 70, Training Loss: 0.153806671500206, Validation Loss: 0.14722448587417603
Epoch 71, Training Loss: 0.14722450077533722, Validation Loss: 0.1403137892484665
Epoch 72, Training Loss: 0.1403137892484665, Validation Loss: 0.13314251601696014
Epoch 73, Training Loss: 0.13314251601696014, Validation Loss: 0.12576863169670105
Epoch 74, Training Loss: 0.12576864659786224, Validation Loss: 0.11825491487979889
Epoch 75, Training Loss: 0.11825490742921829, Validation Loss: 0.11071006208658218
Epoch 76, Training Loss: 0.11071005463600159, Validation Loss: 0.10325752943754196
Epoch 77, Training Loss: 0.10325754433870316, Validation Loss: 0.09599530696868896
Epoch 78, Training Loss: 0.09599532186985016, Validation Loss: 0.08907021582126617
Epoch 79, Training Loss: 0.08907022327184677, Validation Loss: 0.08243487775325775
Epoch 80, Training Loss: 0.08243487775325775, Validation Loss: 0.07596712559461594
Epoch 81, Training Loss: 0.07596712559461594, Validation Loss: 0.06966804713010788
Epoch 82, Training Loss: 0.06966804713010788, Validation Loss: 0.06356903165578842
Epoch 83, Training Loss: 0.06356903165578842, Validation Loss: 0.05778121203184128
Epoch 84, Training Loss: 0.05778121575713158, Validation Loss: 0.05219670757651329
Epoch 85, Training Loss: 0.052196696400642395, Validation Loss: 0.046836450695991516
Epoch 86, Training Loss: 0.046836454421281815, Validation Loss: 0.041873831301927567
Epoch 87, Training Loss: 0.041873831301927567, Validation Loss: 0.037205830216407776
Epoch 88, Training Loss: 0.037205830216407776, Validation Loss: 0.03291737288236618
Epoch 89, Training Loss: 0.03291737288236618, Validation Loss: 0.028987538069486618
Epoch 90, Training Loss: 0.028987538069486618, Validation Loss: 0.0253907423466444
Epoch 91, Training Loss: 0.0253907423466444, Validation Loss: 0.022118065506219864
Epoch 92, Training Loss: 0.022118059918284416, Validation Loss: 0.019127169623970985
Epoch 93, Training Loss: 0.019127169623970985, Validation Loss: 0.016429085284471512
Epoch 94, Training Loss: 0.016429085284471512, Validation Loss: 0.01400645263493061
Epoch 95, Training Loss: 0.01400645263493061, Validation Loss: 0.011872949078679085
Epoch 96, Training Loss: 0.01187295001000166, Validation Loss: 0.010034059174358845
Epoch 97, Training Loss: 0.010034057311713696, Validation Loss: 0.008410691283643246
Epoch 98, Training Loss: 0.008410691283643246, Validation Loss: 0.007029226515442133
Epoch 99, Training Loss: 0.007029226049780846, Validation Loss: 0.005845041014254093
Epoch 100, Training Loss: 0.0058450400829315186, Validation Loss: 0.004849132150411606
Epoch 101, Training Loss: 0.004849132616072893, Validation Loss: 0.00403356971219182
Epoch 102, Training Loss: 0.004033569246530533, Validation Loss: 0.0033619932364672422
Epoch 103, Training Loss: 0.0033619916066527367, Validation Loss: 0.002801429247483611
Epoch 104, Training Loss: 0.00280142854899168, Validation Loss: 0.002339186379685998
Epoch 105, Training Loss: 0.002339187078177929, Validation Loss: 0.001959757646545768
Epoch 106, Training Loss: 0.0019597585778683424, Validation Loss: 0.001649939687922597
Epoch 107, Training Loss: 0.0016499400371685624, Validation Loss: 0.0013962330995127559
Epoch 108, Training Loss: 0.0013962334487587214, Validation Loss: 0.0011877529323101044
Epoch 109, Training Loss: 0.0011877530487254262, Validation Loss: 0.0010249005863443017
Epoch 110, Training Loss: 0.0010248994221910834, Validation Loss: 0.0008995990501716733
Epoch 111, Training Loss: 0.0008995987591333687, Validation Loss: 0.0008035075152292848
Epoch 112, Training Loss: 0.0008035083301365376, Validation Loss: 0.0007283453014679253
Epoch 113, Training Loss: 0.0007283445447683334, Validation Loss: 0.000667074229568243
Epoch 114, Training Loss: 0.0006670755101367831, Validation Loss: 0.0006153365247882903
Epoch 115, Training Loss: 0.0006153378635644913, Validation Loss: 0.0005665449425578117
Epoch 116, Training Loss: 0.0005665452335961163, Validation Loss: 0.0005239492165856063
Epoch 117, Training Loss: 0.0005239486927166581, Validation Loss: 0.0004879767948295921
Epoch 118, Training Loss: 0.0004879770567640662, Validation Loss: 0.0004583488334901631
Epoch 119, Training Loss: 0.000458348571555689, Validation Loss: 0.00043355918023735285
Epoch 120, Training Loss: 0.0004335598205216229, Validation Loss: 0.0004111521993763745
Epoch 121, Training Loss: 0.000411151850130409, Validation Loss: 0.00038833182770758867
Epoch 122, Training Loss: 0.00038833165308460593, Validation Loss: 0.0003628171980381012
Epoch 123, Training Loss: 0.00036281728534959257, Validation Loss: 0.00033478709519840777
Epoch 124, Training Loss: 0.0003347874153405428, Validation Loss: 0.0003047391364816576
Epoch 125, Training Loss: 0.0003047393693123013, Validation Loss: 0.0002746864629443735
Epoch 126, Training Loss: 0.00027468655025586486, Validation Loss: 0.00024646142264828086
Epoch 127, Training Loss: 0.00024646130623295903, Validation Loss: 0.00022184164845384657
Epoch 128, Training Loss: 0.00022184161935001612, Validation Loss: 0.00020083336858078837
Epoch 129, Training Loss: 0.00020083363051526248, Validation Loss: 0.00018302496755495667
Epoch 130, Training Loss: 0.0001830247783800587, Validation Loss: 0.0001672710059210658
Epoch 131, Training Loss: 0.00016727134061511606, Validation Loss: 0.00015221744251903147
Epoch 132, Training Loss: 0.0001522171514807269, Validation Loss: 0.0001371884427499026
Epoch 133, Training Loss: 0.00013718847185373306, Validation Loss: 0.0001221322308992967
Epoch 134, Training Loss: 0.0001221321726916358, Validation Loss: 0.00010741093865362927
Epoch 135, Training Loss: 0.00010741082223830745, Validation Loss: 9.332099580205977e-05
Epoch 136, Training Loss: 9.332082117907703e-05, Validation Loss: 8.019608503673226e-05
Epoch 137, Training Loss: 8.019607048481703e-05, Validation Loss: 6.853508966742083e-05
Epoch 138, Training Loss: 6.853525701444596e-05, Validation Loss: 5.832023816765286e-05
Epoch 139, Training Loss: 5.832026727148332e-05, Validation Loss: 4.9408325139665976e-05
Epoch 140, Training Loss: 4.9408463382860646e-05, Validation Loss: 4.1684324969537556e-05
Epoch 141, Training Loss: 4.16841940023005e-05, Validation Loss: 3.513945921440609e-05
Epoch 142, Training Loss: 3.513940828270279e-05, Validation Loss: 2.9917830033809878e-05
Epoch 143, Training Loss: 2.9917704523541033e-05, Validation Loss: 2.589847645140253e-05
Epoch 144, Training Loss: 2.589838913991116e-05, Validation Loss: 2.3016675186227076e-05
Epoch 145, Training Loss: 2.3016782506601885e-05, Validation Loss: 2.1086558263050392e-05
Epoch 146, Training Loss: 2.1086470951559022e-05, Validation Loss: 1.9836155843222514e-05
Epoch 147, Training Loss: 1.9836070350720547e-05, Validation Loss: 1.897920446936041e-05
Epoch 148, Training Loss: 1.8979158994625323e-05, Validation Loss: 1.828422500693705e-05
Epoch 149, Training Loss: 1.8284283214597963e-05, Validation Loss: 1.7604732420295477e-05
Epoch 150, Training Loss: 1.7604766981094144e-05, Validation Loss: 1.687854455667548e-05
Epoch 151, Training Loss: 1.6878464521141723e-05, Validation Loss: 1.608674028830137e-05
Epoch 152, Training Loss: 1.608680213394109e-05, Validation Loss: 1.5224048183881678e-05
Epoch 153, Training Loss: 1.5224070921249222e-05, Validation Loss: 1.4278284652391449e-05
Epoch 154, Training Loss: 1.4278292837843765e-05, Validation Loss: 1.323359083471587e-05
Epoch 155, Training Loss: 1.3233559911896009e-05, Validation Loss: 1.2102798791602254e-05
Epoch 156, Training Loss: 1.2102778782718815e-05, Validation Loss: 1.0924821253865957e-05
Epoch 157, Training Loss: 1.0924770322162658e-05, Validation Loss: 9.764024071046151e-06
Epoch 158, Training Loss: 9.764045898918994e-06, Validation Loss: 8.690308277436998e-06
Epoch 159, Training Loss: 8.690328286320437e-06, Validation Loss: 7.753642421448603e-06
Epoch 160, Training Loss: 7.75355329096783e-06, Validation Loss: 6.965491593291517e-06
Epoch 161, Training Loss: 6.965437933104113e-06, Validation Loss: 6.298535026871832e-06
Epoch 162, Training Loss: 6.298440439422848e-06, Validation Loss: 5.7019051382667385e-06
Epoch 163, Training Loss: 5.701889676856808e-06, Validation Loss: 5.126000814925646e-06
Epoch 164, Training Loss: 5.1260767577332444e-06, Validation Loss: 4.542623628367437e-06
Epoch 165, Training Loss: 4.542647729977034e-06, Validation Loss: 3.953115992771927e-06
Epoch 166, Training Loss: 3.953088253183523e-06, Validation Loss: 3.3815235838119406e-06
Epoch 167, Training Loss: 3.381456053830334e-06, Validation Loss: 2.8587994620465906e-06
Epoch 168, Training Loss: 2.8587910492205992e-06, Validation Loss: 2.4073156055237632e-06
Epoch 169, Training Loss: 2.4073253825918073e-06, Validation Loss: 2.0319798750279006e-06
Epoch 170, Training Loss: 2.0320137537055416e-06, Validation Loss: 1.7219707615367952e-06
Epoch 171, Training Loss: 1.7219609844687511e-06, Validation Loss: 1.4591959143217537e-06
Epoch 172, Training Loss: 1.4591804529118235e-06, Validation Loss: 1.2286641322134528e-06
Epoch 173, Training Loss: 1.2287184745218838e-06, Validation Loss: 1.0248166972814943e-06
Epoch 174, Training Loss: 1.0248193120787619e-06, Validation Loss: 8.495674705955025e-07
Epoch 175, Training Loss: 8.495318297718768e-07, Validation Loss: 7.097804655131768e-07
Epoch 176, Training Loss: 7.097965522007144e-07, Validation Loss: 6.100939913267212e-07
Epoch 177, Training Loss: 6.100861469349184e-07, Validation Loss: 5.486442660185276e-07
Epoch 178, Training Loss: 5.486486998051987e-07, Validation Loss: 5.17331443461444e-07
Epoch 179, Training Loss: 5.173016006665421e-07, Validation Loss: 5.048618731962051e-07
Epoch 180, Training Loss: 5.0484067060097e-07, Validation Loss: 5.009783308196347e-07
Epoch 181, Training Loss: 5.009778760722838e-07, Validation Loss: 4.99298153044947e-07
Epoch 182, Training Loss: 4.993027005184558e-07, Validation Loss: 4.975794354322716e-07
Epoch 183, Training Loss: 4.975826755071466e-07, Validation Loss: 4.960544970344927e-07
Epoch 184, Training Loss: 4.960790533914405e-07, Validation Loss: 4.953193979417847e-07
Epoch 185, Training Loss: 4.953005259267229e-07, Validation Loss: 4.944312763655034e-07
Epoch 186, Training Loss: 4.944300826537074e-07, Validation Loss: 4.912686790703447e-07
Epoch 187, Training Loss: 4.912516260446864e-07, Validation Loss: 4.83240569337795e-07
Epoch 188, Training Loss: 4.832463673665188e-07, Validation Loss: 4.684697501033952e-07
Epoch 189, Training Loss: 4.684786176767375e-07, Validation Loss: 4.464569656192907e-07
Epoch 190, Training Loss: 4.464362746148254e-07, Validation Loss: 4.1789442661865905e-07
Epoch 191, Training Loss: 4.179051416031143e-07, Validation Loss: 3.8411621972045396e-07
Epoch 192, Training Loss: 3.841171860585746e-07, Validation Loss: 3.46303750120569e-07
Epoch 193, Training Loss: 3.4630386380740674e-07, Validation Loss: 3.05569756164914e-07
Epoch 194, Training Loss: 3.055708646115818e-07, Validation Loss: 2.629918185448332e-07
Epoch 195, Training Loss: 2.629919606533804e-07, Validation Loss: 2.20189761535039e-07
Epoch 196, Training Loss: 2.2018926415512396e-07, Validation Loss: 1.7925913198268972e-07
Epoch 197, Training Loss: 1.7923915152096015e-07, Validation Loss: 1.4248321633658634e-07
Epoch 198, Training Loss: 1.4248753643641976e-07, Validation Loss: 1.1174520153645062e-07
Epoch 199, Training Loss: 1.1175131220397816e-07, Validation Loss: 8.783961646940952e-08
Epoch 200, Training Loss: 8.784000016248683e-08, Validation Loss: 7.034065419020408e-08
Epoch 201, Training Loss: 7.033921889387784e-08, Validation Loss: 5.788705692566509e-08
Epoch 202, Training Loss: 5.787854107097701e-08, Validation Loss: 4.8762089477349946e-08
Epoch 203, Training Loss: 4.876006087783935e-08, Validation Loss: 4.158114208507868e-08
Epoch 204, Training Loss: 4.157424626782813e-08, Validation Loss: 3.553326877181462e-08
Epoch 205, Training Loss: 3.5527978781146885e-08, Validation Loss: 3.043357565957194e-08
Epoch 206, Training Loss: 3.0431884567860834e-08, Validation Loss: 2.6375882811180418e-08
Epoch 207, Training Loss: 2.6374534556339313e-08, Validation Loss: 2.3419032046945176e-08
Epoch 208, Training Loss: 2.341209359713048e-08, Validation Loss: 2.137408117164341e-08
Epoch 209, Training Loss: 2.137553956060856e-08, Validation Loss: 1.9915601612296996e-08
Epoch 210, Training Loss: 1.9913114712721836e-08, Validation Loss: 1.8682385416468605e-08
Epoch 211, Training Loss: 1.8683042668499183e-08, Validation Loss: 1.7498814841587773e-08
Epoch 212, Training Loss: 1.74940595343287e-08, Validation Loss: 1.6402792013536782e-08
Epoch 213, Training Loss: 1.6407216918423728e-08, Validation Loss: 1.5593757396459296e-08
Epoch 214, Training Loss: 1.559027751341091e-08, Validation Loss: 1.5224912885969388e-08
Epoch 215, Training Loss: 1.5220269489191196e-08, Validation Loss: 1.5308328826790785e-08
Epoch 216, Training Loss: 1.5314338241978476e-08, Validation Loss: 1.5707501077599773e-08
Epoch 217, Training Loss: 1.5709185063883524e-08, Validation Loss: 1.6151139092812627e-08
Epoch 218, Training Loss: 1.6147390979881493e-08, Validation Loss: 1.6392780466389922e-08
Epoch 219, Training Loss: 1.6390931278920107e-08, Validation Loss: 1.6283236092817788e-08
Epoch 220, Training Loss: 1.6279281922493283e-08, Validation Loss: 1.579965491771418e-08
Epoch 221, Training Loss: 1.5808405251505064e-08, Validation Loss: 1.50282168931426e-08
Epoch 222, Training Loss: 1.5029090860707583e-08, Validation Loss: 1.4045732577017134e-08
Epoch 223, Training Loss: 1.4041870777248278e-08, Validation Loss: 1.293529283685757e-08
Epoch 224, Training Loss: 1.2938902393955232e-08, Validation Loss: 1.1759930806931607e-08
Epoch 225, Training Loss: 1.1764705654115915e-08, Validation Loss: 1.0547177353714687e-08
Epoch 226, Training Loss: 1.0549394247050259e-08, Validation Loss: 9.33201693698038e-09
Epoch 227, Training Loss: 9.333868788985455e-09, Validation Loss: 8.153255848242225e-09
Epoch 228, Training Loss: 8.155033981438464e-09, Validation Loss: 7.045228400670567e-09
Epoch 229, Training Loss: 7.0444978739203634e-09, Validation Loss: 6.0260187950689215e-09
Epoch 230, Training Loss: 6.0268536827834396e-09, Validation Loss: 5.087326115926771e-09
Epoch 231, Training Loss: 5.089990651185872e-09, Validation Loss: 4.218143168088773e-09
Epoch 232, Training Loss: 4.221346383559421e-09, Validation Loss: 3.4035638751817032e-09
Epoch 233, Training Loss: 3.4070699594934695e-09, Validation Loss: 2.6546544962258167e-09
Epoch 234, Training Loss: 2.6546604914301497e-09, Validation Loss: 1.9992525412959594e-09
Epoch 235, Training Loss: 1.99683736212819e-09, Validation Loss: 1.4650493040946344e-09
Epoch 236, Training Loss: 1.4629528699572347e-09, Validation Loss: 1.077151368100715e-09
Epoch 237, Training Loss: 1.076604805305692e-09, Validation Loss: 8.288172925752235e-10
Epoch 238, Training Loss: 8.302337151100403e-10, Validation Loss: 6.927987072913311e-10
Epoch 239, Training Loss: 6.935793606110963e-10, Validation Loss: 6.290520881968575e-10
Epoch 240, Training Loss: 6.289036513784652e-10, Validation Loss: 6.04452654595633e-10
Epoch 241, Training Loss: 6.048056500063126e-10, Validation Loss: 5.991210305644756e-10
Epoch 242, Training Loss: 5.991613316602695e-10, Validation Loss: 6.046181888486046e-10
Epoch 243, Training Loss: 6.046980138840752e-10, Validation Loss: 6.224071813498711e-10
Epoch 244, Training Loss: 6.225815973870397e-10, Validation Loss: 6.482306358357448e-10
Epoch 245, Training Loss: 6.488479753485876e-10, Validation Loss: 6.730768720153435e-10
Epoch 246, Training Loss: 6.739481195339181e-10, Validation Loss: 6.886766157343516e-10
Epoch 247, Training Loss: 6.889928072517648e-10, Validation Loss: 6.865276680478871e-10
Epoch 248, Training Loss: 6.853668743644903e-10, Validation Loss: 6.648468442449484e-10
Epoch 249, Training Loss: 6.636569072071552e-10, Validation Loss: 6.291531184920984e-10
Epoch 250, Training Loss: 6.29795604556449e-10, Validation Loss: 5.914145839724938e-10
Epoch 251, Training Loss: 5.909786549018747e-10, Validation Loss: 5.54911006034331e-10
Epoch 252, Training Loss: 5.54690182674733e-10, Validation Loss: 5.242372647096261e-10
Epoch 253, Training Loss: 5.26106436193885e-10, Validation Loss: 4.972542377856826e-10
Epoch 254, Training Loss: 4.966506095271939e-10, Validation Loss: 4.667142228242938e-10
Epoch 255, Training Loss: 4.655562324540341e-10, Validation Loss: 4.3170461649921776e-10
Epoch 256, Training Loss: 4.308188250590206e-10, Validation Loss: 3.8839795268863497e-10
Epoch 257, Training Loss: 3.893299849178078e-10, Validation Loss: 3.4358135780898635e-10
Epoch 258, Training Loss: 3.442549023624508e-10, Validation Loss: 2.972810608792287e-10
Epoch 259, Training Loss: 2.976099922058495e-10, Validation Loss: 2.521807762612127e-10
Epoch 260, Training Loss: 2.520778863424056e-10, Validation Loss: 2.095881523889176e-10
Epoch 261, Training Loss: 2.0952570234378243e-10, Validation Loss: 1.723844261780627e-10
Epoch 262, Training Loss: 1.7200672830508523e-10, Validation Loss: 1.3956362454603521e-10
Epoch 263, Training Loss: 1.3949676136437716e-10, Validation Loss: 1.127009874313245e-10
Epoch 264, Training Loss: 1.1270585159595115e-10, Validation Loss: 9.243938947633978e-11
Epoch 265, Training Loss: 9.201855249996171e-11, Validation Loss: 7.792887168900364e-11
Epoch 266, Training Loss: 7.769843102245488e-11, Validation Loss: 6.815129016679577e-11
Epoch 267, Training Loss: 6.76999081794527e-11, Validation Loss: 6.062916835247734e-11
Epoch 268, Training Loss: 6.05186317725881e-11, Validation Loss: 5.427725630058333e-11
Epoch 269, Training Loss: 5.424517432461862e-11, Validation Loss: 4.869770559023934e-11
Epoch 270, Training Loss: 4.8741174291100364e-11, Validation Loss: 4.361203412295289e-11
Epoch 271, Training Loss: 4.3715128739130193e-11, Validation Loss: 3.94926487345959e-11
Epoch 272, Training Loss: 3.955261812516042e-11, Validation Loss: 3.6453961377302946e-11
Epoch 273, Training Loss: 3.631778905388572e-11, Validation Loss: 3.441499515921542e-11
Epoch 274, Training Loss: 3.437633164238285e-11, Validation Loss: 3.303306239654802e-11
Epoch 275, Training Loss: 3.2927514881375686e-11, Validation Loss: 3.1452351140215384e-11
Epoch 276, Training Loss: 3.1593273136509836e-11, Validation Loss: 3.000259415908424e-11
Epoch 277, Training Loss: 3.009373306106511e-11, Validation Loss: 2.8243874253264245e-11
Epoch 278, Training Loss: 2.828635242702049e-11, Validation Loss: 2.6566150321261084e-11
Epoch 279, Training Loss: 2.6677566405952646e-11, Validation Loss: 2.5220494095923307e-11
Epoch 280, Training Loss: 2.518624024616667e-11, Validation Loss: 2.4221400926616177e-11
Epoch 281, Training Loss: 2.408219283711599e-11, Validation Loss: 2.2996618498360988e-11
Epoch 282, Training Loss: 2.315426149424038e-11, Validation Loss: 2.19160401632168e-11
Epoch 283, Training Loss: 2.186594134923059e-11, Validation Loss: 2.020069875263708e-11
Epoch 284, Training Loss: 2.0199980577118026e-11, Validation Loss: 1.8381303423797846e-11
Epoch 285, Training Loss: 1.8481815036719418e-11, Validation Loss: 1.6086323245678713e-11
Epoch 286, Training Loss: 1.620259308665606e-11, Validation Loss: 1.3916008102798916e-11
Epoch 287, Training Loss: 1.3913366986306741e-11, Validation Loss: 1.198074191938181e-11
Epoch 288, Training Loss: 1.196381362034149e-11, Validation Loss: 1.0308487570498404e-11
Epoch 289, Training Loss: 1.0233165009809753e-11, Validation Loss: 8.76014018269533e-12
Epoch 290, Training Loss: 8.795174658016158e-12, Validation Loss: 7.53169315109714e-12
Epoch 291, Training Loss: 7.572920589227206e-12, Validation Loss: 6.373546655724649e-12
Epoch 292, Training Loss: 6.420954913599619e-12, Validation Loss: 5.460435922866047e-12
Epoch 293, Training Loss: 5.4595828725967355e-12, Validation Loss: 4.618570716846682e-12
Epoch 294, Training Loss: 4.58440880743427e-12, Validation Loss: 4.01772972530301e-12
Epoch 295, Training Loss: 3.955347768064277e-12, Validation Loss: 3.4894036445021204e-12
Epoch 296, Training Loss: 3.4302925083773417e-12, Validation Loss: 3.0480921606179656e-12
Epoch 297, Training Loss: 2.984789932575227e-12, Validation Loss: 2.660180235813936e-12
Epoch 298, Training Loss: 2.642851866171969e-12, Validation Loss: 2.3763460817172177e-12
Epoch 299, Training Loss: 2.3854919775634364e-12, Validation Loss: 2.166781294318798e-12
Epoch 300, Training Loss: 2.221123025086813e-12, Validation Loss: 2.0438609572154265e-12
Epoch 301, Training Loss: 2.0228094373131444e-12, Validation Loss: 1.990119657610534e-12
Epoch 302, Training Loss: 1.9398885709592806e-12, Validation Loss: 1.9259756550010776e-12
Epoch 303, Training Loss: 1.939065227829495e-12, Validation Loss: 1.8920537879496546e-12
Epoch 304, Training Loss: 1.9054545268015755e-12, Validation Loss: 1.830020076448724e-12
Epoch 305, Training Loss: 1.8395352515548913e-12, Validation Loss: 1.7773379339461326e-12
Epoch 306, Training Loss: 1.8031419456512876e-12, Validation Loss: 1.6958134115702128e-12
Epoch 307, Training Loss: 1.7359501423147572e-12, Validation Loss: 1.564147357642487e-12
Epoch 308, Training Loss: 1.5767891549736679e-12, Validation Loss: 1.4303945397933782e-12
Epoch 309, Training Loss: 1.4257890658050942e-12, Validation Loss: 1.2911290959982669e-12
Epoch 310, Training Loss: 1.297345585994647e-12, Validation Loss: 1.1418165675111669e-12
Epoch 311, Training Loss: 1.155342640134227e-12, Validation Loss: 1.0369528586490206e-12
Epoch 312, Training Loss: 1.014078578054356e-12, Validation Loss: 9.184682094737218e-13
Epoch 313, Training Loss: 9.02172596611156e-13, Validation Loss: 7.718673790402253e-13
Epoch 314, Training Loss: 7.745695361147109e-13, Validation Loss: 6.691521252030763e-13
Epoch 315, Training Loss: 6.920247252843736e-13, Validation Loss: 5.66660704904437e-13
Epoch 316, Training Loss: 5.886430665819065e-13, Validation Loss: 4.875344919441638e-13
Epoch 317, Training Loss: 4.720594574958437e-13, Validation Loss: 4.162318276504373e-13
Epoch 318, Training Loss: 4.286886871960466e-13, Validation Loss: 3.7252788202303544e-13
Epoch 319, Training Loss: 3.5285384098089623e-13, Validation Loss: 2.79429772506376e-13
Epoch 320, Training Loss: 3.154431739687408e-13, Validation Loss: 2.8138000826918863e-13
Epoch 321, Training Loss: 2.7954510451247416e-13, Validation Loss: 2.3340113479083935e-13
Epoch 322, Training Loss: 2.4292750428443755e-13, Validation Loss: 2.0050480102184326e-13
Epoch 323, Training Loss: 2.1237212563616353e-13, Validation Loss: 1.726282826538736e-13
Epoch 324, Training Loss: 1.7294631980864505e-13, Validation Loss: 1.6120088662356646e-13
Epoch 325, Training Loss: 1.5665025971268315e-13, Validation Loss: 1.2024254747271257e-13
Epoch 326, Training Loss: 1.3065930444793733e-13, Validation Loss: 1.0584417321551562e-13
Epoch 327, Training Loss: 1.0380093323509448e-13, Validation Loss: 8.571311385261945e-14
Epoch 328, Training Loss: 8.186469758380069e-14, Validation Loss: 7.34685885262279e-14
Epoch 329, Training Loss: 6.874509913146892e-14, Validation Loss: 5.6054749871751325e-14
Epoch 330, Training Loss: 4.754947859606819e-14, Validation Loss: 4.646367044911469e-14
Epoch 331, Training Loss: 4.621373474330247e-14, Validation Loss: 3.9811829234768364e-14
Epoch 332, Training Loss: 4.035981889406043e-14, Validation Loss: 3.3710041051973616e-14
Epoch 333, Training Loss: 3.776303949447682e-14, Validation Loss: 3.250067790307003e-14
Epoch 334, Training Loss: 3.566767649461344e-14, Validation Loss: 3.394111841624817e-14
Epoch 335, Training Loss: 3.0843708663519376e-14, Validation Loss: 3.293891242118867e-14
Epoch 336, Training Loss: 3.626664059667127e-14, Validation Loss: 3.246239879011771e-14
Epoch 337, Training Loss: 3.175705751428011e-14, Validation Loss: 3.304611629912496e-14
Epoch 338, Training Loss: 3.282406491793635e-14, Validation Loss: 2.675631729522586e-14
Epoch 339, Training Loss: 3.073065348198345e-14, Validation Loss: 3.048058563903146e-14
Epoch 340, Training Loss: 2.773743725209641e-14, Validation Loss: 3.021699237397771e-14
Epoch 341, Training Loss: 3.000351974247889e-14, Validation Loss: 2.5483421593080514e-14
Epoch 342, Training Loss: 3.0495381610554095e-14, Validation Loss: 2.798363415447945e-14
Epoch 343, Training Loss: 3.037901961239209e-14, Validation Loss: 2.44093719575008e-14
Epoch 344, Training Loss: 3.096177150383947e-14, Validation Loss: 2.6394093819727925e-14
Epoch 345, Training Loss: 2.670684379484263e-14, Validation Loss: 2.6518827891540593e-14
Epoch 346, Training Loss: 2.6777233926825357e-14, Validation Loss: 2.5305087276365594e-14
Epoch 347, Training Loss: 2.5851692883821845e-14, Validation Loss: 2.2268857019351086e-14
Epoch 348, Training Loss: 2.620010464008185e-14, Validation Loss: 2.688695518668089e-14
Epoch 349, Training Loss: 2.2473234211062287e-14, Validation Loss: 2.1129477426615542e-14
Epoch 350, Training Loss: 2.2466037819142415e-14, Validation Loss: 2.2858454631078176e-14
Epoch 351, Training Loss: 2.1968338199994733e-14, Validation Loss: 2.092917276931474e-14
Epoch 352, Training Loss: 2.0662713144767482e-14, Validation Loss: 1.8989790886688243e-14
Epoch 353, Training Loss: 1.871947387409919e-14, Validation Loss: 1.7691824703370065e-14
Epoch 354, Training Loss: 1.7653142402734856e-14, Validation Loss: 1.6357447961781214e-14
Epoch 355, Training Loss: 1.5304538574499073e-14, Validation Loss: 1.4282273145182697e-14
Epoch 356, Training Loss: 1.2727013927872448e-14, Validation Loss: 1.363321551462425e-14
Epoch 357, Training Loss: 1.4497815925204605e-14, Validation Loss: 1.1559778809633499e-14
Epoch 358, Training Loss: 1.4129459084135602e-14, Validation Loss: 1.3201185512844247e-14
Epoch 359, Training Loss: 1.0920711932687916e-14, Validation Loss: 1.2816677447536999e-14
Epoch 360, Training Loss: 8.91417050173952e-15, Validation Loss: 1.0773073242948544e-14
Epoch 361, Training Loss: 8.207454491428526e-15, Validation Loss: 1.1030062192112552e-14
Epoch 362, Training Loss: 7.370929834917862e-15, Validation Loss: 1.0573979842762316e-14
Epoch 363, Training Loss: 5.9460882804963575e-15, Validation Loss: 1.2105215511622539e-14
Epoch 364, Training Loss: 7.261867566695293e-15, Validation Loss: 1.0924315210845536e-14
Epoch 365, Training Loss: 6.797970914890162e-15, Validation Loss: 1.0620805518152428e-14
Epoch 366, Training Loss: 7.610634229760199e-15, Validation Loss: 9.845471368784362e-15
Epoch 367, Training Loss: 6.836105608724972e-15, Validation Loss: 9.75379360477124e-15
Epoch 368, Training Loss: 4.114587478647484e-15, Validation Loss: 1.0969517971108709e-14
Epoch 369, Training Loss: 4.8356988138970654e-15, Validation Loss: 1.0310815176379877e-14
Epoch 370, Training Loss: 3.897154968120252e-15, Validation Loss: 9.409309540287653e-15
Epoch 371, Training Loss: 3.831002118456165e-15, Validation Loss: 7.955661242362976e-15
Epoch 372, Training Loss: 4.138848619839215e-15, Validation Loss: 7.694327014179554e-15
Epoch 373, Training Loss: 3.3693486216536004e-15, Validation Loss: 7.787897049796842e-15
Epoch 374, Training Loss: 3.319700420725e-15, Validation Loss: 8.798294700489238e-15
Epoch 375, Training Loss: 4.5993927152391135e-15, Validation Loss: 9.924488531334874e-15
Epoch 376, Training Loss: 4.1394072380679294e-15, Validation Loss: 9.55759451616578e-15
Epoch 377, Training Loss: 5.585278079470917e-15, Validation Loss: 9.339820651360804e-15
Epoch 378, Training Loss: 6.227909694575019e-15, Validation Loss: 9.011561502981873e-15
Epoch 379, Training Loss: 3.9495261682160384e-15, Validation Loss: 9.76601629020012e-15
Epoch 380, Training Loss: 4.527363998019923e-15, Validation Loss: 7.962516280005105e-15
Epoch 381, Training Loss: 4.6816209796926665e-15, Validation Loss: 8.017844472119756e-15
Epoch 382, Training Loss: 3.861363590934022e-15, Validation Loss: 5.9388321727537035e-15
Epoch 383, Training Loss: 3.3468181805313465e-15, Validation Loss: 5.039078624312875e-15
Epoch 384, Training Loss: 2.974144436046662e-15, Validation Loss: 5.106332193291919e-15
Epoch 385, Training Loss: 3.1674077084569395e-15, Validation Loss: 4.78505810211252e-15
Epoch 386, Training Loss: 2.5916963548671366e-15, Validation Loss: 3.671349113392938e-15
Epoch 387, Training Loss: 2.8845518553914434e-15, Validation Loss: 4.4924861458673065e-15
Epoch 388, Training Loss: 3.698579105064796e-15, Validation Loss: 5.964219444248809e-15
Epoch 389, Training Loss: 3.311243643779613e-15, Validation Loss: 6.405723086027378e-15
Epoch 390, Training Loss: 3.3464636972429206e-15, Validation Loss: 6.051022110134009e-15
Epoch 391, Training Loss: 3.314170989645324e-15, Validation Loss: 6.758109544392375e-15
Epoch 392, Training Loss: 2.1670850911556603e-15, Validation Loss: 6.5809009344643555e-15
Epoch 393, Training Loss: 2.540676172322221e-15, Validation Loss: 7.697395814547456e-15
Epoch 394, Training Loss: 1.7812175379680693e-15, Validation Loss: 5.0240996936736296e-15
Epoch 395, Training Loss: 1.548856177624599e-15, Validation Loss: 6.927491146371291e-15
Epoch 396, Training Loss: 3.595484183955633e-15, Validation Loss: 6.6104373968515866e-15
Epoch 397, Training Loss: 4.886743136880978e-15, Validation Loss: 5.1959292208701106e-15
Epoch 398, Training Loss: 3.908626758841391e-15, Validation Loss: 5.9634854902000135e-15
Epoch 399, Training Loss: 4.036341539595447e-15, Validation Loss: 4.873545940046282e-15
Epoch 400, Training Loss: 3.608039753332784e-15, Validation Loss: 5.163294735478297e-15
Epoch 401, Training Loss: 1.8498725229583457e-15, Validation Loss: 3.842152460173821e-15
Epoch 402, Training Loss: 3.3667882528122875e-15, Validation Loss: 4.729797249117176e-15
Epoch 403, Training Loss: 2.260293231946234e-15, Validation Loss: 4.716769458871931e-15
Epoch 404, Training Loss: 1.7511766674607483e-15, Validation Loss: 4.882936147299543e-15
Epoch 405, Training Loss: 1.58446808970513e-15, Validation Loss: 3.5903007658349105e-15
Epoch 406, Training Loss: 3.3431526454521035e-15, Validation Loss: 4.4735418304854904e-15
Epoch 407, Training Loss: 2.3695723406033002e-15, Validation Loss: 3.892676281411645e-15
Epoch 408, Training Loss: 2.706292289334118e-15, Validation Loss: 2.361849517706709e-15
Epoch 409, Training Loss: 2.137703212281303e-15, Validation Loss: 4.372577620755146e-15
Epoch 410, Training Loss: 2.830391721711056e-15, Validation Loss: 4.996940429252868e-15
Epoch 411, Training Loss: 2.3968859767786992e-15, Validation Loss: 6.454591381369794e-15
Epoch 412, Training Loss: 1.7663388748539554e-15, Validation Loss: 5.8358329663675806e-15
Epoch 413, Training Loss: 2.5261895795835676e-15, Validation Loss: 5.502228193058527e-15
Epoch 414, Training Loss: 1.2328445962673726e-15, Validation Loss: 5.25723195987822e-15
Epoch 415, Training Loss: 1.9249575468094663e-15, Validation Loss: 5.543461333414393e-15
Epoch 416, Training Loss: 1.6700449930365344e-15, Validation Loss: 4.806871318086686e-15
Epoch 417, Training Loss: 1.846719866328665e-15, Validation Loss: 5.31376039767913e-15
Epoch 418, Training Loss: 1.319981099012909e-15, Validation Loss: 4.577003940377288e-15
Epoch 419, Training Loss: 1.4292686779994478e-15, Validation Loss: 5.9251004981292904e-15
Epoch 420, Training Loss: 1.5592395310085158e-15, Validation Loss: 5.878112615929779e-15
Epoch 421, Training Loss: 2.004304628692934e-15, Validation Loss: 6.482597255221337e-15
Epoch 422, Training Loss: 2.031976771563258e-15, Validation Loss: 5.792710942539338e-15
Epoch 423, Training Loss: 1.9125059507265913e-15, Validation Loss: 5.766023051953723e-15
Epoch 424, Training Loss: 1.679786189567314e-15, Validation Loss: 6.141790584278254e-15
Epoch 425, Training Loss: 8.7423223398182e-16, Validation Loss: 5.830074412875672e-15
Epoch 426, Training Loss: 1.2591657215868263e-15, Validation Loss: 5.8106752408011806e-15
Epoch 427, Training Loss: 1.9128479402790452e-15, Validation Loss: 5.193113683353437e-15
Epoch 428, Training Loss: 1.7432787205023123e-15, Validation Loss: 5.092950343274722e-15
Epoch 429, Training Loss: 1.724063354577375e-15, Validation Loss: 5.479393455349972e-15
Epoch 430, Training Loss: 1.4018050111132664e-15, Validation Loss: 5.632032180576986e-15
Epoch 431, Training Loss: 1.2448792403819617e-15, Validation Loss: 5.653382493045478e-15
Epoch 432, Training Loss: 1.2619596597633446e-15, Validation Loss: 5.6309649190634456e-15
Epoch 433, Training Loss: 2.561000727891588e-15, Validation Loss: 5.651430929135004e-15
Epoch 434, Training Loss: 2.6597465583330735e-15, Validation Loss: 6.1672278307172475e-15
Epoch 435, Training Loss: 1.0778120500522996e-15, Validation Loss: 5.900347230795204e-15
Epoch 436, Training Loss: 1.5288401538062694e-15, Validation Loss: 5.233145730990096e-15
Epoch 437, Training Loss: 6.298530643035873e-16, Validation Loss: 4.8232173599028e-15
Epoch 438, Training Loss: 6.298530643035873e-16, Validation Loss: 4.963062923010958e-15
Epoch 439, Training Loss: 6.267839462983297e-16, Validation Loss: 5.0484645964013995e-15
Epoch 440, Training Loss: 5.947582658373551e-16, Validation Loss: 4.779720100478923e-15
Epoch 441, Training Loss: 5.711894152613266e-16, Validation Loss: 4.236351429430605e-15
Epoch 442, Training Loss: 1.2645325223406296e-15, Validation Loss: 2.6435544647551235e-15
Epoch 443, Training Loss: 1.803189149103372e-15, Validation Loss: 2.7552939923657267e-15
Epoch 444, Training Loss: 1.166679146988195e-15, Validation Loss: 2.805788590966871e-15
Epoch 445, Training Loss: 1.5663326907879417e-15, Validation Loss: 3.4629819729836957e-15
Epoch 446, Training Loss: 1.7016745797155492e-15, Validation Loss: 2.899864093495433e-15
Epoch 447, Training Loss: 1.4287891514721835e-15, Validation Loss: 2.685292013231079e-15
Epoch 448, Training Loss: 1.6663128599918135e-15, Validation Loss: 2.7438389305452964e-15
Epoch 449, Training Loss: 1.6466137323748755e-15, Validation Loss: 2.762604098458768e-15
Epoch 450, Training Loss: 1.3294845969228654e-15, Validation Loss: 3.1415744741151042e-15
Epoch 451, Training Loss: 9.810970869809747e-16, Validation Loss: 2.864018717958815e-15
Epoch 452, Training Loss: 1.0277177803978514e-15, Validation Loss: 2.9387452351150103e-15
Epoch 453, Training Loss: 1.9658029578337264e-15, Validation Loss: 3.246191513430483e-15
Epoch 454, Training Loss: 1.9658029578337264e-15, Validation Loss: 3.1020760572352153e-15
Epoch 455, Training Loss: 2.6977228570067464e-15, Validation Loss: 3.161490336287421e-15
Epoch 456, Training Loss: 9.219913396798065e-16, Validation Loss: 2.947985941053081e-15
Epoch 457, Training Loss: 9.801337987617098e-16, Validation Loss: 3.0280500363263994e-15
Epoch 458, Training Loss: 1.9802311052990193e-15, Validation Loss: 3.241554643318976e-15
Epoch 459, Training Loss: 2.6408439593239097e-15, Validation Loss: 3.238435444490712e-15
Epoch 460, Training Loss: 9.205319019116873e-16, Validation Loss: 4.764991468075592e-15
Epoch 461, Training Loss: 4.439082094971462e-16, Validation Loss: 4.934810986088238e-15
Epoch 462, Training Loss: 1.1366300179096382e-15, Validation Loss: 5.577409143390924e-15
Epoch 463, Training Loss: 2.5974841309957253e-15, Validation Loss: 4.851494284297464e-15
Epoch 464, Training Loss: 4.697789779864567e-16, Validation Loss: 4.008152283110824e-15
Epoch 465, Training Loss: 6.332433136749726e-16, Validation Loss: 4.1502662004517295e-15
Epoch 466, Training Loss: 1.1483227783508918e-15, Validation Loss: 4.267693766061382e-15
Epoch 467, Training Loss: 8.430531100120668e-16, Validation Loss: 4.267693766061382e-15
Epoch 468, Training Loss: 6.875201261438441e-16, Validation Loss: 4.8868557922629625e-15
Epoch 469, Training Loss: 1.2796863652834826e-15, Validation Loss: 6.301527022086785e-15
Epoch 470, Training Loss: 1.4097906259817432e-15, Validation Loss: 6.472330792384141e-15
Epoch 471, Training Loss: 8.8600419200364185e-16, Validation Loss: 5.736808038569975e-15
Epoch 472, Training Loss: 2.7281055053082846e-15, Validation Loss: 7.528826940681431e-15
Epoch 473, Training Loss: 2.865815910114652e-15, Validation Loss: 6.167736474002074e-15
Epoch 474, Training Loss: 2.886282343702684e-15, Validation Loss: 4.557563263688381e-15
Epoch 475, Training Loss: 2.7101412070464417e-15, Validation Loss: 5.929328886601984e-15
Epoch 476, Training Loss: 3.1644136587466324e-15, Validation Loss: 5.926372318099593e-15
Epoch 477, Training Loss: 2.546243084609813e-15, Validation Loss: 5.5259679854712234e-15
Epoch 478, Training Loss: 1.9214506186495967e-15, Validation Loss: 6.1824943290420854e-15
Epoch 479, Training Loss: 1.9765698053845126e-15, Validation Loss: 5.408540843378044e-15
Epoch 480, Training Loss: 1.9765698053845126e-15, Validation Loss: 5.2057116043779505e-15
Epoch 481, Training Loss: 3.1258410488780924e-15, Validation Loss: 5.1824304803061924e-15
Epoch 482, Training Loss: 3.1258410488780924e-15, Validation Loss: 5.337417180862995e-15
Epoch 483, Training Loss: 2.7728413386592836e-15, Validation Loss: 5.1404591507367946e-15
Epoch 484, Training Loss: 1.9426092899137723e-15, Validation Loss: 5.420462832110649e-15
Epoch 485, Training Loss: 2.1906582298359843e-15, Validation Loss: 5.692497204000261e-15
Epoch 486, Training Loss: 1.3909005207085514e-15, Validation Loss: 5.277714910608723e-15
Epoch 487, Training Loss: 2.1423860339301985e-15, Validation Loss: 5.300132908107229e-15
Epoch 488, Training Loss: 6.25437058033077e-16, Validation Loss: 4.616918673950752e-15
Epoch 489, Training Loss: 6.530091451365069e-16, Validation Loss: 4.65961972240421e-15
Epoch 490, Training Loss: 6.530091451365069e-16, Validation Loss: 4.4748047566098466e-15
Epoch 491, Training Loss: 6.594142494649664e-16, Validation Loss: 4.565544431633884e-15
Epoch 492, Training Loss: 9.749087701474532e-16, Validation Loss: 4.565544431633884e-15
Epoch 493, Training Loss: 1.3141556299181676e-15, Validation Loss: 4.609129358967802e-15
Epoch 494, Training Loss: 1.3141556299181676e-15, Validation Loss: 4.586711361469296e-15
Epoch 495, Training Loss: 7.538899750611061e-16, Validation Loss: 4.584759797558822e-15
Epoch 496, Training Loss: 7.538899750611061e-16, Validation Loss: 5.190928761865995e-15
Epoch 497, Training Loss: 6.320172864233812e-16, Validation Loss: 5.019241112688179e-15
Epoch 498, Training Loss: 1.576232282479858e-15, Validation Loss: 4.93082019035725e-15
Epoch 499, Training Loss: 1.9541350789852984e-15, Validation Loss: 4.874775408369222e-15
Epoch 500, Training Loss: 2.2692378998692394e-15, Validation Loss: 4.768022998993815e-15
