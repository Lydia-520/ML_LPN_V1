Epoch 1, Training Loss: 0.46162909269332886, Validation Loss: 0.4605060815811157
Epoch 2, Training Loss: 0.4605060815811157, Validation Loss: 0.45939871668815613
Epoch 3, Training Loss: 0.45939871668815613, Validation Loss: 0.45832404494285583
Epoch 4, Training Loss: 0.45832404494285583, Validation Loss: 0.4573073983192444
Epoch 5, Training Loss: 0.4573073983192444, Validation Loss: 0.4562917947769165
Epoch 6, Training Loss: 0.4562917649745941, Validation Loss: 0.4552752673625946
Epoch 7, Training Loss: 0.4552752673625946, Validation Loss: 0.45426467061042786
Epoch 8, Training Loss: 0.45426470041275024, Validation Loss: 0.4532530605792999
Epoch 9, Training Loss: 0.4532530903816223, Validation Loss: 0.45223376154899597
Epoch 10, Training Loss: 0.45223376154899597, Validation Loss: 0.45119813084602356
Epoch 11, Training Loss: 0.45119813084602356, Validation Loss: 0.45015865564346313
Epoch 12, Training Loss: 0.45015865564346313, Validation Loss: 0.4490939676761627
Epoch 13, Training Loss: 0.4490939676761627, Validation Loss: 0.44801318645477295
Epoch 14, Training Loss: 0.44801318645477295, Validation Loss: 0.44691893458366394
Epoch 15, Training Loss: 0.4469189941883087, Validation Loss: 0.44581538438796997
Epoch 16, Training Loss: 0.44581538438796997, Validation Loss: 0.44472432136535645
Epoch 17, Training Loss: 0.44472432136535645, Validation Loss: 0.4436508119106293
Epoch 18, Training Loss: 0.4436508119106293, Validation Loss: 0.44256675243377686
Epoch 19, Training Loss: 0.44256675243377686, Validation Loss: 0.44147297739982605
Epoch 20, Training Loss: 0.44147297739982605, Validation Loss: 0.44034916162490845
Epoch 21, Training Loss: 0.44034916162490845, Validation Loss: 0.43918392062187195
Epoch 22, Training Loss: 0.43918392062187195, Validation Loss: 0.4380094110965729
Epoch 23, Training Loss: 0.4380094110965729, Validation Loss: 0.43681445717811584
Epoch 24, Training Loss: 0.43681445717811584, Validation Loss: 0.4355795681476593
Epoch 25, Training Loss: 0.4355795681476593, Validation Loss: 0.43430355191230774
Epoch 26, Training Loss: 0.4343035817146301, Validation Loss: 0.4329737424850464
Epoch 27, Training Loss: 0.4329737424850464, Validation Loss: 0.4315844476222992
Epoch 28, Training Loss: 0.4315844476222992, Validation Loss: 0.4301310181617737
Epoch 29, Training Loss: 0.4301310181617737, Validation Loss: 0.4286683201789856
Epoch 30, Training Loss: 0.4286683201789856, Validation Loss: 0.4271467924118042
Epoch 31, Training Loss: 0.4271467924118042, Validation Loss: 0.42555296421051025
Epoch 32, Training Loss: 0.42555296421051025, Validation Loss: 0.42387083172798157
Epoch 33, Training Loss: 0.42387083172798157, Validation Loss: 0.4220818877220154
Epoch 34, Training Loss: 0.42208197712898254, Validation Loss: 0.42017343640327454
Epoch 35, Training Loss: 0.42017343640327454, Validation Loss: 0.41814491152763367
Epoch 36, Training Loss: 0.41814491152763367, Validation Loss: 0.4159901738166809
Epoch 37, Training Loss: 0.4159901738166809, Validation Loss: 0.41370517015457153
Epoch 38, Training Loss: 0.41370517015457153, Validation Loss: 0.4113297164440155
Epoch 39, Training Loss: 0.4113296866416931, Validation Loss: 0.40879467129707336
Epoch 40, Training Loss: 0.40879467129707336, Validation Loss: 0.4060841500759125
Epoch 41, Training Loss: 0.4060841500759125, Validation Loss: 0.40319401025772095
Epoch 42, Training Loss: 0.40319401025772095, Validation Loss: 0.4001219868659973
Epoch 43, Training Loss: 0.4001219868659973, Validation Loss: 0.39686307311058044
Epoch 44, Training Loss: 0.39686304330825806, Validation Loss: 0.3933440148830414
Epoch 45, Training Loss: 0.3933440148830414, Validation Loss: 0.38962769508361816
Epoch 46, Training Loss: 0.38962769508361816, Validation Loss: 0.3856772184371948
Epoch 47, Training Loss: 0.3856772184371948, Validation Loss: 0.38145413994789124
Epoch 48, Training Loss: 0.38145413994789124, Validation Loss: 0.3769623041152954
Epoch 49, Training Loss: 0.376962274312973, Validation Loss: 0.3721901476383209
Epoch 50, Training Loss: 0.3721901476383209, Validation Loss: 0.367095410823822
Epoch 51, Training Loss: 0.3670954406261444, Validation Loss: 0.36168739199638367
Epoch 52, Training Loss: 0.36168739199638367, Validation Loss: 0.3558681309223175
Epoch 53, Training Loss: 0.3558681309223175, Validation Loss: 0.34965986013412476
Epoch 54, Training Loss: 0.34965986013412476, Validation Loss: 0.3430294692516327
Epoch 55, Training Loss: 0.3430294692516327, Validation Loss: 0.3360273838043213
Epoch 56, Training Loss: 0.3360273838043213, Validation Loss: 0.32862335443496704
Epoch 57, Training Loss: 0.32862335443496704, Validation Loss: 0.3207617402076721
Epoch 58, Training Loss: 0.32076168060302734, Validation Loss: 0.3124730885028839
Epoch 59, Training Loss: 0.3124730885028839, Validation Loss: 0.3038179576396942
Epoch 60, Training Loss: 0.3038179576396942, Validation Loss: 0.2948673963546753
Epoch 61, Training Loss: 0.2948673665523529, Validation Loss: 0.2856355607509613
Epoch 62, Training Loss: 0.2856355309486389, Validation Loss: 0.27621331810951233
Epoch 63, Training Loss: 0.27621331810951233, Validation Loss: 0.26675236225128174
Epoch 64, Training Loss: 0.26675236225128174, Validation Loss: 0.2574070692062378
Epoch 65, Training Loss: 0.2574070394039154, Validation Loss: 0.24829334020614624
Epoch 66, Training Loss: 0.24829337000846863, Validation Loss: 0.2395782619714737
Epoch 67, Training Loss: 0.2395782768726349, Validation Loss: 0.2314024120569229
Epoch 68, Training Loss: 0.23140238225460052, Validation Loss: 0.22390799224376678
Epoch 69, Training Loss: 0.22390799224376678, Validation Loss: 0.2172582447528839
Epoch 70, Training Loss: 0.2172582447528839, Validation Loss: 0.21149471402168274
Epoch 71, Training Loss: 0.21149471402168274, Validation Loss: 0.2066117525100708
Epoch 72, Training Loss: 0.206611767411232, Validation Loss: 0.20243482291698456
Epoch 73, Training Loss: 0.20243480801582336, Validation Loss: 0.19863411784172058
Epoch 74, Training Loss: 0.19863411784172058, Validation Loss: 0.1948208510875702
Epoch 75, Training Loss: 0.1948208510875702, Validation Loss: 0.19073833525180817
Epoch 76, Training Loss: 0.19073832035064697, Validation Loss: 0.18623752892017365
Epoch 77, Training Loss: 0.18623752892017365, Validation Loss: 0.1810472011566162
Epoch 78, Training Loss: 0.18104718625545502, Validation Loss: 0.1752425730228424
Epoch 79, Training Loss: 0.1752425730228424, Validation Loss: 0.16887471079826355
Epoch 80, Training Loss: 0.16887472569942474, Validation Loss: 0.16215674579143524
Epoch 81, Training Loss: 0.16215677559375763, Validation Loss: 0.15520663559436798
Epoch 82, Training Loss: 0.15520663559436798, Validation Loss: 0.14835964143276215
Epoch 83, Training Loss: 0.14835962653160095, Validation Loss: 0.14147327840328217
Epoch 84, Training Loss: 0.14147326350212097, Validation Loss: 0.1346260905265808
Epoch 85, Training Loss: 0.13462607562541962, Validation Loss: 0.1277201622724533
Epoch 86, Training Loss: 0.1277201622724533, Validation Loss: 0.12066663801670074
Epoch 87, Training Loss: 0.12066661566495895, Validation Loss: 0.11349143087863922
Epoch 88, Training Loss: 0.11349144577980042, Validation Loss: 0.1061789020895958
Epoch 89, Training Loss: 0.1061788946390152, Validation Loss: 0.09869423508644104
Epoch 90, Training Loss: 0.09869422018527985, Validation Loss: 0.09111904352903366
Epoch 91, Training Loss: 0.09111905097961426, Validation Loss: 0.08350422233343124
Epoch 92, Training Loss: 0.08350422233343124, Validation Loss: 0.0757804811000824
Epoch 93, Training Loss: 0.075780488550663, Validation Loss: 0.06812969595193863
Epoch 94, Training Loss: 0.06812970340251923, Validation Loss: 0.06060688942670822
Epoch 95, Training Loss: 0.06060688942670822, Validation Loss: 0.053277451545000076
Epoch 96, Training Loss: 0.05327745899558067, Validation Loss: 0.04618803411722183
Epoch 97, Training Loss: 0.04618804156780243, Validation Loss: 0.039494384080171585
Epoch 98, Training Loss: 0.039494387805461884, Validation Loss: 0.033306848257780075
Epoch 99, Training Loss: 0.03330684080719948, Validation Loss: 0.02790442667901516
Epoch 100, Training Loss: 0.02790442854166031, Validation Loss: 0.023204216733574867
Epoch 101, Training Loss: 0.023204222321510315, Validation Loss: 0.019180642440915108
Epoch 102, Training Loss: 0.019180644303560257, Validation Loss: 0.015917694196105003
Epoch 103, Training Loss: 0.015917692333459854, Validation Loss: 0.013328311033546925
Epoch 104, Training Loss: 0.01332831010222435, Validation Loss: 0.01123950257897377
Epoch 105, Training Loss: 0.011239501647651196, Validation Loss: 0.00954042561352253
Epoch 106, Training Loss: 0.00954042561352253, Validation Loss: 0.008142289705574512
Epoch 107, Training Loss: 0.00814228504896164, Validation Loss: 0.007008102722465992
Epoch 108, Training Loss: 0.00700810132548213, Validation Loss: 0.006058934610337019
Epoch 109, Training Loss: 0.006058935075998306, Validation Loss: 0.005209545139223337
Epoch 110, Training Loss: 0.00520954467356205, Validation Loss: 0.004441820550709963
Epoch 111, Training Loss: 0.004441817756742239, Validation Loss: 0.003784234868362546
Epoch 112, Training Loss: 0.0037842332385480404, Validation Loss: 0.003225727239623666
Epoch 113, Training Loss: 0.0032257274724543095, Validation Loss: 0.0027428455650806427
Epoch 114, Training Loss: 0.002742844633758068, Validation Loss: 0.0023348089307546616
Epoch 115, Training Loss: 0.0023348089307546616, Validation Loss: 0.0019990813452750444
Epoch 116, Training Loss: 0.001999084372073412, Validation Loss: 0.0017281657783314586
Epoch 117, Training Loss: 0.0017281670588999987, Validation Loss: 0.0015110484091565013
Epoch 118, Training Loss: 0.0015110457316040993, Validation Loss: 0.001334509695880115
Epoch 119, Training Loss: 0.0013345093466341496, Validation Loss: 0.0011848232243210077
Epoch 120, Training Loss: 0.0011848241556435823, Validation Loss: 0.0010564287658780813
Epoch 121, Training Loss: 0.0010564292315393686, Validation Loss: 0.0009471419034525752
Epoch 122, Training Loss: 0.0009471405064687133, Validation Loss: 0.0008559837006032467
Epoch 123, Training Loss: 0.0008559841080568731, Validation Loss: 0.0007845153450034559
Epoch 124, Training Loss: 0.0007845149957574904, Validation Loss: 0.0007319511496461928
Epoch 125, Training Loss: 0.0007319504511542618, Validation Loss: 0.0006975773139856756
Epoch 126, Training Loss: 0.0006975759170018137, Validation Loss: 0.0006768277962692082
Epoch 127, Training Loss: 0.0006768283201381564, Validation Loss: 0.0006623311201110482
Epoch 128, Training Loss: 0.0006623308290727437, Validation Loss: 0.000647397362627089
Epoch 129, Training Loss: 0.0006473969551734626, Validation Loss: 0.0006284384289756417
Epoch 130, Training Loss: 0.0006284387782216072, Validation Loss: 0.0006000193534418941
Epoch 131, Training Loss: 0.0006000192952342331, Validation Loss: 0.0005579513381235301
Epoch 132, Training Loss: 0.0005579513381235301, Validation Loss: 0.0005032869521528482
Epoch 133, Training Loss: 0.0005032864282839, Validation Loss: 0.0004397633601911366
Epoch 134, Training Loss: 0.00043976257438771427, Validation Loss: 0.00037282000994309783
Epoch 135, Training Loss: 0.00037282027187757194, Validation Loss: 0.00030831710319034755
Epoch 136, Training Loss: 0.000308317132294178, Validation Loss: 0.0002512885257601738
Epoch 137, Training Loss: 0.0002512885257601738, Validation Loss: 0.00020504376152530313
Epoch 138, Training Loss: 0.00020504335407167673, Validation Loss: 0.0001707586634438485
Epoch 139, Training Loss: 0.0001707582123344764, Validation Loss: 0.00014759179612156004
Epoch 140, Training Loss: 0.00014759191253688186, Validation Loss: 0.00013323521125130355
Epoch 141, Training Loss: 0.00013323557504918426, Validation Loss: 0.00012488187348935753
Epoch 142, Training Loss: 0.0001248818007297814, Validation Loss: 0.0001191905394080095
Epoch 143, Training Loss: 0.0001191901828860864, Validation Loss: 0.00011369387357262895
Epoch 144, Training Loss: 0.0001136938517447561, Validation Loss: 0.0001068996061803773
Epoch 145, Training Loss: 0.00010689978807931766, Validation Loss: 9.834607044467703e-05
Epoch 146, Training Loss: 9.834594675339758e-05, Validation Loss: 8.842472016112879e-05
Epoch 147, Training Loss: 8.842432725941762e-05, Validation Loss: 7.800623279763386e-05
Epoch 148, Training Loss: 7.80062546255067e-05, Validation Loss: 6.810315244365484e-05
Epoch 149, Training Loss: 6.810332706663758e-05, Validation Loss: 5.956763561698608e-05
Epoch 150, Training Loss: 5.956732275080867e-05, Validation Loss: 5.2862051234114915e-05
Epoch 151, Training Loss: 5.286215673550032e-05, Validation Loss: 4.798662121174857e-05
Epoch 152, Training Loss: 4.798659574589692e-05, Validation Loss: 4.452524080988951e-05
Epoch 153, Training Loss: 4.452508801477961e-05, Validation Loss: 4.189988976577297e-05
Epoch 154, Training Loss: 4.189979154034518e-05, Validation Loss: 3.9506034227088094e-05
Epoch 155, Training Loss: 3.950630343751982e-05, Validation Loss: 3.68781438737642e-05
Epoch 156, Training Loss: 3.687801290652715e-05, Validation Loss: 3.3783860999392346e-05
Epoch 157, Training Loss: 3.378384280949831e-05, Validation Loss: 3.0243791115935892e-05
Epoch 158, Training Loss: 3.0243640139815398e-05, Validation Loss: 2.64684440480778e-05
Epoch 159, Training Loss: 2.6468471332918853e-05, Validation Loss: 2.2760432329960167e-05
Epoch 160, Training Loss: 2.2760570573154837e-05, Validation Loss: 1.9402612451813184e-05
Epoch 161, Training Loss: 1.9402465113671497e-05, Validation Loss: 1.6578165741520934e-05
Epoch 162, Training Loss: 1.6578162103542127e-05, Validation Loss: 1.4340506822918542e-05
Epoch 163, Training Loss: 1.4340566849568859e-05, Validation Loss: 1.2620935194718186e-05
Epoch 164, Training Loss: 1.2620848792721517e-05, Validation Loss: 1.127245559473522e-05
Epoch 165, Training Loss: 1.1272417395957746e-05, Validation Loss: 1.0128253961738665e-05
Epoch 166, Training Loss: 1.0128243047802243e-05, Validation Loss: 9.05576871446101e-06
Epoch 167, Training Loss: 9.055751434061676e-06, Validation Loss: 7.98907240096014e-06
Epoch 168, Training Loss: 7.989054211066104e-06, Validation Loss: 6.936466888873838e-06
Epoch 169, Training Loss: 6.93642687110696e-06, Validation Loss: 5.962629529676633e-06
Epoch 170, Training Loss: 5.962510840618052e-06, Validation Loss: 5.155236067366786e-06
Epoch 171, Training Loss: 5.155200142326066e-06, Validation Loss: 4.58835802419344e-06
Epoch 172, Training Loss: 4.588337105815299e-06, Validation Loss: 4.2931746975227725e-06
Epoch 173, Training Loss: 4.293203801353229e-06, Validation Loss: 4.2448582462384365e-06
Epoch 174, Training Loss: 4.244825959176524e-06, Validation Loss: 4.366945177025627e-06
Epoch 175, Training Loss: 4.366916982689872e-06, Validation Loss: 4.552003247226821e-06
Epoch 176, Training Loss: 4.551984147838084e-06, Validation Loss: 4.6887116695870645e-06
Epoch 177, Training Loss: 4.688599346991396e-06, Validation Loss: 4.688843546318822e-06
Epoch 178, Training Loss: 4.6888117140042596e-06, Validation Loss: 4.506034656515112e-06
Epoch 179, Training Loss: 4.506098775891587e-06, Validation Loss: 4.1417456486669835e-06
Epoch 180, Training Loss: 4.1417974898649845e-06, Validation Loss: 3.638820544438204e-06
Epoch 181, Training Loss: 3.6386988995218417e-06, Validation Loss: 3.0652306577394484e-06
Epoch 182, Training Loss: 3.065194505325053e-06, Validation Loss: 2.495191210982739e-06
Epoch 183, Training Loss: 2.4951812065410195e-06, Validation Loss: 1.990310011024121e-06
Epoch 184, Training Loss: 1.9903004613297526e-06, Validation Loss: 1.5884087360973353e-06
Epoch 185, Training Loss: 1.5884384083619807e-06, Validation Loss: 1.2997860494579072e-06
Epoch 186, Training Loss: 1.2997707017348148e-06, Validation Loss: 1.1105888688689447e-06
Epoch 187, Training Loss: 1.1105533985755756e-06, Validation Loss: 9.923603556671878e-07
Epoch 188, Training Loss: 9.923535344569245e-07, Validation Loss: 9.123425570578547e-07
Epoch 189, Training Loss: 9.123443192038394e-07, Validation Loss: 8.42861254568561e-07
Epoch 190, Training Loss: 8.428393130088807e-07, Validation Loss: 7.670356581002125e-07
Epoch 191, Training Loss: 7.670216177757538e-07, Validation Loss: 6.800735832257487e-07
Epoch 192, Training Loss: 6.800777896387444e-07, Validation Loss: 5.870777499694668e-07
Epoch 193, Training Loss: 5.870721793144185e-07, Validation Loss: 4.981806682735623e-07
Epoch 194, Training Loss: 4.981753818356083e-07, Validation Loss: 4.2376134956612077e-07
Epoch 195, Training Loss: 4.237751909386134e-07, Validation Loss: 3.7031267652309907e-07
Epoch 196, Training Loss: 3.703612208028062e-07, Validation Loss: 3.3882022876241535e-07
Epoch 197, Training Loss: 3.388093432477035e-07, Validation Loss: 3.248839846037299e-07
Epoch 198, Training Loss: 3.248746054396179e-07, Validation Loss: 3.208942587207275e-07
Epoch 199, Training Loss: 3.2093007007460983e-07, Validation Loss: 3.187604704635305e-07
Epoch 200, Training Loss: 3.1872431804913504e-07, Validation Loss: 3.119336042800569e-07
Epoch 201, Training Loss: 3.1194971938930394e-07, Validation Loss: 2.9745879714937473e-07
Epoch 202, Training Loss: 2.9746070140390657e-07, Validation Loss: 2.755001844434446e-07
Epoch 203, Training Loss: 2.755050445557572e-07, Validation Loss: 2.4886699634407705e-07
Epoch 204, Training Loss: 2.4889075689316087e-07, Validation Loss: 2.2145115963212447e-07
Epoch 205, Training Loss: 2.2145964351238945e-07, Validation Loss: 1.966397746855364e-07
Epoch 206, Training Loss: 1.9663097816646768e-07, Validation Loss: 1.7637918858781632e-07
Epoch 207, Training Loss: 1.7636648408370093e-07, Validation Loss: 1.6078838882549462e-07
Epoch 208, Training Loss: 1.6079960118986492e-07, Validation Loss: 1.4856692587272846e-07
Epoch 209, Training Loss: 1.485651921484532e-07, Validation Loss: 1.376727851720716e-07
Epoch 210, Training Loss: 1.3766585027497058e-07, Validation Loss: 1.2623095813069085e-07
Epoch 211, Training Loss: 1.2623570455616573e-07, Validation Loss: 1.1325853677135456e-07
Epoch 212, Training Loss: 1.1326002891109965e-07, Validation Loss: 9.879116191768844e-08
Epoch 213, Training Loss: 9.880760387659393e-08, Validation Loss: 8.38816518466956e-08
Epoch 214, Training Loss: 8.387730332515275e-08, Validation Loss: 6.998489965326371e-08
Epoch 215, Training Loss: 7.000038948490328e-08, Validation Loss: 5.8549719739176e-08
Epoch 216, Training Loss: 5.855327600556848e-08, Validation Loss: 5.0394916684126656e-08
Epoch 217, Training Loss: 5.039014183694235e-08, Validation Loss: 4.5569187534511e-08
Epoch 218, Training Loss: 4.556594035420858e-08, Validation Loss: 4.334482994750033e-08
Epoch 219, Training Loss: 4.335241499120457e-08, Validation Loss: 4.253616836535912e-08
Epoch 220, Training Loss: 4.254779994994351e-08, Validation Loss: 4.185876534279487e-08
Epoch 221, Training Loss: 4.185882218621373e-08, Validation Loss: 4.0256718847331285e-08
Epoch 222, Training Loss: 4.0246913357577796e-08, Validation Loss: 3.721948615975634e-08
Epoch 223, Training Loss: 3.721526553590593e-08, Validation Loss: 3.28081419809223e-08
Epoch 224, Training Loss: 3.281780891484232e-08, Validation Loss: 2.7541084079985012e-08
Epoch 225, Training Loss: 2.7547274683570322e-08, Validation Loss: 2.216340710958775e-08
Epoch 226, Training Loss: 2.2155493439868224e-08, Validation Loss: 1.7350041403574323e-08
Epoch 227, Training Loss: 1.735620713816388e-08, Validation Loss: 1.3635120588162408e-08
Epoch 228, Training Loss: 1.3638426388240532e-08, Validation Loss: 1.1210060435473679e-08
Epoch 229, Training Loss: 1.1206046757195054e-08, Validation Loss: 9.92947768452268e-09
Epoch 230, Training Loss: 9.930741562413914e-09, Validation Loss: 9.48387324228861e-09
Epoch 231, Training Loss: 9.483741791882494e-09, Validation Loss: 9.437632009223762e-09
Epoch 232, Training Loss: 9.442270076931436e-09, Validation Loss: 9.451189164622065e-09
Epoch 233, Training Loss: 9.451770033308549e-09, Validation Loss: 9.281746038425354e-09
Epoch 234, Training Loss: 9.279649049176442e-09, Validation Loss: 8.846833488007633e-09
Epoch 235, Training Loss: 8.847708343751037e-09, Validation Loss: 8.1994127043572e-09
Epoch 236, Training Loss: 8.197422296518653e-09, Validation Loss: 7.448871741644325e-09
Epoch 237, Training Loss: 7.447811256611203e-09, Validation Loss: 6.713559930204838e-09
Epoch 238, Training Loss: 6.714182987366257e-09, Validation Loss: 6.0841207627504446e-09
Epoch 239, Training Loss: 6.083463954809076e-09, Validation Loss: 5.576792361239313e-09
Epoch 240, Training Loss: 5.57686208324526e-09, Validation Loss: 5.168314665127127e-09
Epoch 241, Training Loss: 5.169804584426174e-09, Validation Loss: 4.804781017497817e-09
Epoch 242, Training Loss: 4.806889553066185e-09, Validation Loss: 4.4392174380902816e-09
Epoch 243, Training Loss: 4.437645362287412e-09, Validation Loss: 4.036959211362046e-09
Epoch 244, Training Loss: 4.035400458235472e-09, Validation Loss: 3.6011089665777263e-09
Epoch 245, Training Loss: 3.6020060267816234e-09, Validation Loss: 3.157614392179653e-09
Epoch 246, Training Loss: 3.1580122961116786e-09, Validation Loss: 2.7444304606660808e-09
Epoch 247, Training Loss: 2.744076743610435e-09, Validation Loss: 2.3887802846900286e-09
Epoch 248, Training Loss: 2.3894377587652116e-09, Validation Loss: 2.107636509762756e-09
Epoch 249, Training Loss: 2.107737318013392e-09, Validation Loss: 1.8899788400972284e-09
Epoch 250, Training Loss: 1.8906334275925474e-09, Validation Loss: 1.7173181765528511e-09
Epoch 251, Training Loss: 1.7183503508988451e-09, Validation Loss: 1.5655355900534573e-09
Epoch 252, Training Loss: 1.5650699625169295e-09, Validation Loss: 1.4125510761076043e-09
Epoch 253, Training Loss: 1.411202710244197e-09, Validation Loss: 1.2470376953288564e-09
Epoch 254, Training Loss: 1.2480564359762525e-09, Validation Loss: 1.0767281510837279e-09
Epoch 255, Training Loss: 1.0768866909316444e-09, Validation Loss: 9.108160892168371e-10
Epoch 256, Training Loss: 9.102441023145502e-10, Validation Loss: 7.645115096543975e-10
Epoch 257, Training Loss: 7.63984986384969e-10, Validation Loss: 6.493603432744521e-10
Epoch 258, Training Loss: 6.485758041741008e-10, Validation Loss: 5.691004334451577e-10
Epoch 259, Training Loss: 5.694351656870822e-10, Validation Loss: 5.224348176291471e-10
Epoch 260, Training Loss: 5.22230036992255e-10, Validation Loss: 4.980061918402612e-10
Epoch 261, Training Loss: 4.968481737144259e-10, Validation Loss: 4.802608311038625e-10
Epoch 262, Training Loss: 4.80155082360767e-10, Validation Loss: 4.633546046850512e-10
Epoch 263, Training Loss: 4.6255854702081933e-10, Validation Loss: 4.355528715471735e-10
Epoch 264, Training Loss: 4.356468241706324e-10, Validation Loss: 3.976055595877881e-10
Epoch 265, Training Loss: 3.976241835790262e-10, Validation Loss: 3.554233851676969e-10
Epoch 266, Training Loss: 3.5498623485175074e-10, Validation Loss: 3.107991364270646e-10
Epoch 267, Training Loss: 3.1062330485553957e-10, Validation Loss: 2.7107283084859546e-10
Epoch 268, Training Loss: 2.7028215776603304e-10, Validation Loss: 2.3907423263302974e-10
Epoch 269, Training Loss: 2.3845533880795244e-10, Validation Loss: 2.156374523387683e-10
Epoch 270, Training Loss: 2.1615297052246518e-10, Validation Loss: 2.0064890027260418e-10
Epoch 271, Training Loss: 1.9996665434618421e-10, Validation Loss: 1.8864189377243434e-10
Epoch 272, Training Loss: 1.8793309963793803e-10, Validation Loss: 1.7778895022857455e-10
Epoch 273, Training Loss: 1.7831124077272165e-10, Validation Loss: 1.6708943950671795e-10
Epoch 274, Training Loss: 1.6685522408188547e-10, Validation Loss: 1.5425452581929733e-10
Epoch 275, Training Loss: 1.541470562305136e-10, Validation Loss: 1.4038452345044306e-10
Epoch 276, Training Loss: 1.402494648194974e-10, Validation Loss: 1.2602266452610422e-10
Epoch 277, Training Loss: 1.2604402244154045e-10, Validation Loss: 1.1224435270129618e-10
Epoch 278, Training Loss: 1.1214023459826805e-10, Validation Loss: 9.913306286968293e-11
Epoch 279, Training Loss: 9.960671176756364e-11, Validation Loss: 8.781197990970213e-11
Epoch 280, Training Loss: 8.764435011077154e-11, Validation Loss: 7.681694863537203e-11
Epoch 281, Training Loss: 7.7192155445438e-11, Validation Loss: 6.722897932798233e-11
Epoch 282, Training Loss: 6.676414282535958e-11, Validation Loss: 5.710031752981237e-11
Epoch 283, Training Loss: 5.719657039660042e-11, Validation Loss: 4.850219531560285e-11
Epoch 284, Training Loss: 4.85176517017738e-11, Validation Loss: 4.098719280642982e-11
Epoch 285, Training Loss: 4.096956107701999e-11, Validation Loss: 3.5480708648893966e-11
Epoch 286, Training Loss: 3.5656436137010417e-11, Validation Loss: 3.1702897251850715e-11
Epoch 287, Training Loss: 3.195372438868915e-11, Validation Loss: 2.9882339658282575e-11
Epoch 288, Training Loss: 2.980658428408667e-11, Validation Loss: 2.8655492909090974e-11
Epoch 289, Training Loss: 2.8616374894707697e-11, Validation Loss: 2.771760251873978e-11
Epoch 290, Training Loss: 2.7903663754602626e-11, Validation Loss: 2.6736775987634687e-11
Epoch 291, Training Loss: 2.6841414507705608e-11, Validation Loss: 2.583879811501877e-11
Epoch 292, Training Loss: 2.547988209311569e-11, Validation Loss: 2.3956871209040997e-11
Epoch 293, Training Loss: 2.3877913535308437e-11, Validation Loss: 2.1347939041516106e-11
Epoch 294, Training Loss: 2.1383356890725125e-11, Validation Loss: 1.8585842934126795e-11
Epoch 295, Training Loss: 1.8494386577749822e-11, Validation Loss: 1.5608134576461374e-11
Epoch 296, Training Loss: 1.5594156174691953e-11, Validation Loss: 1.3218369107614869e-11
Epoch 297, Training Loss: 1.3096300953419071e-11, Validation Loss: 1.1146989581378719e-11
Epoch 298, Training Loss: 1.1189793015786709e-11, Validation Loss: 9.294271081927707e-12
Epoch 299, Training Loss: 9.531489313097108e-12, Validation Loss: 8.172732456068754e-12
Epoch 300, Training Loss: 8.05797095715377e-12, Validation Loss: 7.090523914538016e-12
Epoch 301, Training Loss: 7.148487531083436e-12, Validation Loss: 6.389031231152087e-12
Epoch 302, Training Loss: 6.402721668824496e-12, Validation Loss: 5.856919983726616e-12
Epoch 303, Training Loss: 5.904453575372726e-12, Validation Loss: 5.533161168830292e-12
Epoch 304, Training Loss: 5.530989728719238e-12, Validation Loss: 5.17170724648186e-12
Epoch 305, Training Loss: 5.1337727471900685e-12, Validation Loss: 4.892013877322299e-12
Epoch 306, Training Loss: 4.826494238996393e-12, Validation Loss: 4.612865645015063e-12
Epoch 307, Training Loss: 4.5606144728760345e-12, Validation Loss: 4.3708608780945735e-12
Epoch 308, Training Loss: 4.379047038177708e-12, Validation Loss: 4.162501072990654e-12
Epoch 309, Training Loss: 4.210101885171458e-12, Validation Loss: 3.9817663055607966e-12
Epoch 310, Training Loss: 4.028403912531564e-12, Validation Loss: 3.787835062968314e-12
Epoch 311, Training Loss: 3.817360923891178e-12, Validation Loss: 3.539168524219205e-12
Epoch 312, Training Loss: 3.567058540904222e-12, Validation Loss: 3.267025755829267e-12
Epoch 313, Training Loss: 3.279898271382753e-12, Validation Loss: 2.9755512290230435e-12
Epoch 314, Training Loss: 2.966895826239657e-12, Validation Loss: 2.6427499511677555e-12
Epoch 315, Training Loss: 2.608978788218308e-12, Validation Loss: 2.2725144249030604e-12
Epoch 316, Training Loss: 2.2792713896824246e-12, Validation Loss: 1.922980438079369e-12
Epoch 317, Training Loss: 1.9222783087524675e-12, Validation Loss: 1.573229719241398e-12
Epoch 318, Training Loss: 1.5870882082505422e-12, Validation Loss: 1.2874547348357135e-12
Epoch 319, Training Loss: 1.2818743462539306e-12, Validation Loss: 1.0324793320651282e-12
Epoch 320, Training Loss: 1.0286364858849706e-12, Validation Loss: 8.313439455072402e-13
Epoch 321, Training Loss: 8.222992057237144e-13, Validation Loss: 6.623085868802392e-13
Epoch 322, Training Loss: 6.622205496638334e-13, Validation Loss: 5.248888888635672e-13
Epoch 323, Training Loss: 5.284310857812946e-13, Validation Loss: 4.2089967036869347e-13
Epoch 324, Training Loss: 4.2631211603395835e-13, Validation Loss: 3.8542162083404774e-13
Epoch 325, Training Loss: 3.6465250849264386e-13, Validation Loss: 3.606092475409023e-13
Epoch 326, Training Loss: 3.434473300374663e-13, Validation Loss: 3.393553613031258e-13
Epoch 327, Training Loss: 3.1906129214359646e-13, Validation Loss: 3.068364247578448e-13
Epoch 328, Training Loss: 2.9603958715852807e-13, Validation Loss: 3.006280662777583e-13
Epoch 329, Training Loss: 2.976068285039102e-13, Validation Loss: 2.7544641372466427e-13
Epoch 330, Training Loss: 2.894715175026652e-13, Validation Loss: 2.76477923671567e-13
Epoch 331, Training Loss: 2.915806973039642e-13, Validation Loss: 2.7758592408173854e-13
Epoch 332, Training Loss: 2.7509906245365423e-13, Validation Loss: 2.6411335683589054e-13
Epoch 333, Training Loss: 2.701010259637676e-13, Validation Loss: 2.6568414894338754e-13
Epoch 334, Training Loss: 2.7731411459709643e-13, Validation Loss: 2.6182997285052745e-13
Epoch 335, Training Loss: 2.679486949160037e-13, Validation Loss: 2.5384921486897027e-13
Epoch 336, Training Loss: 2.529046037261923e-13, Validation Loss: 2.412373144126956e-13
Epoch 337, Training Loss: 2.4572764613026155e-13, Validation Loss: 2.1797675968902863e-13
Epoch 338, Training Loss: 2.2254354121228198e-13, Validation Loss: 2.0571229181892692e-13
Epoch 339, Training Loss: 2.0507316819077387e-13, Validation Loss: 1.9806689112184667e-13
Epoch 340, Training Loss: 1.819745797191491e-13, Validation Loss: 1.772779378806863e-13
Epoch 341, Training Loss: 1.7351141953347166e-13, Validation Loss: 1.5638232625080767e-13
Epoch 342, Training Loss: 1.3448363787599976e-13, Validation Loss: 1.3015069165629722e-13
Epoch 343, Training Loss: 1.2494452900687486e-13, Validation Loss: 1.2511950568498686e-13
Epoch 344, Training Loss: 1.0344709707984026e-13, Validation Loss: 1.0381258163218512e-13
Epoch 345, Training Loss: 8.915925045786463e-14, Validation Loss: 8.637312192512e-14
Epoch 346, Training Loss: 8.131849685809323e-14, Validation Loss: 7.117251259918314e-14
Epoch 347, Training Loss: 6.030897623746784e-14, Validation Loss: 5.619535056473196e-14
Epoch 348, Training Loss: 5.356827449069096e-14, Validation Loss: 4.053967109381683e-14
Epoch 349, Training Loss: 3.8616597983556766e-14, Validation Loss: 3.315902240286217e-14
Epoch 350, Training Loss: 3.267311348234027e-14, Validation Loss: 3.017478302815013e-14
Epoch 351, Training Loss: 2.785211704282517e-14, Validation Loss: 2.623856501808488e-14
Epoch 352, Training Loss: 2.487450146576066e-14, Validation Loss: 2.3604937991229813e-14
Epoch 353, Training Loss: 2.407474481542441e-14, Validation Loss: 2.0021419418203568e-14
Epoch 354, Training Loss: 2.1358831925875378e-14, Validation Loss: 1.9488174908457306e-14
Epoch 355, Training Loss: 1.869432546589521e-14, Validation Loss: 2.6574313631783433e-14
Epoch 356, Training Loss: 1.7905920751118062e-14, Validation Loss: 1.9589620656418165e-14
Epoch 357, Training Loss: 1.6158141109292277e-14, Validation Loss: 2.0769152998985352e-14
Epoch 358, Training Loss: 1.6387831033599226e-14, Validation Loss: 1.7752977094030037e-14
Epoch 359, Training Loss: 1.7578230808879686e-14, Validation Loss: 1.7924035397728043e-14
Epoch 360, Training Loss: 1.655820154654406e-14, Validation Loss: 1.496803948960925e-14
Epoch 361, Training Loss: 2.037082897927544e-14, Validation Loss: 1.5006852233318338e-14
Epoch 362, Training Loss: 1.7775296412190188e-14, Validation Loss: 1.6165637350875478e-14
Epoch 363, Training Loss: 1.9022786208115587e-14, Validation Loss: 1.2412311541814321e-14
Epoch 364, Training Loss: 1.5673284203690865e-14, Validation Loss: 1.187673769146311e-14
Epoch 365, Training Loss: 1.4020665325357312e-14, Validation Loss: 1.28301427302995e-14
Epoch 366, Training Loss: 1.288663135755189e-14, Validation Loss: 1.0548358790173767e-14
Epoch 367, Training Loss: 1.0041654363763825e-14, Validation Loss: 7.391286577739225e-15
Epoch 368, Training Loss: 9.778822581329658e-15, Validation Loss: 9.710936278739014e-15
Epoch 369, Training Loss: 8.680475805657954e-15, Validation Loss: 9.220631257220863e-15
Epoch 370, Training Loss: 6.826247839284826e-15, Validation Loss: 8.717717303249883e-15
Epoch 371, Training Loss: 9.18894968389471e-15, Validation Loss: 6.964160049690877e-15
Epoch 372, Training Loss: 9.126949413254537e-15, Validation Loss: 7.98749358755374e-15
Epoch 373, Training Loss: 7.936132897764028e-15, Validation Loss: 7.463729917586096e-15
Epoch 374, Training Loss: 4.94107437121671e-15, Validation Loss: 8.046815540014695e-15
Epoch 375, Training Loss: 5.476978987933824e-15, Validation Loss: 8.211283927383062e-15
Epoch 376, Training Loss: 4.434835389411284e-15, Validation Loss: 6.476575274482832e-15
Epoch 377, Training Loss: 3.3694064316522505e-15, Validation Loss: 6.294218821817875e-15
Epoch 378, Training Loss: 4.617206665152819e-15, Validation Loss: 6.647634001697312e-15
Epoch 379, Training Loss: 4.074321226400909e-15, Validation Loss: 4.47765417544441e-15
Epoch 380, Training Loss: 3.627338128486552e-15, Validation Loss: 6.704715975529253e-15
Epoch 381, Training Loss: 3.046047368873185e-15, Validation Loss: 6.513699034495094e-15
Epoch 382, Training Loss: 2.7252069585627803e-15, Validation Loss: 5.6835555006925706e-15
Epoch 383, Training Loss: 2.2830775711944274e-15, Validation Loss: 6.759728224354578e-15
Epoch 384, Training Loss: 2.8718410672267086e-15, Validation Loss: 6.439199098652289e-15
Epoch 385, Training Loss: 4.763006446363701e-15, Validation Loss: 6.364224400842548e-15
Epoch 386, Training Loss: 2.842150656601314e-15, Validation Loss: 6.186167487417854e-15
Epoch 387, Training Loss: 2.9419639603145767e-15, Validation Loss: 7.846149199645415e-15
Epoch 388, Training Loss: 2.9821294156404284e-15, Validation Loss: 4.110218482705546e-15
Epoch 389, Training Loss: 2.2827023355987937e-15, Validation Loss: 3.1078504925948847e-15
Epoch 390, Training Loss: 2.2691080920700726e-15, Validation Loss: 3.047402621588792e-15
Epoch 391, Training Loss: 2.529850244223364e-15, Validation Loss: 3.238503630642966e-15
Epoch 392, Training Loss: 1.8772439691323948e-15, Validation Loss: 2.9930987040656084e-15
Epoch 393, Training Loss: 1.5944840425481752e-15, Validation Loss: 2.967615294330989e-15
Epoch 394, Training Loss: 1.2426438145550392e-15, Validation Loss: 3.0298108060655042e-15
Epoch 395, Training Loss: 1.423838985049311e-15, Validation Loss: 3.640593770594608e-15
Epoch 396, Training Loss: 1.0654017468256032e-15, Validation Loss: 3.641208716514315e-15
Epoch 397, Training Loss: 9.001859587604022e-16, Validation Loss: 3.857252516524523e-15
Epoch 398, Training Loss: 8.609044881941288e-16, Validation Loss: 3.7489699421299014e-15
Epoch 399, Training Loss: 7.800063301655611e-16, Validation Loss: 3.4503400062459253e-15
Epoch 400, Training Loss: 8.096217254355644e-16, Validation Loss: 3.1565675925562158e-15
Epoch 401, Training Loss: 1.334850974160195e-15, Validation Loss: 3.1885568506004585e-15
Epoch 402, Training Loss: 6.961808262712825e-16, Validation Loss: 3.032228449855205e-15
Epoch 403, Training Loss: 7.239114144149674e-16, Validation Loss: 2.6186637663253454e-15
Epoch 404, Training Loss: 7.171976724563523e-16, Validation Loss: 2.4873834003798223e-15
Epoch 405, Training Loss: 1.6722130797441502e-15, Validation Loss: 2.4873834003798223e-15
Epoch 406, Training Loss: 1.2953193112371264e-15, Validation Loss: 2.8010140780014353e-15
Epoch 407, Training Loss: 1.1813529340081916e-15, Validation Loss: 3.1782715412801863e-15
Epoch 408, Training Loss: 1.7087840448792098e-15, Validation Loss: 3.2443244410564976e-15
Epoch 409, Training Loss: 1.5497482091971762e-15, Validation Loss: 3.2740540269557026e-15
Epoch 410, Training Loss: 1.1563329571748389e-15, Validation Loss: 3.2100026660337533e-15
Epoch 411, Training Loss: 1.1349825388272286e-15, Validation Loss: 3.581500517029412e-15
Epoch 412, Training Loss: 1.2269228830539994e-15, Validation Loss: 3.581500517029412e-15
Epoch 413, Training Loss: 1.654465516037686e-15, Validation Loss: 4.351411537952682e-15
Epoch 414, Training Loss: 1.1043078759171245e-15, Validation Loss: 4.005149974829281e-15
Epoch 415, Training Loss: 1.1409205574248365e-15, Validation Loss: 3.99597576097757e-15
Epoch 416, Training Loss: 5.815556162280615e-16, Validation Loss: 3.412366460429331e-15
Epoch 417, Training Loss: 5.628739869390127e-16, Validation Loss: 3.412366460429331e-15
Epoch 418, Training Loss: 5.690039114387329e-16, Validation Loss: 3.514848553201155e-15
Epoch 419, Training Loss: 9.79332717351844e-16, Validation Loss: 3.5091617857515266e-15
Epoch 420, Training Loss: 9.79332717351844e-16, Validation Loss: 3.0018551189160865e-15
Epoch 421, Training Loss: 6.073012885389744e-16, Validation Loss: 3.0018551189160865e-15
Epoch 422, Training Loss: 1.2894729839560588e-15, Validation Loss: 3.0018551189160865e-15
Epoch 423, Training Loss: 1.2798653009935901e-15, Validation Loss: 2.9730320700286804e-15
Epoch 424, Training Loss: 1.340714030341971e-15, Validation Loss: 2.976935197849628e-15
Epoch 425, Training Loss: 1.3243008611647875e-15, Validation Loss: 2.7239323857353994e-15
Epoch 426, Training Loss: 1.3243008611647875e-15, Validation Loss: 2.662583271673428e-15
Epoch 427, Training Loss: 1.3403137013952749e-15, Validation Loss: 2.9842973964689257e-15
Epoch 428, Training Loss: 9.854710592414775e-16, Validation Loss: 3.3791138527442584e-15
Epoch 429, Training Loss: 9.366402451069776e-16, Validation Loss: 3.2671572729409213e-15
Epoch 430, Training Loss: 9.077837384181549e-16, Validation Loss: 2.605293563011173e-15
Epoch 431, Training Loss: 9.584910481681783e-16, Validation Loss: 2.5877796745190328e-15
Epoch 432, Training Loss: 9.584910481681783e-16, Validation Loss: 3.601378262719102e-15
Epoch 433, Training Loss: 5.297474812839627e-16, Validation Loss: 3.0359376071312314e-15
Epoch 434, Training Loss: 4.800826573337724e-16, Validation Loss: 3.5231615463037456e-15
Epoch 435, Training Loss: 5.409314396217124e-16, Validation Loss: 2.811991624997851e-15
Epoch 436, Training Loss: 8.383698119071386e-16, Validation Loss: 3.953091329891032e-15
Epoch 437, Training Loss: 8.72563843773525e-16, Validation Loss: 5.076800389585898e-15
Epoch 438, Training Loss: 8.46943320580569e-16, Validation Loss: 5.076800389585898e-15
Epoch 439, Training Loss: 1.2568718504865433e-15, Validation Loss: 5.054382392087392e-15
Epoch 440, Training Loss: 2.132531864380079e-15, Validation Loss: 5.070395126438761e-15
Epoch 441, Training Loss: 2.132531864380079e-15, Validation Loss: 5.661268793300889e-15
Epoch 442, Training Loss: 1.3386957625869007e-15, Validation Loss: 5.648458267006615e-15
Epoch 443, Training Loss: 1.3386957625869007e-15, Validation Loss: 5.2486379635953775e-15
Epoch 444, Training Loss: 1.3386957625869007e-15, Validation Loss: 5.2486379635953775e-15
Epoch 445, Training Loss: 7.809987880819471e-16, Validation Loss: 5.2486379635953775e-15
Epoch 446, Training Loss: 8.258347301393998e-16, Validation Loss: 5.2486379635953775e-15
Epoch 447, Training Loss: 8.258347301393998e-16, Validation Loss: 4.9524796698514895e-15
Epoch 448, Training Loss: 8.700868547379574e-16, Validation Loss: 4.9524796698514895e-15
Epoch 449, Training Loss: 7.889802207252468e-16, Validation Loss: 4.9524796698514895e-15
Epoch 450, Training Loss: 6.092361764882992e-16, Validation Loss: 4.9524796698514895e-15
Epoch 451, Training Loss: 5.574863279988833e-16, Validation Loss: 5.756978857659415e-15
Epoch 452, Training Loss: 5.180380978211192e-16, Validation Loss: 5.756978857659415e-15
Epoch 453, Training Loss: 5.340508851120473e-16, Validation Loss: 5.700139135250389e-15
Epoch 454, Training Loss: 5.340508851120473e-16, Validation Loss: 5.700139135250389e-15
Epoch 455, Training Loss: 5.430998439666834e-16, Validation Loss: 5.700139135250389e-15
Epoch 456, Training Loss: 5.430998439666834e-16, Validation Loss: 5.813521271503955e-15
Epoch 457, Training Loss: 5.876772292169867e-16, Validation Loss: 5.812041081428628e-15
Epoch 458, Training Loss: 1.1913275939950583e-15, Validation Loss: 5.812041081428628e-15
Epoch 459, Training Loss: 1.1913275939950583e-15, Validation Loss: 5.914523174200452e-15
Epoch 460, Training Loss: 1.4715522450890273e-15, Validation Loss: 6.1371268208706715e-15
Epoch 461, Training Loss: 1.4427290903225027e-15, Validation Loss: 6.1371268208706715e-15
Epoch 462, Training Loss: 9.273994332897884e-16, Validation Loss: 6.1371268208706715e-15
Epoch 463, Training Loss: 9.703589326712767e-16, Validation Loss: 4.724502446163889e-15
Epoch 464, Training Loss: 9.636451377731023e-16, Validation Loss: 4.2284757170870345e-15
Epoch 465, Training Loss: 3.9252089110915515e-16, Validation Loss: 4.178956900441127e-15
Epoch 466, Training Loss: 9.027630565024234e-16, Validation Loss: 4.114905539519178e-15
Epoch 467, Training Loss: 1.7294254966499683e-15, Validation Loss: 5.265040756618957e-15
Epoch 468, Training Loss: 1.7294254966499683e-15, Validation Loss: 4.911726373660243e-15
Epoch 469, Training Loss: 1.7158313590003656e-15, Validation Loss: 4.937236464932701e-15
Epoch 470, Training Loss: 1.72383772617605e-15, Validation Loss: 4.742966070348138e-15
Epoch 471, Training Loss: 8.245837154158644e-16, Validation Loss: 4.328165142231761e-15
Epoch 472, Training Loss: 1.3807877943512823e-15, Validation Loss: 4.35231743968977e-15
Epoch 473, Training Loss: 2.057329949982237e-15, Validation Loss: 3.1043863395988514e-15
Epoch 474, Training Loss: 2.15916152145057e-15, Validation Loss: 3.050746495906315e-15
Epoch 475, Training Loss: 1.3329411266223734e-15, Validation Loss: 3.150889083677823e-15
Epoch 476, Training Loss: 1.3286460343050837e-15, Validation Loss: 3.125212338672993e-15
Epoch 477, Training Loss: 8.242417788029697e-16, Validation Loss: 3.0143234438996698e-15
Epoch 478, Training Loss: 2.270734395328801e-15, Validation Loss: 3.1423260040975556e-15
Epoch 479, Training Loss: 2.2307023476921418e-15, Validation Loss: 3.206377365019505e-15
Epoch 480, Training Loss: 2.193339089114044e-15, Validation Loss: 3.206377365019505e-15
Epoch 481, Training Loss: 2.2362900122869416e-15, Validation Loss: 2.9899121661180377e-15
Epoch 482, Training Loss: 1.0833661509665644e-15, Validation Loss: 2.9899121661180377e-15
Epoch 483, Training Loss: 1.0726908888532e-15, Validation Loss: 2.682465887802565e-15
Epoch 484, Training Loss: 9.95829319274332e-16, Validation Loss: 2.8254215441348048e-15
Epoch 485, Training Loss: 1.0118421595048193e-15, Validation Loss: 3.1091489941030255e-15
Epoch 486, Training Loss: 8.085125357911349e-16, Validation Loss: 2.981975255644028e-15
Epoch 487, Training Loss: 8.448040859327191e-16, Validation Loss: 2.7020132906428263e-15
Epoch 488, Training Loss: 1.5160086634465508e-15, Validation Loss: 2.616611617252385e-15
Epoch 489, Training Loss: 1.4360779758624252e-15, Validation Loss: 2.616611617252385e-15
Epoch 490, Training Loss: 1.4905382768434956e-15, Validation Loss: 2.366327569140606e-15
Epoch 491, Training Loss: 1.5041325203722167e-15, Validation Loss: 2.4726210984168375e-15
Epoch 492, Training Loss: 1.1664118022142178e-15, Validation Loss: 2.4726210984168375e-15
Epoch 493, Training Loss: 4.722722194666997e-16, Validation Loss: 2.8072893215911688e-15
Epoch 494, Training Loss: 6.299819721302476e-16, Validation Loss: 2.8020768925920026e-15
Epoch 495, Training Loss: 4.93989614838708e-16, Validation Loss: 2.7997937152826786e-15
Epoch 496, Training Loss: 5.484499687593376e-16, Validation Loss: 2.7944561371655557e-15
Epoch 497, Training Loss: 4.743905959282235e-16, Validation Loss: 2.7944561371655557e-15
Epoch 498, Training Loss: 4.690529648715414e-16, Validation Loss: 2.5496411690359606e-15
Epoch 499, Training Loss: 4.690529648715414e-16, Validation Loss: 2.5496411690359606e-15
Epoch 500, Training Loss: 4.690529648715414e-16, Validation Loss: 2.488133659812853e-15
