Epoch 1, Training Loss: 0.46308350563049316, Validation Loss: 0.4618810713291168
Epoch 2, Training Loss: 0.4618811011314392, Validation Loss: 0.4606987535953522
Epoch 3, Training Loss: 0.4606987535953522, Validation Loss: 0.4595400393009186
Epoch 4, Training Loss: 0.45954009890556335, Validation Loss: 0.4583785831928253
Epoch 5, Training Loss: 0.4583785831928253, Validation Loss: 0.457219660282135
Epoch 6, Training Loss: 0.457219660282135, Validation Loss: 0.4560602307319641
Epoch 7, Training Loss: 0.4560602307319641, Validation Loss: 0.4549229145050049
Epoch 8, Training Loss: 0.45492294430732727, Validation Loss: 0.45378974080085754
Epoch 9, Training Loss: 0.45378974080085754, Validation Loss: 0.4526393711566925
Epoch 10, Training Loss: 0.4526393711566925, Validation Loss: 0.4514678716659546
Epoch 11, Training Loss: 0.451467901468277, Validation Loss: 0.4502699375152588
Epoch 12, Training Loss: 0.4502699077129364, Validation Loss: 0.44904887676239014
Epoch 13, Training Loss: 0.44904887676239014, Validation Loss: 0.44781243801116943
Epoch 14, Training Loss: 0.44781243801116943, Validation Loss: 0.44655105471611023
Epoch 15, Training Loss: 0.44655105471611023, Validation Loss: 0.44525137543678284
Epoch 16, Training Loss: 0.44525134563446045, Validation Loss: 0.4439179599285126
Epoch 17, Training Loss: 0.4439179003238678, Validation Loss: 0.4425395131111145
Epoch 18, Training Loss: 0.4425395131111145, Validation Loss: 0.44110754132270813
Epoch 19, Training Loss: 0.44110754132270813, Validation Loss: 0.4396286904811859
Epoch 20, Training Loss: 0.4396286606788635, Validation Loss: 0.4381006360054016
Epoch 21, Training Loss: 0.4381006062030792, Validation Loss: 0.43651053309440613
Epoch 22, Training Loss: 0.4365105926990509, Validation Loss: 0.4348304569721222
Epoch 23, Training Loss: 0.4348304569721222, Validation Loss: 0.43306294083595276
Epoch 24, Training Loss: 0.43306294083595276, Validation Loss: 0.4312191307544708
Epoch 25, Training Loss: 0.4312191307544708, Validation Loss: 0.4293174147605896
Epoch 26, Training Loss: 0.4293174147605896, Validation Loss: 0.427333265542984
Epoch 27, Training Loss: 0.427333265542984, Validation Loss: 0.42524993419647217
Epoch 28, Training Loss: 0.42524993419647217, Validation Loss: 0.4230346977710724
Epoch 29, Training Loss: 0.4230346977710724, Validation Loss: 0.42071205377578735
Epoch 30, Training Loss: 0.42071205377578735, Validation Loss: 0.41823193430900574
Epoch 31, Training Loss: 0.4182319939136505, Validation Loss: 0.415642648935318
Epoch 32, Training Loss: 0.415642648935318, Validation Loss: 0.4129093885421753
Epoch 33, Training Loss: 0.4129093289375305, Validation Loss: 0.4100255072116852
Epoch 34, Training Loss: 0.41002553701400757, Validation Loss: 0.4070074260234833
Epoch 35, Training Loss: 0.4070073664188385, Validation Loss: 0.4038022756576538
Epoch 36, Training Loss: 0.4038023054599762, Validation Loss: 0.40037986636161804
Epoch 37, Training Loss: 0.40037986636161804, Validation Loss: 0.3967108726501465
Epoch 38, Training Loss: 0.3967108726501465, Validation Loss: 0.39283475279808044
Epoch 39, Training Loss: 0.39283475279808044, Validation Loss: 0.38870757818222046
Epoch 40, Training Loss: 0.38870754837989807, Validation Loss: 0.384310781955719
Epoch 41, Training Loss: 0.3843108117580414, Validation Loss: 0.3796278238296509
Epoch 42, Training Loss: 0.3796278238296509, Validation Loss: 0.37452229857444763
Epoch 43, Training Loss: 0.37452229857444763, Validation Loss: 0.3690272867679596
Epoch 44, Training Loss: 0.3690272867679596, Validation Loss: 0.36312806606292725
Epoch 45, Training Loss: 0.36312800645828247, Validation Loss: 0.3569051921367645
Epoch 46, Training Loss: 0.3569051921367645, Validation Loss: 0.35035860538482666
Epoch 47, Training Loss: 0.35035860538482666, Validation Loss: 0.3434058427810669
Epoch 48, Training Loss: 0.3434058725833893, Validation Loss: 0.3361051380634308
Epoch 49, Training Loss: 0.3361051380634308, Validation Loss: 0.32845088839530945
Epoch 50, Training Loss: 0.32845088839530945, Validation Loss: 0.32049670815467834
Epoch 51, Training Loss: 0.32049670815467834, Validation Loss: 0.3122200667858124
Epoch 52, Training Loss: 0.31222003698349, Validation Loss: 0.30376705527305603
Epoch 53, Training Loss: 0.30376705527305603, Validation Loss: 0.2950688600540161
Epoch 54, Training Loss: 0.2950688302516937, Validation Loss: 0.2861984968185425
Epoch 55, Training Loss: 0.2861984968185425, Validation Loss: 0.27726078033447266
Epoch 56, Training Loss: 0.27726078033447266, Validation Loss: 0.26835572719573975
Epoch 57, Training Loss: 0.26835569739341736, Validation Loss: 0.25963860750198364
Epoch 58, Training Loss: 0.25963860750198364, Validation Loss: 0.2512839734554291
Epoch 59, Training Loss: 0.2512839734554291, Validation Loss: 0.24337591230869293
Epoch 60, Training Loss: 0.24337592720985413, Validation Loss: 0.23608297109603882
Epoch 61, Training Loss: 0.23608297109603882, Validation Loss: 0.2295522838830948
Epoch 62, Training Loss: 0.22955229878425598, Validation Loss: 0.22386951744556427
Epoch 63, Training Loss: 0.22386951744556427, Validation Loss: 0.21895651519298553
Epoch 64, Training Loss: 0.21895651519298553, Validation Loss: 0.2147943079471588
Epoch 65, Training Loss: 0.2147943377494812, Validation Loss: 0.21125973761081696
Epoch 66, Training Loss: 0.21125973761081696, Validation Loss: 0.20798176527023315
Epoch 67, Training Loss: 0.20798173546791077, Validation Loss: 0.20470963418483734
Epoch 68, Training Loss: 0.20470963418483734, Validation Loss: 0.20116224884986877
Epoch 69, Training Loss: 0.20116227865219116, Validation Loss: 0.19718845188617706
Epoch 70, Training Loss: 0.19718845188617706, Validation Loss: 0.192606121301651
Epoch 71, Training Loss: 0.192606121301651, Validation Loss: 0.1875632256269455
Epoch 72, Training Loss: 0.1875632256269455, Validation Loss: 0.18216060101985931
Epoch 73, Training Loss: 0.18216060101985931, Validation Loss: 0.17654448747634888
Epoch 74, Training Loss: 0.17654448747634888, Validation Loss: 0.170816570520401
Epoch 75, Training Loss: 0.1708166003227234, Validation Loss: 0.16498342156410217
Epoch 76, Training Loss: 0.16498343646526337, Validation Loss: 0.1591557413339615
Epoch 77, Training Loss: 0.1591557413339615, Validation Loss: 0.1532822698354721
Epoch 78, Training Loss: 0.15328224003314972, Validation Loss: 0.1474314033985138
Epoch 79, Training Loss: 0.1474314033985138, Validation Loss: 0.14160114526748657
Epoch 80, Training Loss: 0.14160113036632538, Validation Loss: 0.13569487631320953
Epoch 81, Training Loss: 0.13569487631320953, Validation Loss: 0.12969772517681122
Epoch 82, Training Loss: 0.12969771027565002, Validation Loss: 0.123672254383564
Epoch 83, Training Loss: 0.123672254383564, Validation Loss: 0.11774100363254547
Epoch 84, Training Loss: 0.11774100363254547, Validation Loss: 0.11172524094581604
Epoch 85, Training Loss: 0.11172524839639664, Validation Loss: 0.10559549927711487
Epoch 86, Training Loss: 0.10559550672769547, Validation Loss: 0.09946172684431076
Epoch 87, Training Loss: 0.09946170449256897, Validation Loss: 0.09341902285814285
Epoch 88, Training Loss: 0.09341902285814285, Validation Loss: 0.08737459778785706
Epoch 89, Training Loss: 0.08737459033727646, Validation Loss: 0.08141616731882095
Epoch 90, Training Loss: 0.08141616731882095, Validation Loss: 0.0755392387509346
Epoch 91, Training Loss: 0.075539231300354, Validation Loss: 0.06981022655963898
Epoch 92, Training Loss: 0.06981022655963898, Validation Loss: 0.06437588483095169
Epoch 93, Training Loss: 0.0643758773803711, Validation Loss: 0.059197019785642624
Epoch 94, Training Loss: 0.059197016060352325, Validation Loss: 0.05424068868160248
Epoch 95, Training Loss: 0.05424068868160248, Validation Loss: 0.049637869000434875
Epoch 96, Training Loss: 0.049637869000434875, Validation Loss: 0.04534565657377243
Epoch 97, Training Loss: 0.04534565284848213, Validation Loss: 0.0414082296192646
Epoch 98, Training Loss: 0.041408222168684006, Validation Loss: 0.037861328572034836
Epoch 99, Training Loss: 0.037861328572034836, Validation Loss: 0.03468552231788635
Epoch 100, Training Loss: 0.03468552231788635, Validation Loss: 0.03170564025640488
Epoch 101, Training Loss: 0.031705647706985474, Validation Loss: 0.028908148407936096
Epoch 102, Training Loss: 0.028908144682645798, Validation Loss: 0.02630404196679592
Epoch 103, Training Loss: 0.02630404382944107, Validation Loss: 0.023845341056585312
Epoch 104, Training Loss: 0.023845339193940163, Validation Loss: 0.021505022421479225
Epoch 105, Training Loss: 0.021505020558834076, Validation Loss: 0.019314974546432495
Epoch 106, Training Loss: 0.019314972683787346, Validation Loss: 0.017272472381591797
Epoch 107, Training Loss: 0.017272470518946648, Validation Loss: 0.015362665988504887
Epoch 108, Training Loss: 0.015362663194537163, Validation Loss: 0.01355399377644062
Epoch 109, Training Loss: 0.01355399377644062, Validation Loss: 0.011858521029353142
Epoch 110, Training Loss: 0.011858520098030567, Validation Loss: 0.010290306992828846
Epoch 111, Training Loss: 0.01029030978679657, Validation Loss: 0.008864166215062141
Epoch 112, Training Loss: 0.008864165283739567, Validation Loss: 0.0075539653189480305
Epoch 113, Training Loss: 0.0075539639219641685, Validation Loss: 0.006353342905640602
Epoch 114, Training Loss: 0.00635334150865674, Validation Loss: 0.005261229816824198
Epoch 115, Training Loss: 0.005261227022856474, Validation Loss: 0.004286476410925388
Epoch 116, Training Loss: 0.004286475013941526, Validation Loss: 0.003421126864850521
Epoch 117, Training Loss: 0.0034211298916488886, Validation Loss: 0.0026674058753997087
Epoch 118, Training Loss: 0.0026674082037061453, Validation Loss: 0.002027236856520176
Epoch 119, Training Loss: 0.002027236856520176, Validation Loss: 0.001501773134805262
Epoch 120, Training Loss: 0.0015017729019746184, Validation Loss: 0.0010882208589464426
Epoch 121, Training Loss: 0.0010882202768698335, Validation Loss: 0.000781316077336669
Epoch 122, Training Loss: 0.0007813167758285999, Validation Loss: 0.0005749621777795255
Epoch 123, Training Loss: 0.0005749619449488819, Validation Loss: 0.0004464912344701588
Epoch 124, Training Loss: 0.00044649073970504105, Validation Loss: 0.0003777852398343384
Epoch 125, Training Loss: 0.00037778602563776076, Validation Loss: 0.0003495708224363625
Epoch 126, Training Loss: 0.0003495708224363625, Validation Loss: 0.000346818589605391
Epoch 127, Training Loss: 0.0003468186187092215, Validation Loss: 0.000357178709236905
Epoch 128, Training Loss: 0.0003571795532479882, Validation Loss: 0.00037127427640371025
Epoch 129, Training Loss: 0.00037127535324543715, Validation Loss: 0.00038287919596768916
Epoch 130, Training Loss: 0.0003828791086561978, Validation Loss: 0.0003902886819560081
Epoch 131, Training Loss: 0.0003902880707755685, Validation Loss: 0.00039277426549233496
Epoch 132, Training Loss: 0.0003927747893612832, Validation Loss: 0.0003899510484188795
Epoch 133, Training Loss: 0.0003899518051184714, Validation Loss: 0.0003826325701083988
Epoch 134, Training Loss: 0.000382632773835212, Validation Loss: 0.0003708803269546479
Epoch 135, Training Loss: 0.00037088035605847836, Validation Loss: 0.00035508006112650037
Epoch 136, Training Loss: 0.0003550804394762963, Validation Loss: 0.00033547967905178666
Epoch 137, Training Loss: 0.0003354801738169044, Validation Loss: 0.0003125311923213303
Epoch 138, Training Loss: 0.0003125321527477354, Validation Loss: 0.0002870765747502446
Epoch 139, Training Loss: 0.00028707628371194005, Validation Loss: 0.0002602355962153524
Epoch 140, Training Loss: 0.0002602355962153524, Validation Loss: 0.00023325132497120649
Epoch 141, Training Loss: 0.00023325094662141055, Validation Loss: 0.00020736776059493423
Epoch 142, Training Loss: 0.00020736768783535808, Validation Loss: 0.00018357997760176659
Epoch 143, Training Loss: 0.00018357980297878385, Validation Loss: 0.00016246632731053978
Epoch 144, Training Loss: 0.00016246693849097937, Validation Loss: 0.00014414527686312795
Epoch 145, Training Loss: 0.000144145407830365, Validation Loss: 0.0001283440215047449
Epoch 146, Training Loss: 0.00012834314838983119, Validation Loss: 0.00011455078492872417
Epoch 147, Training Loss: 0.0001145511050708592, Validation Loss: 0.00010221562843071297
Epoch 148, Training Loss: 0.00010221566481050104, Validation Loss: 9.0882254880853e-05
Epoch 149, Training Loss: 9.08826186787337e-05, Validation Loss: 8.029586024349555e-05
Epoch 150, Training Loss: 8.029602031456307e-05, Validation Loss: 7.041545904939994e-05
Epoch 151, Training Loss: 7.041554636089131e-05, Validation Loss: 6.135430157883093e-05
Epoch 152, Training Loss: 6.135417788755149e-05, Validation Loss: 5.3283769375411794e-05
Epoch 153, Training Loss: 5.3283631132217124e-05, Validation Loss: 4.633748176274821e-05
Epoch 154, Training Loss: 4.633743083104491e-05, Validation Loss: 4.0545004594605416e-05
Epoch 155, Training Loss: 4.05447390221525e-05, Validation Loss: 3.580942575354129e-05
Epoch 156, Training Loss: 3.5809644032269716e-05, Validation Loss: 3.1934116123011336e-05
Epoch 157, Training Loss: 3.193409429513849e-05, Validation Loss: 2.8671714972006157e-05
Epoch 158, Training Loss: 2.8671563995885663e-05, Validation Loss: 2.578788007667754e-05
Epoch 159, Training Loss: 2.578787098173052e-05, Validation Loss: 2.3109972971724346e-05
Epoch 160, Training Loss: 2.3110022084438242e-05, Validation Loss: 2.0549647160805762e-05
Epoch 161, Training Loss: 2.054968717857264e-05, Validation Loss: 1.8100899978890084e-05
Epoch 162, Training Loss: 1.8100945453625172e-05, Validation Loss: 1.581299329700414e-05
Epoch 163, Training Loss: 1.5813107893336564e-05, Validation Loss: 1.3755659892922267e-05
Epoch 164, Training Loss: 1.3755598956777249e-05, Validation Loss: 1.1985595847363584e-05
Epoch 165, Training Loss: 1.1985542187176179e-05, Validation Loss: 1.0537200068938546e-05
Epoch 166, Training Loss: 1.0537235539231915e-05, Validation Loss: 9.367920029035304e-06
Epoch 167, Training Loss: 9.367948223371059e-06, Validation Loss: 8.426477506873198e-06
Epoch 168, Training Loss: 8.426453860010952e-06, Validation Loss: 7.658418326172978e-06
Epoch 169, Training Loss: 7.658372851437889e-06, Validation Loss: 7.012861260591308e-06
Epoch 170, Training Loss: 7.0128780862432905e-06, Validation Loss: 6.454278718592832e-06
Epoch 171, Training Loss: 6.454296908486867e-06, Validation Loss: 5.965608124824939e-06
Epoch 172, Training Loss: 5.9657077144947834e-06, Validation Loss: 5.545271051232703e-06
Epoch 173, Training Loss: 5.545298336073756e-06, Validation Loss: 5.198229246161645e-06
Epoch 174, Training Loss: 5.198194685362978e-06, Validation Loss: 4.926848760078428e-06
Epoch 175, Training Loss: 4.926902420265833e-06, Validation Loss: 4.724577138404129e-06
Epoch 176, Training Loss: 4.724615791928954e-06, Validation Loss: 4.573109436023515e-06
Epoch 177, Training Loss: 4.573011210595723e-06, Validation Loss: 4.44499301011092e-06
Epoch 178, Training Loss: 4.444965725269867e-06, Validation Loss: 4.310198164603207e-06
Epoch 179, Training Loss: 4.3102695599372964e-06, Validation Loss: 4.143129444855731e-06
Epoch 180, Training Loss: 4.1431035242567305e-06, Validation Loss: 3.927335455955472e-06
Epoch 181, Training Loss: 3.9273609218071215e-06, Validation Loss: 3.659232106656418e-06
Epoch 182, Training Loss: 3.659202320704935e-06, Validation Loss: 3.346076709931367e-06
Epoch 183, Training Loss: 3.346089442857192e-06, Validation Loss: 3.0034811970836017e-06
Epoch 184, Training Loss: 3.0035052986931987e-06, Validation Loss: 2.649805310284137e-06
Epoch 185, Training Loss: 2.649886027938919e-06, Validation Loss: 2.3022521418170072e-06
Epoch 186, Training Loss: 2.302228949702112e-06, Validation Loss: 1.9734077341126977e-06
Epoch 187, Training Loss: 1.973359758267179e-06, Validation Loss: 1.6707540453353431e-06
Epoch 188, Training Loss: 1.6707859913367429e-06, Validation Loss: 1.397504888700496e-06
Epoch 189, Training Loss: 1.3974560033602756e-06, Validation Loss: 1.1538230637597735e-06
Epoch 190, Training Loss: 1.153814309873269e-06, Validation Loss: 9.394339599566592e-07
Epoch 191, Training Loss: 9.394320841238368e-07, Validation Loss: 7.542778917013493e-07
Epoch 192, Training Loss: 7.543066544712929e-07, Validation Loss: 5.992237106511311e-07
Epoch 193, Training Loss: 5.992471869831206e-07, Validation Loss: 4.750628193050943e-07
Epoch 194, Training Loss: 4.7507370481980615e-07, Validation Loss: 3.818369407326827e-07
Epoch 195, Training Loss: 3.81832336415755e-07, Validation Loss: 3.1775485354046396e-07
Epoch 196, Training Loss: 3.1774848707755154e-07, Validation Loss: 2.7886554221367987e-07
Epoch 197, Training Loss: 2.788741824133467e-07, Validation Loss: 2.595530474991392e-07
Epoch 198, Training Loss: 2.595216415102186e-07, Validation Loss: 2.530788663079875e-07
Epoch 199, Training Loss: 2.530725282667845e-07, Validation Loss: 2.531337486288976e-07
Epoch 200, Training Loss: 2.531335496769316e-07, Validation Loss: 2.545235986417538e-07
Epoch 201, Training Loss: 2.545364168327069e-07, Validation Loss: 2.5392586167072295e-07
Epoch 202, Training Loss: 2.5394604108441854e-07, Validation Loss: 2.4991715008582105e-07
Epoch 203, Training Loss: 2.499089930552145e-07, Validation Loss: 2.4254370600829134e-07
Epoch 204, Training Loss: 2.4254248387478583e-07, Validation Loss: 2.327352603970212e-07
Epoch 205, Training Loss: 2.327092829546018e-07, Validation Loss: 2.2158772594593756e-07
Epoch 206, Training Loss: 2.2158199897148734e-07, Validation Loss: 2.099065739002981e-07
Epoch 207, Training Loss: 2.0991173244055972e-07, Validation Loss: 1.980352521968598e-07
Epoch 208, Training Loss: 1.9803816542207642e-07, Validation Loss: 1.8586437988687976e-07
Epoch 209, Training Loss: 1.8586635519568517e-07, Validation Loss: 1.7316170897174743e-07
Epoch 210, Training Loss: 1.731561667384085e-07, Validation Loss: 1.5974309519606322e-07
Epoch 211, Training Loss: 1.5974286782238778e-07, Validation Loss: 1.457531055848449e-07
Epoch 212, Training Loss: 1.4575513773706916e-07, Validation Loss: 1.3155936073872e-07
Epoch 213, Training Loss: 1.3154757994016109e-07, Validation Loss: 1.1770761432217114e-07
Epoch 214, Training Loss: 1.1770232788421708e-07, Validation Loss: 1.0473574008074138e-07
Epoch 215, Training Loss: 1.0473699063595632e-07, Validation Loss: 9.301444947595883e-08
Epoch 216, Training Loss: 9.301715664378207e-08, Validation Loss: 8.262905026867884e-08
Epoch 217, Training Loss: 8.262791340030162e-08, Validation Loss: 7.342477204019815e-08
Epoch 218, Training Loss: 7.341143515304793e-08, Validation Loss: 6.507677596800931e-08
Epoch 219, Training Loss: 6.506768102099159e-08, Validation Loss: 5.729549101829434e-08
Epoch 220, Training Loss: 5.728368535073969e-08, Validation Loss: 4.982643275752707e-08
Epoch 221, Training Loss: 4.982385704010994e-08, Validation Loss: 4.264483877136627e-08
Epoch 222, Training Loss: 4.2644284548032374e-08, Validation Loss: 3.5849900825724035e-08
Epoch 223, Training Loss: 3.5854608171348445e-08, Validation Loss: 2.9626878728095107e-08
Epoch 224, Training Loss: 2.961807155088536e-08, Validation Loss: 2.4144389598745875e-08
Epoch 225, Training Loss: 2.415210431649939e-08, Validation Loss: 1.958443007765709e-08
Epoch 226, Training Loss: 1.9574939003064173e-08, Validation Loss: 1.5934540797957197e-08
Epoch 227, Training Loss: 1.59343560568459e-08, Validation Loss: 1.3131822740319876e-08
Epoch 228, Training Loss: 1.3130066811584129e-08, Validation Loss: 1.1047969650235245e-08
Epoch 229, Training Loss: 1.104993874179172e-08, Validation Loss: 9.534355527307525e-09
Epoch 230, Training Loss: 9.535381373382279e-09, Validation Loss: 8.462405887144087e-09
Epoch 231, Training Loss: 8.46059045045422e-09, Validation Loss: 7.750138308892929e-09
Epoch 232, Training Loss: 7.750841746201331e-09, Validation Loss: 7.352135789062686e-09
Epoch 233, Training Loss: 7.354329589759345e-09, Validation Loss: 7.228860177121987e-09
Epoch 234, Training Loss: 7.2267392070557435e-09, Validation Loss: 7.334687079918467e-09
Epoch 235, Training Loss: 7.332614515576097e-09, Validation Loss: 7.59751195289482e-09
Epoch 236, Training Loss: 7.593301987185441e-09, Validation Loss: 7.917961397652107e-09
Epoch 237, Training Loss: 7.916719724221366e-09, Validation Loss: 8.194684042450717e-09
Epoch 238, Training Loss: 8.195407907862773e-09, Validation Loss: 8.336741075254395e-09
Epoch 239, Training Loss: 8.332324163973226e-09, Validation Loss: 8.269882556533048e-09
Epoch 240, Training Loss: 8.269990914300251e-09, Validation Loss: 7.979869209862045e-09
Epoch 241, Training Loss: 7.978385063722726e-09, Validation Loss: 7.484254993528339e-09
Epoch 242, Training Loss: 7.486538500245388e-09, Validation Loss: 6.838400068431838e-09
Epoch 243, Training Loss: 6.835169319430179e-09, Validation Loss: 6.089958315413924e-09
Epoch 244, Training Loss: 6.092327087259264e-09, Validation Loss: 5.315426321317318e-09
Epoch 245, Training Loss: 5.317027707008037e-09, Validation Loss: 4.556667043686957e-09
Epoch 246, Training Loss: 4.555624766311439e-09, Validation Loss: 3.844647267214896e-09
Epoch 247, Training Loss: 3.842750118110416e-09, Validation Loss: 3.1930744714969705e-09
Epoch 248, Training Loss: 3.1944467071554072e-09, Validation Loss: 2.619058525610285e-09
Epoch 249, Training Loss: 2.6162736421753152e-09, Validation Loss: 2.118438091613939e-09
Epoch 250, Training Loss: 2.1165054153726715e-09, Validation Loss: 1.696602192069463e-09
Epoch 251, Training Loss: 1.6980439276892412e-09, Validation Loss: 1.3588429270683378e-09
Epoch 252, Training Loss: 1.3602499127074452e-09, Validation Loss: 1.1062981641885017e-09
Epoch 253, Training Loss: 1.1057729176755515e-09, Validation Loss: 9.268668055284479e-10
Epoch 254, Training Loss: 9.27642407333451e-10, Validation Loss: 8.11768319231021e-10
Epoch 255, Training Loss: 8.117484462388802e-10, Validation Loss: 7.443029526044143e-10
Epoch 256, Training Loss: 7.440592031393578e-10, Validation Loss: 7.03318681072318e-10
Epoch 257, Training Loss: 7.038518656798942e-10, Validation Loss: 6.723757106641415e-10
Epoch 258, Training Loss: 6.723178680445585e-10, Validation Loss: 6.419318410166852e-10
Epoch 259, Training Loss: 6.417137377034976e-10, Validation Loss: 6.038872735203427e-10
Epoch 260, Training Loss: 6.040581368438325e-10, Validation Loss: 5.603618680183331e-10
Epoch 261, Training Loss: 5.602506791824169e-10, Validation Loss: 5.132735347856965e-10
Epoch 262, Training Loss: 5.136578384856705e-10, Validation Loss: 4.698841316042035e-10
Epoch 263, Training Loss: 4.698111344403344e-10, Validation Loss: 4.32308494557887e-10
Epoch 264, Training Loss: 4.315574286817281e-10, Validation Loss: 4.0215716867741946e-10
Epoch 265, Training Loss: 4.0217582042423317e-10, Validation Loss: 3.7742156622222467e-10
Epoch 266, Training Loss: 3.769447809442994e-10, Validation Loss: 3.585704788644506e-10
Epoch 267, Training Loss: 3.579334328929207e-10, Validation Loss: 3.3916822128610136e-10
Epoch 268, Training Loss: 3.3988642456073137e-10, Validation Loss: 3.222896671761788e-10
Epoch 269, Training Loss: 3.223442068822635e-10, Validation Loss: 3.0439620268829515e-10
Epoch 270, Training Loss: 3.045758645292551e-10, Validation Loss: 2.8618585279360786e-10
Epoch 271, Training Loss: 2.8595550927157376e-10, Validation Loss: 2.680977384539318e-10
Epoch 272, Training Loss: 2.680728694581802e-10, Validation Loss: 2.510819607781656e-10
Epoch 273, Training Loss: 2.5078678023149337e-10, Validation Loss: 2.330526049920678e-10
Epoch 274, Training Loss: 2.326599468638335e-10, Validation Loss: 2.1442339570576507e-10
Epoch 275, Training Loss: 2.1427759566705618e-10, Validation Loss: 1.945241606682302e-10
Epoch 276, Training Loss: 1.94471966308285e-10, Validation Loss: 1.7217489933774033e-10
Epoch 277, Training Loss: 1.7260042006750353e-10, Validation Loss: 1.491537032771717e-10
Epoch 278, Training Loss: 1.4977093176771206e-10, Validation Loss: 1.266951682454831e-10
Epoch 279, Training Loss: 1.263662785522257e-10, Validation Loss: 1.0404815897757658e-10
Epoch 280, Training Loss: 1.0400189043302532e-10, Validation Loss: 8.396652817488359e-11
Epoch 281, Training Loss: 8.381238064680829e-11, Validation Loss: 6.71305303012737e-11
Epoch 282, Training Loss: 6.707874533606883e-11, Validation Loss: 5.3294244017898507e-11
Epoch 283, Training Loss: 5.343049960804258e-11, Validation Loss: 4.292244337733564e-11
Epoch 284, Training Loss: 4.2972181368838847e-11, Validation Loss: 3.5437482809319576e-11
Epoch 285, Training Loss: 3.529795900014676e-11, Validation Loss: 2.972781049104256e-11
Epoch 286, Training Loss: 2.9735790219032054e-11, Validation Loss: 2.6116468362924472e-11
Epoch 287, Training Loss: 2.5920215626640264e-11, Validation Loss: 2.3565092585609015e-11
Epoch 288, Training Loss: 2.3534675944181238e-11, Validation Loss: 2.20170479070525e-11
Epoch 289, Training Loss: 2.187588825364184e-11, Validation Loss: 2.099259654997354e-11
Epoch 290, Training Loss: 2.1344049791482966e-11, Validation Loss: 2.0950519097340248e-11
Epoch 291, Training Loss: 2.0748756879296337e-11, Validation Loss: 2.090200235116413e-11
Epoch 292, Training Loss: 2.0793833668819595e-11, Validation Loss: 2.081774856665941e-11
Epoch 293, Training Loss: 2.0911692516500935e-11, Validation Loss: 2.0980099602052604e-11
Epoch 294, Training Loss: 2.1088747068076508e-11, Validation Loss: 2.076145332041701e-11
Epoch 295, Training Loss: 2.082855068974432e-11, Validation Loss: 2.0458280902690973e-11
Epoch 296, Training Loss: 2.01172654923365e-11, Validation Loss: 1.9439262699538773e-11
Epoch 297, Training Loss: 1.931449791769957e-11, Validation Loss: 1.8137763860281986e-11
Epoch 298, Training Loss: 1.8139807364536686e-11, Validation Loss: 1.6803992225478126e-11
Epoch 299, Training Loss: 1.6798543459040083e-11, Validation Loss: 1.520534392840389e-11
Epoch 300, Training Loss: 1.5189202326459927e-11, Validation Loss: 1.3797226382228356e-11
Epoch 301, Training Loss: 1.3507780831367722e-11, Validation Loss: 1.2090345218040977e-11
Epoch 302, Training Loss: 1.2130720039582599e-11, Validation Loss: 1.0635953055782021e-11
Epoch 303, Training Loss: 1.0634303333756367e-11, Validation Loss: 9.308806329932917e-12
Epoch 304, Training Loss: 9.288785886296669e-12, Validation Loss: 8.083208581644019e-12
Epoch 305, Training Loss: 8.085120246914546e-12, Validation Loss: 6.9997623149131716e-12
Epoch 306, Training Loss: 6.886187366855756e-12, Validation Loss: 6.023500274954241e-12
Epoch 307, Training Loss: 5.923792706363784e-12, Validation Loss: 5.061570086672962e-12
Epoch 308, Training Loss: 4.936807039557234e-12, Validation Loss: 4.236178248462341e-12
Epoch 309, Training Loss: 4.1751198852357785e-12, Validation Loss: 3.5639297502748635e-12
Epoch 310, Training Loss: 3.5242360245379967e-12, Validation Loss: 2.916039371775314e-12
Epoch 311, Training Loss: 2.9042334943191195e-12, Validation Loss: 2.4019280488174477e-12
Epoch 312, Training Loss: 2.428088979877785e-12, Validation Loss: 2.0919758980664227e-12
Epoch 313, Training Loss: 2.08535836168644e-12, Validation Loss: 1.8480570806306273e-12
Epoch 314, Training Loss: 1.8344592338237486e-12, Validation Loss: 1.6633647584307631e-12
Epoch 315, Training Loss: 1.6810706472691894e-12, Validation Loss: 1.5048687122820592e-12
Epoch 316, Training Loss: 1.5177526119583562e-12, Validation Loss: 1.3792092468101202e-12
Epoch 317, Training Loss: 1.4123363936691113e-12, Validation Loss: 1.3119676785938728e-12
Epoch 318, Training Loss: 1.2987190533067516e-12, Validation Loss: 1.218508475543667e-12
Epoch 319, Training Loss: 1.2608229347718658e-12, Validation Loss: 1.1414582386931604e-12
Epoch 320, Training Loss: 1.1315629423053197e-12, Validation Loss: 1.0672328906030648e-12
Epoch 321, Training Loss: 1.077416693189004e-12, Validation Loss: 1.0029315702583808e-12
Epoch 322, Training Loss: 9.863791641112618e-13, Validation Loss: 9.399460376702251e-13
Epoch 323, Training Loss: 9.284461220671059e-13, Validation Loss: 8.668636555103637e-13
Epoch 324, Training Loss: 8.976197606383463e-13, Validation Loss: 8.158865835543316e-13
Epoch 325, Training Loss: 8.211974394760346e-13, Validation Loss: 7.542188444967235e-13
Epoch 326, Training Loss: 7.817775832079377e-13, Validation Loss: 7.276256420302163e-13
Epoch 327, Training Loss: 6.759770694586553e-13, Validation Loss: 6.675513549055101e-13
Epoch 328, Training Loss: 6.550488233433849e-13, Validation Loss: 6.174750923244876e-13
Epoch 329, Training Loss: 6.130686236449634e-13, Validation Loss: 5.632768557140011e-13
Epoch 330, Training Loss: 5.530008417332921e-13, Validation Loss: 5.020964655329252e-13
Epoch 331, Training Loss: 5.007607826665317e-13, Validation Loss: 4.4781168248402003e-13
Epoch 332, Training Loss: 4.570491663087595e-13, Validation Loss: 4.099531315544108e-13
Epoch 333, Training Loss: 4.1098228336158837e-13, Validation Loss: 3.9575132992734907e-13
Epoch 334, Training Loss: 3.865418456237141e-13, Validation Loss: 3.428396618248425e-13
Epoch 335, Training Loss: 3.273908379640422e-13, Validation Loss: 3.22237137147241e-13
Epoch 336, Training Loss: 3.0191542083231326e-13, Validation Loss: 2.7439452077691884e-13
Epoch 337, Training Loss: 2.413912440161342e-13, Validation Loss: 2.4038439966865555e-13
Epoch 338, Training Loss: 2.206651473959237e-13, Validation Loss: 2.0757652324440712e-13
Epoch 339, Training Loss: 1.9678952477980571e-13, Validation Loss: 1.7819964525257054e-13
Epoch 340, Training Loss: 1.6483042957881472e-13, Validation Loss: 1.6212106255988207e-13
Epoch 341, Training Loss: 1.488926576432778e-13, Validation Loss: 1.4102654048893382e-13
Epoch 342, Training Loss: 1.2937494500188385e-13, Validation Loss: 1.1112345174894497e-13
Epoch 343, Training Loss: 1.1270989024904365e-13, Validation Loss: 1.0663567468274793e-13
Epoch 344, Training Loss: 1.014221597873434e-13, Validation Loss: 7.921072651961847e-14
Epoch 345, Training Loss: 8.140353896599756e-14, Validation Loss: 6.775820410396399e-14
Epoch 346, Training Loss: 6.398746414454023e-14, Validation Loss: 5.568665984606071e-14
Epoch 347, Training Loss: 6.15446617822403e-14, Validation Loss: 4.8449569687138497e-14
Epoch 348, Training Loss: 5.0702406276291814e-14, Validation Loss: 4.6492744007996245e-14
Epoch 349, Training Loss: 4.231295150955265e-14, Validation Loss: 3.834592352306397e-14
Epoch 350, Training Loss: 3.4128526149894076e-14, Validation Loss: 3.364786883364515e-14
Epoch 351, Training Loss: 3.030482969060798e-14, Validation Loss: 2.55845810439052e-14
Epoch 352, Training Loss: 2.517735640198554e-14, Validation Loss: 1.959870084961273e-14
Epoch 353, Training Loss: 2.1703972440893088e-14, Validation Loss: 2.396408165493153e-14
Epoch 354, Training Loss: 2.1836111274730653e-14, Validation Loss: 2.0234192400487953e-14
Epoch 355, Training Loss: 1.7445192426052136e-14, Validation Loss: 2.163715848201367e-14
Epoch 356, Training Loss: 1.538860998264585e-14, Validation Loss: 1.9269052567200302e-14
Epoch 357, Training Loss: 1.4073622672252598e-14, Validation Loss: 1.8991639112579152e-14
Epoch 358, Training Loss: 1.2792261722832394e-14, Validation Loss: 2.120450421695154e-14
Epoch 359, Training Loss: 1.4335698901297815e-14, Validation Loss: 2.2731728337773566e-14
Epoch 360, Training Loss: 1.4522949086815534e-14, Validation Loss: 1.9079374785255752e-14
Epoch 361, Training Loss: 1.3475342972816152e-14, Validation Loss: 2.0568685711358677e-14
Epoch 362, Training Loss: 1.2058140808545934e-14, Validation Loss: 1.9915362422877857e-14
Epoch 363, Training Loss: 1.3760304338030285e-14, Validation Loss: 1.8723239782582682e-14
Epoch 364, Training Loss: 1.5049603680232157e-14, Validation Loss: 1.706527782041785e-14
Epoch 365, Training Loss: 1.2667562379370563e-14, Validation Loss: 1.4959282863000536e-14
Epoch 366, Training Loss: 1.2427436162120494e-14, Validation Loss: 1.2225107943108701e-14
Epoch 367, Training Loss: 1.2474607426953086e-14, Validation Loss: 1.4247553264674744e-14
Epoch 368, Training Loss: 9.77547764822095e-15, Validation Loss: 1.4527645037475112e-14
Epoch 369, Training Loss: 1.014087072100751e-14, Validation Loss: 1.0289406418638024e-14
Epoch 370, Training Loss: 8.547794023701198e-15, Validation Loss: 1.3209904870003283e-14
Epoch 371, Training Loss: 9.501958851091275e-15, Validation Loss: 6.081126084595901e-15
Epoch 372, Training Loss: 7.515733505382774e-15, Validation Loss: 7.994960182983787e-15
Epoch 373, Training Loss: 7.036283211083686e-15, Validation Loss: 5.51198643612737e-15
Epoch 374, Training Loss: 7.808435057668917e-15, Validation Loss: 9.074824699746402e-15
Epoch 375, Training Loss: 7.598199786094505e-15, Validation Loss: 8.121311240692763e-15
Epoch 376, Training Loss: 6.259694182404263e-15, Validation Loss: 8.05906109533315e-15
Epoch 377, Training Loss: 5.818406957543718e-15, Validation Loss: 7.135804500188383e-15
Epoch 378, Training Loss: 4.729067530233116e-15, Validation Loss: 5.602142081934276e-15
Epoch 379, Training Loss: 5.31196807596274e-15, Validation Loss: 7.63820684625922e-15
Epoch 380, Training Loss: 4.709151668060799e-15, Validation Loss: 8.537911690305582e-15
Epoch 381, Training Loss: 5.111574056686002e-15, Validation Loss: 6.2300120303501044e-15
Epoch 382, Training Loss: 5.45728420136074e-15, Validation Loss: 6.055538913325243e-15
Epoch 383, Training Loss: 2.801556179087678e-15, Validation Loss: 4.8586381601746064e-15
Epoch 384, Training Loss: 2.8064266185343903e-15, Validation Loss: 5.192380576337589e-15
Epoch 385, Training Loss: 2.9607837618531464e-15, Validation Loss: 6.461664106479368e-15
Epoch 386, Training Loss: 2.9769633616951244e-15, Validation Loss: 5.514505088596031e-15
Epoch 387, Training Loss: 3.1018634519654545e-15, Validation Loss: 6.0616104454911616e-15
Epoch 388, Training Loss: 3.68676553654944e-15, Validation Loss: 5.4562254101766725e-15
Epoch 389, Training Loss: 3.846593453916275e-15, Validation Loss: 5.703723778683169e-15
Epoch 390, Training Loss: 2.219756564431248e-15, Validation Loss: 5.31155938256569e-15
Epoch 391, Training Loss: 2.558361161469707e-15, Validation Loss: 4.909595662281425e-15
Epoch 392, Training Loss: 2.5735734496859205e-15, Validation Loss: 3.857619281790684e-15
Epoch 393, Training Loss: 1.9119765551345574e-15, Validation Loss: 4.215973087269087e-15
Epoch 394, Training Loss: 2.2685956371369838e-15, Validation Loss: 3.898735531599829e-15
Epoch 395, Training Loss: 1.4647514175555225e-15, Validation Loss: 5.871916569920614e-15
Epoch 396, Training Loss: 1.6422270546201639e-15, Validation Loss: 5.724898755331579e-15
Epoch 397, Training Loss: 3.016228209239808e-15, Validation Loss: 5.140097044151843e-15
Epoch 398, Training Loss: 3.596559915798646e-15, Validation Loss: 5.001252250470866e-15
Epoch 399, Training Loss: 2.8135323779289066e-15, Validation Loss: 4.883057696527474e-15
Epoch 400, Training Loss: 3.3429233112816344e-15, Validation Loss: 5.36878026980098e-15
Epoch 401, Training Loss: 3.3149009202876204e-15, Validation Loss: 4.573342640462781e-15
Epoch 402, Training Loss: 3.1900008300172903e-15, Validation Loss: 3.724762587530321e-15
Epoch 403, Training Loss: 2.666981490252046e-15, Validation Loss: 4.032208865845793e-15
Epoch 404, Training Loss: 2.7203576949397495e-15, Validation Loss: 4.037380001988781e-15
Epoch 405, Training Loss: 2.5666345557820132e-15, Validation Loss: 3.810931672770974e-15
Epoch 406, Training Loss: 3.1608772961918457e-15, Validation Loss: 3.764894585054756e-15
Epoch 407, Training Loss: 3.173954637864505e-15, Validation Loss: 5.3996715613873446e-15
Epoch 408, Training Loss: 3.6853645440546815e-15, Validation Loss: 5.352967435225163e-15
Epoch 409, Training Loss: 3.64106217981444e-15, Validation Loss: 6.707160936131502e-15
Epoch 410, Training Loss: 3.1086354803787526e-15, Validation Loss: 5.386728050920352e-15
Epoch 411, Training Loss: 3.786278778841138e-15, Validation Loss: 4.963855745849588e-15
Epoch 412, Training Loss: 2.2225253033775856e-15, Validation Loss: 4.92195556704776e-15
Epoch 413, Training Loss: 2.598560074596975e-15, Validation Loss: 4.6342248276125785e-15
Epoch 414, Training Loss: 2.16781481003972e-15, Validation Loss: 4.59993058116062e-15
Epoch 415, Training Loss: 1.493541220399749e-15, Validation Loss: 4.574577190983404e-15
Epoch 416, Training Loss: 2.2442762624301288e-15, Validation Loss: 6.5664399644723564e-15
Epoch 417, Training Loss: 2.256018891936152e-15, Validation Loss: 5.497750353382867e-15
Epoch 418, Training Loss: 2.1996403789669057e-15, Validation Loss: 5.451046227220686e-15
Epoch 419, Training Loss: 1.295048790089597e-15, Validation Loss: 5.16761883867403e-15
Epoch 420, Training Loss: 1.2713631019064067e-15, Validation Loss: 5.206316809418764e-15
Epoch 421, Training Loss: 1.1619421152306753e-15, Validation Loss: 5.293086017502547e-15
Epoch 422, Training Loss: 1.276166943387641e-15, Validation Loss: 5.307397486179356e-15
Epoch 423, Training Loss: 1.191832743268977e-15, Validation Loss: 5.323410644047198e-15
Epoch 424, Training Loss: 1.1938343880024574e-15, Validation Loss: 5.30256050453406e-15
Epoch 425, Training Loss: 1.1457958673109954e-15, Validation Loss: 5.5606671136719694e-15
Epoch 426, Training Loss: 1.5427472701298826e-15, Validation Loss: 5.4832720192154495e-15
Epoch 427, Training Loss: 1.0623622749734996e-15, Validation Loss: 4.369679497526115e-15
Epoch 428, Training Loss: 7.931465640345539e-16, Validation Loss: 5.1149765880351226e-15
Epoch 429, Training Loss: 1.1806570964420222e-15, Validation Loss: 5.055929497765552e-15
Epoch 430, Training Loss: 1.0477506389960077e-15, Validation Loss: 4.20190344649872e-15
Epoch 431, Training Loss: 1.128215063216022e-15, Validation Loss: 3.595250402862191e-15
Epoch 432, Training Loss: 1.863204186273418e-15, Validation Loss: 3.5367034855479738e-15
Epoch 433, Training Loss: 1.791146458175784e-15, Validation Loss: 3.5014753852716674e-15
Epoch 434, Training Loss: 1.650800510354035e-15, Validation Loss: 4.240334178348595e-15
Epoch 435, Training Loss: 1.786909599373618e-15, Validation Loss: 4.1462588875782695e-15
Epoch 436, Training Loss: 1.6860288223885782e-15, Validation Loss: 3.6605363143047635e-15
Epoch 437, Training Loss: 1.7244595542384531e-15, Validation Loss: 3.6605363143047635e-15
Epoch 438, Training Loss: 2.380185028157686e-15, Validation Loss: 3.652529735370842e-15
Epoch 439, Training Loss: 2.0727387498422137e-15, Validation Loss: 3.7005683619414226e-15
Epoch 440, Training Loss: 2.0727387498422137e-15, Validation Loss: 4.850889926289598e-15
Epoch 441, Training Loss: 1.1036287672516634e-15, Validation Loss: 4.7558807816949246e-15
Epoch 442, Training Loss: 2.1962043898163686e-15, Validation Loss: 4.7558807816949246e-15
Epoch 443, Training Loss: 1.4329259545074551e-15, Validation Loss: 4.7558807816949246e-15
Epoch 444, Training Loss: 1.4329259545074551e-15, Validation Loss: 4.813526879469737e-15
Epoch 445, Training Loss: 2.3849222716734427e-15, Validation Loss: 4.186691158282506e-15
Epoch 446, Training Loss: 2.341687592463215e-15, Validation Loss: 3.602122804679739e-15
Epoch 447, Training Loss: 2.49274194256239e-15, Validation Loss: 3.5423413368448984e-15
Epoch 448, Training Loss: 2.6986736514900394e-15, Validation Loss: 2.7066217851506e-15
Epoch 449, Training Loss: 9.580454029588042e-16, Validation Loss: 2.7664862622142714e-15
Epoch 450, Training Loss: 1.7416066774644324e-15, Validation Loss: 3.4438290757386183e-15
Epoch 451, Training Loss: 3.2748354148495447e-15, Validation Loss: 4.4537386236951585e-15
Epoch 452, Training Loss: 2.0882845572814087e-15, Validation Loss: 4.426249863457915e-15
Epoch 453, Training Loss: 2.319269594964709e-15, Validation Loss: 3.672445597543159e-15
Epoch 454, Training Loss: 1.6963704593998428e-15, Validation Loss: 3.664439442125711e-15
Epoch 455, Training Loss: 1.6317853618420049e-15, Validation Loss: 4.065393922653322e-15
Epoch 456, Training Loss: 1.6317853618420049e-15, Validation Loss: 4.3033513120419465e-15
Epoch 457, Training Loss: 1.3492255467915742e-15, Validation Loss: 3.657500548221804e-15
Epoch 458, Training Loss: 9.713226444070153e-16, Validation Loss: 3.6949470277869694e-15
Epoch 459, Training Loss: 1.1327854412411693e-15, Validation Loss: 3.689075818913076e-15
Epoch 460, Training Loss: 1.0320379660662036e-15, Validation Loss: 3.3224818651655464e-15
Epoch 461, Training Loss: 4.491708781379964e-16, Validation Loss: 3.3224818651655464e-15
Epoch 462, Training Loss: 1.534307222085204e-15, Validation Loss: 3.393738935369788e-15
Epoch 463, Training Loss: 1.2145842599904644e-15, Validation Loss: 3.1387345844011974e-15
Epoch 464, Training Loss: 1.2145842599904644e-15, Validation Loss: 3.7186995256938745e-15
Epoch 465, Training Loss: 9.003991993048735e-16, Validation Loss: 3.7122942625467375e-15
Epoch 466, Training Loss: 1.575473552717355e-15, Validation Loss: 3.633130986812824e-15
Epoch 467, Training Loss: 8.020536978100841e-16, Validation Loss: 4.446641334630115e-15
Epoch 468, Training Loss: 4.0333416665336275e-16, Validation Loss: 4.561133084044584e-15
Epoch 469, Training Loss: 9.60580784328173e-16, Validation Loss: 2.9142882175542265e-15
Epoch 470, Training Loss: 9.779280190879412e-16, Validation Loss: 3.082889913946958e-15
Epoch 471, Training Loss: 9.875357020504099e-16, Validation Loss: 2.9761377163297882e-15
Epoch 472, Training Loss: 9.38496411931767e-16, Validation Loss: 2.9761377163297882e-15
Epoch 473, Training Loss: 9.745252759805838e-16, Validation Loss: 2.9494496139859366e-15
Epoch 474, Training Loss: 1.6951027687151583e-15, Validation Loss: 2.9494496139859366e-15
Epoch 475, Training Loss: 1.3940614359094676e-15, Validation Loss: 2.9494496139859366e-15
Epoch 476, Training Loss: 1.2939813168178198e-15, Validation Loss: 2.8878002267441636e-15
Epoch 477, Training Loss: 1.370842886396688e-15, Validation Loss: 3.219032249009721e-15
Epoch 478, Training Loss: 1.3360483611102574e-15, Validation Loss: 2.5339498836880747e-15
Epoch 479, Training Loss: 1.6538362764369945e-15, Validation Loss: 2.261331482581331e-15
Epoch 480, Training Loss: 1.6490324349557601e-15, Validation Loss: 2.4960195365517903e-15
Epoch 481, Training Loss: 1.6308845423026e-15, Validation Loss: 2.6001029451103988e-15
Epoch 482, Training Loss: 1.6308845423026e-15, Validation Loss: 2.5662843076583236e-15
Epoch 483, Training Loss: 1.9466710246540935e-15, Validation Loss: 4.115959672022036e-15
Epoch 484, Training Loss: 1.989905703864321e-15, Validation Loss: 4.115959672022036e-15
Epoch 485, Training Loss: 2.1628776667484114e-15, Validation Loss: 3.328995548529932e-15
Epoch 486, Training Loss: 2.2013083985982862e-15, Validation Loss: 3.328995548529932e-15
Epoch 487, Training Loss: 1.817000444824827e-15, Validation Loss: 3.300972945777681e-15
Epoch 488, Training Loss: 1.7209234034419032e-15, Validation Loss: 3.3025742615644654e-15
Epoch 489, Training Loss: 1.7209234034419032e-15, Validation Loss: 3.3441076751001327e-15
Epoch 490, Training Loss: 1.6449291956010235e-15, Validation Loss: 3.5312574872136022e-15
Epoch 491, Training Loss: 1.6449291956010235e-15, Validation Loss: 3.5312574872136022e-15
Epoch 492, Training Loss: 2.24174088106076e-15, Validation Loss: 4.042000143199579e-15
Epoch 493, Training Loss: 1.6189083434613714e-15, Validation Loss: 2.91469669919304e-15
Epoch 494, Training Loss: 1.7769016933435718e-15, Validation Loss: 3.1877822389701944e-15
Epoch 495, Training Loss: 2.065132605734107e-15, Validation Loss: 4.3463107055443165e-15
Epoch 496, Training Loss: 1.1778548996942682e-15, Validation Loss: 4.01200967115262e-15
Epoch 497, Training Loss: 1.1935341148226557e-15, Validation Loss: 2.8008389539395905e-15
Epoch 498, Training Loss: 1.8668737447591604e-15, Validation Loss: 3.5380964312297335e-15
Epoch 499, Training Loss: 1.8348480642981857e-15, Validation Loss: 4.319522441554452e-15
Epoch 500, Training Loss: 1.83057795945284e-15, Validation Loss: 4.420670457434351e-15
