Epoch 1, Training Loss: 0.4562896490097046, Validation Loss: 0.45512089133262634
Epoch 2, Training Loss: 0.45512089133262634, Validation Loss: 0.4539981484413147
Epoch 3, Training Loss: 0.4539981484413147, Validation Loss: 0.4529212415218353
Epoch 4, Training Loss: 0.4529212713241577, Validation Loss: 0.45187467336654663
Epoch 5, Training Loss: 0.45187467336654663, Validation Loss: 0.4508342742919922
Epoch 6, Training Loss: 0.45083433389663696, Validation Loss: 0.4497854709625244
Epoch 7, Training Loss: 0.4497854709625244, Validation Loss: 0.44874829053878784
Epoch 8, Training Loss: 0.44874832034111023, Validation Loss: 0.44771143794059753
Epoch 9, Training Loss: 0.44771143794059753, Validation Loss: 0.44664645195007324
Epoch 10, Training Loss: 0.44664645195007324, Validation Loss: 0.4455745816230774
Epoch 11, Training Loss: 0.4455745816230774, Validation Loss: 0.44449102878570557
Epoch 12, Training Loss: 0.44449102878570557, Validation Loss: 0.443403959274292
Epoch 13, Training Loss: 0.443403959274292, Validation Loss: 0.4423438012599945
Epoch 14, Training Loss: 0.4423438012599945, Validation Loss: 0.44128483533859253
Epoch 15, Training Loss: 0.44128483533859253, Validation Loss: 0.44021233916282654
Epoch 16, Training Loss: 0.44021233916282654, Validation Loss: 0.4391264319419861
Epoch 17, Training Loss: 0.4391264319419861, Validation Loss: 0.43802520632743835
Epoch 18, Training Loss: 0.43802520632743835, Validation Loss: 0.43689751625061035
Epoch 19, Training Loss: 0.43689751625061035, Validation Loss: 0.43574488162994385
Epoch 20, Training Loss: 0.43574488162994385, Validation Loss: 0.434556245803833
Epoch 21, Training Loss: 0.434556245803833, Validation Loss: 0.43331825733184814
Epoch 22, Training Loss: 0.43331825733184814, Validation Loss: 0.43202802538871765
Epoch 23, Training Loss: 0.43202802538871765, Validation Loss: 0.4306671619415283
Epoch 24, Training Loss: 0.4306671619415283, Validation Loss: 0.4292563199996948
Epoch 25, Training Loss: 0.4292563199996948, Validation Loss: 0.4277884364128113
Epoch 26, Training Loss: 0.4277884364128113, Validation Loss: 0.4262683391571045
Epoch 27, Training Loss: 0.4262683391571045, Validation Loss: 0.4247102737426758
Epoch 28, Training Loss: 0.4247102737426758, Validation Loss: 0.4230916202068329
Epoch 29, Training Loss: 0.4230915904045105, Validation Loss: 0.42141175270080566
Epoch 30, Training Loss: 0.42141175270080566, Validation Loss: 0.419677197933197
Epoch 31, Training Loss: 0.419677197933197, Validation Loss: 0.4178868532180786
Epoch 32, Training Loss: 0.4178868532180786, Validation Loss: 0.41602271795272827
Epoch 33, Training Loss: 0.41602271795272827, Validation Loss: 0.4140702188014984
Epoch 34, Training Loss: 0.4140702188014984, Validation Loss: 0.41199779510498047
Epoch 35, Training Loss: 0.41199779510498047, Validation Loss: 0.4097980260848999
Epoch 36, Training Loss: 0.4097980260848999, Validation Loss: 0.4074558615684509
Epoch 37, Training Loss: 0.4074558615684509, Validation Loss: 0.4049665927886963
Epoch 38, Training Loss: 0.4049665927886963, Validation Loss: 0.40232348442077637
Epoch 39, Training Loss: 0.40232348442077637, Validation Loss: 0.399554580450058
Epoch 40, Training Loss: 0.399554580450058, Validation Loss: 0.3965950012207031
Epoch 41, Training Loss: 0.3965950012207031, Validation Loss: 0.39346814155578613
Epoch 42, Training Loss: 0.39346814155578613, Validation Loss: 0.3901188373565674
Epoch 43, Training Loss: 0.3901188373565674, Validation Loss: 0.3865290582180023
Epoch 44, Training Loss: 0.3865290582180023, Validation Loss: 0.38268813490867615
Epoch 45, Training Loss: 0.38268816471099854, Validation Loss: 0.37857192754745483
Epoch 46, Training Loss: 0.37857192754745483, Validation Loss: 0.37415239214897156
Epoch 47, Training Loss: 0.37415239214897156, Validation Loss: 0.36941617727279663
Epoch 48, Training Loss: 0.36941617727279663, Validation Loss: 0.3643565773963928
Epoch 49, Training Loss: 0.3643565773963928, Validation Loss: 0.3590240180492401
Epoch 50, Training Loss: 0.3590240180492401, Validation Loss: 0.3533655107021332
Epoch 51, Training Loss: 0.3533655107021332, Validation Loss: 0.3473145663738251
Epoch 52, Training Loss: 0.3473145663738251, Validation Loss: 0.3408845365047455
Epoch 53, Training Loss: 0.3408845365047455, Validation Loss: 0.3340280055999756
Epoch 54, Training Loss: 0.3340280055999756, Validation Loss: 0.3267842233181
Epoch 55, Training Loss: 0.3267842233181, Validation Loss: 0.3191617429256439
Epoch 56, Training Loss: 0.3191617727279663, Validation Loss: 0.3111361265182495
Epoch 57, Training Loss: 0.3111361265182495, Validation Loss: 0.30273258686065674
Epoch 58, Training Loss: 0.3027326166629791, Validation Loss: 0.2939779758453369
Epoch 59, Training Loss: 0.2939779758453369, Validation Loss: 0.284948468208313
Epoch 60, Training Loss: 0.284948468208313, Validation Loss: 0.27564916014671326
Epoch 61, Training Loss: 0.27564916014671326, Validation Loss: 0.266136109828949
Epoch 62, Training Loss: 0.266136109828949, Validation Loss: 0.2565612196922302
Epoch 63, Training Loss: 0.2565612196922302, Validation Loss: 0.24705640971660614
Epoch 64, Training Loss: 0.24705640971660614, Validation Loss: 0.23780064284801483
Epoch 65, Training Loss: 0.23780064284801483, Validation Loss: 0.22893059253692627
Epoch 66, Training Loss: 0.22893056273460388, Validation Loss: 0.22051820158958435
Epoch 67, Training Loss: 0.22051820158958435, Validation Loss: 0.2127087116241455
Epoch 68, Training Loss: 0.2127087116241455, Validation Loss: 0.2057095766067505
Epoch 69, Training Loss: 0.2057095766067505, Validation Loss: 0.19947509467601776
Epoch 70, Training Loss: 0.19947509467601776, Validation Loss: 0.19393418729305267
Epoch 71, Training Loss: 0.19393417239189148, Validation Loss: 0.1888575255870819
Epoch 72, Training Loss: 0.1888575255870819, Validation Loss: 0.18397770822048187
Epoch 73, Training Loss: 0.18397770822048187, Validation Loss: 0.1790665090084076
Epoch 74, Training Loss: 0.1790665090084076, Validation Loss: 0.17383849620819092
Epoch 75, Training Loss: 0.17383849620819092, Validation Loss: 0.16814498603343964
Epoch 76, Training Loss: 0.16814498603343964, Validation Loss: 0.16198401153087616
Epoch 77, Training Loss: 0.16198399662971497, Validation Loss: 0.15525048971176147
Epoch 78, Training Loss: 0.15525047481060028, Validation Loss: 0.14807377755641937
Epoch 79, Training Loss: 0.14807377755641937, Validation Loss: 0.14049473404884338
Epoch 80, Training Loss: 0.14049473404884338, Validation Loss: 0.13272488117218018
Epoch 81, Training Loss: 0.13272488117218018, Validation Loss: 0.12489768862724304
Epoch 82, Training Loss: 0.12489768117666245, Validation Loss: 0.11704114079475403
Epoch 83, Training Loss: 0.11704112589359283, Validation Loss: 0.10972583293914795
Epoch 84, Training Loss: 0.10972584784030914, Validation Loss: 0.102505162358284
Epoch 85, Training Loss: 0.1025051698088646, Validation Loss: 0.09531255811452866
Epoch 86, Training Loss: 0.09531255066394806, Validation Loss: 0.08830132335424423
Epoch 87, Training Loss: 0.08830132335424423, Validation Loss: 0.08135688304901123
Epoch 88, Training Loss: 0.08135687559843063, Validation Loss: 0.07447239756584167
Epoch 89, Training Loss: 0.07447239756584167, Validation Loss: 0.06763292849063873
Epoch 90, Training Loss: 0.06763292849063873, Validation Loss: 0.06099161505699158
Epoch 91, Training Loss: 0.06099162623286247, Validation Loss: 0.054539453238248825
Epoch 92, Training Loss: 0.05453944206237793, Validation Loss: 0.04835087060928345
Epoch 93, Training Loss: 0.04835086688399315, Validation Loss: 0.04245676100254059
Epoch 94, Training Loss: 0.04245675727725029, Validation Loss: 0.03698083013296127
Epoch 95, Training Loss: 0.03698083758354187, Validation Loss: 0.03202621266245842
Epoch 96, Training Loss: 0.03202621266245842, Validation Loss: 0.02748734876513481
Epoch 97, Training Loss: 0.027487345039844513, Validation Loss: 0.02350728027522564
Epoch 98, Training Loss: 0.023507285863161087, Validation Loss: 0.020081307739019394
Epoch 99, Training Loss: 0.020081307739019394, Validation Loss: 0.017143964767456055
Epoch 100, Training Loss: 0.017143964767456055, Validation Loss: 0.014702032320201397
Epoch 101, Training Loss: 0.014702029526233673, Validation Loss: 0.012637026607990265
Epoch 102, Training Loss: 0.012637026607990265, Validation Loss: 0.010860173031687737
Epoch 103, Training Loss: 0.010860170237720013, Validation Loss: 0.009282778948545456
Epoch 104, Training Loss: 0.009282782673835754, Validation Loss: 0.0078738359734416
Epoch 105, Training Loss: 0.007873833179473877, Validation Loss: 0.006592725869268179
Epoch 106, Training Loss: 0.006592722609639168, Validation Loss: 0.005446448456496
Epoch 107, Training Loss: 0.005446448456496, Validation Loss: 0.004491808824241161
Epoch 108, Training Loss: 0.004491804167628288, Validation Loss: 0.003699341556057334
Epoch 109, Training Loss: 0.0036993406247347593, Validation Loss: 0.0030848849564790726
Epoch 110, Training Loss: 0.003084882628172636, Validation Loss: 0.0026247897185385227
Epoch 111, Training Loss: 0.00262479018419981, Validation Loss: 0.0023001781664788723
Epoch 112, Training Loss: 0.0023001788649708033, Validation Loss: 0.00208607641980052
Epoch 113, Training Loss: 0.0020860768854618073, Validation Loss: 0.0019566589035093784
Epoch 114, Training Loss: 0.001956659834831953, Validation Loss: 0.001880134455859661
Epoch 115, Training Loss: 0.0018801335245370865, Validation Loss: 0.0018236798932775855
Epoch 116, Training Loss: 0.0018236786127090454, Validation Loss: 0.0017653100658208132
Epoch 117, Training Loss: 0.0017653093673288822, Validation Loss: 0.0016949186101555824
Epoch 118, Training Loss: 0.0016949176788330078, Validation Loss: 0.0015897999983280897
Epoch 119, Training Loss: 0.001589801162481308, Validation Loss: 0.0014517174568027258
Epoch 120, Training Loss: 0.0014517176896333694, Validation Loss: 0.0012847788166254759
Epoch 121, Training Loss: 0.001284779398702085, Validation Loss: 0.001102939830161631
Epoch 122, Training Loss: 0.0011029401794075966, Validation Loss: 0.0009211719734594226
Epoch 123, Training Loss: 0.0009211715660057962, Validation Loss: 0.0007531482260674238
Epoch 124, Training Loss: 0.0007531484588980675, Validation Loss: 0.0006084204069338739
Epoch 125, Training Loss: 0.0006084204069338739, Validation Loss: 0.0004949677968397737
Epoch 126, Training Loss: 0.0004949677968397737, Validation Loss: 0.0004140373202972114
Epoch 127, Training Loss: 0.00041403796058148146, Validation Loss: 0.0003618145710788667
Epoch 128, Training Loss: 0.00036181401810608804, Validation Loss: 0.0003312008921056986
Epoch 129, Training Loss: 0.0003312010667286813, Validation Loss: 0.000313412252580747
Epoch 130, Training Loss: 0.0003134123980998993, Validation Loss: 0.0003004941390827298
Epoch 131, Training Loss: 0.00030049518682062626, Validation Loss: 0.0002855334023479372
Epoch 132, Training Loss: 0.0002855334314517677, Validation Loss: 0.0002656554861459881
Epoch 133, Training Loss: 0.000265655544353649, Validation Loss: 0.00024090625811368227
Epoch 134, Training Loss: 0.00024090625811368227, Validation Loss: 0.00021331582684069872
Epoch 135, Training Loss: 0.00021331616153474897, Validation Loss: 0.00018581878975965083
Epoch 136, Training Loss: 0.00018581926997285336, Validation Loss: 0.0001611952029634267
Epoch 137, Training Loss: 0.00016119462088681757, Validation Loss: 0.00014131204807199538
Epoch 138, Training Loss: 0.00014131201896816492, Validation Loss: 0.00012677907943725586
Epoch 139, Training Loss: 0.0001267797197215259, Validation Loss: 0.00011700553295668215
Epoch 140, Training Loss: 0.00011700574395945296, Validation Loss: 0.00011057168012484908
Epoch 141, Training Loss: 0.00011057175288442522, Validation Loss: 0.00010574812768027186
Epoch 142, Training Loss: 0.00010574828775133938, Validation Loss: 0.00010098573693539947
Epoch 143, Training Loss: 0.00010098597704200074, Validation Loss: 9.526018402539194e-05
Epoch 144, Training Loss: 9.526026406092569e-05, Validation Loss: 8.821161463856697e-05
Epoch 145, Training Loss: 8.821192750474438e-05, Validation Loss: 8.009502198547125e-05
Epoch 146, Training Loss: 8.00953057478182e-05, Validation Loss: 7.157077197916806e-05
Epoch 147, Training Loss: 7.157088839448988e-05, Validation Loss: 6.344272696878761e-05
Epoch 148, Training Loss: 6.344267603708431e-05, Validation Loss: 5.63955691177398e-05
Epoch 149, Training Loss: 5.6395798310404643e-05, Validation Loss: 5.081989729660563e-05
Epoch 150, Training Loss: 5.082010102341883e-05, Validation Loss: 4.672133218264207e-05
Epoch 151, Training Loss: 4.6721252147108316e-05, Validation Loss: 4.375950084067881e-05
Epoch 152, Training Loss: 4.375961725600064e-05, Validation Loss: 4.137331779929809e-05
Epoch 153, Training Loss: 4.137307041673921e-05, Validation Loss: 3.90249551855959e-05
Epoch 154, Training Loss: 3.902499156538397e-05, Validation Loss: 3.63111357728485e-05
Epoch 155, Training Loss: 3.6311168514657766e-05, Validation Loss: 3.299911259091459e-05
Epoch 156, Training Loss: 3.299919990240596e-05, Validation Loss: 2.9086395443300717e-05
Epoch 157, Training Loss: 2.9086570066283457e-05, Validation Loss: 2.477250927768182e-05
Epoch 158, Training Loss: 2.4772696633590385e-05, Validation Loss: 2.038686943706125e-05
Epoch 159, Training Loss: 2.0386774849612266e-05, Validation Loss: 1.629055623197928e-05
Epoch 160, Training Loss: 1.629049438633956e-05, Validation Loss: 1.2787568266503513e-05
Epoch 161, Training Loss: 1.2787524610757828e-05, Validation Loss: 1.0059324267785996e-05
Epoch 162, Training Loss: 1.005927970254561e-05, Validation Loss: 8.143912054947577e-06
Epoch 163, Training Loss: 8.143919330905192e-06, Validation Loss: 6.947023848624667e-06
Epoch 164, Training Loss: 6.947017936909106e-06, Validation Loss: 6.284407845669193e-06
Epoch 165, Training Loss: 6.2844387684890535e-06, Validation Loss: 5.93897402723087e-06
Epoch 166, Training Loss: 5.939001766819274e-06, Validation Loss: 5.713267000828637e-06
Epoch 167, Training Loss: 5.713354767067358e-06, Validation Loss: 5.4685551731381565e-06
Epoch 168, Training Loss: 5.468538347486174e-06, Validation Loss: 5.139828772371402e-06
Epoch 169, Training Loss: 5.139851964486297e-06, Validation Loss: 4.7310923037002794e-06
Epoch 170, Training Loss: 4.731108674604911e-06, Validation Loss: 4.292579887987813e-06
Epoch 171, Training Loss: 4.2925657908199355e-06, Validation Loss: 3.891763299179729e-06
Epoch 172, Training Loss: 3.891786946041975e-06, Validation Loss: 3.5858161027135793e-06
Epoch 173, Training Loss: 3.5858543014910538e-06, Validation Loss: 3.402137281227624e-06
Epoch 174, Training Loss: 3.402169568289537e-06, Validation Loss: 3.3320600323349936e-06
Epoch 175, Training Loss: 3.332102778585977e-06, Validation Loss: 3.3360688576067332e-06
Epoch 176, Training Loss: 3.3360588531650137e-06, Validation Loss: 3.3573883229109924e-06
Epoch 177, Training Loss: 3.3574197004782036e-06, Validation Loss: 3.3397234346921323e-06
Epoch 178, Training Loss: 3.3396154321962968e-06, Validation Loss: 3.2414088764198823e-06
Epoch 179, Training Loss: 3.2413961434940575e-06, Validation Loss: 3.0454866646323353e-06
Epoch 180, Training Loss: 3.04553532259888e-06, Validation Loss: 2.76025639323052e-06
Epoch 181, Training Loss: 2.7602334284893004e-06, Validation Loss: 2.4141288577084197e-06
Epoch 182, Training Loss: 2.4141386347764637e-06, Validation Loss: 2.045939481831738e-06
Epoch 183, Training Loss: 2.0459171992115444e-06, Validation Loss: 1.6937841564867995e-06
Epoch 184, Training Loss: 1.6938229236984625e-06, Validation Loss: 1.3866535937268054e-06
Epoch 185, Training Loss: 1.3866937251805211e-06, Validation Loss: 1.139045139098016e-06
Epoch 186, Training Loss: 1.139044798037503e-06, Validation Loss: 9.509641927252233e-07
Epoch 187, Training Loss: 9.51008814809029e-07, Validation Loss: 8.116279559544637e-07
Epoch 188, Training Loss: 8.116114145195752e-07, Validation Loss: 7.047448775665544e-07
Epoch 189, Training Loss: 7.047676149340987e-07, Validation Loss: 6.151688012323575e-07
Epoch 190, Training Loss: 6.151601041892718e-07, Validation Loss: 5.313644351190305e-07
Epoch 191, Training Loss: 5.313301016940386e-07, Validation Loss: 4.494626182349748e-07
Epoch 192, Training Loss: 4.494665404308762e-07, Validation Loss: 3.716397714015329e-07
Epoch 193, Training Loss: 3.716576770784741e-07, Validation Loss: 3.040479725768819e-07
Epoch 194, Training Loss: 3.040248373054055e-07, Validation Loss: 2.531974132580217e-07
Epoch 195, Training Loss: 2.531700147301308e-07, Validation Loss: 2.2334745608532103e-07
Epoch 196, Training Loss: 2.2334430127557425e-07, Validation Loss: 2.14642000173626e-07
Epoch 197, Training Loss: 2.146294661997672e-07, Validation Loss: 2.2286425860329473e-07
Epoch 198, Training Loss: 2.2286820922090556e-07, Validation Loss: 2.40655083416641e-07
Epoch 199, Training Loss: 2.406520991371508e-07, Validation Loss: 2.5940340719898813e-07
Epoch 200, Training Loss: 2.5941193371181726e-07, Validation Loss: 2.716044207318191e-07
Epoch 201, Training Loss: 2.71607319746181e-07, Validation Loss: 2.723860745845741e-07
Epoch 202, Training Loss: 2.723735690324247e-07, Validation Loss: 2.602417907837662e-07
Epoch 203, Training Loss: 2.6025867327916785e-07, Validation Loss: 2.3712804875231086e-07
Epoch 204, Training Loss: 2.3710337870852527e-07, Validation Loss: 2.0699808089830185e-07
Epoch 205, Training Loss: 2.070010367560826e-07, Validation Loss: 1.748031053239174e-07
Epoch 206, Training Loss: 1.7482531688983727e-07, Validation Loss: 1.4498179723432258e-07
Epoch 207, Training Loss: 1.449752744520083e-07, Validation Loss: 1.2040156605053198e-07
Epoch 208, Training Loss: 1.2039305374855758e-07, Validation Loss: 1.0209475931333145e-07
Epoch 209, Training Loss: 1.0209796386106973e-07, Validation Loss: 8.947940699499668e-08
Epoch 210, Training Loss: 8.947108653956093e-08, Validation Loss: 8.08476130487179e-08
Epoch 211, Training Loss: 8.085103786470427e-08, Validation Loss: 7.4214590028987e-08
Epoch 212, Training Loss: 7.419949810127946e-08, Validation Loss: 6.78808405041309e-08
Epoch 213, Training Loss: 6.787939810237731e-08, Validation Loss: 6.095412175000092e-08
Epoch 214, Training Loss: 6.094978033388543e-08, Validation Loss: 5.331166263999876e-08
Epoch 215, Training Loss: 5.3314600734211126e-08, Validation Loss: 4.5509619184258554e-08
Epoch 216, Training Loss: 4.551221621795776e-08, Validation Loss: 3.8343141994801044e-08
Epoch 217, Training Loss: 3.833699224742304e-08, Validation Loss: 3.252025848610174e-08
Epoch 218, Training Loss: 3.250986679859125e-08, Validation Loss: 2.8403857044168035e-08
Epoch 219, Training Loss: 2.840926072167349e-08, Validation Loss: 2.591886172353952e-08
Epoch 220, Training Loss: 2.5926857105673662e-08, Validation Loss: 2.4603322046345966e-08
Epoch 221, Training Loss: 2.4606015003314496e-08, Validation Loss: 2.3821250749733736e-08
Epoch 222, Training Loss: 2.382254393751282e-08, Validation Loss: 2.295831080800781e-08
Epoch 223, Training Loss: 2.296112100452774e-08, Validation Loss: 2.1607256428524124e-08
Epoch 224, Training Loss: 2.16156816890134e-08, Validation Loss: 1.9684176066903092e-08
Epoch 225, Training Loss: 1.968347440595153e-08, Validation Loss: 1.7334809143676466e-08
Epoch 226, Training Loss: 1.7331377222262745e-08, Validation Loss: 1.4881273102673731e-08
Epoch 227, Training Loss: 1.488053413822854e-08, Validation Loss: 1.2697462636879209e-08
Epoch 228, Training Loss: 1.269254390479091e-08, Validation Loss: 1.1046014769533485e-08
Epoch 229, Training Loss: 1.1040613756563289e-08, Validation Loss: 1.0025565266857939e-08
Epoch 230, Training Loss: 1.0018402107903057e-08, Validation Loss: 9.538582368406878e-09
Epoch 231, Training Loss: 9.53783718671275e-09, Validation Loss: 9.37683353186003e-09
Epoch 232, Training Loss: 9.381106558237207e-09, Validation Loss: 9.282087987116938e-09
Epoch 233, Training Loss: 9.280023860469555e-09, Validation Loss: 9.016101643055663e-09
Epoch 234, Training Loss: 9.015327151473684e-09, Validation Loss: 8.454357214304764e-09
Epoch 235, Training Loss: 8.451691790867244e-09, Validation Loss: 7.583852656978252e-09
Epoch 236, Training Loss: 7.581432370784569e-09, Validation Loss: 6.499951687999328e-09
Epoch 237, Training Loss: 6.499795368597461e-09, Validation Loss: 5.353579801692376e-09
Epoch 238, Training Loss: 5.353415044595522e-09, Validation Loss: 4.2973073988150645e-09
Epoch 239, Training Loss: 4.299485212300169e-09, Validation Loss: 3.4512097624173066e-09
Epoch 240, Training Loss: 3.4529192838306244e-09, Validation Loss: 2.867568182907121e-09
Epoch 241, Training Loss: 2.8660589457274455e-09, Validation Loss: 2.5211099874411502e-09
Epoch 242, Training Loss: 2.5201294384658013e-09, Validation Loss: 2.351430161695589e-09
Epoch 243, Training Loss: 2.3530699611029604e-09, Validation Loss: 2.2721762249489075e-09
Epoch 244, Training Loss: 2.2704220725699997e-09, Validation Loss: 2.2078836536820745e-09
Epoch 245, Training Loss: 2.207141580612415e-09, Validation Loss: 2.1088517598855105e-09
Epoch 246, Training Loss: 2.1098829350307824e-09, Validation Loss: 1.9648243032577284e-09
Epoch 247, Training Loss: 1.961220963409005e-09, Validation Loss: 1.7815299235834914e-09
Epoch 248, Training Loss: 1.7818784225909212e-09, Validation Loss: 1.596000220871474e-09
Epoch 249, Training Loss: 1.5955556875724142e-09, Validation Loss: 1.4312038221220291e-09
Epoch 250, Training Loss: 1.4300041151216192e-09, Validation Loss: 1.3042522617467966e-09
Epoch 251, Training Loss: 1.3034519019683444e-09, Validation Loss: 1.2105290103647803e-09
Epoch 252, Training Loss: 1.213382061493462e-09, Validation Loss: 1.1428944457492207e-09
Epoch 253, Training Loss: 1.142093752903861e-09, Validation Loss: 1.076655431475615e-09
Epoch 254, Training Loss: 1.0768607117128681e-09, Validation Loss: 9.943320611327522e-10
Epoch 255, Training Loss: 9.945015921886124e-10, Validation Loss: 8.894566194683762e-10
Epoch 256, Training Loss: 8.884578628354234e-10, Validation Loss: 7.613329411348957e-10
Epoch 257, Training Loss: 7.598368045869108e-10, Validation Loss: 6.236590688324384e-10
Epoch 258, Training Loss: 6.222979909153992e-10, Validation Loss: 4.912472650886457e-10
Epoch 259, Training Loss: 4.907030337619744e-10, Validation Loss: 3.82176595925543e-10
Epoch 260, Training Loss: 3.8302078175789234e-10, Validation Loss: 3.0605062928401594e-10
Epoch 261, Training Loss: 3.0525199035125183e-10, Validation Loss: 2.6081531379062994e-10
Epoch 262, Training Loss: 2.612826899284215e-10, Validation Loss: 2.446833569091922e-10
Epoch 263, Training Loss: 2.441067070702019e-10, Validation Loss: 2.447231306490494e-10
Epoch 264, Training Loss: 2.4440061086039577e-10, Validation Loss: 2.49854137379657e-10
Epoch 265, Training Loss: 2.496428064269196e-10, Validation Loss: 2.5206306486502683e-10
Epoch 266, Training Loss: 2.5192867236789596e-10, Validation Loss: 2.4516172425492755e-10
Epoch 267, Training Loss: 2.4450053093261204e-10, Validation Loss: 2.2948429267977133e-10
Epoch 268, Training Loss: 2.2930235488161088e-10, Validation Loss: 2.07113257100211e-10
Epoch 269, Training Loss: 2.0743484707708149e-10, Validation Loss: 1.8390874934048895e-10
Epoch 270, Training Loss: 1.8431137172036927e-10, Validation Loss: 1.633187196592445e-10
Epoch 271, Training Loss: 1.6400292235374536e-10, Validation Loss: 1.4773132717138537e-10
Epoch 272, Training Loss: 1.4808385073727948e-10, Validation Loss: 1.3732673331823264e-10
Epoch 273, Training Loss: 1.3760607930901614e-10, Validation Loss: 1.3036607904304276e-10
Epoch 274, Training Loss: 1.3014650468434752e-10, Validation Loss: 1.2318177033954214e-10
Epoch 275, Training Loss: 1.2402850968484813e-10, Validation Loss: 1.155221959758812e-10
Epoch 276, Training Loss: 1.1574496916466614e-10, Validation Loss: 1.0514399073624503e-10
Epoch 277, Training Loss: 1.0490069923818623e-10, Validation Loss: 9.238761838892273e-11
Epoch 278, Training Loss: 9.263716183038895e-11, Validation Loss: 7.858474981858876e-11
Epoch 279, Training Loss: 7.866052254001943e-11, Validation Loss: 6.523920986767351e-11
Epoch 280, Training Loss: 6.531385848829174e-11, Validation Loss: 5.32940566677631e-11
Epoch 281, Training Loss: 5.334409997059808e-11, Validation Loss: 4.4453961345336523e-11
Epoch 282, Training Loss: 4.43969166985525e-11, Validation Loss: 3.8267417012960436e-11
Epoch 283, Training Loss: 3.827928946043002e-11, Validation Loss: 3.384396582428728e-11
Epoch 284, Training Loss: 3.3772651342189874e-11, Validation Loss: 3.069162979318918e-11
Epoch 285, Training Loss: 3.0848597981636416e-11, Validation Loss: 2.7913537800627886e-11
Epoch 286, Training Loss: 2.808953070143616e-11, Validation Loss: 2.509304916631372e-11
Epoch 287, Training Loss: 2.5205317000231986e-11, Validation Loss: 2.2192563758904882e-11
Epoch 288, Training Loss: 2.2432380605841296e-11, Validation Loss: 1.9697762518311457e-11
Epoch 289, Training Loss: 1.9666192285772155e-11, Validation Loss: 1.703164519140099e-11
Epoch 290, Training Loss: 1.7226706172657202e-11, Validation Loss: 1.52049171864288e-11
Epoch 291, Training Loss: 1.5117015278454105e-11, Validation Loss: 1.3846756206914446e-11
Epoch 292, Training Loss: 1.3990196154334278e-11, Validation Loss: 1.3497220702207713e-11
Epoch 293, Training Loss: 1.3441204746444946e-11, Validation Loss: 1.3408786234125891e-11
Epoch 294, Training Loss: 1.3474363118326504e-11, Validation Loss: 1.3454534361634352e-11
Epoch 295, Training Loss: 1.3426966136154128e-11, Validation Loss: 1.3111764278483928e-11
Epoch 296, Training Loss: 1.3117203503942854e-11, Validation Loss: 1.2266484702982972e-11
Epoch 297, Training Loss: 1.2291315534818104e-11, Validation Loss: 1.0933474611785066e-11
Epoch 298, Training Loss: 1.1132424843074418e-11, Validation Loss: 9.78425934022864e-12
Epoch 299, Training Loss: 9.787236125713417e-12, Validation Loss: 8.12251481352444e-12
Epoch 300, Training Loss: 8.314675337128818e-12, Validation Loss: 6.983926457981848e-12
Epoch 301, Training Loss: 6.963536951926086e-12, Validation Loss: 5.932160145050158e-12
Epoch 302, Training Loss: 5.804592050073776e-12, Validation Loss: 5.105037486491382e-12
Epoch 303, Training Loss: 5.140419340188274e-12, Validation Loss: 4.5267357570710764e-12
Epoch 304, Training Loss: 4.611980502361446e-12, Validation Loss: 4.365488005808604e-12
Epoch 305, Training Loss: 4.272888466660962e-12, Validation Loss: 4.118670248604017e-12
Epoch 306, Training Loss: 4.0815432630902926e-12, Validation Loss: 3.913208732747586e-12
Epoch 307, Training Loss: 3.9033880294692125e-12, Validation Loss: 3.5671324834923857e-12
Epoch 308, Training Loss: 3.5563960630591307e-12, Validation Loss: 3.2757611727329827e-12
Epoch 309, Training Loss: 3.239318535630531e-12, Validation Loss: 2.809480512816487e-12
Epoch 310, Training Loss: 2.797806691184901e-12, Validation Loss: 2.4326981401534553e-12
Epoch 311, Training Loss: 2.398680646470419e-12, Validation Loss: 1.9832377927408995e-12
Epoch 312, Training Loss: 1.971079983259516e-12, Validation Loss: 1.6588319259880357e-12
Epoch 313, Training Loss: 1.6758702715488627e-12, Validation Loss: 1.4334341005839413e-12
Epoch 314, Training Loss: 1.4125058544686708e-12, Validation Loss: 1.2094257886841042e-12
Epoch 315, Training Loss: 1.2012169687755647e-12, Validation Loss: 1.1644448426328946e-12
Epoch 316, Training Loss: 1.114633775903262e-12, Validation Loss: 1.096914009277028e-12
Epoch 317, Training Loss: 1.0417222640057844e-12, Validation Loss: 1.0052353914546952e-12
Epoch 318, Training Loss: 1.0124134603578527e-12, Validation Loss: 9.397725653226274e-13
Epoch 319, Training Loss: 9.64023457415697e-13, Validation Loss: 9.191682788164957e-13
Epoch 320, Training Loss: 9.166766738039067e-13, Validation Loss: 8.705847457865512e-13
Epoch 321, Training Loss: 8.361449011472233e-13, Validation Loss: 7.828512144092414e-13
Epoch 322, Training Loss: 7.64411537540477e-13, Validation Loss: 6.772377797448215e-13
Epoch 323, Training Loss: 6.844902249170115e-13, Validation Loss: 5.722259688659137e-13
Epoch 324, Training Loss: 5.948530513652517e-13, Validation Loss: 5.134406897040755e-13
Epoch 325, Training Loss: 5.090934726732776e-13, Validation Loss: 4.352374038431306e-13
Epoch 326, Training Loss: 4.377441876861343e-13, Validation Loss: 3.95772336344441e-13
Epoch 327, Training Loss: 3.74535336555501e-13, Validation Loss: 3.1087206918932464e-13
Epoch 328, Training Loss: 3.191975763566779e-13, Validation Loss: 2.5856538589906497e-13
Epoch 329, Training Loss: 2.649108959539709e-13, Validation Loss: 2.2182405109809344e-13
Epoch 330, Training Loss: 2.2487593113584142e-13, Validation Loss: 1.936589316643353e-13
Epoch 331, Training Loss: 2.0384497041725513e-13, Validation Loss: 1.7438864751122968e-13
Epoch 332, Training Loss: 1.7898468894061298e-13, Validation Loss: 1.5080037912840183e-13
Epoch 333, Training Loss: 1.5580704857808686e-13, Validation Loss: 1.463118227918933e-13
Epoch 334, Training Loss: 1.3712765460898585e-13, Validation Loss: 1.4201350327907453e-13
Epoch 335, Training Loss: 1.2903130712331456e-13, Validation Loss: 1.2680702570887908e-13
Epoch 336, Training Loss: 1.228317306808252e-13, Validation Loss: 1.2003644063972307e-13
Epoch 337, Training Loss: 1.3110451851754135e-13, Validation Loss: 1.2066679578280615e-13
Epoch 338, Training Loss: 1.2185287230192382e-13, Validation Loss: 1.2737200346096128e-13
Epoch 339, Training Loss: 1.2089363798234443e-13, Validation Loss: 1.1009928727176085e-13
Epoch 340, Training Loss: 1.2794602074865657e-13, Validation Loss: 1.0859499063875511e-13
Epoch 341, Training Loss: 1.1347509303732961e-13, Validation Loss: 9.90973457264642e-14
Epoch 342, Training Loss: 1.151912495511026e-13, Validation Loss: 7.803412321698289e-14
Epoch 343, Training Loss: 9.152209968620734e-14, Validation Loss: 7.92034352600085e-14
Epoch 344, Training Loss: 9.068277812690484e-14, Validation Loss: 7.487960311481842e-14
Epoch 345, Training Loss: 8.122911794149895e-14, Validation Loss: 6.719011604689948e-14
Epoch 346, Training Loss: 7.213798108125433e-14, Validation Loss: 6.019874675784395e-14
Epoch 347, Training Loss: 7.039808731616748e-14, Validation Loss: 5.084854995287928e-14
Epoch 348, Training Loss: 5.956755813434078e-14, Validation Loss: 4.496400539226453e-14
Epoch 349, Training Loss: 4.911574077136327e-14, Validation Loss: 4.0338907344658614e-14
Epoch 350, Training Loss: 4.2225239553798574e-14, Validation Loss: 3.3925922645174425e-14
Epoch 351, Training Loss: 4.0154847085220255e-14, Validation Loss: 3.051766196519867e-14
Epoch 352, Training Loss: 3.490007829715265e-14, Validation Loss: 2.7595735416284344e-14
Epoch 353, Training Loss: 3.0940934493337013e-14, Validation Loss: 2.4698494795584794e-14
Epoch 354, Training Loss: 2.654181805979497e-14, Validation Loss: 2.2586252123148534e-14
Epoch 355, Training Loss: 2.1121928668989612e-14, Validation Loss: 1.9914379864659042e-14
Epoch 356, Training Loss: 2.036172168102656e-14, Validation Loss: 1.6995455200509782e-14
Epoch 357, Training Loss: 1.8634985725742362e-14, Validation Loss: 1.3615526078553791e-14
Epoch 358, Training Loss: 1.4942987643161258e-14, Validation Loss: 1.2304147975548789e-14
Epoch 359, Training Loss: 1.132016165918473e-14, Validation Loss: 1.0203253003506895e-14
Epoch 360, Training Loss: 1.0826560832468812e-14, Validation Loss: 1.1173505527664173e-14
Epoch 361, Training Loss: 9.667295447230578e-15, Validation Loss: 1.0534296349183452e-14
Epoch 362, Training Loss: 8.962347194680503e-15, Validation Loss: 8.705174439366942e-15
Epoch 363, Training Loss: 8.004924678575286e-15, Validation Loss: 1.087383204718918e-14
Epoch 364, Training Loss: 8.255303382618921e-15, Validation Loss: 9.915975850214968e-15
Epoch 365, Training Loss: 6.526217334422565e-15, Validation Loss: 1.2054925471478156e-14
Epoch 366, Training Loss: 5.673022645993463e-15, Validation Loss: 1.0760966601033439e-14
Epoch 367, Training Loss: 4.886397547438498e-15, Validation Loss: 6.989099240756885e-15
Epoch 368, Training Loss: 5.836592331404794e-15, Validation Loss: 7.17962998487932e-15
Epoch 369, Training Loss: 4.524057181393842e-15, Validation Loss: 4.875989206582637e-15
Epoch 370, Training Loss: 3.451492182812428e-15, Validation Loss: 8.538135307003657e-15
Epoch 371, Training Loss: 3.374513828565957e-15, Validation Loss: 5.374722205925969e-15
Epoch 372, Training Loss: 3.735950622214129e-15, Validation Loss: 7.561919670897709e-15
Epoch 373, Training Loss: 2.661434059722241e-15, Validation Loss: 6.144072067521683e-15
Epoch 374, Training Loss: 2.38966078573862e-15, Validation Loss: 6.5703803617429835e-15
Epoch 375, Training Loss: 3.99026845297897e-15, Validation Loss: 6.0848746289039746e-15
Epoch 376, Training Loss: 4.191640795309787e-15, Validation Loss: 8.322921175765285e-15
Epoch 377, Training Loss: 3.135772510184649e-15, Validation Loss: 8.322921175765285e-15
Epoch 378, Training Loss: 3.0759967598222027e-15, Validation Loss: 7.87803660197775e-15
Epoch 379, Training Loss: 2.8542414166486587e-15, Validation Loss: 7.87283243154982e-15
Epoch 380, Training Loss: 4.4311774776285666e-15, Validation Loss: 7.747064979541501e-15
Epoch 381, Training Loss: 4.491169856667273e-15, Validation Loss: 7.836692923822268e-15
Epoch 382, Training Loss: 4.429659594587087e-15, Validation Loss: 7.817863381404805e-15
Epoch 383, Training Loss: 4.368944272927899e-15, Validation Loss: 7.76061750669757e-15
Epoch 384, Training Loss: 3.769597311977912e-15, Validation Loss: 7.773917618035357e-15
Epoch 385, Training Loss: 2.479468724520678e-15, Validation Loss: 6.279344499747616e-15
Epoch 386, Training Loss: 2.8666013214149935e-15, Validation Loss: 6.5875107560682544e-15
Epoch 387, Training Loss: 2.240510565704873e-15, Validation Loss: 3.835010701879046e-15
Epoch 388, Training Loss: 1.9434391704438447e-15, Validation Loss: 2.98311684429869e-15
Epoch 389, Training Loss: 2.465301886719613e-15, Validation Loss: 2.1094667337098706e-15
Epoch 390, Training Loss: 1.205458962291457e-15, Validation Loss: 2.3718436594513627e-15
Epoch 391, Training Loss: 1.714817142925147e-15, Validation Loss: 3.0168717425214844e-15
Epoch 392, Training Loss: 1.7733640602393642e-15, Validation Loss: 2.9477718534756626e-15
Epoch 393, Training Loss: 1.2665356493817676e-15, Validation Loss: 3.5605631331227065e-15
Epoch 394, Training Loss: 2.1547141749610112e-15, Validation Loss: 3.261178490882727e-15
Epoch 395, Training Loss: 1.1999656359911576e-15, Validation Loss: 3.4937398568808675e-15
Epoch 396, Training Loss: 1.583339524182032e-15, Validation Loss: 2.830641808188733e-15
Epoch 397, Training Loss: 1.3625236464261115e-15, Validation Loss: 2.7329191935475308e-15
Epoch 398, Training Loss: 2.1728563501417775e-15, Validation Loss: 2.4200906561269676e-15
Epoch 399, Training Loss: 2.018538382096832e-15, Validation Loss: 2.9071864815662096e-15
Epoch 400, Training Loss: 1.9917945873366982e-15, Validation Loss: 2.0960588374295454e-15
Epoch 401, Training Loss: 2.38210736943148e-15, Validation Loss: 3.276971843700757e-15
Epoch 402, Training Loss: 1.2844610900071551e-15, Validation Loss: 3.759224970022309e-15
Epoch 403, Training Loss: 1.4898812969137815e-15, Validation Loss: 3.2182080859520425e-15
Epoch 404, Training Loss: 1.915322335276212e-15, Validation Loss: 3.2716952519558362e-15
Epoch 405, Training Loss: 2.399310185073741e-15, Validation Loss: 3.3645753792375856e-15
Epoch 406, Training Loss: 1.808420001069141e-15, Validation Loss: 2.4818901799586414e-15
Epoch 407, Training Loss: 2.035668776422103e-15, Validation Loss: 2.454459864994758e-15
Epoch 408, Training Loss: 1.9038297922478655e-15, Validation Loss: 2.438883564369462e-15
Epoch 409, Training Loss: 1.8102269341038714e-15, Validation Loss: 2.0306452357701744e-15
Epoch 410, Training Loss: 1.209578930546902e-15, Validation Loss: 1.978748162366614e-15
Epoch 411, Training Loss: 6.403004745541402e-16, Validation Loss: 2.324247184079249e-15
Epoch 412, Training Loss: 6.895955156832948e-16, Validation Loss: 2.065411914848464e-15
Epoch 413, Training Loss: 1.0550439103092224e-15, Validation Loss: 2.2215370276863766e-15
Epoch 414, Training Loss: 1.1997487955566605e-15, Validation Loss: 2.2215370276863766e-15
Epoch 415, Training Loss: 1.2136988988023468e-15, Validation Loss: 2.231656318548987e-15
Epoch 416, Training Loss: 1.2136988988023468e-15, Validation Loss: 2.793851355641216e-15
Epoch 417, Training Loss: 1.2317688644243596e-15, Validation Loss: 2.2553641354679244e-15
Epoch 418, Training Loss: 1.2317688644243596e-15, Validation Loss: 2.2128634103064926e-15
Epoch 419, Training Loss: 7.187243964042189e-16, Validation Loss: 2.2273917194177983e-15
Epoch 420, Training Loss: 9.27614050262799e-16, Validation Loss: 2.338197181445817e-15
Epoch 421, Training Loss: 9.290596178664068e-16, Validation Loss: 1.9715200067112193e-15
Epoch 422, Training Loss: 9.146036241929729e-16, Validation Loss: 1.535562313154798e-15
Epoch 423, Training Loss: 9.146036241929729e-16, Validation Loss: 1.8670029172836167e-15
Epoch 424, Training Loss: 6.856201253640343e-16, Validation Loss: 1.421034458960952e-15
Epoch 425, Training Loss: 4.607565947905407e-16, Validation Loss: 1.421034458960952e-15
Epoch 426, Training Loss: 1.4712330195470308e-15, Validation Loss: 1.3257691927788529e-15
Epoch 427, Training Loss: 1.4491876106661984e-15, Validation Loss: 1.6999273625036004e-15
Epoch 428, Training Loss: 4.293869942867737e-16, Validation Loss: 2.2944678349943928e-15
Epoch 429, Training Loss: 5.810307204985599e-16, Validation Loss: 2.324825495823987e-15
Epoch 430, Training Loss: 1.1345159295524099e-15, Validation Loss: 2.324825495823987e-15
Epoch 431, Training Loss: 7.742717053544127e-16, Validation Loss: 2.742026491796409e-15
Epoch 432, Training Loss: 7.742717053544127e-16, Validation Loss: 2.742026491796409e-15
Epoch 433, Training Loss: 7.612612792845866e-16, Validation Loss: 2.766601670453335e-15
Epoch 434, Training Loss: 7.612612792845866e-16, Validation Loss: 2.766601670453335e-15
Epoch 435, Training Loss: 7.560571088566562e-16, Validation Loss: 2.781057770005887e-15
Epoch 436, Training Loss: 7.868484505552445e-16, Validation Loss: 2.781057770005887e-15
Epoch 437, Training Loss: 7.940764473919615e-16, Validation Loss: 2.810548069097493e-15
Epoch 438, Training Loss: 8.273253493078898e-16, Validation Loss: 2.810548069097493e-15
Epoch 439, Training Loss: 4.930658195306087e-16, Validation Loss: 2.8076567221320403e-15
Epoch 440, Training Loss: 5.107744197214992e-16, Validation Loss: 2.793778934324226e-15
Epoch 441, Training Loss: 6.69501617773377e-16, Validation Loss: 1.5966028954657319e-15
Epoch 442, Training Loss: 6.69501617773377e-16, Validation Loss: 1.5966028954657319e-15
Epoch 443, Training Loss: 7.471304933233391e-16, Validation Loss: 1.5966028954657319e-15
Epoch 444, Training Loss: 7.471304933233391e-16, Validation Loss: 1.5966028954657319e-15
Epoch 445, Training Loss: 7.268920704167961e-16, Validation Loss: 1.5966028954657319e-15
Epoch 446, Training Loss: 7.08099215113861e-16, Validation Loss: 1.5966028954657319e-15
Epoch 447, Training Loss: 6.803436394982321e-16, Validation Loss: 1.1633557073405243e-15
Epoch 448, Training Loss: 6.816446821052147e-16, Validation Loss: 1.0068692290714893e-15
Epoch 449, Training Loss: 6.465888471545562e-16, Validation Loss: 1.0083147966750972e-15
Epoch 450, Training Loss: 6.48034414758164e-16, Validation Loss: 1.0083147966750972e-15
Epoch 451, Training Loss: 6.451432266113891e-16, Validation Loss: 1.0354198509872348e-15
Epoch 452, Training Loss: 3.1207631922384213e-16, Validation Loss: 1.0354198509872348e-15
Epoch 453, Training Loss: 3.1207631922384213e-16, Validation Loss: 1.0354198509872348e-15
Epoch 454, Training Loss: 3.1207631922384213e-16, Validation Loss: 1.8827600594431516e-15
Epoch 455, Training Loss: 2.9559644620206246e-16, Validation Loss: 1.8827600594431516e-15
Epoch 456, Training Loss: 2.9017543533963494e-16, Validation Loss: 1.982506659311818e-15
Epoch 457, Training Loss: 2.9017543533963494e-16, Validation Loss: 1.982506659311818e-15
Epoch 458, Training Loss: 2.9704204027544993e-16, Validation Loss: 1.982506659311818e-15
Epoch 459, Training Loss: 3.700449777328807e-16, Validation Loss: 1.982506659311818e-15
Epoch 460, Training Loss: 4.4232513138850753e-16, Validation Loss: 1.993348681036673e-15
Epoch 461, Training Loss: 4.4232513138850753e-16, Validation Loss: 2.7602410882941655e-15
Epoch 462, Training Loss: 9.118570139823824e-16, Validation Loss: 2.6294138849754234e-15
Epoch 463, Training Loss: 1.0367571042527125e-15, Validation Loss: 2.6294138849754234e-15
Epoch 464, Training Loss: 8.614054023033113e-16, Validation Loss: 2.610621188491166e-15
Epoch 465, Training Loss: 8.614054023033113e-16, Validation Loss: 2.610621188491166e-15
Epoch 466, Training Loss: 8.151461272571162e-16, Validation Loss: 2.651820871045615e-15
Epoch 467, Training Loss: 1.1369373849903731e-15, Validation Loss: 2.651820871045615e-15
Epoch 468, Training Loss: 1.1230595971825586e-15, Validation Loss: 3.1045836982755617e-15
Epoch 469, Training Loss: 1.3276123364720782e-15, Validation Loss: 3.1045836982755617e-15
Epoch 470, Training Loss: 1.3276123364720782e-15, Validation Loss: 3.1045836982755617e-15
Epoch 471, Training Loss: 1.3059282930223681e-15, Validation Loss: 3.1045836982755617e-15
Epoch 472, Training Loss: 1.3030371578151524e-15, Validation Loss: 3.0062825601313847e-15
Epoch 473, Training Loss: 1.323853839526874e-15, Validation Loss: 3.0062825601313847e-15
Epoch 474, Training Loss: 1.2650177663402879e-15, Validation Loss: 2.967974224542388e-15
Epoch 475, Training Loss: 1.7923738089163557e-15, Validation Loss: 2.7470860313485957e-15
Epoch 476, Training Loss: 1.2885810582626e-15, Validation Loss: 2.7470860313485957e-15
Epoch 477, Training Loss: 8.496960188404679e-16, Validation Loss: 2.7054526679251524e-15
Epoch 478, Training Loss: 8.270361934355208e-16, Validation Loss: 2.7054526679251524e-15
Epoch 479, Training Loss: 4.2458034700890157e-16, Validation Loss: 2.692008560986332e-15
Epoch 480, Training Loss: 4.1012432686568805e-16, Validation Loss: 2.7368223213684786e-15
Epoch 481, Training Loss: 4.1012432686568805e-16, Validation Loss: 2.7368223213684786e-15
Epoch 482, Training Loss: 7.752836450285855e-16, Validation Loss: 2.72251085269167e-15
Epoch 483, Training Loss: 7.752836450285855e-16, Validation Loss: 2.7543139752457535e-15
Epoch 484, Training Loss: 6.412762565093772e-16, Validation Loss: 2.7612528691496607e-15
Epoch 485, Training Loss: 7.479617502819508e-16, Validation Loss: 1.91535833417647e-15
Epoch 486, Training Loss: 7.479617502819508e-16, Validation Loss: 1.91535833417647e-15
Epoch 487, Training Loss: 7.479617502819508e-16, Validation Loss: 1.9182496811419227e-15
Epoch 488, Training Loss: 7.479617502819508e-16, Validation Loss: 1.6661364653805478e-15
Epoch 489, Training Loss: 9.243253389659657e-16, Validation Loss: 1.653559720179716e-15
Epoch 490, Training Loss: 9.270358443971794e-16, Validation Loss: 1.6482832343139137e-15
Epoch 491, Training Loss: 8.259881489819712e-16, Validation Loss: 1.6555112840901899e-15
Epoch 492, Training Loss: 9.37010504384046e-16, Validation Loss: 1.7084203501074825e-15
Epoch 493, Training Loss: 7.397579185504377e-16, Validation Loss: 1.7084203501074825e-15
Epoch 494, Training Loss: 7.513227770166559e-16, Validation Loss: 2.2784216428416073e-15
Epoch 495, Training Loss: 7.513227770166559e-16, Validation Loss: 2.2870952602214913e-15
Epoch 496, Training Loss: 7.513227770166559e-16, Validation Loss: 2.637075721499812e-15
Epoch 497, Training Loss: 1.0887264930941449e-15, Validation Loss: 3.563851738540421e-15
Epoch 498, Training Loss: 1.0800528757142608e-15, Validation Loss: 3.563851738540421e-15
Epoch 499, Training Loss: 1.0800528757142608e-15, Validation Loss: 3.579464249824213e-15
Epoch 500, Training Loss: 1.0814984433178687e-15, Validation Loss: 3.6263017836755864e-15
