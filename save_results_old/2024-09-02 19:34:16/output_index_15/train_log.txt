Epoch 1, Training Loss: 0.4500782787799835, Validation Loss: 0.44838497042655945
Epoch 2, Training Loss: 0.4483850300312042, Validation Loss: 0.44674792885780334
Epoch 3, Training Loss: 0.44674792885780334, Validation Loss: 0.4451465904712677
Epoch 4, Training Loss: 0.4451465904712677, Validation Loss: 0.443552166223526
Epoch 5, Training Loss: 0.443552166223526, Validation Loss: 0.44196879863739014
Epoch 6, Training Loss: 0.44196879863739014, Validation Loss: 0.44038739800453186
Epoch 7, Training Loss: 0.44038745760917664, Validation Loss: 0.43880560994148254
Epoch 8, Training Loss: 0.43880555033683777, Validation Loss: 0.43726077675819397
Epoch 9, Training Loss: 0.43726077675819397, Validation Loss: 0.43574151396751404
Epoch 10, Training Loss: 0.43574151396751404, Validation Loss: 0.4342101216316223
Epoch 11, Training Loss: 0.4342101812362671, Validation Loss: 0.432667076587677
Epoch 12, Training Loss: 0.432667076587677, Validation Loss: 0.4310813844203949
Epoch 13, Training Loss: 0.4310814142227173, Validation Loss: 0.42942482233047485
Epoch 14, Training Loss: 0.42942482233047485, Validation Loss: 0.42774856090545654
Epoch 15, Training Loss: 0.42774856090545654, Validation Loss: 0.42605170607566833
Epoch 16, Training Loss: 0.42605170607566833, Validation Loss: 0.42429426312446594
Epoch 17, Training Loss: 0.42429426312446594, Validation Loss: 0.42247793078422546
Epoch 18, Training Loss: 0.42247796058654785, Validation Loss: 0.42061081528663635
Epoch 19, Training Loss: 0.42061081528663635, Validation Loss: 0.418678343296051
Epoch 20, Training Loss: 0.418678343296051, Validation Loss: 0.4166701138019562
Epoch 21, Training Loss: 0.41667014360427856, Validation Loss: 0.4145829379558563
Epoch 22, Training Loss: 0.4145829379558563, Validation Loss: 0.41240164637565613
Epoch 23, Training Loss: 0.41240161657333374, Validation Loss: 0.4101172685623169
Epoch 24, Training Loss: 0.4101172983646393, Validation Loss: 0.40773069858551025
Epoch 25, Training Loss: 0.40773066878318787, Validation Loss: 0.4052458703517914
Epoch 26, Training Loss: 0.40524592995643616, Validation Loss: 0.40265747904777527
Epoch 27, Training Loss: 0.40265753865242004, Validation Loss: 0.39992934465408325
Epoch 28, Training Loss: 0.39992931485176086, Validation Loss: 0.3970601260662079
Epoch 29, Training Loss: 0.3970600664615631, Validation Loss: 0.39404547214508057
Epoch 30, Training Loss: 0.39404547214508057, Validation Loss: 0.390838623046875
Epoch 31, Training Loss: 0.390838623046875, Validation Loss: 0.38744837045669556
Epoch 32, Training Loss: 0.38744837045669556, Validation Loss: 0.3838401436805725
Epoch 33, Training Loss: 0.38384008407592773, Validation Loss: 0.3800607919692993
Epoch 34, Training Loss: 0.3800607919692993, Validation Loss: 0.37614595890045166
Epoch 35, Training Loss: 0.37614595890045166, Validation Loss: 0.3720214068889618
Epoch 36, Training Loss: 0.3720214068889618, Validation Loss: 0.3676636815071106
Epoch 37, Training Loss: 0.3676636815071106, Validation Loss: 0.36303991079330444
Epoch 38, Training Loss: 0.36303991079330444, Validation Loss: 0.3580954670906067
Epoch 39, Training Loss: 0.3580954670906067, Validation Loss: 0.3528650104999542
Epoch 40, Training Loss: 0.3528650104999542, Validation Loss: 0.3473285436630249
Epoch 41, Training Loss: 0.3473285436630249, Validation Loss: 0.3414601981639862
Epoch 42, Training Loss: 0.3414601683616638, Validation Loss: 0.3353002965450287
Epoch 43, Training Loss: 0.3353002965450287, Validation Loss: 0.3288376033306122
Epoch 44, Training Loss: 0.3288376033306122, Validation Loss: 0.32205435633659363
Epoch 45, Training Loss: 0.32205435633659363, Validation Loss: 0.3149791955947876
Epoch 46, Training Loss: 0.3149791955947876, Validation Loss: 0.30761009454727173
Epoch 47, Training Loss: 0.30761009454727173, Validation Loss: 0.29997631907463074
Epoch 48, Training Loss: 0.29997631907463074, Validation Loss: 0.29214581847190857
Epoch 49, Training Loss: 0.29214581847190857, Validation Loss: 0.28416600823402405
Epoch 50, Training Loss: 0.28416600823402405, Validation Loss: 0.27610763907432556
Epoch 51, Training Loss: 0.2761076092720032, Validation Loss: 0.2680134177207947
Epoch 52, Training Loss: 0.2680134177207947, Validation Loss: 0.2599743902683258
Epoch 53, Training Loss: 0.2599743902683258, Validation Loss: 0.25214481353759766
Epoch 54, Training Loss: 0.25214481353759766, Validation Loss: 0.2446211725473404
Epoch 55, Training Loss: 0.2446211725473404, Validation Loss: 0.23758892714977264
Epoch 56, Training Loss: 0.23758889734745026, Validation Loss: 0.2310468554496765
Epoch 57, Training Loss: 0.2310468703508377, Validation Loss: 0.22508957982063293
Epoch 58, Training Loss: 0.22508956491947174, Validation Loss: 0.21980853378772736
Epoch 59, Training Loss: 0.21980854868888855, Validation Loss: 0.21519185602664948
Epoch 60, Training Loss: 0.21519185602664948, Validation Loss: 0.211125448346138
Epoch 61, Training Loss: 0.211125448346138, Validation Loss: 0.20743253827095032
Epoch 62, Training Loss: 0.20743253827095032, Validation Loss: 0.20397645235061646
Epoch 63, Training Loss: 0.20397645235061646, Validation Loss: 0.2005365490913391
Epoch 64, Training Loss: 0.2005365490913391, Validation Loss: 0.19684799015522003
Epoch 65, Training Loss: 0.1968480348587036, Validation Loss: 0.19284851849079132
Epoch 66, Training Loss: 0.19284851849079132, Validation Loss: 0.18849821388721466
Epoch 67, Training Loss: 0.18849822878837585, Validation Loss: 0.18369196355342865
Epoch 68, Training Loss: 0.18369196355342865, Validation Loss: 0.17861035466194153
Epoch 69, Training Loss: 0.17861035466194153, Validation Loss: 0.17343121767044067
Epoch 70, Training Loss: 0.17343123257160187, Validation Loss: 0.1680944412946701
Epoch 71, Training Loss: 0.1680944263935089, Validation Loss: 0.16276216506958008
Epoch 72, Training Loss: 0.16276216506958008, Validation Loss: 0.1574411243200302
Epoch 73, Training Loss: 0.1574411392211914, Validation Loss: 0.15209591388702393
Epoch 74, Training Loss: 0.15209591388702393, Validation Loss: 0.14687541127204895
Epoch 75, Training Loss: 0.14687541127204895, Validation Loss: 0.1416318267583847
Epoch 76, Training Loss: 0.1416318267583847, Validation Loss: 0.1363419145345688
Epoch 77, Training Loss: 0.1363418996334076, Validation Loss: 0.13095471262931824
Epoch 78, Training Loss: 0.13095472753047943, Validation Loss: 0.1254982203245163
Epoch 79, Training Loss: 0.1254982054233551, Validation Loss: 0.11994217336177826
Epoch 80, Training Loss: 0.11994220316410065, Validation Loss: 0.11420951038599014
Epoch 81, Training Loss: 0.11420951038599014, Validation Loss: 0.10826169699430466
Epoch 82, Training Loss: 0.10826168954372406, Validation Loss: 0.10219680517911911
Epoch 83, Training Loss: 0.10219679772853851, Validation Loss: 0.09618515521287918
Epoch 84, Training Loss: 0.09618515521287918, Validation Loss: 0.09009858965873718
Epoch 85, Training Loss: 0.09009858965873718, Validation Loss: 0.0839778408408165
Epoch 86, Training Loss: 0.0839778333902359, Validation Loss: 0.07787877321243286
Epoch 87, Training Loss: 0.07787877321243286, Validation Loss: 0.07184018194675446
Epoch 88, Training Loss: 0.07184017449617386, Validation Loss: 0.06597528606653214
Epoch 89, Training Loss: 0.06597529351711273, Validation Loss: 0.06026455760002136
Epoch 90, Training Loss: 0.060264553874731064, Validation Loss: 0.05478442832827568
Epoch 91, Training Loss: 0.05478443205356598, Validation Loss: 0.049712907522916794
Epoch 92, Training Loss: 0.049712907522916794, Validation Loss: 0.044958408921957016
Epoch 93, Training Loss: 0.044958408921957016, Validation Loss: 0.04052460193634033
Epoch 94, Training Loss: 0.04052460193634033, Validation Loss: 0.03650970384478569
Epoch 95, Training Loss: 0.03650970384478569, Validation Loss: 0.032832175493240356
Epoch 96, Training Loss: 0.032832175493240356, Validation Loss: 0.029508840292692184
Epoch 97, Training Loss: 0.029508844017982483, Validation Loss: 0.02653147093951702
Epoch 98, Training Loss: 0.02653147093951702, Validation Loss: 0.02385464683175087
Epoch 99, Training Loss: 0.023854641243815422, Validation Loss: 0.021467439830303192
Epoch 100, Training Loss: 0.02146744355559349, Validation Loss: 0.01933986321091652
Epoch 101, Training Loss: 0.01933986321091652, Validation Loss: 0.017467036843299866
Epoch 102, Training Loss: 0.017467036843299866, Validation Loss: 0.015848714858293533
Epoch 103, Training Loss: 0.015848714858293533, Validation Loss: 0.01439854595810175
Epoch 104, Training Loss: 0.0143985440954566, Validation Loss: 0.013079852797091007
Epoch 105, Training Loss: 0.013079852797091007, Validation Loss: 0.011794528923928738
Epoch 106, Training Loss: 0.011794526129961014, Validation Loss: 0.010554375126957893
Epoch 107, Training Loss: 0.010554373264312744, Validation Loss: 0.009375265799462795
Epoch 108, Training Loss: 0.009375265799462795, Validation Loss: 0.00827168021351099
Epoch 109, Training Loss: 0.00827168207615614, Validation Loss: 0.007227389607578516
Epoch 110, Training Loss: 0.007227387744933367, Validation Loss: 0.006253720726817846
Epoch 111, Training Loss: 0.006253720726817846, Validation Loss: 0.005369018297642469
Epoch 112, Training Loss: 0.005369019228965044, Validation Loss: 0.004583313595503569
Epoch 113, Training Loss: 0.004583314061164856, Validation Loss: 0.0038889788556843996
Epoch 114, Training Loss: 0.003888979321345687, Validation Loss: 0.003285821294412017
Epoch 115, Training Loss: 0.003285823157057166, Validation Loss: 0.0027731498703360558
Epoch 116, Training Loss: 0.0027731498703360558, Validation Loss: 0.002340317703783512
Epoch 117, Training Loss: 0.0023403174709528685, Validation Loss: 0.0019762872252613306
Epoch 118, Training Loss: 0.0019762874580919743, Validation Loss: 0.0016738459235057235
Epoch 119, Training Loss: 0.0016738452250137925, Validation Loss: 0.0014248049119487405
Epoch 120, Training Loss: 0.0014248053776100278, Validation Loss: 0.001215976313687861
Epoch 121, Training Loss: 0.001215974916703999, Validation Loss: 0.001039033057168126
Epoch 122, Training Loss: 0.0010390328243374825, Validation Loss: 0.0008870215970091522
Epoch 123, Training Loss: 0.000887021014932543, Validation Loss: 0.0007541979430243373
Epoch 124, Training Loss: 0.0007541975937783718, Validation Loss: 0.0006376146920956671
Epoch 125, Training Loss: 0.0006376152741722763, Validation Loss: 0.0005357833579182625
Epoch 126, Training Loss: 0.000535783648956567, Validation Loss: 0.0004474114684853703
Epoch 127, Training Loss: 0.00044741103192791343, Validation Loss: 0.00037301896372810006
Epoch 128, Training Loss: 0.0003730186726897955, Validation Loss: 0.00031146142282523215
Epoch 129, Training Loss: 0.0003114613355137408, Validation Loss: 0.0002624808403197676
Epoch 130, Training Loss: 0.00026248034555464983, Validation Loss: 0.00022606694255955517
Epoch 131, Training Loss: 0.00022606688435189426, Validation Loss: 0.00020072607730980963
Epoch 132, Training Loss: 0.0002007261209655553, Validation Loss: 0.00018508790526539087
Epoch 133, Training Loss: 0.0001850880798883736, Validation Loss: 0.00017691610264591873
Epoch 134, Training Loss: 0.0001769165537552908, Validation Loss: 0.00017371967260260135
Epoch 135, Training Loss: 0.00017371946887578815, Validation Loss: 0.00017302986816503108
Epoch 136, Training Loss: 0.00017302991182077676, Validation Loss: 0.00017262306937482208
Epoch 137, Training Loss: 0.0001726234331727028, Validation Loss: 0.00017055081843864173
Epoch 138, Training Loss: 0.0001705508038867265, Validation Loss: 0.00016598275396972895
Epoch 139, Training Loss: 0.00016598310321569443, Validation Loss: 0.0001586609723744914
Epoch 140, Training Loss: 0.00015866116154938936, Validation Loss: 0.00014893671323079616
Epoch 141, Training Loss: 0.00014893674233462662, Validation Loss: 0.00013758048589807004
Epoch 142, Training Loss: 0.00013758019485976547, Validation Loss: 0.00012555019930005074
Epoch 143, Training Loss: 0.00012555001012515277, Validation Loss: 0.000113773719931487
Epoch 144, Training Loss: 0.00011377364717191085, Validation Loss: 0.00010295207175659016
Epoch 145, Training Loss: 0.00010295215179212391, Validation Loss: 9.348920866614208e-05
Epoch 146, Training Loss: 9.348943422082812e-05, Validation Loss: 8.548861660528928e-05
Epoch 147, Training Loss: 8.54885729495436e-05, Validation Loss: 7.879830809542909e-05
Epoch 148, Training Loss: 7.879849727032706e-05, Validation Loss: 7.308727072086185e-05
Epoch 149, Training Loss: 7.308737986022606e-05, Validation Loss: 6.797788228141144e-05
Epoch 150, Training Loss: 6.797807873226702e-05, Validation Loss: 6.310705794021487e-05
Epoch 151, Training Loss: 6.31069196970202e-05, Validation Loss: 5.8189089031657204e-05
Epoch 152, Training Loss: 5.8189089031657204e-05, Validation Loss: 5.305891318130307e-05
Epoch 153, Training Loss: 5.3058629418956116e-05, Validation Loss: 4.767780774272978e-05
Epoch 154, Training Loss: 4.767769496538676e-05, Validation Loss: 4.212292333249934e-05
Epoch 155, Training Loss: 4.2123203456867486e-05, Validation Loss: 3.6553505196934566e-05
Epoch 156, Training Loss: 3.655328328022733e-05, Validation Loss: 3.1169078283710405e-05
Epoch 157, Training Loss: 3.116919833701104e-05, Validation Loss: 2.6170671844738536e-05
Epoch 158, Training Loss: 2.6170528144575655e-05, Validation Loss: 2.172305539716035e-05
Epoch 159, Training Loss: 2.1723009922425263e-05, Validation Loss: 1.793484807421919e-05
Epoch 160, Training Loss: 1.7934860807145014e-05, Validation Loss: 1.4845455552858766e-05
Epoch 161, Training Loss: 1.4845363693893887e-05, Validation Loss: 1.2418743608577643e-05
Epoch 162, Training Loss: 1.2418864571372978e-05, Validation Loss: 1.0568241123110056e-05
Epoch 163, Training Loss: 1.0568240213615354e-05, Validation Loss: 9.175776540359948e-06
Epoch 164, Training Loss: 9.175789273285773e-06, Validation Loss: 8.119121957861353e-06
Epoch 165, Training Loss: 8.119048288790509e-06, Validation Loss: 7.289744189620251e-06
Epoch 166, Training Loss: 7.2897732934507076e-06, Validation Loss: 6.6064503698726185e-06
Epoch 167, Training Loss: 6.606465831282549e-06, Validation Loss: 6.017666237312369e-06
Epoch 168, Training Loss: 6.017786745360354e-06, Validation Loss: 5.498025075212354e-06
Epoch 169, Training Loss: 5.498035989148775e-06, Validation Loss: 5.039563347963849e-06
Epoch 170, Training Loss: 5.039540155848954e-06, Validation Loss: 4.643020474759396e-06
Epoch 171, Training Loss: 4.643045940611046e-06, Validation Loss: 4.309354608267313e-06
Epoch 172, Training Loss: 4.309401901991805e-06, Validation Loss: 4.035963229398476e-06
Epoch 173, Training Loss: 4.036073733004741e-06, Validation Loss: 3.814817318925634e-06
Epoch 174, Training Loss: 3.814791853073984e-06, Validation Loss: 3.633369715316803e-06
Epoch 175, Training Loss: 3.6333533444121713e-06, Validation Loss: 3.477333848422859e-06
Epoch 176, Training Loss: 3.4773381685226923e-06, Validation Loss: 3.3324877222185023e-06
Epoch 177, Training Loss: 3.332422920721001e-06, Validation Loss: 3.186062258464517e-06
Epoch 178, Training Loss: 3.1860536182648502e-06, Validation Loss: 3.02840135191218e-06
Epoch 179, Training Loss: 3.028339278898784e-06, Validation Loss: 2.8525532798084896e-06
Epoch 180, Training Loss: 2.8525607831397792e-06, Validation Loss: 2.6553927909844788e-06
Epoch 181, Training Loss: 2.6553664156381274e-06, Validation Loss: 2.4373221094720066e-06
Epoch 182, Training Loss: 2.4373593987547792e-06, Validation Loss: 2.2025121779734036e-06
Epoch 183, Training Loss: 2.202506721005193e-06, Validation Loss: 1.9583512766985223e-06
Epoch 184, Training Loss: 1.9583221728680655e-06, Validation Loss: 1.7146362552011851e-06
Epoch 185, Training Loss: 1.7146088566732942e-06, Validation Loss: 1.482082666370843e-06
Epoch 186, Training Loss: 1.4821013110122294e-06, Validation Loss: 1.2704813343589194e-06
Epoch 187, Training Loss: 1.2704983873845777e-06, Validation Loss: 1.0870908226934262e-06
Epoch 188, Training Loss: 1.0870511459870613e-06, Validation Loss: 9.353315704174747e-07
Epoch 189, Training Loss: 9.353166774417332e-07, Validation Loss: 8.146227514771454e-07
Epoch 190, Training Loss: 8.14639236068615e-07, Validation Loss: 7.210071544250241e-07
Epoch 191, Training Loss: 7.209993100332213e-07, Validation Loss: 6.481315608652949e-07
Epoch 192, Training Loss: 6.48122124857764e-07, Validation Loss: 5.890054239898745e-07
Epoch 193, Training Loss: 5.890216243642499e-07, Validation Loss: 5.372704094952496e-07
Epoch 194, Training Loss: 5.3727637805423e-07, Validation Loss: 4.883039537162404e-07
Epoch 195, Training Loss: 4.883291921942146e-07, Validation Loss: 4.396729025302193e-07
Epoch 196, Training Loss: 4.396754320623586e-07, Validation Loss: 3.9082863168005133e-07
Epoch 197, Training Loss: 3.908206736014108e-07, Validation Loss: 3.428230854751746e-07
Epoch 198, Training Loss: 3.42829451938087e-07, Validation Loss: 2.9743878826593573e-07
Epoch 199, Training Loss: 2.974433357394446e-07, Validation Loss: 2.56625241945585e-07
Epoch 200, Training Loss: 2.566239345469512e-07, Validation Loss: 2.2183741066328366e-07
Epoch 201, Training Loss: 2.2185039938449336e-07, Validation Loss: 1.939166196507358e-07
Epoch 202, Training Loss: 1.9392001604501274e-07, Validation Loss: 1.7271412389163743e-07
Epoch 203, Training Loss: 1.7270089358589757e-07, Validation Loss: 1.573525167941625e-07
Epoch 204, Training Loss: 1.5736975456093205e-07, Validation Loss: 1.465222823071599e-07
Epoch 205, Training Loss: 1.4650764512680325e-07, Validation Loss: 1.3852893232524366e-07
Epoch 206, Training Loss: 1.3853941993602348e-07, Validation Loss: 1.318214941647966e-07
Epoch 207, Training Loss: 1.3184478575567482e-07, Validation Loss: 1.2513882552411815e-07
Epoch 208, Training Loss: 1.251384134093314e-07, Validation Loss: 1.1764250018586608e-07
Epoch 209, Training Loss: 1.1765143170805459e-07, Validation Loss: 1.0911369940913573e-07
Epoch 210, Training Loss: 1.0911311676409241e-07, Validation Loss: 9.971448378109926e-08
Epoch 211, Training Loss: 9.972500691901587e-08, Validation Loss: 9.003998968637461e-08
Epoch 212, Training Loss: 9.003193213175109e-08, Validation Loss: 8.067421219948301e-08
Epoch 213, Training Loss: 8.067162582392484e-08, Validation Loss: 7.216247865926562e-08
Epoch 214, Training Loss: 7.216978303858923e-08, Validation Loss: 6.487836401447566e-08
Epoch 215, Training Loss: 6.488610893029545e-08, Validation Loss: 5.884027487468302e-08
Epoch 216, Training Loss: 5.883853049226673e-08, Validation Loss: 5.3854961379329325e-08
Epoch 217, Training Loss: 5.3853540293857804e-08, Validation Loss: 4.9610122232479625e-08
Epoch 218, Training Loss: 4.960620358929191e-08, Validation Loss: 4.570703282524846e-08
Epoch 219, Training Loss: 4.571361955640896e-08, Validation Loss: 4.188690638784465e-08
Epoch 220, Training Loss: 4.1895468427810556e-08, Validation Loss: 3.79687818963248e-08
Epoch 221, Training Loss: 3.7972910149619565e-08, Validation Loss: 3.392021952208779e-08
Epoch 222, Training Loss: 3.3916474961870335e-08, Validation Loss: 2.98303106660569e-08
Epoch 223, Training Loss: 2.9834357206937057e-08, Validation Loss: 2.5855417362663502e-08
Epoch 224, Training Loss: 2.585776570640519e-08, Validation Loss: 2.2165531632367674e-08
Epoch 225, Training Loss: 2.2163131774277645e-08, Validation Loss: 1.8889149799861116e-08
Epoch 226, Training Loss: 1.8882547081489065e-08, Validation Loss: 1.6113471446033145e-08
Epoch 227, Training Loss: 1.6118161028089162e-08, Validation Loss: 1.3879486893131343e-08
Epoch 228, Training Loss: 1.3878209692563814e-08, Validation Loss: 1.2142046479368673e-08
Epoch 229, Training Loss: 1.2146907479859692e-08, Validation Loss: 1.0846973985678687e-08
Epoch 230, Training Loss: 1.0847184483964156e-08, Validation Loss: 9.88295045800669e-09
Epoch 231, Training Loss: 9.885332552528325e-09, Validation Loss: 9.146330803844194e-09
Epoch 232, Training Loss: 9.147433921441461e-09, Validation Loss: 8.520622429841751e-09
Epoch 233, Training Loss: 8.519892347180757e-09, Validation Loss: 7.92428789253563e-09
Epoch 234, Training Loss: 7.925343048498235e-09, Validation Loss: 7.312917382762407e-09
Epoch 235, Training Loss: 7.313214478443797e-09, Validation Loss: 6.66092070389368e-09
Epoch 236, Training Loss: 6.660708873340582e-09, Validation Loss: 5.983859185931806e-09
Epoch 237, Training Loss: 5.983233020145917e-09, Validation Loss: 5.311107109662316e-09
Epoch 238, Training Loss: 5.3148356826682175e-09, Validation Loss: 4.689619359510289e-09
Epoch 239, Training Loss: 4.689965305004762e-09, Validation Loss: 4.150300991767608e-09
Epoch 240, Training Loss: 4.15082856974891e-09, Validation Loss: 3.7048055734345553e-09
Epoch 241, Training Loss: 3.7063272451121065e-09, Validation Loss: 3.3677285404820623e-09
Epoch 242, Training Loss: 3.3655358500084276e-09, Validation Loss: 3.111380486586768e-09
Epoch 243, Training Loss: 3.1100955144580666e-09, Validation Loss: 2.915107710776965e-09
Epoch 244, Training Loss: 2.9162230408275036e-09, Validation Loss: 2.7521791512441496e-09
Epoch 245, Training Loss: 2.7501689814357633e-09, Validation Loss: 2.5953477145179704e-09
Epoch 246, Training Loss: 2.5945532389215487e-09, Validation Loss: 2.429340728582474e-09
Epoch 247, Training Loss: 2.4281934241088265e-09, Validation Loss: 2.243824015479845e-09
Epoch 248, Training Loss: 2.2440709290805216e-09, Validation Loss: 2.0404842260290934e-09
Epoch 249, Training Loss: 2.0392514343825496e-09, Validation Loss: 1.8254694422736861e-09
Epoch 250, Training Loss: 1.8255122968824367e-09, Validation Loss: 1.6087196019753947e-09
Epoch 251, Training Loss: 1.6083127052368695e-09, Validation Loss: 1.4046501739528594e-09
Epoch 252, Training Loss: 1.4034122752804024e-09, Validation Loss: 1.220853751426887e-09
Epoch 253, Training Loss: 1.2209920852157552e-09, Validation Loss: 1.0640965886210552e-09
Epoch 254, Training Loss: 1.0638344649649412e-09, Validation Loss: 9.38918498505359e-10
Epoch 255, Training Loss: 9.38364497216071e-10, Validation Loss: 8.41117064886987e-10
Epoch 256, Training Loss: 8.408627127920454e-10, Validation Loss: 7.65461694030023e-10
Epoch 257, Training Loss: 7.645140631673542e-10, Validation Loss: 7.029863913210477e-10
Epoch 258, Training Loss: 7.025037773722431e-10, Validation Loss: 6.464384583182436e-10
Epoch 259, Training Loss: 6.466164825802423e-10, Validation Loss: 5.888191600966763e-10
Epoch 260, Training Loss: 5.879134401531871e-10, Validation Loss: 5.27495325197691e-10
Epoch 261, Training Loss: 5.261592272987059e-10, Validation Loss: 4.6369802442214336e-10
Epoch 262, Training Loss: 4.6417941712562083e-10, Validation Loss: 4.014866494816971e-10
Epoch 263, Training Loss: 4.009945708816076e-10, Validation Loss: 3.4408886850911813e-10
Epoch 264, Training Loss: 3.4390740255574315e-10, Validation Loss: 2.9557670200297537e-10
Epoch 265, Training Loss: 2.948568333938084e-10, Validation Loss: 2.5646312851179687e-10
Epoch 266, Training Loss: 2.563444179148888e-10, Validation Loss: 2.2805245192270007e-10
Epoch 267, Training Loss: 2.2787102760268851e-10, Validation Loss: 2.0792792487789313e-10
Epoch 268, Training Loss: 2.0760272667619262e-10, Validation Loss: 1.9248976024233144e-10
Epoch 269, Training Loss: 1.9258437899960512e-10, Validation Loss: 1.8046013294803487e-10
Epoch 270, Training Loss: 1.8061430129279188e-10, Validation Loss: 1.6854195816762285e-10
Epoch 271, Training Loss: 1.687528450311504e-10, Validation Loss: 1.5562995336892982e-10
Epoch 272, Training Loss: 1.5549736498421396e-10, Validation Loss: 1.416515515995087e-10
Epoch 273, Training Loss: 1.4167823858546313e-10, Validation Loss: 1.269381127988467e-10
Epoch 274, Training Loss: 1.2711076635696372e-10, Validation Loss: 1.1282789980082697e-10
Epoch 275, Training Loss: 1.1260593152373488e-10, Validation Loss: 9.959728874964213e-11
Epoch 276, Training Loss: 9.954494173403106e-11, Validation Loss: 8.796037509473109e-11
Epoch 277, Training Loss: 8.788209743260111e-11, Validation Loss: 7.862235862354794e-11
Epoch 278, Training Loss: 7.871243934420846e-11, Validation Loss: 7.196008372511997e-11
Epoch 279, Training Loss: 7.184943612292827e-11, Validation Loss: 6.656269979643525e-11
Epoch 280, Training Loss: 6.679575642598579e-11, Validation Loss: 6.297453530867969e-11
Epoch 281, Training Loss: 6.295192145344686e-11, Validation Loss: 6.002805891247576e-11
Epoch 282, Training Loss: 6.006104641409493e-11, Validation Loss: 5.6768957590325186e-11
Epoch 283, Training Loss: 5.691937893237409e-11, Validation Loss: 5.336316111215211e-11
Epoch 284, Training Loss: 5.3280248268894326e-11, Validation Loss: 4.9101951671293165e-11
Epoch 285, Training Loss: 4.91371804356433e-11, Validation Loss: 4.4515377495280006e-11
Epoch 286, Training Loss: 4.4573712776330154e-11, Validation Loss: 3.984720539640385e-11
Epoch 287, Training Loss: 3.9865312440046097e-11, Validation Loss: 3.511710019998837e-11
Epoch 288, Training Loss: 3.505377238477436e-11, Validation Loss: 3.0350489482744436e-11
Epoch 289, Training Loss: 3.047630203756313e-11, Validation Loss: 2.630069599607321e-11
Epoch 290, Training Loss: 2.6325908467073056e-11, Validation Loss: 2.2929109999569874e-11
Epoch 291, Training Loss: 2.2862513965327125e-11, Validation Loss: 1.9777474796756067e-11
Epoch 292, Training Loss: 1.9894242503371018e-11, Validation Loss: 1.7425186293884565e-11
Epoch 293, Training Loss: 1.7362340731796877e-11, Validation Loss: 1.5176367107461175e-11
Epoch 294, Training Loss: 1.5333840100439922e-11, Validation Loss: 1.357060470941196e-11
Epoch 295, Training Loss: 1.3651007407800009e-11, Validation Loss: 1.2198208589053738e-11
Epoch 296, Training Loss: 1.213710121988898e-11, Validation Loss: 1.0886595444570268e-11
Epoch 297, Training Loss: 1.0717997669940083e-11, Validation Loss: 9.443891849092445e-12
Epoch 298, Training Loss: 9.402948038250702e-12, Validation Loss: 8.254561097154056e-12
Epoch 299, Training Loss: 8.290559211365789e-12, Validation Loss: 7.2313374906152195e-12
Epoch 300, Training Loss: 7.311576691315658e-12, Validation Loss: 6.2758192739820196e-12
Epoch 301, Training Loss: 6.2726022292958206e-12, Validation Loss: 5.495649942066638e-12
Epoch 302, Training Loss: 5.463143392531178e-12, Validation Loss: 4.879180393047022e-12
Epoch 303, Training Loss: 4.756106966596896e-12, Validation Loss: 4.3066821810155975e-12
Epoch 304, Training Loss: 4.298818245818126e-12, Validation Loss: 3.9057103905226764e-12
Epoch 305, Training Loss: 3.900282007085476e-12, Validation Loss: 3.772535669271937e-12
Epoch 306, Training Loss: 3.654626514609793e-12, Validation Loss: 3.549259844359831e-12
Epoch 307, Training Loss: 3.504056203182393e-12, Validation Loss: 3.417333256650057e-12
Epoch 308, Training Loss: 3.399012842020266e-12, Validation Loss: 3.2686555285349472e-12
Epoch 309, Training Loss: 3.2707966109851716e-12, Validation Loss: 3.101855144266308e-12
Epoch 310, Training Loss: 3.120948161364212e-12, Validation Loss: 2.9101983409912657e-12
Epoch 311, Training Loss: 2.945334297635438e-12, Validation Loss: 2.699071868783598e-12
Epoch 312, Training Loss: 2.7145575284132084e-12, Validation Loss: 2.4521068769239873e-12
Epoch 313, Training Loss: 2.4664120572281956e-12, Validation Loss: 2.234706126744146e-12
Epoch 314, Training Loss: 2.2458647355033667e-12, Validation Loss: 2.0694166866230823e-12
Epoch 315, Training Loss: 2.066275319248523e-12, Validation Loss: 1.872515163758859e-12
Epoch 316, Training Loss: 1.8887541270579122e-12, Validation Loss: 1.694432896943987e-12
Epoch 317, Training Loss: 1.728721658010579e-12, Validation Loss: 1.5153426473693554e-12
Epoch 318, Training Loss: 1.545216320349152e-12, Validation Loss: 1.3918014961020186e-12
Epoch 319, Training Loss: 1.39029066037466e-12, Validation Loss: 1.2391828015101414e-12
Epoch 320, Training Loss: 1.2365651037848924e-12, Validation Loss: 1.1404742168014126e-12
Epoch 321, Training Loss: 1.1398929760167431e-12, Validation Loss: 1.0097857879726169e-12
Epoch 322, Training Loss: 1.003343458663708e-12, Validation Loss: 8.614274116074128e-13
Epoch 323, Training Loss: 8.25538530764558e-13, Validation Loss: 7.355417273521847e-13
Epoch 324, Training Loss: 7.306611370626326e-13, Validation Loss: 6.368864853903422e-13
Epoch 325, Training Loss: 6.077513167203341e-13, Validation Loss: 5.240593115712899e-13
Epoch 326, Training Loss: 5.07237101713548e-13, Validation Loss: 4.32490875794736e-13
Epoch 327, Training Loss: 4.2425085796868323e-13, Validation Loss: 3.377325274913495e-13
Epoch 328, Training Loss: 3.4181994257656556e-13, Validation Loss: 2.8660155303693313e-13
Epoch 329, Training Loss: 2.9311416575167337e-13, Validation Loss: 2.264160674269114e-13
Epoch 330, Training Loss: 2.314434180330366e-13, Validation Loss: 1.9802882207306527e-13
Epoch 331, Training Loss: 1.8746987198291903e-13, Validation Loss: 1.5731827732873294e-13
Epoch 332, Training Loss: 1.7440146820191932e-13, Validation Loss: 1.460425069722479e-13
Epoch 333, Training Loss: 1.5491317809698119e-13, Validation Loss: 1.4501866775571554e-13
Epoch 334, Training Loss: 1.3905228964800065e-13, Validation Loss: 1.305402319443441e-13
Epoch 335, Training Loss: 1.2655946169531918e-13, Validation Loss: 1.4034234115545968e-13
Epoch 336, Training Loss: 1.3654454357556883e-13, Validation Loss: 1.2346693762863015e-13
Epoch 337, Training Loss: 1.3621154443081707e-13, Validation Loss: 1.264536435632846e-13
Epoch 338, Training Loss: 1.2368856210521334e-13, Validation Loss: 1.2685605875212974e-13
Epoch 339, Training Loss: 1.2070832072601234e-13, Validation Loss: 1.2052327452022338e-13
Epoch 340, Training Loss: 1.1961427941881153e-13, Validation Loss: 1.0961019011922549e-13
Epoch 341, Training Loss: 1.0815801650566198e-13, Validation Loss: 1.0515128671213445e-13
Epoch 342, Training Loss: 1.0885070649739939e-13, Validation Loss: 1.0762648639060096e-13
Epoch 343, Training Loss: 1.0622899044784861e-13, Validation Loss: 9.78459392501907e-14
Epoch 344, Training Loss: 9.211140422453468e-14, Validation Loss: 8.776773795585169e-14
Epoch 345, Training Loss: 9.34514035708274e-14, Validation Loss: 8.22213120071219e-14
Epoch 346, Training Loss: 8.92759648217327e-14, Validation Loss: 8.178602516365971e-14
Epoch 347, Training Loss: 8.213870257784209e-14, Validation Loss: 7.333816578114147e-14
Epoch 348, Training Loss: 7.14940056483794e-14, Validation Loss: 6.747101250099974e-14
Epoch 349, Training Loss: 6.06379977154993e-14, Validation Loss: 5.477281293992699e-14
Epoch 350, Training Loss: 6.078170193719867e-14, Validation Loss: 4.1199004928091365e-14
Epoch 351, Training Loss: 4.219019949483656e-14, Validation Loss: 4.080917664884241e-14
Epoch 352, Training Loss: 3.9593430259648316e-14, Validation Loss: 3.4103332001910944e-14
Epoch 353, Training Loss: 3.7851408747797965e-14, Validation Loss: 2.9532579588200866e-14
Epoch 354, Training Loss: 2.968984650145168e-14, Validation Loss: 2.4639221124001832e-14
Epoch 355, Training Loss: 2.218007441395168e-14, Validation Loss: 2.0831172751383312e-14
Epoch 356, Training Loss: 2.3910140902784482e-14, Validation Loss: 2.848762214622755e-14
Epoch 357, Training Loss: 2.1061037164477395e-14, Validation Loss: 2.100209722387565e-14
Epoch 358, Training Loss: 1.55251957394565e-14, Validation Loss: 2.1890617844886467e-14
Epoch 359, Training Loss: 1.3558215829342565e-14, Validation Loss: 1.5351867387459854e-14
Epoch 360, Training Loss: 1.6585555628542692e-14, Validation Loss: 1.6178585096507207e-14
Epoch 361, Training Loss: 1.0880763317796562e-14, Validation Loss: 1.4546403429125006e-14
Epoch 362, Training Loss: 1.0907666778267253e-14, Validation Loss: 1.2890411665595486e-14
Epoch 363, Training Loss: 1.2120986418067466e-14, Validation Loss: 1.2176149438757403e-14
Epoch 364, Training Loss: 1.091248300760534e-14, Validation Loss: 8.465470891557553e-15
Epoch 365, Training Loss: 1.11346267153852e-14, Validation Loss: 7.494378957749546e-15
Epoch 366, Training Loss: 1.0693338643491708e-14, Validation Loss: 7.145120168542286e-15
Epoch 367, Training Loss: 9.57132237914193e-15, Validation Loss: 6.531136054747271e-15
Epoch 368, Training Loss: 9.453027451794289e-15, Validation Loss: 5.827697214909203e-15
Epoch 369, Training Loss: 8.286142158162556e-15, Validation Loss: 3.864015227575401e-15
Epoch 370, Training Loss: 4.375358429920982e-15, Validation Loss: 4.446198759915174e-15
Epoch 371, Training Loss: 2.4281647859384324e-15, Validation Loss: 3.212317818836836e-15
Epoch 372, Training Loss: 3.331304772102384e-15, Validation Loss: 3.210007748231437e-15
Epoch 373, Training Loss: 3.29068890700683e-15, Validation Loss: 4.560998829322444e-15
Epoch 374, Training Loss: 3.100570032654997e-15, Validation Loss: 5.875152235779125e-15
Epoch 375, Training Loss: 3.290288683939252e-15, Validation Loss: 3.742634559200913e-15
Epoch 376, Training Loss: 3.2146948050450685e-15, Validation Loss: 4.173429586943819e-15
Epoch 377, Training Loss: 2.526009585082276e-15, Validation Loss: 4.186590361361783e-15
Epoch 378, Training Loss: 3.604256904190346e-15, Validation Loss: 4.585735579514059e-15
Epoch 379, Training Loss: 3.4721511046377235e-15, Validation Loss: 4.206698076496653e-15
Epoch 380, Training Loss: 3.115365157144688e-15, Validation Loss: 3.937974332881384e-15
Epoch 381, Training Loss: 3.145289137105288e-15, Validation Loss: 3.741416949339235e-15
Epoch 382, Training Loss: 4.136833951974171e-15, Validation Loss: 3.677157218312261e-15
Epoch 383, Training Loss: 3.795309844124763e-15, Validation Loss: 4.180514594031128e-15
Epoch 384, Training Loss: 3.642387362860419e-15, Validation Loss: 4.2490861462761e-15
Epoch 385, Training Loss: 2.8247322710739766e-15, Validation Loss: 4.4095899959348435e-15
Epoch 386, Training Loss: 2.3798925900326466e-15, Validation Loss: 4.6826590185695266e-15
Epoch 387, Training Loss: 2.6741450596452125e-15, Validation Loss: 3.9703127802581326e-15
Epoch 388, Training Loss: 1.6533101630976312e-15, Validation Loss: 3.149880267437643e-15
Epoch 389, Training Loss: 2.771506202976174e-15, Validation Loss: 3.067076444096431e-15
Epoch 390, Training Loss: 2.2956585515599955e-15, Validation Loss: 3.974703799056699e-15
Epoch 391, Training Loss: 2.8369587681511188e-15, Validation Loss: 3.928266488272903e-15
Epoch 392, Training Loss: 2.428298193627625e-15, Validation Loss: 4.089120586055336e-15
Epoch 393, Training Loss: 1.850701556455471e-15, Validation Loss: 3.51751247182027e-15
Epoch 394, Training Loss: 2.614847459381491e-15, Validation Loss: 3.996829993704876e-15
Epoch 395, Training Loss: 2.614313616866484e-15, Validation Loss: 4.039263803263474e-15
Epoch 396, Training Loss: 2.0406537770749312e-15, Validation Loss: 3.2415495611212925e-15
Epoch 397, Training Loss: 2.0605198760615968e-15, Validation Loss: 3.630819857416241e-15
Epoch 398, Training Loss: 2.6665054577356892e-15, Validation Loss: 3.7245449000628764e-15
Epoch 399, Training Loss: 3.083839649639067e-15, Validation Loss: 2.651935432251731e-15
Epoch 400, Training Loss: 2.3064838443841423e-15, Validation Loss: 2.2251934571614366e-15
Epoch 401, Training Loss: 2.431567105529316e-15, Validation Loss: 2.7340177952801196e-15
Epoch 402, Training Loss: 1.5365665765928863e-15, Validation Loss: 2.7353522956885187e-15
Epoch 403, Training Loss: 1.838508517179745e-15, Validation Loss: 2.7301481252605883e-15
Epoch 404, Training Loss: 1.4896289869746181e-15, Validation Loss: 3.606233455572764e-15
Epoch 405, Training Loss: 1.6286736804311478e-15, Validation Loss: 3.450233491852808e-15
Epoch 406, Training Loss: 1.2069357642349949e-15, Validation Loss: 2.249187571216546e-15
Epoch 407, Training Loss: 1.7176116104972573e-15, Validation Loss: 2.9578722978551965e-15
Epoch 408, Training Loss: 2.3979568381822655e-15, Validation Loss: 3.3597777846243373e-15
Epoch 409, Training Loss: 1.7425149085421258e-15, Validation Loss: 1.961323635850409e-15
Epoch 410, Training Loss: 2.1379319111770618e-15, Validation Loss: 1.961323635850409e-15
Epoch 411, Training Loss: 1.4226919965596102e-15, Validation Loss: 2.168172681459935e-15
Epoch 412, Training Loss: 1.9449771705178217e-15, Validation Loss: 2.786585083503195e-15
Epoch 413, Training Loss: 1.8537540514391385e-15, Validation Loss: 2.3809390992389793e-15
Epoch 414, Training Loss: 1.3884478309306582e-15, Validation Loss: 2.3553686568690297e-15
Epoch 415, Training Loss: 9.822556162945818e-16, Validation Loss: 3.3083489086823716e-15
Epoch 416, Training Loss: 7.069683731897173e-16, Validation Loss: 3.6447018803887916e-15
Epoch 417, Training Loss: 2.9662790998566954e-15, Validation Loss: 4.242164193031138e-15
Epoch 418, Training Loss: 2.6949782584994057e-15, Validation Loss: 3.833169675768189e-15
Epoch 419, Training Loss: 2.8995422209754764e-15, Validation Loss: 2.9632016174010838e-15
Epoch 420, Training Loss: 2.410483820197446e-15, Validation Loss: 3.972869125692946e-15
Epoch 421, Training Loss: 2.3360908222642323e-15, Validation Loss: 4.250687462062884e-15
Epoch 422, Training Loss: 2.341695427517977e-15, Validation Loss: 4.315405861430796e-15
Epoch 423, Training Loss: 2.085806774152453e-15, Validation Loss: 2.8901388847115328e-15
Epoch 424, Training Loss: 1.5653562735579944e-15, Validation Loss: 2.9405917669400247e-15
Epoch 425, Training Loss: 1.4060619869479297e-15, Validation Loss: 2.7297561607642464e-15
Epoch 426, Training Loss: 1.9204742014196493e-15, Validation Loss: 2.7351562075612294e-15
Epoch 427, Training Loss: 1.2353251322534068e-15, Validation Loss: 2.879972371762113e-15
Epoch 428, Training Loss: 1.1819490334448218e-15, Validation Loss: 2.495664417988654e-15
Epoch 429, Training Loss: 1.6120270477978775e-15, Validation Loss: 2.8852265171339314e-15
Epoch 430, Training Loss: 1.6120270477978775e-15, Validation Loss: 2.8852265171339314e-15
Epoch 431, Training Loss: 1.6120270477978775e-15, Validation Loss: 2.1426814366705535e-15
Epoch 432, Training Loss: 2.131126424962347e-15, Validation Loss: 2.4587598277514945e-15
Epoch 433, Training Loss: 1.7528231936310922e-15, Validation Loss: 2.3791126844464622e-15
Epoch 434, Training Loss: 1.12685483418185e-15, Validation Loss: 2.3791126844464622e-15
Epoch 435, Training Loss: 1.1088404550970007e-15, Validation Loss: 2.3791126844464622e-15
Epoch 436, Training Loss: 1.4710474134524637e-15, Validation Loss: 2.3871190516221467e-15
Epoch 437, Training Loss: 1.6898893868039265e-15, Validation Loss: 3.0404967619698277e-15
Epoch 438, Training Loss: 1.5124972883637081e-15, Validation Loss: 3.516611652280865e-15
Epoch 439, Training Loss: 1.4166704393375794e-15, Validation Loss: 3.494193654782359e-15
Epoch 440, Training Loss: 1.5805351039727914e-15, Validation Loss: 3.4696407107402986e-15
Epoch 441, Training Loss: 1.6169642969683044e-15, Validation Loss: 3.393312877797319e-15
Epoch 442, Training Loss: 1.0705264020356101e-15, Validation Loss: 2.9115601361893572e-15
Epoch 443, Training Loss: 1.1031358999554798e-15, Validation Loss: 2.621727908012038e-15
Epoch 444, Training Loss: 1.1111422671311643e-15, Validation Loss: 2.5819459468530556e-15
Epoch 445, Training Loss: 1.1002001896394148e-15, Validation Loss: 2.4419587174844687e-15
Epoch 446, Training Loss: 1.4140517311020243e-15, Validation Loss: 2.7308361277719956e-15
Epoch 447, Training Loss: 1.2168936953211532e-15, Validation Loss: 2.9158886863080635e-15
Epoch 448, Training Loss: 1.3523355341365367e-15, Validation Loss: 2.850186034655442e-15
Epoch 449, Training Loss: 8.34520629497019e-16, Validation Loss: 2.782932042159924e-15
Epoch 450, Training Loss: 8.425270496122627e-16, Validation Loss: 2.7871854181045616e-15
Epoch 451, Training Loss: 7.678004795165082e-16, Validation Loss: 2.4355286786236245e-15
Epoch 452, Training Loss: 7.039159311456088e-16, Validation Loss: 2.489972356583105e-15
Epoch 453, Training Loss: 7.164760003852916e-16, Validation Loss: 1.9859850001097178e-15
Epoch 454, Training Loss: 3.6437718911522656e-16, Validation Loss: 2.0047501680231896e-15
Epoch 455, Training Loss: 1.6653364427618661e-15, Validation Loss: 1.857882490024056e-15
Epoch 456, Training Loss: 1.6416507545786757e-15, Validation Loss: 1.857882490024056e-15
Epoch 457, Training Loss: 1.6289739536109495e-15, Validation Loss: 2.0430307632831636e-15
Epoch 458, Training Loss: 1.6509916221627593e-15, Validation Loss: 2.058126160952656e-15
Epoch 459, Training Loss: 1.5980324753224603e-15, Validation Loss: 2.3276755499332608e-15
Epoch 460, Training Loss: 1.22214794657209e-15, Validation Loss: 3.3495068748641684e-15
Epoch 461, Training Loss: 1.2278191497913128e-15, Validation Loss: 3.3749940962470503e-15
Epoch 462, Training Loss: 6.787124128604979e-16, Validation Loss: 3.2669698669013413e-15
Epoch 463, Training Loss: 7.938046556950113e-16, Validation Loss: 3.2135314052920147e-15
Epoch 464, Training Loss: 7.430973459449878e-16, Validation Loss: 2.7528954068173394e-15
Epoch 465, Training Loss: 8.111518904547793e-16, Validation Loss: 2.75696116496416e-15
Epoch 466, Training Loss: 7.321719444143874e-16, Validation Loss: 2.5036750203290747e-15
Epoch 467, Training Loss: 3.256795095380686e-16, Validation Loss: 2.375572298485176e-15
Epoch 468, Training Loss: 3.40224521080303e-16, Validation Loss: 2.375572298485176e-15
Epoch 469, Training Loss: 9.189382094214283e-16, Validation Loss: 2.4066806422642743e-15
Epoch 470, Training Loss: 9.189382094214283e-16, Validation Loss: 2.4066806422642743e-15
Epoch 471, Training Loss: 9.136006313043054e-16, Validation Loss: 2.345493946769939e-15
Epoch 472, Training Loss: 9.136006313043054e-16, Validation Loss: 2.3168043055717255e-15
Epoch 473, Training Loss: 9.162694203628668e-16, Validation Loss: 2.4639847504866327e-15
Epoch 474, Training Loss: 4.1643559582545944e-16, Validation Loss: 2.2140553974215162e-15
Epoch 475, Training Loss: 4.1910438488402093e-16, Validation Loss: 2.583434607257855e-15
Epoch 476, Training Loss: 4.197715821486613e-16, Validation Loss: 3.010527042230076e-15
Epoch 477, Training Loss: 4.197715821486613e-16, Validation Loss: 3.010527042230076e-15
Epoch 478, Training Loss: 4.197715821486613e-16, Validation Loss: 2.823914884279876e-15
Epoch 479, Training Loss: 4.171027930900998e-16, Validation Loss: 2.8321715496914743e-15
Epoch 480, Training Loss: 5.120955264214199e-16, Validation Loss: 2.8321715496914743e-15
Epoch 481, Training Loss: 4.987515281890532e-16, Validation Loss: 2.8321715496914743e-15
Epoch 482, Training Loss: 3.46629651878542e-16, Validation Loss: 4.408764562327744e-15
Epoch 483, Training Loss: 3.7732091134045633e-16, Validation Loss: 4.519498873588193e-15
Epoch 484, Training Loss: 6.067547405297585e-16, Validation Loss: 4.556862343924528e-15
Epoch 485, Training Loss: 6.768275527946203e-16, Validation Loss: 4.513619194384828e-15
Epoch 486, Training Loss: 6.465366487491816e-16, Validation Loss: 3.4749033264415896e-15
Epoch 487, Training Loss: 5.440378270766492e-16, Validation Loss: 3.2915562687448182e-15
Epoch 488, Training Loss: 5.046729237650712e-16, Validation Loss: 3.0634735894552846e-15
Epoch 489, Training Loss: 8.570553587235684e-16, Validation Loss: 2.863730091482038e-15
Epoch 490, Training Loss: 8.199756444245642e-16, Validation Loss: 2.550012169466858e-15
Epoch 491, Training Loss: 2.311220664383425e-15, Validation Loss: 2.387757079189666e-15
Epoch 492, Training Loss: 2.3052158360621026e-15, Validation Loss: 2.387757079189666e-15
Epoch 493, Training Loss: 2.3052158360621026e-15, Validation Loss: 2.3119963348048733e-15
Epoch 494, Training Loss: 2.305883086266302e-15, Validation Loss: 2.2969634058152407e-15
Epoch 495, Training Loss: 3.2279388004501e-16, Validation Loss: 2.2969634058152407e-15
Epoch 496, Training Loss: 8.522014364193277e-16, Validation Loss: 2.5144710905165412e-15
Epoch 497, Training Loss: 8.522014364193277e-16, Validation Loss: 3.0401005623087495e-15
Epoch 498, Training Loss: 1.2375769693436824e-15, Validation Loss: 3.0747950318282856e-15
Epoch 499, Training Loss: 1.5978657157109696e-15, Validation Loss: 2.5090083632814614e-15
Epoch 500, Training Loss: 1.5898592426561668e-15, Validation Loss: 2.1468181338267067e-15
