Epoch 1, Training Loss: 0.46594610810279846, Validation Loss: 0.464612752199173
Epoch 2, Training Loss: 0.464612752199173, Validation Loss: 0.463312029838562
Epoch 3, Training Loss: 0.4633120596408844, Validation Loss: 0.4620579779148102
Epoch 4, Training Loss: 0.4620579481124878, Validation Loss: 0.4608410596847534
Epoch 5, Training Loss: 0.4608410596847534, Validation Loss: 0.45961830019950867
Epoch 6, Training Loss: 0.45961833000183105, Validation Loss: 0.458408385515213
Epoch 7, Training Loss: 0.45840832591056824, Validation Loss: 0.4572034478187561
Epoch 8, Training Loss: 0.4572034180164337, Validation Loss: 0.45602262020111084
Epoch 9, Training Loss: 0.45602256059646606, Validation Loss: 0.4548420310020447
Epoch 10, Training Loss: 0.4548420310020447, Validation Loss: 0.45365968346595764
Epoch 11, Training Loss: 0.45365965366363525, Validation Loss: 0.4524608254432678
Epoch 12, Training Loss: 0.4524608254432678, Validation Loss: 0.4512421786785126
Epoch 13, Training Loss: 0.45124220848083496, Validation Loss: 0.44999459385871887
Epoch 14, Training Loss: 0.4499945342540741, Validation Loss: 0.4487297534942627
Epoch 15, Training Loss: 0.4487297534942627, Validation Loss: 0.44744735956192017
Epoch 16, Training Loss: 0.44744735956192017, Validation Loss: 0.4461333751678467
Epoch 17, Training Loss: 0.44613340497016907, Validation Loss: 0.44484683871269226
Epoch 18, Training Loss: 0.44484683871269226, Validation Loss: 0.4435414671897888
Epoch 19, Training Loss: 0.44354143738746643, Validation Loss: 0.4421999454498291
Epoch 20, Training Loss: 0.4421999454498291, Validation Loss: 0.44081977009773254
Epoch 21, Training Loss: 0.44081977009773254, Validation Loss: 0.439398854970932
Epoch 22, Training Loss: 0.439398854970932, Validation Loss: 0.4379196763038635
Epoch 23, Training Loss: 0.4379197061061859, Validation Loss: 0.4363900125026703
Epoch 24, Training Loss: 0.4363900125026703, Validation Loss: 0.4348064363002777
Epoch 25, Training Loss: 0.4348064363002777, Validation Loss: 0.43323951959609985
Epoch 26, Training Loss: 0.43323951959609985, Validation Loss: 0.4315968453884125
Epoch 27, Training Loss: 0.4315968453884125, Validation Loss: 0.42989182472229004
Epoch 28, Training Loss: 0.42989182472229004, Validation Loss: 0.4281727969646454
Epoch 29, Training Loss: 0.4281727969646454, Validation Loss: 0.4264521300792694
Epoch 30, Training Loss: 0.4264521300792694, Validation Loss: 0.4246505796909332
Epoch 31, Training Loss: 0.4246505796909332, Validation Loss: 0.4227449595928192
Epoch 32, Training Loss: 0.42274489998817444, Validation Loss: 0.4207083284854889
Epoch 33, Training Loss: 0.4207083284854889, Validation Loss: 0.41854920983314514
Epoch 34, Training Loss: 0.41854918003082275, Validation Loss: 0.41628560423851013
Epoch 35, Training Loss: 0.41628560423851013, Validation Loss: 0.41389238834381104
Epoch 36, Training Loss: 0.41389238834381104, Validation Loss: 0.41135701537132263
Epoch 37, Training Loss: 0.41135698556900024, Validation Loss: 0.4086852967739105
Epoch 38, Training Loss: 0.4086853265762329, Validation Loss: 0.40584227442741394
Epoch 39, Training Loss: 0.40584227442741394, Validation Loss: 0.40282613039016724
Epoch 40, Training Loss: 0.40282613039016724, Validation Loss: 0.3996098041534424
Epoch 41, Training Loss: 0.3996098041534424, Validation Loss: 0.3961718678474426
Epoch 42, Training Loss: 0.3961718678474426, Validation Loss: 0.39247551560401917
Epoch 43, Training Loss: 0.39247551560401917, Validation Loss: 0.3885209262371063
Epoch 44, Training Loss: 0.3885209262371063, Validation Loss: 0.384304404258728
Epoch 45, Training Loss: 0.384304404258728, Validation Loss: 0.37980058789253235
Epoch 46, Training Loss: 0.37980061769485474, Validation Loss: 0.3749659061431885
Epoch 47, Training Loss: 0.3749659061431885, Validation Loss: 0.3698134124279022
Epoch 48, Training Loss: 0.36981338262557983, Validation Loss: 0.3643275201320648
Epoch 49, Training Loss: 0.3643275499343872, Validation Loss: 0.35849809646606445
Epoch 50, Training Loss: 0.35849806666374207, Validation Loss: 0.3522697687149048
Epoch 51, Training Loss: 0.3522697687149048, Validation Loss: 0.3456568419933319
Epoch 52, Training Loss: 0.3456568419933319, Validation Loss: 0.33862459659576416
Epoch 53, Training Loss: 0.3386245667934418, Validation Loss: 0.33116140961647034
Epoch 54, Training Loss: 0.33116140961647034, Validation Loss: 0.3232786953449249
Epoch 55, Training Loss: 0.32327866554260254, Validation Loss: 0.31495752930641174
Epoch 56, Training Loss: 0.31495746970176697, Validation Loss: 0.3062288463115692
Epoch 57, Training Loss: 0.3062288761138916, Validation Loss: 0.2971259653568268
Epoch 58, Training Loss: 0.2971259355545044, Validation Loss: 0.28766489028930664
Epoch 59, Training Loss: 0.28766489028930664, Validation Loss: 0.27790823578834534
Epoch 60, Training Loss: 0.27790823578834534, Validation Loss: 0.26786792278289795
Epoch 61, Training Loss: 0.26786795258522034, Validation Loss: 0.2575613558292389
Epoch 62, Training Loss: 0.2575613260269165, Validation Loss: 0.24708719551563263
Epoch 63, Training Loss: 0.24708719551563263, Validation Loss: 0.23646029829978943
Epoch 64, Training Loss: 0.23646026849746704, Validation Loss: 0.2258363962173462
Epoch 65, Training Loss: 0.225836381316185, Validation Loss: 0.21534743905067444
Epoch 66, Training Loss: 0.21534746885299683, Validation Loss: 0.204997256398201
Epoch 67, Training Loss: 0.2049972414970398, Validation Loss: 0.1949700266122818
Epoch 68, Training Loss: 0.1949700266122818, Validation Loss: 0.18540418148040771
Epoch 69, Training Loss: 0.18540416657924652, Validation Loss: 0.17625856399536133
Epoch 70, Training Loss: 0.17625854909420013, Validation Loss: 0.16753607988357544
Epoch 71, Training Loss: 0.16753607988357544, Validation Loss: 0.15915757417678833
Epoch 72, Training Loss: 0.15915757417678833, Validation Loss: 0.1510315239429474
Epoch 73, Training Loss: 0.15103153884410858, Validation Loss: 0.14304043352603912
Epoch 74, Training Loss: 0.14304044842720032, Validation Loss: 0.13526110351085663
Epoch 75, Training Loss: 0.13526108860969543, Validation Loss: 0.1275315135717392
Epoch 76, Training Loss: 0.127531498670578, Validation Loss: 0.11969918012619019
Epoch 77, Training Loss: 0.11969917267560959, Validation Loss: 0.11187293380498886
Epoch 78, Training Loss: 0.11187294870615005, Validation Loss: 0.10428689420223236
Epoch 79, Training Loss: 0.10428688675165176, Validation Loss: 0.09682534635066986
Epoch 80, Training Loss: 0.09682533144950867, Validation Loss: 0.08944131433963776
Epoch 81, Training Loss: 0.08944129943847656, Validation Loss: 0.08222855627536774
Epoch 82, Training Loss: 0.08222854137420654, Validation Loss: 0.07518330961465836
Epoch 83, Training Loss: 0.07518332451581955, Validation Loss: 0.06844611465930939
Epoch 84, Training Loss: 0.06844612210988998, Validation Loss: 0.06194823607802391
Epoch 85, Training Loss: 0.06194823607802391, Validation Loss: 0.05585210397839546
Epoch 86, Training Loss: 0.05585210397839546, Validation Loss: 0.050119850784540176
Epoch 87, Training Loss: 0.050119850784540176, Validation Loss: 0.04475528746843338
Epoch 88, Training Loss: 0.04475528001785278, Validation Loss: 0.039817072451114655
Epoch 89, Training Loss: 0.039817068725824356, Validation Loss: 0.03529222682118416
Epoch 90, Training Loss: 0.035292234271764755, Validation Loss: 0.031212491914629936
Epoch 91, Training Loss: 0.031212491914629936, Validation Loss: 0.027586109936237335
Epoch 92, Training Loss: 0.027586111798882484, Validation Loss: 0.024414418265223503
Epoch 93, Training Loss: 0.024414416402578354, Validation Loss: 0.02169145457446575
Epoch 94, Training Loss: 0.0216914601624012, Validation Loss: 0.019413122907280922
Epoch 95, Training Loss: 0.01941312663257122, Validation Loss: 0.017524119466543198
Epoch 96, Training Loss: 0.017524119466543198, Validation Loss: 0.01597021147608757
Epoch 97, Training Loss: 0.01597020961344242, Validation Loss: 0.014661448076367378
Epoch 98, Training Loss: 0.014661449007689953, Validation Loss: 0.013523953035473824
Epoch 99, Training Loss: 0.013523952104151249, Validation Loss: 0.012517384253442287
Epoch 100, Training Loss: 0.012517381459474564, Validation Loss: 0.011573596857488155
Epoch 101, Training Loss: 0.01157359965145588, Validation Loss: 0.010649248026311398
Epoch 102, Training Loss: 0.010649245232343674, Validation Loss: 0.009715083055198193
Epoch 103, Training Loss: 0.009715080261230469, Validation Loss: 0.008767682127654552
Epoch 104, Training Loss: 0.008767685852944851, Validation Loss: 0.007845152169466019
Epoch 105, Training Loss: 0.007845151238143444, Validation Loss: 0.006978316232562065
Epoch 106, Training Loss: 0.006978318560868502, Validation Loss: 0.006197897717356682
Epoch 107, Training Loss: 0.006197895389050245, Validation Loss: 0.005520130041986704
Epoch 108, Training Loss: 0.0055201295763254166, Validation Loss: 0.0049578407779335976
Epoch 109, Training Loss: 0.004957843106240034, Validation Loss: 0.004479580093175173
Epoch 110, Training Loss: 0.004479581024497747, Validation Loss: 0.0040563843213021755
Epoch 111, Training Loss: 0.00405638525262475, Validation Loss: 0.003671009559184313
Epoch 112, Training Loss: 0.003671010723337531, Validation Loss: 0.0033061166759580374
Epoch 113, Training Loss: 0.0033061166759580374, Validation Loss: 0.0029565980657935143
Epoch 114, Training Loss: 0.002956596901640296, Validation Loss: 0.0026293043047189713
Epoch 115, Training Loss: 0.0026293040718883276, Validation Loss: 0.002326320158317685
Epoch 116, Training Loss: 0.0023263206239789724, Validation Loss: 0.002052132273092866
Epoch 117, Training Loss: 0.002052130876109004, Validation Loss: 0.0018136217258870602
Epoch 118, Training Loss: 0.0018136214930564165, Validation Loss: 0.0016098531195893884
Epoch 119, Training Loss: 0.0016098528867587447, Validation Loss: 0.0014356779865920544
Epoch 120, Training Loss: 0.0014356764731928706, Validation Loss: 0.0012837769463658333
Epoch 121, Training Loss: 0.001283777761273086, Validation Loss: 0.0011445338604971766
Epoch 122, Training Loss: 0.0011445345589891076, Validation Loss: 0.0010142899118363857
Epoch 123, Training Loss: 0.0010142895625904202, Validation Loss: 0.0008871172904036939
Epoch 124, Training Loss: 0.0008871167083270848, Validation Loss: 0.0007635388756170869
Epoch 125, Training Loss: 0.0007635372458025813, Validation Loss: 0.0006467400817200541
Epoch 126, Training Loss: 0.0006467417115345597, Validation Loss: 0.0005410765297710896
Epoch 127, Training Loss: 0.000541076238732785, Validation Loss: 0.0004504017124418169
Epoch 128, Training Loss: 0.00045040258555673063, Validation Loss: 0.00037677533691748977
Epoch 129, Training Loss: 0.00037677460932172835, Validation Loss: 0.00032000054488889873
Epoch 130, Training Loss: 0.0003200003120582551, Validation Loss: 0.0002774994063656777
Epoch 131, Training Loss: 0.0002774992026388645, Validation Loss: 0.0002451704640407115
Epoch 132, Training Loss: 0.00024517037672922015, Validation Loss: 0.0002194326661992818
Epoch 133, Training Loss: 0.0002194326079916209, Validation Loss: 0.000196383087313734
Epoch 134, Training Loss: 0.0001963827817235142, Validation Loss: 0.00017498394299764186
Epoch 135, Training Loss: 0.00017498373927082866, Validation Loss: 0.00015415802772622555
Epoch 136, Training Loss: 0.00015415792586281896, Validation Loss: 0.00013373640831559896
Epoch 137, Training Loss: 0.00013373619003687054, Validation Loss: 0.00011413526226533577
Epoch 138, Training Loss: 0.00011413518222980201, Validation Loss: 9.637209586799145e-05
Epoch 139, Training Loss: 9.637192124500871e-05, Validation Loss: 8.105533197522163e-05
Epoch 140, Training Loss: 8.105529559543356e-05, Validation Loss: 6.848955672467127e-05
Epoch 141, Training Loss: 6.848978955531493e-05, Validation Loss: 5.891161708859727e-05
Epoch 142, Training Loss: 5.891156251891516e-05, Validation Loss: 5.164176764083095e-05
Epoch 143, Training Loss: 5.164184040040709e-05, Validation Loss: 4.566844290820882e-05
Epoch 144, Training Loss: 4.5668482925975695e-05, Validation Loss: 4.04470665671397e-05
Epoch 145, Training Loss: 4.044700472149998e-05, Validation Loss: 3.5751701943809167e-05
Epoch 146, Training Loss: 3.575205846573226e-05, Validation Loss: 3.160641063004732e-05
Epoch 147, Training Loss: 3.160630149068311e-05, Validation Loss: 2.8151916922070086e-05
Epoch 148, Training Loss: 2.8151871447334997e-05, Validation Loss: 2.5505380108370446e-05
Epoch 149, Training Loss: 2.5505447410978377e-05, Validation Loss: 2.3657241399632767e-05
Epoch 150, Training Loss: 2.365733598708175e-05, Validation Loss: 2.244365168735385e-05
Epoch 151, Training Loss: 2.2443666239269078e-05, Validation Loss: 2.1592941266135313e-05
Epoch 152, Training Loss: 2.1593092242255807e-05, Validation Loss: 2.081703132716939e-05
Epoch 153, Training Loss: 2.081711500068195e-05, Validation Loss: 1.989985685213469e-05
Epoch 154, Training Loss: 1.9900229744962417e-05, Validation Loss: 1.875492489489261e-05
Epoch 155, Training Loss: 1.8754788470687345e-05, Validation Loss: 1.7431088053854182e-05
Epoch 156, Training Loss: 1.7430991647415794e-05, Validation Loss: 1.606784098839853e-05
Epoch 157, Training Loss: 1.6067775504780002e-05, Validation Loss: 1.4827539416728541e-05
Epoch 158, Training Loss: 1.4827539416728541e-05, Validation Loss: 1.382676691719098e-05
Epoch 159, Training Loss: 1.3826954273099545e-05, Validation Loss: 1.3098304407321848e-05
Epoch 160, Training Loss: 1.3098438103043009e-05, Validation Loss: 1.2586493539856747e-05
Epoch 161, Training Loss: 1.258643351320643e-05, Validation Loss: 1.2175798474345356e-05
Epoch 162, Training Loss: 1.2175845768069848e-05, Validation Loss: 1.1739080036932137e-05
Epoch 163, Training Loss: 1.1739049114112277e-05, Validation Loss: 1.1180225556017831e-05
Epoch 164, Training Loss: 1.1180153705936391e-05, Validation Loss: 1.0461923011462204e-05
Epoch 165, Training Loss: 1.0461970305186696e-05, Validation Loss: 9.607973879610654e-06
Epoch 166, Training Loss: 9.60800298344111e-06, Validation Loss: 8.684988642926328e-06
Epoch 167, Training Loss: 8.68494316819124e-06, Validation Loss: 7.772424396534916e-06
Epoch 168, Training Loss: 7.77240620664088e-06, Validation Loss: 6.935900273674633e-06
Epoch 169, Training Loss: 6.9358998189272825e-06, Validation Loss: 6.209662842593389e-06
Epoch 170, Training Loss: 6.2097356021695305e-06, Validation Loss: 5.595506081590429e-06
Epoch 171, Training Loss: 5.595515176537447e-06, Validation Loss: 5.071569830761291e-06
Epoch 172, Training Loss: 5.071525265520904e-06, Validation Loss: 4.608920789905824e-06
Epoch 173, Training Loss: 4.6089216994005255e-06, Validation Loss: 4.18440913563245e-06
Epoch 174, Training Loss: 4.184360477665905e-06, Validation Loss: 3.787493824347621e-06
Epoch 175, Training Loss: 3.787593414017465e-06, Validation Loss: 3.4205784231744474e-06
Epoch 176, Training Loss: 3.420554094191175e-06, Validation Loss: 3.090570089625544e-06
Epoch 177, Training Loss: 3.0905766834621318e-06, Validation Loss: 2.8025981464452343e-06
Epoch 178, Training Loss: 2.802569724735804e-06, Validation Loss: 2.5538761292409617e-06
Epoch 179, Training Loss: 2.5538738555042073e-06, Validation Loss: 2.3331506326940143e-06
Epoch 180, Training Loss: 2.3332097498496296e-06, Validation Loss: 2.124745151377283e-06
Epoch 181, Training Loss: 2.1247121821943438e-06, Validation Loss: 1.9139761207043193e-06
Epoch 182, Training Loss: 1.913966798383626e-06, Validation Loss: 1.6931442132772645e-06
Epoch 183, Training Loss: 1.6931246591411764e-06, Validation Loss: 1.46360059716244e-06
Epoch 184, Training Loss: 1.4635810430263518e-06, Validation Loss: 1.234760361512599e-06
Epoch 185, Training Loss: 1.2347730944384239e-06, Validation Loss: 1.019931346490921e-06
Epoch 186, Training Loss: 1.0198979225606308e-06, Validation Loss: 8.309333452416467e-07
Epoch 187, Training Loss: 8.309706345244194e-07, Validation Loss: 6.74689374591253e-07
Epoch 188, Training Loss: 6.746961389580974e-07, Validation Loss: 5.510382834472694e-07
Epoch 189, Training Loss: 5.510268579200783e-07, Validation Loss: 4.54213449074814e-07
Epoch 190, Training Loss: 4.5420839001053537e-07, Validation Loss: 3.7565533261840756e-07
Epoch 191, Training Loss: 3.756414344024961e-07, Validation Loss: 3.0756655178265646e-07
Epoch 192, Training Loss: 3.075836048083147e-07, Validation Loss: 2.453802210311551e-07
Epoch 193, Training Loss: 2.453785441502987e-07, Validation Loss: 1.8840898974303855e-07
Epoch 194, Training Loss: 1.8841322457774368e-07, Validation Loss: 1.3903643036883295e-07
Epoch 195, Training Loss: 1.3902653961395117e-07, Validation Loss: 1.0063602928767068e-07
Epoch 196, Training Loss: 1.0063642008617535e-07, Validation Loss: 7.560972647979725e-08
Epoch 197, Training Loss: 7.559723513850258e-08, Validation Loss: 6.404098940038239e-08
Epoch 198, Training Loss: 6.403390528930686e-08, Validation Loss: 6.355703874305618e-08
Epoch 199, Training Loss: 6.355919879297289e-08, Validation Loss: 7.020211256758557e-08
Epoch 200, Training Loss: 7.02013025488668e-08, Validation Loss: 7.973447679887613e-08
Epoch 201, Training Loss: 7.973260807148108e-08, Validation Loss: 8.882393132125799e-08
Epoch 202, Training Loss: 8.883350943733603e-08, Validation Loss: 9.572865877771619e-08
Epoch 203, Training Loss: 9.572298864668483e-08, Validation Loss: 1.0018727891747403e-07
Epoch 204, Training Loss: 1.0019024898610951e-07, Validation Loss: 1.0282968787578284e-07
Epoch 205, Training Loss: 1.028316205520241e-07, Validation Loss: 1.0443899611800589e-07
Epoch 206, Training Loss: 1.0443469733445454e-07, Validation Loss: 1.0534171224207967e-07
Epoch 207, Training Loss: 1.0534093064507033e-07, Validation Loss: 1.053266416306542e-07
Epoch 208, Training Loss: 1.0531685745718278e-07, Validation Loss: 1.0376525949595816e-07
Epoch 209, Training Loss: 1.0376449210980354e-07, Validation Loss: 1.0007639161813131e-07
Epoch 210, Training Loss: 1.0006637296555709e-07, Validation Loss: 9.407963119656415e-08
Epoch 211, Training Loss: 9.407568768438068e-08, Validation Loss: 8.618954439043591e-08
Epoch 212, Training Loss: 8.617491431550661e-08, Validation Loss: 7.730584883347547e-08
Epoch 213, Training Loss: 7.731510009989506e-08, Validation Loss: 6.85093510810475e-08
Epoch 214, Training Loss: 6.850455491758112e-08, Validation Loss: 6.066107971491874e-08
Epoch 215, Training Loss: 6.06552887916223e-08, Validation Loss: 5.4189349896205385e-08
Epoch 216, Training Loss: 5.4189321474495955e-08, Validation Loss: 4.904267569827425e-08
Epoch 217, Training Loss: 4.9045155492422055e-08, Validation Loss: 4.479275261815019e-08
Epoch 218, Training Loss: 4.479654336364547e-08, Validation Loss: 4.090265903755608e-08
Epoch 219, Training Loss: 4.0906549259034364e-08, Validation Loss: 3.6963843541570895e-08
Epoch 220, Training Loss: 3.6967485073091666e-08, Validation Loss: 3.280817395534541e-08
Epoch 221, Training Loss: 3.280736748934032e-08, Validation Loss: 2.856046599220008e-08
Epoch 222, Training Loss: 2.8562698872747205e-08, Validation Loss: 2.4493107986245377e-08
Epoch 223, Training Loss: 2.449772473767098e-08, Validation Loss: 2.0901220310065582e-08
Epoch 224, Training Loss: 2.08987369632041e-08, Validation Loss: 1.7948952546475994e-08
Epoch 225, Training Loss: 1.7942156205208448e-08, Validation Loss: 1.5639487926932816e-08
Epoch 226, Training Loss: 1.563956608663375e-08, Validation Loss: 1.3854042357763774e-08
Epoch 227, Training Loss: 1.3849252411546331e-08, Validation Loss: 1.2384029801637553e-08
Epoch 228, Training Loss: 1.2384905545559377e-08, Validation Loss: 1.1069914762629196e-08
Epoch 229, Training Loss: 1.10724487356606e-08, Validation Loss: 9.804582923322869e-09
Epoch 230, Training Loss: 9.804471012841987e-09, Validation Loss: 8.575586463166474e-09
Epoch 231, Training Loss: 8.57352233651909e-09, Validation Loss: 7.424587167292884e-09
Epoch 232, Training Loss: 7.4235528835231435e-09, Validation Loss: 6.403190422332727e-09
Epoch 233, Training Loss: 6.405690644584183e-09, Validation Loss: 5.537225788998512e-09
Epoch 234, Training Loss: 5.535968128356217e-09, Validation Loss: 4.811083975653219e-09
Epoch 235, Training Loss: 4.806941955592947e-09, Validation Loss: 4.173943413121606e-09
Epoch 236, Training Loss: 4.1709262710298844e-09, Validation Loss: 3.588679575727838e-09
Epoch 237, Training Loss: 3.5891891680961407e-09, Validation Loss: 3.0352944602185516e-09
Epoch 238, Training Loss: 3.031588091673143e-09, Validation Loss: 2.516528097018522e-09
Epoch 239, Training Loss: 2.5145865389930577e-09, Validation Loss: 2.058208492528024e-09
Epoch 240, Training Loss: 2.058646808578146e-09, Validation Loss: 1.6998281671121163e-09
Epoch 241, Training Loss: 1.7013862541048752e-09, Validation Loss: 1.4535581627228567e-09
Epoch 242, Training Loss: 1.4545021853606954e-09, Validation Loss: 1.3099888951373373e-09
Epoch 243, Training Loss: 1.310117014874379e-09, Validation Loss: 1.2349394840072137e-09
Epoch 244, Training Loss: 1.2364081980464903e-09, Validation Loss: 1.1912497654975596e-09
Epoch 245, Training Loss: 1.1908742880706313e-09, Validation Loss: 1.1397068844232194e-09
Epoch 246, Training Loss: 1.1401963817547767e-09, Validation Loss: 1.0650438309056653e-09
Epoch 247, Training Loss: 1.065053822912887e-09, Validation Loss: 9.695119151942322e-10
Epoch 248, Training Loss: 9.689523627898211e-10, Validation Loss: 8.661191763792431e-10
Epoch 249, Training Loss: 8.667186968125407e-10, Validation Loss: 7.773172661096339e-10
Epoch 250, Training Loss: 7.773884314055124e-10, Validation Loss: 7.141383040476512e-10
Epoch 251, Training Loss: 7.144383973312074e-10, Validation Loss: 6.795267681880546e-10
Epoch 252, Training Loss: 6.792550966139288e-10, Validation Loss: 6.66248334280084e-10
Epoch 253, Training Loss: 6.660511586709106e-10, Validation Loss: 6.632163707109839e-10
Epoch 254, Training Loss: 6.638036786910106e-10, Validation Loss: 6.597764001803341e-10
Epoch 255, Training Loss: 6.610751945856919e-10, Validation Loss: 6.509526251363695e-10
Epoch 256, Training Loss: 6.501975069461707e-10, Validation Loss: 6.337424474089914e-10
Epoch 257, Training Loss: 6.337133595657463e-10, Validation Loss: 6.129424745537904e-10
Epoch 258, Training Loss: 6.139112551650783e-10, Validation Loss: 5.923141976893476e-10
Epoch 259, Training Loss: 5.916669931771423e-10, Validation Loss: 5.675689918049898e-10
Epoch 260, Training Loss: 5.685906745434011e-10, Validation Loss: 5.401546987471306e-10
Epoch 261, Training Loss: 5.408939407480773e-10, Validation Loss: 5.072010034190555e-10
Epoch 262, Training Loss: 5.073421127654854e-10, Validation Loss: 4.658862740036795e-10
Epoch 263, Training Loss: 4.662806807331776e-10, Validation Loss: 4.202173886636018e-10
Epoch 264, Training Loss: 4.2004663636241446e-10, Validation Loss: 3.7092379168157663e-10
Epoch 265, Training Loss: 3.708222895415503e-10, Validation Loss: 3.231536427339421e-10
Epoch 266, Training Loss: 3.237060064442687e-10, Validation Loss: 2.812476362912264e-10
Epoch 267, Training Loss: 2.809026067307485e-10, Validation Loss: 2.456805314743349e-10
Epoch 268, Training Loss: 2.459268899634992e-10, Validation Loss: 2.1726108412334355e-10
Epoch 269, Training Loss: 2.1732873833890665e-10, Validation Loss: 1.9222125280382585e-10
Epoch 270, Training Loss: 1.9236955084434015e-10, Validation Loss: 1.6793230694922556e-10
Epoch 271, Training Loss: 1.6773499256217406e-10, Validation Loss: 1.430770640853396e-10
Epoch 272, Training Loss: 1.4332093845048632e-10, Validation Loss: 1.1796773280448036e-10
Epoch 273, Training Loss: 1.1821793544086745e-10, Validation Loss: 9.431723457797858e-11
Epoch 274, Training Loss: 9.416150498209319e-11, Validation Loss: 7.261157647375782e-11
Epoch 275, Training Loss: 7.287245112896912e-11, Validation Loss: 5.572085848282171e-11
Epoch 276, Training Loss: 5.5773788365520716e-11, Validation Loss: 4.365000028094812e-11
Epoch 277, Training Loss: 4.35394185982485e-11, Validation Loss: 3.537774587170084e-11
Epoch 278, Training Loss: 3.536943654625091e-11, Validation Loss: 3.004338444689836e-11
Epoch 279, Training Loss: 3.014038324478108e-11, Validation Loss: 2.6896054827751925e-11
Epoch 280, Training Loss: 2.6711275552537828e-11, Validation Loss: 2.4064375492294232e-11
Epoch 281, Training Loss: 2.3860680792298083e-11, Validation Loss: 2.1484671680616074e-11
Epoch 282, Training Loss: 2.1264674049392696e-11, Validation Loss: 1.883549392844852e-11
Epoch 283, Training Loss: 1.879917228830852e-11, Validation Loss: 1.6971738250881607e-11
Epoch 284, Training Loss: 1.6844230871226884e-11, Validation Loss: 1.5058090191422124e-11
Epoch 285, Training Loss: 1.52085132681945e-11, Validation Loss: 1.4058600637800733e-11
Epoch 286, Training Loss: 1.3973442195003294e-11, Validation Loss: 1.3284279926084608e-11
Epoch 287, Training Loss: 1.3288817962697763e-11, Validation Loss: 1.2620403853913498e-11
Epoch 288, Training Loss: 1.26082868104338e-11, Validation Loss: 1.1890187619212345e-11
Epoch 289, Training Loss: 1.204570818091888e-11, Validation Loss: 1.1115410675222037e-11
Epoch 290, Training Loss: 1.130736650145625e-11, Validation Loss: 1.0370456229868985e-11
Epoch 291, Training Loss: 1.0352082906173177e-11, Validation Loss: 9.89511163979051e-12
Epoch 292, Training Loss: 9.899982743311053e-12, Validation Loss: 9.708981014988627e-12
Epoch 293, Training Loss: 9.61769032470361e-12, Validation Loss: 9.810874335158815e-12
Epoch 294, Training Loss: 9.781914861450858e-12, Validation Loss: 1.0141372984440178e-11
Epoch 295, Training Loss: 1.0210544215683015e-11, Validation Loss: 1.0470129103989922e-11
Epoch 296, Training Loss: 1.0470737124568252e-11, Validation Loss: 1.0633030914086739e-11
Epoch 297, Training Loss: 1.0658107209293721e-11, Validation Loss: 1.0386362776781954e-11
Epoch 298, Training Loss: 1.0351259779883826e-11, Validation Loss: 9.882095142188518e-12
Epoch 299, Training Loss: 9.93488798173292e-12, Validation Loss: 9.229435792013074e-12
Epoch 300, Training Loss: 9.31293150235879e-12, Validation Loss: 8.407711159230669e-12
Epoch 301, Training Loss: 8.304051023200199e-12, Validation Loss: 7.657439786423748e-12
Epoch 302, Training Loss: 7.522629220935162e-12, Validation Loss: 6.7892948207859405e-12
Epoch 303, Training Loss: 6.720306602869819e-12, Validation Loss: 6.0404407170588925e-12
Epoch 304, Training Loss: 6.0189028240620335e-12, Validation Loss: 5.459544274999395e-12
Epoch 305, Training Loss: 5.40720116251614e-12, Validation Loss: 4.787010631640554e-12
Epoch 306, Training Loss: 4.794225346577141e-12, Validation Loss: 4.219726998377915e-12
Epoch 307, Training Loss: 4.2442334369230394e-12, Validation Loss: 3.725583643671149e-12
Epoch 308, Training Loss: 3.753380418969332e-12, Validation Loss: 3.3150374806334426e-12
Epoch 309, Training Loss: 3.2558658460274392e-12, Validation Loss: 2.859103362048976e-12
Epoch 310, Training Loss: 2.787664413542168e-12, Validation Loss: 2.407202909227024e-12
Epoch 311, Training Loss: 2.434024119410405e-12, Validation Loss: 2.0792863958396524e-12
Epoch 312, Training Loss: 2.048486380523684e-12, Validation Loss: 1.762821008957638e-12
Epoch 313, Training Loss: 1.722232165907167e-12, Validation Loss: 1.4299937102502103e-12
Epoch 314, Training Loss: 1.4257583828836129e-12, Validation Loss: 1.174731319164568e-12
Epoch 315, Training Loss: 1.1811256183172358e-12, Validation Loss: 9.530915553307429e-13
Epoch 316, Training Loss: 9.56355762811445e-13, Validation Loss: 7.627605686823247e-13
Epoch 317, Training Loss: 7.636833331513271e-13, Validation Loss: 6.124078566309421e-13
Epoch 318, Training Loss: 5.804631948713723e-13, Validation Loss: 4.772486659337938e-13
Epoch 319, Training Loss: 4.965114148818006e-13, Validation Loss: 3.8854851410960456e-13
Epoch 320, Training Loss: 4.008066122919429e-13, Validation Loss: 3.450745819730955e-13
Epoch 321, Training Loss: 3.341025373027051e-13, Validation Loss: 2.9299200327188857e-13
Epoch 322, Training Loss: 2.866287123013539e-13, Validation Loss: 2.5522861818796927e-13
Epoch 323, Training Loss: 2.627365013919969e-13, Validation Loss: 2.404066529182458e-13
Epoch 324, Training Loss: 2.402480612454655e-13, Validation Loss: 2.3265056873188195e-13
Epoch 325, Training Loss: 2.3913409772334526e-13, Validation Loss: 2.4101971503667774e-13
Epoch 326, Training Loss: 2.3204786074419725e-13, Validation Loss: 2.1783527130551927e-13
Epoch 327, Training Loss: 2.1337006597330066e-13, Validation Loss: 2.044038766371714e-13
Epoch 328, Training Loss: 2.0605286682635893e-13, Validation Loss: 1.9883113168070454e-13
Epoch 329, Training Loss: 1.8498053024236516e-13, Validation Loss: 1.7867434962126616e-13
Epoch 330, Training Loss: 1.7857925153821202e-13, Validation Loss: 1.5398293263298862e-13
Epoch 331, Training Loss: 1.5336790539811906e-13, Validation Loss: 1.3622464972457698e-13
Epoch 332, Training Loss: 1.3983627623892492e-13, Validation Loss: 1.190418477767935e-13
Epoch 333, Training Loss: 1.263555097141475e-13, Validation Loss: 1.1038981957266908e-13
Epoch 334, Training Loss: 1.1280958941506727e-13, Validation Loss: 9.179779874614324e-14
Epoch 335, Training Loss: 1.0481953439988104e-13, Validation Loss: 8.063390450133157e-14
Epoch 336, Training Loss: 9.792619731600893e-14, Validation Loss: 8.331208037901452e-14
Epoch 337, Training Loss: 8.146430172150179e-14, Validation Loss: 7.531293839437014e-14
Epoch 338, Training Loss: 7.943047397119055e-14, Validation Loss: 6.863375156835466e-14
Epoch 339, Training Loss: 6.965420265309802e-14, Validation Loss: 6.625210498484649e-14
Epoch 340, Training Loss: 5.5287554861973426e-14, Validation Loss: 6.676995382374346e-14
Epoch 341, Training Loss: 5.3535748425516394e-14, Validation Loss: 5.888296577757912e-14
Epoch 342, Training Loss: 5.465904963884716e-14, Validation Loss: 5.887175783762105e-14
Epoch 343, Training Loss: 6.359140509093128e-14, Validation Loss: 5.41866695285588e-14
Epoch 344, Training Loss: 5.094650761916335e-14, Validation Loss: 5.6419760085645726e-14
Epoch 345, Training Loss: 4.7213948516870025e-14, Validation Loss: 4.985813465644556e-14
Epoch 346, Training Loss: 4.07574771458738e-14, Validation Loss: 4.033250716370916e-14
Epoch 347, Training Loss: 3.953726519898178e-14, Validation Loss: 3.5611548703396584e-14
Epoch 348, Training Loss: 3.768154476055559e-14, Validation Loss: 3.8196117276012576e-14
Epoch 349, Training Loss: 2.9884599704816175e-14, Validation Loss: 3.443433553703898e-14
Epoch 350, Training Loss: 2.614723792571192e-14, Validation Loss: 3.434179549348555e-14
Epoch 351, Training Loss: 2.479105008573127e-14, Validation Loss: 3.323380524770936e-14
Epoch 352, Training Loss: 2.4745947275355874e-14, Validation Loss: 2.5305287176141146e-14
Epoch 353, Training Loss: 2.3484537339975298e-14, Validation Loss: 2.6321909671962913e-14
Epoch 354, Training Loss: 1.9856129408876363e-14, Validation Loss: 2.6860509124001716e-14
Epoch 355, Training Loss: 2.2444236885145984e-14, Validation Loss: 2.7078882688133347e-14
Epoch 356, Training Loss: 2.0450106180940758e-14, Validation Loss: 2.5005490028855853e-14
Epoch 357, Training Loss: 2.00047819970536e-14, Validation Loss: 2.686204394770214e-14
Epoch 358, Training Loss: 1.6896689464794036e-14, Validation Loss: 2.535280064228443e-14
Epoch 359, Training Loss: 1.754484415823071e-14, Validation Loss: 2.1920917907475648e-14
Epoch 360, Training Loss: 1.4573727017937535e-14, Validation Loss: 1.9552517225196638e-14
Epoch 361, Training Loss: 1.5460570513712787e-14, Validation Loss: 2.096992183034125e-14
Epoch 362, Training Loss: 1.2076659489871754e-14, Validation Loss: 2.0410941071525614e-14
Epoch 363, Training Loss: 1.0616789734949495e-14, Validation Loss: 1.675093034116462e-14
Epoch 364, Training Loss: 1.0849242680730387e-14, Validation Loss: 1.5197460057438973e-14
Epoch 365, Training Loss: 1.2114990271833853e-14, Validation Loss: 1.66017187112422e-14
Epoch 366, Training Loss: 1.083332947275032e-14, Validation Loss: 1.4815346554273613e-14
Epoch 367, Training Loss: 1.1341002904851922e-14, Validation Loss: 1.3838062809621177e-14
Epoch 368, Training Loss: 9.551969370363064e-15, Validation Loss: 1.3431211709231256e-14
Epoch 369, Training Loss: 9.384468605043526e-15, Validation Loss: 1.1175837409367964e-14
Epoch 370, Training Loss: 7.693013266078363e-15, Validation Loss: 1.6367924065272856e-14
Epoch 371, Training Loss: 1.0602211450894301e-14, Validation Loss: 1.1703118807165555e-14
Epoch 372, Training Loss: 8.058239473374314e-15, Validation Loss: 1.075489168073573e-14
Epoch 373, Training Loss: 8.477041361617046e-15, Validation Loss: 1.1582963795465744e-14
Epoch 374, Training Loss: 8.024545349765485e-15, Validation Loss: 1.0203524901082964e-14
Epoch 375, Training Loss: 7.53345174057344e-15, Validation Loss: 1.1657890635913964e-14
Epoch 376, Training Loss: 9.375461256682423e-15, Validation Loss: 1.332736208176609e-14
Epoch 377, Training Loss: 7.106143100441432e-15, Validation Loss: 9.564212384582677e-15
Epoch 378, Training Loss: 8.980444900631539e-15, Validation Loss: 1.0596940364863538e-14
Epoch 379, Training Loss: 8.637036567990964e-15, Validation Loss: 1.1961066597625854e-14
Epoch 380, Training Loss: 7.014569521480822e-15, Validation Loss: 9.98841919006184e-15
Epoch 381, Training Loss: 7.143572639347652e-15, Validation Loss: 1.0840593627305974e-14
Epoch 382, Training Loss: 6.473302762691115e-15, Validation Loss: 1.0833121102645296e-14
Epoch 383, Training Loss: 6.430501764349882e-15, Validation Loss: 1.0772572646476717e-14
Epoch 384, Training Loss: 6.019405758344795e-15, Validation Loss: 1.1032080671625859e-14
Epoch 385, Training Loss: 4.38102592737106e-15, Validation Loss: 9.38777118650487e-15
Epoch 386, Training Loss: 6.291557020781128e-15, Validation Loss: 9.575179767183726e-15
Epoch 387, Training Loss: 4.462091215588033e-15, Validation Loss: 1.0460922967160495e-14
Epoch 388, Training Loss: 5.651577465834879e-15, Validation Loss: 7.238974807229851e-15
Epoch 389, Training Loss: 5.552298004636623e-15, Validation Loss: 7.0882872223968375e-15
Epoch 390, Training Loss: 4.684869351045387e-15, Validation Loss: 6.106842428391015e-15
Epoch 391, Training Loss: 4.369149678417608e-15, Validation Loss: 7.89584292859493e-15
Epoch 392, Training Loss: 6.442344555501918e-15, Validation Loss: 7.292425974333386e-15
Epoch 393, Training Loss: 4.055932141116018e-15, Validation Loss: 7.805603426526246e-15
Epoch 394, Training Loss: 3.697278062457813e-15, Validation Loss: 8.674566903817908e-15
Epoch 395, Training Loss: 4.667121893218041e-15, Validation Loss: 7.991419585264264e-15
Epoch 396, Training Loss: 3.804797460166959e-15, Validation Loss: 7.640738627738564e-15
Epoch 397, Training Loss: 3.4082797382170658e-15, Validation Loss: 7.942379765750029e-15
Epoch 398, Training Loss: 3.4178876329377713e-15, Validation Loss: 6.600237849617224e-15
Epoch 399, Training Loss: 3.3834599787966203e-15, Validation Loss: 6.265836441821278e-15
Epoch 400, Training Loss: 3.19874517464827e-15, Validation Loss: 6.164422034079468e-15
Epoch 401, Training Loss: 3.688737852767122e-15, Validation Loss: 5.911419221965239e-15
Epoch 402, Training Loss: 4.097532046738045e-15, Validation Loss: 5.10604039044159e-15
Epoch 403, Training Loss: 4.043622211293571e-15, Validation Loss: 4.901076204897941e-15
Epoch 404, Training Loss: 4.1608494536111984e-15, Validation Loss: 5.378792199237526e-15
Epoch 405, Training Loss: 4.278777615692678e-15, Validation Loss: 5.519905347151251e-15
Epoch 406, Training Loss: 3.3834932248398e-15, Validation Loss: 5.724836498409956e-15
Epoch 407, Training Loss: 3.1242187690258636e-15, Validation Loss: 5.588727197632136e-15
Epoch 408, Training Loss: 3.6657193089090125e-15, Validation Loss: 4.826115906648304e-15
Epoch 409, Training Loss: 3.811436080891064e-15, Validation Loss: 7.754862764853925e-15
Epoch 410, Training Loss: 3.771404033254405e-15, Validation Loss: 7.090263773779255e-15
Epoch 411, Training Loss: 3.804430694900798e-15, Validation Loss: 6.600738446089051e-15
Epoch 412, Training Loss: 3.2146914169132795e-15, Validation Loss: 6.722702720164198e-15
Epoch 413, Training Loss: 2.9067445421259797e-15, Validation Loss: 7.158251720323569e-15
Epoch 414, Training Loss: 2.0279402360531178e-15, Validation Loss: 6.272608470234576e-15
Epoch 415, Training Loss: 2.7866149414145858e-15, Validation Loss: 6.514969583915975e-15
Epoch 416, Training Loss: 2.3249783852709663e-15, Validation Loss: 6.854742027630461e-15
Epoch 417, Training Loss: 2.508859073724508e-15, Validation Loss: 6.5456940100117305e-15
Epoch 418, Training Loss: 2.2990909408205067e-15, Validation Loss: 6.261266275554367e-15
Epoch 419, Training Loss: 2.108004543084673e-15, Validation Loss: 6.04135661717289e-15
Epoch 420, Training Loss: 2.011927501701749e-15, Validation Loss: 6.54335874017615e-15
Epoch 421, Training Loss: 1.8171046298773395e-15, Validation Loss: 7.300299145578115e-15
Epoch 422, Training Loss: 2.786414829880797e-15, Validation Loss: 6.23614624295412e-15
Epoch 423, Training Loss: 2.4863076685368093e-15, Validation Loss: 6.92763344790643e-15
Epoch 424, Training Loss: 2.574645158122434e-15, Validation Loss: 6.587561154528616e-15
Epoch 425, Training Loss: 2.3456616592934954e-15, Validation Loss: 6.922029054410922e-15
Epoch 426, Training Loss: 3.4208564834178976e-15, Validation Loss: 7.113048960060396e-15
Epoch 427, Training Loss: 3.0001193366489256e-15, Validation Loss: 7.055602762061136e-15
Epoch 428, Training Loss: 3.211488785339711e-15, Validation Loss: 7.026779501415493e-15
Epoch 429, Training Loss: 3.1570451073802304e-15, Validation Loss: 6.8679858112772555e-15
Epoch 430, Training Loss: 3.1383635839703e-15, Validation Loss: 6.614716183784642e-15
Epoch 431, Training Loss: 3.0783153007570745e-15, Validation Loss: 7.634600179969812e-15
Epoch 432, Training Loss: 2.3327179370682656e-15, Validation Loss: 7.634600179969812e-15
Epoch 433, Training Loss: 2.511727974316858e-15, Validation Loss: 7.224671808882515e-15
Epoch 434, Training Loss: 2.388462445876492e-15, Validation Loss: 7.407818119770787e-15
Epoch 435, Training Loss: 3.0129631089863794e-15, Validation Loss: 6.978674382758553e-15
Epoch 436, Training Loss: 2.7347401026258907e-15, Validation Loss: 5.519037985413262e-15
Epoch 437, Training Loss: 3.3133036279073356e-15, Validation Loss: 5.4976876729447705e-15
Epoch 438, Training Loss: 2.2840122720517225e-15, Validation Loss: 5.787478396507674e-15
Epoch 439, Training Loss: 2.1270865013204177e-15, Validation Loss: 5.83631746921341e-15
Epoch 440, Training Loss: 2.5638363824407586e-15, Validation Loss: 5.830379344736684e-15
Epoch 441, Training Loss: 2.4909779964497327e-15, Validation Loss: 5.89553142497359e-15
Epoch 442, Training Loss: 2.424791688984229e-15, Validation Loss: 5.866174533571177e-15
Epoch 443, Training Loss: 2.4936135394651145e-15, Validation Loss: 5.895931648041168e-15
Epoch 444, Training Loss: 1.8380881770796702e-15, Validation Loss: 5.819804138390214e-15
Epoch 445, Training Loss: 2.1730232156323866e-15, Validation Loss: 5.684762522642408e-15
Epoch 446, Training Loss: 1.7941195438206468e-15, Validation Loss: 5.309127974490596e-15
Epoch 447, Training Loss: 2.088121926955536e-15, Validation Loss: 4.652109928293853e-15
Epoch 448, Training Loss: 1.4111793364987666e-15, Validation Loss: 4.680866273336663e-15
Epoch 449, Training Loss: 2.020867934460018e-15, Validation Loss: 4.895238030308991e-15
Epoch 450, Training Loss: 2.020867934460018e-15, Validation Loss: 5.183468942699526e-15
Epoch 451, Training Loss: 1.4217211909229384e-15, Validation Loss: 5.183468942699526e-15
Epoch 452, Training Loss: 1.6880679483299746e-15, Validation Loss: 5.183468942699526e-15
Epoch 453, Training Loss: 1.7060823274148238e-15, Validation Loss: 5.183468942699526e-15
Epoch 454, Training Loss: 1.3536666464131469e-15, Validation Loss: 5.183468942699526e-15
Epoch 455, Training Loss: 1.1783260617711784e-15, Validation Loss: 3.528809773754274e-15
Epoch 456, Training Loss: 1.2621265252539537e-15, Validation Loss: 3.0862801633183435e-15
Epoch 457, Training Loss: 1.2541201580782693e-15, Validation Loss: 3.726326210350952e-15
Epoch 458, Training Loss: 1.7377076789291024e-15, Validation Loss: 3.726326210350952e-15
Epoch 459, Training Loss: 1.2653291568275223e-15, Validation Loss: 3.726326210350952e-15
Epoch 460, Training Loss: 1.0845175863792383e-15, Validation Loss: 3.726326210350952e-15
Epoch 461, Training Loss: 2.165583937014889e-15, Validation Loss: 3.852427393340489e-15
Epoch 462, Training Loss: 2.165583937014889e-15, Validation Loss: 3.8256060950656815e-15
Epoch 463, Training Loss: 2.578181308918984e-15, Validation Loss: 3.822136648113728e-15
Epoch 464, Training Loss: 2.5995316213874757e-15, Validation Loss: 3.506758753280166e-15
Epoch 465, Training Loss: 2.137561546020875e-15, Validation Loss: 3.5463905778492476e-15
Epoch 466, Training Loss: 2.139162861807659e-15, Validation Loss: 3.5537966104235656e-15
Epoch 467, Training Loss: 2.394067051130237e-15, Validation Loss: 3.589625257059475e-15
Epoch 468, Training Loss: 1.7515854667369169e-15, Validation Loss: 3.261562196807833e-15
Epoch 469, Training Loss: 1.6455005193239465e-15, Validation Loss: 3.4399636408838233e-15
Epoch 470, Training Loss: 1.6428316243862666e-15, Validation Loss: 3.902409113492071e-15
Epoch 471, Training Loss: 1.6428316243862666e-15, Validation Loss: 4.071144429332232e-15
Epoch 472, Training Loss: 1.4303948083028224e-15, Validation Loss: 7.611715043800895e-15
Epoch 473, Training Loss: 1.3139681179994691e-15, Validation Loss: 6.755128835450987e-15
Epoch 474, Training Loss: 1.2812752932134133e-15, Validation Loss: 6.69424664830119e-15
Epoch 475, Training Loss: 1.4555482987044861e-15, Validation Loss: 6.405548597240244e-15
Epoch 476, Training Loss: 2.107737515948051e-15, Validation Loss: 6.4499758988402055e-15
Epoch 477, Training Loss: 1.6461009598044314e-15, Validation Loss: 4.425687010064464e-15
Epoch 478, Training Loss: 2.3489974867980197e-15, Validation Loss: 4.380350418595625e-15
Epoch 479, Training Loss: 1.5677047782833753e-15, Validation Loss: 4.380350418595625e-15
Epoch 480, Training Loss: 1.5783800403967397e-15, Validation Loss: 4.380350418595625e-15
Epoch 481, Training Loss: 2.314970267482683e-15, Validation Loss: 4.599826396108108e-15
Epoch 482, Training Loss: 2.1130083902205776e-15, Validation Loss: 4.277734918134608e-15
Epoch 483, Training Loss: 2.305829723190625e-15, Validation Loss: 4.422851143757057e-15
Epoch 484, Training Loss: 2.305829723190625e-15, Validation Loss: 4.5036576634086434e-15
Epoch 485, Training Loss: 2.254054834289706e-15, Validation Loss: 4.516334358497251e-15
Epoch 486, Training Loss: 2.672790442204316e-15, Validation Loss: 4.273139764395754e-15
Epoch 487, Training Loss: 1.3620066386909311e-15, Validation Loss: 7.843267593558856e-15
Epoch 488, Training Loss: 2.1194136533677146e-15, Validation Loss: 7.843267593558856e-15
Epoch 489, Training Loss: 2.216558168022416e-15, Validation Loss: 6.590062866338332e-15
Epoch 490, Training Loss: 7.780719716118283e-16, Validation Loss: 6.7455209407302815e-15
Epoch 491, Training Loss: 7.83543010357703e-16, Validation Loss: 4.930833319367932e-15
Epoch 492, Training Loss: 1.3742831107119613e-15, Validation Loss: 4.930833319367932e-15
Epoch 493, Training Loss: 7.525181522634685e-16, Validation Loss: 4.930833319367932e-15
Epoch 494, Training Loss: 2.0709080998849603e-15, Validation Loss: 5.246686399684904e-15
Epoch 495, Training Loss: 1.3876938657284834e-15, Validation Loss: 5.224468725478423e-15
Epoch 496, Training Loss: 2.1808629290756987e-15, Validation Loss: 5.295525472390639e-15
Epoch 497, Training Loss: 2.295354678490168e-15, Validation Loss: 6.438808616463605e-15
Epoch 498, Training Loss: 2.255322419095272e-15, Validation Loss: 6.271174019938401e-15
Epoch 499, Training Loss: 2.5067239154227166e-15, Validation Loss: 5.595966364715845e-15
Epoch 500, Training Loss: 3.1226843688419124e-15, Validation Loss: 6.58682720047982e-15
