Epoch 1, Training Loss: 0.47664111852645874, Validation Loss: 0.4753888249397278
Epoch 2, Training Loss: 0.4753888249397278, Validation Loss: 0.474166601896286
Epoch 3, Training Loss: 0.474166601896286, Validation Loss: 0.4729772210121155
Epoch 4, Training Loss: 0.4729771912097931, Validation Loss: 0.4718373417854309
Epoch 5, Training Loss: 0.4718373417854309, Validation Loss: 0.4706963300704956
Epoch 6, Training Loss: 0.4706963300704956, Validation Loss: 0.4695861041545868
Epoch 7, Training Loss: 0.4695860743522644, Validation Loss: 0.4684749245643616
Epoch 8, Training Loss: 0.4684749245643616, Validation Loss: 0.4673546552658081
Epoch 9, Training Loss: 0.4673546552658081, Validation Loss: 0.4662570059299469
Epoch 10, Training Loss: 0.4662569761276245, Validation Loss: 0.46516039967536926
Epoch 11, Training Loss: 0.46516042947769165, Validation Loss: 0.4640582799911499
Epoch 12, Training Loss: 0.4640582203865051, Validation Loss: 0.4629359841346741
Epoch 13, Training Loss: 0.4629359841346741, Validation Loss: 0.4617895781993866
Epoch 14, Training Loss: 0.46178963780403137, Validation Loss: 0.46060553193092346
Epoch 15, Training Loss: 0.4606055021286011, Validation Loss: 0.4593823552131653
Epoch 16, Training Loss: 0.45938241481781006, Validation Loss: 0.45812568068504333
Epoch 17, Training Loss: 0.45812565088272095, Validation Loss: 0.4568485915660858
Epoch 18, Training Loss: 0.4568485915660858, Validation Loss: 0.45555785298347473
Epoch 19, Training Loss: 0.45555776357650757, Validation Loss: 0.4542309045791626
Epoch 20, Training Loss: 0.4542309045791626, Validation Loss: 0.45285534858703613
Epoch 21, Training Loss: 0.4528553783893585, Validation Loss: 0.451419472694397
Epoch 22, Training Loss: 0.451419472694397, Validation Loss: 0.44995370507240295
Epoch 23, Training Loss: 0.44995367527008057, Validation Loss: 0.4484480619430542
Epoch 24, Training Loss: 0.4484480619430542, Validation Loss: 0.44688430428504944
Epoch 25, Training Loss: 0.44688424468040466, Validation Loss: 0.4452587366104126
Epoch 26, Training Loss: 0.445258766412735, Validation Loss: 0.4436129629611969
Epoch 27, Training Loss: 0.4436129927635193, Validation Loss: 0.4419534206390381
Epoch 28, Training Loss: 0.4419533908367157, Validation Loss: 0.4402121305465698
Epoch 29, Training Loss: 0.4402121305465698, Validation Loss: 0.43836691975593567
Epoch 30, Training Loss: 0.43836691975593567, Validation Loss: 0.4364165961742401
Epoch 31, Training Loss: 0.4364165961742401, Validation Loss: 0.43437808752059937
Epoch 32, Training Loss: 0.43437811732292175, Validation Loss: 0.4321884214878082
Epoch 33, Training Loss: 0.4321884512901306, Validation Loss: 0.42988264560699463
Epoch 34, Training Loss: 0.42988264560699463, Validation Loss: 0.42742276191711426
Epoch 35, Training Loss: 0.42742276191711426, Validation Loss: 0.42478540539741516
Epoch 36, Training Loss: 0.4247853755950928, Validation Loss: 0.4219828248023987
Epoch 37, Training Loss: 0.4219827950000763, Validation Loss: 0.41902250051498413
Epoch 38, Training Loss: 0.41902247071266174, Validation Loss: 0.4159218370914459
Epoch 39, Training Loss: 0.41592180728912354, Validation Loss: 0.4126124978065491
Epoch 40, Training Loss: 0.4126124978065491, Validation Loss: 0.40906599164009094
Epoch 41, Training Loss: 0.40906602144241333, Validation Loss: 0.405292272567749
Epoch 42, Training Loss: 0.405292272567749, Validation Loss: 0.401297003030777
Epoch 43, Training Loss: 0.401297003030777, Validation Loss: 0.39702746272087097
Epoch 44, Training Loss: 0.39702746272087097, Validation Loss: 0.3924340605735779
Epoch 45, Training Loss: 0.3924340605735779, Validation Loss: 0.3875163793563843
Epoch 46, Training Loss: 0.3875163793563843, Validation Loss: 0.3823179006576538
Epoch 47, Training Loss: 0.38231784105300903, Validation Loss: 0.37683767080307007
Epoch 48, Training Loss: 0.37683767080307007, Validation Loss: 0.3710033595561981
Epoch 49, Training Loss: 0.3710033595561981, Validation Loss: 0.3647972047328949
Epoch 50, Training Loss: 0.3647972047328949, Validation Loss: 0.3581249713897705
Epoch 51, Training Loss: 0.3581249713897705, Validation Loss: 0.3510485887527466
Epoch 52, Training Loss: 0.35104861855506897, Validation Loss: 0.34352588653564453
Epoch 53, Training Loss: 0.34352585673332214, Validation Loss: 0.33555150032043457
Epoch 54, Training Loss: 0.33555150032043457, Validation Loss: 0.32718145847320557
Epoch 55, Training Loss: 0.32718145847320557, Validation Loss: 0.3183736801147461
Epoch 56, Training Loss: 0.3183736801147461, Validation Loss: 0.3092081546783447
Epoch 57, Training Loss: 0.3092081546783447, Validation Loss: 0.2997012734413147
Epoch 58, Training Loss: 0.2997013032436371, Validation Loss: 0.2899187505245209
Epoch 59, Training Loss: 0.2899187505245209, Validation Loss: 0.28001245856285095
Epoch 60, Training Loss: 0.28001245856285095, Validation Loss: 0.2700464725494385
Epoch 61, Training Loss: 0.2700464725494385, Validation Loss: 0.2600265443325043
Epoch 62, Training Loss: 0.2600265443325043, Validation Loss: 0.25009024143218994
Epoch 63, Training Loss: 0.25009024143218994, Validation Loss: 0.24031049013137817
Epoch 64, Training Loss: 0.24031049013137817, Validation Loss: 0.23082417249679565
Epoch 65, Training Loss: 0.23082417249679565, Validation Loss: 0.22170940041542053
Epoch 66, Training Loss: 0.22170943021774292, Validation Loss: 0.21294620633125305
Epoch 67, Training Loss: 0.21294620633125305, Validation Loss: 0.2045190930366516
Epoch 68, Training Loss: 0.2045190930366516, Validation Loss: 0.19641231000423431
Epoch 69, Training Loss: 0.19641231000423431, Validation Loss: 0.18859779834747314
Epoch 70, Training Loss: 0.18859779834747314, Validation Loss: 0.18126451969146729
Epoch 71, Training Loss: 0.18126451969146729, Validation Loss: 0.1741681545972824
Epoch 72, Training Loss: 0.1741681545972824, Validation Loss: 0.16710232198238373
Epoch 73, Training Loss: 0.16710233688354492, Validation Loss: 0.1600920855998993
Epoch 74, Training Loss: 0.1600920855998993, Validation Loss: 0.1528310328722
Epoch 75, Training Loss: 0.1528310477733612, Validation Loss: 0.1453147679567337
Epoch 76, Training Loss: 0.1453147530555725, Validation Loss: 0.13758742809295654
Epoch 77, Training Loss: 0.13758742809295654, Validation Loss: 0.12959107756614685
Epoch 78, Training Loss: 0.12959107756614685, Validation Loss: 0.121493399143219
Epoch 79, Training Loss: 0.1214933916926384, Validation Loss: 0.11339642107486725
Epoch 80, Training Loss: 0.11339643597602844, Validation Loss: 0.10551931709051132
Epoch 81, Training Loss: 0.10551931709051132, Validation Loss: 0.0977601706981659
Epoch 82, Training Loss: 0.0977601706981659, Validation Loss: 0.09028339385986328
Epoch 83, Training Loss: 0.09028339385986328, Validation Loss: 0.08324582874774933
Epoch 84, Training Loss: 0.08324583619832993, Validation Loss: 0.07652847468852997
Epoch 85, Training Loss: 0.07652848213911057, Validation Loss: 0.07003805786371231
Epoch 86, Training Loss: 0.07003805786371231, Validation Loss: 0.06383158266544342
Epoch 87, Training Loss: 0.06383158266544342, Validation Loss: 0.05796182528138161
Epoch 88, Training Loss: 0.05796181783080101, Validation Loss: 0.052416879683732986
Epoch 89, Training Loss: 0.05241688713431358, Validation Loss: 0.04721280559897423
Epoch 90, Training Loss: 0.04721280559897423, Validation Loss: 0.042424850165843964
Epoch 91, Training Loss: 0.042424850165843964, Validation Loss: 0.0380433090031147
Epoch 92, Training Loss: 0.0380433015525341, Validation Loss: 0.03408944606781006
Epoch 93, Training Loss: 0.03408943489193916, Validation Loss: 0.030560176819562912
Epoch 94, Training Loss: 0.030560176819562912, Validation Loss: 0.02739805541932583
Epoch 95, Training Loss: 0.027398059144616127, Validation Loss: 0.024594729766249657
Epoch 96, Training Loss: 0.024594727903604507, Validation Loss: 0.022139472886919975
Epoch 97, Training Loss: 0.022139472886919975, Validation Loss: 0.01998794637620449
Epoch 98, Training Loss: 0.019987940788269043, Validation Loss: 0.018097201362252235
Epoch 99, Training Loss: 0.018097205087542534, Validation Loss: 0.016408344730734825
Epoch 100, Training Loss: 0.016408342868089676, Validation Loss: 0.014938827604055405
Epoch 101, Training Loss: 0.014938830398023129, Validation Loss: 0.013562025502324104
Epoch 102, Training Loss: 0.01356202270835638, Validation Loss: 0.01226075366139412
Epoch 103, Training Loss: 0.01226074993610382, Validation Loss: 0.011016343720257282
Epoch 104, Training Loss: 0.011016340926289558, Validation Loss: 0.009843475185334682
Epoch 105, Training Loss: 0.009843473322689533, Validation Loss: 0.00875635165721178
Epoch 106, Training Loss: 0.008756349794566631, Validation Loss: 0.007757761515676975
Epoch 107, Training Loss: 0.00775776244699955, Validation Loss: 0.006847894284874201
Epoch 108, Training Loss: 0.006847894750535488, Validation Loss: 0.006038384046405554
Epoch 109, Training Loss: 0.006038382183760405, Validation Loss: 0.005334348417818546
Epoch 110, Training Loss: 0.005334346555173397, Validation Loss: 0.004723618272691965
Epoch 111, Training Loss: 0.004723620600998402, Validation Loss: 0.00418935576453805
Epoch 112, Training Loss: 0.004189354833215475, Validation Loss: 0.00371992657892406
Epoch 113, Training Loss: 0.0037199242506176233, Validation Loss: 0.0033026246819645166
Epoch 114, Training Loss: 0.0033026249147951603, Validation Loss: 0.0029254613909870386
Epoch 115, Training Loss: 0.0029254599940031767, Validation Loss: 0.0025776561815291643
Epoch 116, Training Loss: 0.0025776566471904516, Validation Loss: 0.0022566155530512333
Epoch 117, Training Loss: 0.0022566155530512333, Validation Loss: 0.0019593220204114914
Epoch 118, Training Loss: 0.0019593213219195604, Validation Loss: 0.001687163719907403
Epoch 119, Training Loss: 0.0016871645348146558, Validation Loss: 0.0014383437810465693
Epoch 120, Training Loss: 0.0014383435482159257, Validation Loss: 0.0012159602483734488
Epoch 121, Training Loss: 0.0012159619946032763, Validation Loss: 0.0010197613155469298
Epoch 122, Training Loss: 0.001019759802147746, Validation Loss: 0.0008486647275276482
Epoch 123, Training Loss: 0.0008486653096042573, Validation Loss: 0.0007017658208496869
Epoch 124, Training Loss: 0.000701765762642026, Validation Loss: 0.0005777875194326043
Epoch 125, Training Loss: 0.0005777868791483343, Validation Loss: 0.0004737004928756505
Epoch 126, Training Loss: 0.00047370055108331144, Validation Loss: 0.0003870342916343361
Epoch 127, Training Loss: 0.00038703373866155744, Validation Loss: 0.00031598712666891515
Epoch 128, Training Loss: 0.0003159869520459324, Validation Loss: 0.00025865380303002894
Epoch 129, Training Loss: 0.0002586539485491812, Validation Loss: 0.00021354587806854397
Epoch 130, Training Loss: 0.00021354564523790032, Validation Loss: 0.00017915655917022377
Epoch 131, Training Loss: 0.000179156064405106, Validation Loss: 0.00015492727106902748
Epoch 132, Training Loss: 0.00015492709644604474, Validation Loss: 0.00013792379468213767
Epoch 133, Training Loss: 0.00013792402751278132, Validation Loss: 0.0001258381234947592
Epoch 134, Training Loss: 0.0001258380652870983, Validation Loss: 0.00011723839998012409
Epoch 135, Training Loss: 0.0001172385091194883, Validation Loss: 0.00011092346539953724
Epoch 136, Training Loss: 0.00011092367640230805, Validation Loss: 0.00010511926666367799
Epoch 137, Training Loss: 0.00010511965228943154, Validation Loss: 9.970949759008363e-05
Epoch 138, Training Loss: 9.970913379220292e-05, Validation Loss: 9.506818605586886e-05
Epoch 139, Training Loss: 9.506796777714044e-05, Validation Loss: 9.102003969019279e-05
Epoch 140, Training Loss: 9.102000331040472e-05, Validation Loss: 8.778135816100985e-05
Epoch 141, Training Loss: 8.778184565017e-05, Validation Loss: 8.544983575120568e-05
Epoch 142, Training Loss: 8.544958109268919e-05, Validation Loss: 8.391125447815284e-05
Epoch 143, Training Loss: 8.391126903006807e-05, Validation Loss: 8.283367060357705e-05
Epoch 144, Training Loss: 8.283384522655979e-05, Validation Loss: 8.173960668500513e-05
Epoch 145, Training Loss: 8.17393884062767e-05, Validation Loss: 8.0100740888156e-05
Epoch 146, Training Loss: 8.010047167772427e-05, Validation Loss: 7.748245843686163e-05
Epoch 147, Training Loss: 7.74821819504723e-05, Validation Loss: 7.365529745584354e-05
Epoch 148, Training Loss: 7.365557394223288e-05, Validation Loss: 6.863527232781053e-05
Epoch 149, Training Loss: 6.863527232781053e-05, Validation Loss: 6.265484262257814e-05
Epoch 150, Training Loss: 6.265479896683246e-05, Validation Loss: 5.6112105085048825e-05
Epoch 151, Training Loss: 5.611199958366342e-05, Validation Loss: 4.945607724948786e-05
Epoch 152, Training Loss: 4.945577529724687e-05, Validation Loss: 4.310719668865204e-05
Epoch 153, Training Loss: 4.310729855205864e-05, Validation Loss: 3.737680890480988e-05
Epoch 154, Training Loss: 3.73771290469449e-05, Validation Loss: 3.242957609472796e-05
Epoch 155, Training Loss: 3.242950333515182e-05, Validation Loss: 2.82833516394021e-05
Epoch 156, Training Loss: 2.8283178835408762e-05, Validation Loss: 2.4842282073223032e-05
Epoch 157, Training Loss: 2.4842374841682613e-05, Validation Loss: 2.1947516870568506e-05
Epoch 158, Training Loss: 2.194749868067447e-05, Validation Loss: 1.9429251551628113e-05
Epoch 159, Training Loss: 1.9429226085776463e-05, Validation Loss: 1.7147856851806864e-05
Epoch 160, Training Loss: 1.714779318717774e-05, Validation Loss: 1.5016948054835666e-05
Epoch 161, Training Loss: 1.5016878933238331e-05, Validation Loss: 1.300547501159599e-05
Epoch 162, Training Loss: 1.3005422260903288e-05, Validation Loss: 1.1126980098197237e-05
Epoch 163, Training Loss: 1.1127039215352852e-05, Validation Loss: 9.418881745659746e-06
Epoch 164, Training Loss: 9.418879926670343e-06, Validation Loss: 7.919978997961152e-06
Epoch 165, Training Loss: 7.920119969639927e-06, Validation Loss: 6.6563084146764595e-06
Epoch 166, Training Loss: 6.656350706180092e-06, Validation Loss: 5.632171450997703e-06
Epoch 167, Training Loss: 5.632177362713264e-06, Validation Loss: 4.830260877497494e-06
Epoch 168, Training Loss: 4.830308171221986e-06, Validation Loss: 4.21617869506008e-06
Epoch 169, Training Loss: 4.216169145365711e-06, Validation Loss: 3.753175860765623e-06
Epoch 170, Training Loss: 3.753218379642931e-06, Validation Loss: 3.4064362353092292e-06
Epoch 171, Training Loss: 3.4064619285345543e-06, Validation Loss: 3.146790277241962e-06
Epoch 172, Training Loss: 3.1466699965676526e-06, Validation Loss: 2.9507730232580798e-06
Epoch 173, Training Loss: 2.950846464955248e-06, Validation Loss: 2.800808715619496e-06
Epoch 174, Training Loss: 2.800732318064547e-06, Validation Loss: 2.6813577278517187e-06
Epoch 175, Training Loss: 2.681360001588473e-06, Validation Loss: 2.5783224373299163e-06
Epoch 176, Training Loss: 2.5782933334994595e-06, Validation Loss: 2.478149781381944e-06
Epoch 177, Training Loss: 2.478189799148822e-06, Validation Loss: 2.369280764469295e-06
Epoch 178, Training Loss: 2.3692650756856892e-06, Validation Loss: 2.243395556433825e-06
Epoch 179, Training Loss: 2.243372591692605e-06, Validation Loss: 2.097269998557749e-06
Epoch 180, Training Loss: 2.0972584025003016e-06, Validation Loss: 1.9333790532982675e-06
Epoch 181, Training Loss: 1.9333901946083643e-06, Validation Loss: 1.7587138927410706e-06
Epoch 182, Training Loss: 1.758709686328075e-06, Validation Loss: 1.583197558829852e-06
Epoch 183, Training Loss: 1.5831564041945967e-06, Validation Loss: 1.4164915000947076e-06
Epoch 184, Training Loss: 1.4165021866574534e-06, Validation Loss: 1.2661498658417258e-06
Epoch 185, Training Loss: 1.2661536175073707e-06, Validation Loss: 1.1357343510098872e-06
Epoch 186, Training Loss: 1.1357358289387776e-06, Validation Loss: 1.0245348676107824e-06
Epoch 187, Training Loss: 1.0244849590890226e-06, Validation Loss: 9.286004001296533e-07
Epoch 188, Training Loss: 9.285847681894666e-07, Validation Loss: 8.426049475929176e-07
Epoch 189, Training Loss: 8.425773216913512e-07, Validation Loss: 7.61412422889407e-07
Epoch 190, Training Loss: 7.614057722094003e-07, Validation Loss: 6.818990527790447e-07
Epoch 191, Training Loss: 6.819721534156997e-07, Validation Loss: 6.034494504092436e-07
Epoch 192, Training Loss: 6.034487682882173e-07, Validation Loss: 5.276202728055068e-07
Epoch 193, Training Loss: 5.276074830362631e-07, Validation Loss: 4.5731283648819954e-07
Epoch 194, Training Loss: 4.573153375986294e-07, Validation Loss: 3.95598249269824e-07
Epoch 195, Training Loss: 3.955995566684578e-07, Validation Loss: 3.4450027897037216e-07
Epoch 196, Training Loss: 3.4451625197107205e-07, Validation Loss: 3.043960248305666e-07
Epoch 197, Training Loss: 3.043962806259515e-07, Validation Loss: 2.739568287779548e-07
Epoch 198, Training Loss: 2.7393807044973073e-07, Validation Loss: 2.5059972585950163e-07
Epoch 199, Training Loss: 2.506074565644667e-07, Validation Loss: 2.3135768856263894e-07
Epoch 200, Training Loss: 2.3135579851896182e-07, Validation Loss: 2.1346869516492006e-07
Epoch 201, Training Loss: 2.1347801748561324e-07, Validation Loss: 1.9518978433552547e-07
Epoch 202, Training Loss: 1.9519306704296469e-07, Validation Loss: 1.7586029343874543e-07
Epoch 203, Training Loss: 1.758521221972842e-07, Validation Loss: 1.5583178480937931e-07
Epoch 204, Training Loss: 1.5582271828407102e-07, Validation Loss: 1.3612557836495398e-07
Epoch 205, Training Loss: 1.361359664997508e-07, Validation Loss: 1.1797150989423244e-07
Epoch 206, Training Loss: 1.1796319654422405e-07, Validation Loss: 1.0224997737395825e-07
Epoch 207, Training Loss: 1.0224398039326843e-07, Validation Loss: 8.943597151755966e-08
Epoch 208, Training Loss: 8.943451490495136e-08, Validation Loss: 7.944002078374979e-08
Epoch 209, Training Loss: 7.944223767708536e-08, Validation Loss: 7.179809813351312e-08
Epoch 210, Training Loss: 7.180234717907297e-08, Validation Loss: 6.581919365089561e-08
Epoch 211, Training Loss: 6.581991840448609e-08, Validation Loss: 6.084486869895045e-08
Epoch 212, Training Loss: 6.082792225470257e-08, Validation Loss: 5.634220201500284e-08
Epoch 213, Training Loss: 5.633289745787806e-08, Validation Loss: 5.2040544318288084e-08
Epoch 214, Training Loss: 5.2056094546060194e-08, Validation Loss: 4.787888130408646e-08
Epoch 215, Training Loss: 4.788478591422063e-08, Validation Loss: 4.3870983290617005e-08
Epoch 216, Training Loss: 4.386528118516253e-08, Validation Loss: 4.007268827876942e-08
Epoch 217, Training Loss: 4.0064232820213874e-08, Validation Loss: 3.651600977150338e-08
Epoch 218, Training Loss: 3.6519129054113364e-08, Validation Loss: 3.3237537166996844e-08
Epoch 219, Training Loss: 3.324003117199936e-08, Validation Loss: 3.02000202623276e-08
Epoch 220, Training Loss: 3.020015881816107e-08, Validation Loss: 2.734964077433233e-08
Epoch 221, Training Loss: 2.7348091791168372e-08, Validation Loss: 2.470869553405919e-08
Epoch 222, Training Loss: 2.470395443765483e-08, Validation Loss: 2.2279435185623697e-08
Epoch 223, Training Loss: 2.2282307554633007e-08, Validation Loss: 2.0119736987567194e-08
Epoch 224, Training Loss: 2.0124273802935022e-08, Validation Loss: 1.826083995126737e-08
Epoch 225, Training Loss: 1.825607220951042e-08, Validation Loss: 1.669281779470566e-08
Epoch 226, Training Loss: 1.6698196603215365e-08, Validation Loss: 1.539438265751869e-08
Epoch 227, Training Loss: 1.5388959440088e-08, Validation Loss: 1.4269814663236957e-08
Epoch 228, Training Loss: 1.4270954196149432e-08, Validation Loss: 1.323766873895238e-08
Epoch 229, Training Loss: 1.3240383900381403e-08, Validation Loss: 1.2206280430859806e-08
Epoch 230, Training Loss: 1.220926204581474e-08, Validation Loss: 1.1128708621299666e-08
Epoch 231, Training Loss: 1.1125827370506158e-08, Validation Loss: 9.990202443077578e-09
Epoch 232, Training Loss: 9.990293925454807e-09, Validation Loss: 8.833628051263531e-09
Epoch 233, Training Loss: 8.830207676169266e-09, Validation Loss: 7.707646965116055e-09
Epoch 234, Training Loss: 7.706783655692107e-09, Validation Loss: 6.670670682495938e-09
Epoch 235, Training Loss: 6.6713541357898976e-09, Validation Loss: 5.773166833478172e-09
Epoch 236, Training Loss: 5.772582856167219e-09, Validation Loss: 5.019758830826504e-09
Epoch 237, Training Loss: 5.020388993415281e-09, Validation Loss: 4.39772618321399e-09
Epoch 238, Training Loss: 4.399511865926797e-09, Validation Loss: 3.8813596781039905e-09
Epoch 239, Training Loss: 3.8788749989748794e-09, Validation Loss: 3.421777083900679e-09
Epoch 240, Training Loss: 3.4220064559775665e-09, Validation Loss: 2.9951978675057944e-09
Epoch 241, Training Loss: 2.996318748671456e-09, Validation Loss: 2.5879154375019198e-09
Epoch 242, Training Loss: 2.5857400665074692e-09, Validation Loss: 2.2002533128784307e-09
Epoch 243, Training Loss: 2.1991439780322253e-09, Validation Loss: 1.8478933938581577e-09
Epoch 244, Training Loss: 1.8486197017608674e-09, Validation Loss: 1.5537451325542406e-09
Epoch 245, Training Loss: 1.5527280572413815e-09, Validation Loss: 1.3257932529597838e-09
Epoch 246, Training Loss: 1.3263350417958009e-09, Validation Loss: 1.1711974723382923e-09
Epoch 247, Training Loss: 1.1702068203334193e-09, Validation Loss: 1.0791265658838256e-09
Epoch 248, Training Loss: 1.0797821525798668e-09, Validation Loss: 1.0350188484054001e-09
Epoch 249, Training Loss: 1.0353636836768487e-09, Validation Loss: 1.0159030283674042e-09
Epoch 250, Training Loss: 1.0165046582244486e-09, Validation Loss: 1.003843341784716e-09
Epoch 251, Training Loss: 1.0021485863376256e-09, Validation Loss: 9.832853420377319e-10
Epoch 252, Training Loss: 9.840249726167372e-10, Validation Loss: 9.484215635069404e-10
Epoch 253, Training Loss: 9.490115360222262e-10, Validation Loss: 9.010515666929564e-10
Epoch 254, Training Loss: 9.01824892540759e-10, Validation Loss: 8.448799992955003e-10
Epoch 255, Training Loss: 8.447662014354762e-10, Validation Loss: 7.821875924740596e-10
Epoch 256, Training Loss: 7.82600817483825e-10, Validation Loss: 7.195868900744529e-10
Epoch 257, Training Loss: 7.195570805862417e-10, Validation Loss: 6.586876044600842e-10
Epoch 258, Training Loss: 6.586937106867197e-10, Validation Loss: 6.012880748862415e-10
Epoch 259, Training Loss: 6.006438124650515e-10, Validation Loss: 5.452421847351729e-10
Epoch 260, Training Loss: 5.462259533572933e-10, Validation Loss: 4.934725406080531e-10
Epoch 261, Training Loss: 4.93944662949275e-10, Validation Loss: 4.4529974152496266e-10
Epoch 262, Training Loss: 4.4546966115888154e-10, Validation Loss: 3.99874272583034e-10
Epoch 263, Training Loss: 4.007173481923587e-10, Validation Loss: 3.5883537807812615e-10
Epoch 264, Training Loss: 3.591386354973025e-10, Validation Loss: 3.2186020515467817e-10
Epoch 265, Training Loss: 3.209685572880261e-10, Validation Loss: 2.865324366663202e-10
Epoch 266, Training Loss: 2.864703751992437e-10, Validation Loss: 2.534171483770109e-10
Epoch 267, Training Loss: 2.54024717927237e-10, Validation Loss: 2.2275944977501183e-10
Epoch 268, Training Loss: 2.2320668924269427e-10, Validation Loss: 1.9408895324257713e-10
Epoch 269, Training Loss: 1.935255566909433e-10, Validation Loss: 1.6650497647319185e-10
Epoch 270, Training Loss: 1.6663018187479395e-10, Validation Loss: 1.41873360282041e-10
Epoch 271, Training Loss: 1.4252579672024979e-10, Validation Loss: 1.2027032147976513e-10
Epoch 272, Training Loss: 1.2065966281671336e-10, Validation Loss: 1.0217236084963943e-10
Epoch 273, Training Loss: 1.0255865601216385e-10, Validation Loss: 8.825178782201348e-11
Epoch 274, Training Loss: 8.824779101912483e-11, Validation Loss: 7.695057091527957e-11
Epoch 275, Training Loss: 7.686586089850067e-11, Validation Loss: 6.908684735407178e-11
Epoch 276, Training Loss: 6.850725542406622e-11, Validation Loss: 6.202992286485909e-11
Epoch 277, Training Loss: 6.193329182835328e-11, Validation Loss: 5.593973201323266e-11
Epoch 278, Training Loss: 5.6270047649187305e-11, Validation Loss: 5.037362194038053e-11
Epoch 279, Training Loss: 5.057207430603228e-11, Validation Loss: 4.5096364142960255e-11
Epoch 280, Training Loss: 4.526783461966666e-11, Validation Loss: 4.00076534401439e-11
Epoch 281, Training Loss: 4.0001821299817664e-11, Validation Loss: 3.545953461414619e-11
Epoch 282, Training Loss: 3.516983926310502e-11, Validation Loss: 3.146990654179227e-11
Epoch 283, Training Loss: 3.1450151510847846e-11, Validation Loss: 2.8312661243257153e-11
Epoch 284, Training Loss: 2.831199857888933e-11, Validation Loss: 2.6288034249422054e-11
Epoch 285, Training Loss: 2.626299698549328e-11, Validation Loss: 2.4580544197294607e-11
Epoch 286, Training Loss: 2.4517781901933766e-11, Validation Loss: 2.3651039460226286e-11
Epoch 287, Training Loss: 2.3713116539814116e-11, Validation Loss: 2.2751470846182897e-11
Epoch 288, Training Loss: 2.2873319557858984e-11, Validation Loss: 2.168232260402192e-11
Epoch 289, Training Loss: 2.1793481949639038e-11, Validation Loss: 2.0500781627852405e-11
Epoch 290, Training Loss: 2.055567695224969e-11, Validation Loss: 1.9076884169577646e-11
Epoch 291, Training Loss: 1.91354501688501e-11, Validation Loss: 1.7716618103125192e-11
Epoch 292, Training Loss: 1.7639882610165358e-11, Validation Loss: 1.6149066459081318e-11
Epoch 293, Training Loss: 1.6151401396879983e-11, Validation Loss: 1.477200826938141e-11
Epoch 294, Training Loss: 1.4743511966841538e-11, Validation Loss: 1.3413841218334888e-11
Epoch 295, Training Loss: 1.3462033571221e-11, Validation Loss: 1.2510254117359398e-11
Epoch 296, Training Loss: 1.2420012934777347e-11, Validation Loss: 1.1567010370361341e-11
Epoch 297, Training Loss: 1.1519889209221645e-11, Validation Loss: 1.0591329896447732e-11
Epoch 298, Training Loss: 1.0633341429588938e-11, Validation Loss: 9.835215974973721e-12
Epoch 299, Training Loss: 9.852108712182783e-12, Validation Loss: 9.100340273016094e-12
Epoch 300, Training Loss: 9.028483689832445e-12, Validation Loss: 8.217039895730416e-12
Epoch 301, Training Loss: 8.187671894643866e-12, Validation Loss: 7.148331405970598e-12
Epoch 302, Training Loss: 7.254930163569373e-12, Validation Loss: 6.299476999066522e-12
Epoch 303, Training Loss: 6.268247206009381e-12, Validation Loss: 5.341078274101463e-12
Epoch 304, Training Loss: 5.325130961186808e-12, Validation Loss: 4.42576877923706e-12
Epoch 305, Training Loss: 4.5227606382258756e-12, Validation Loss: 3.699481693208995e-12
Epoch 306, Training Loss: 3.681970093399878e-12, Validation Loss: 3.063669326910934e-12
Epoch 307, Training Loss: 2.978944348142054e-12, Validation Loss: 2.4879495165441856e-12
Epoch 308, Training Loss: 2.469601780019648e-12, Validation Loss: 2.0993038037098177e-12
Epoch 309, Training Loss: 2.073164990373799e-12, Validation Loss: 1.7503331683349499e-12
Epoch 310, Training Loss: 1.750922974316782e-12, Validation Loss: 1.568819618484596e-12
Epoch 311, Training Loss: 1.475351199715924e-12, Validation Loss: 1.3714010396043141e-12
Epoch 312, Training Loss: 1.3633428153775329e-12, Validation Loss: 1.2724322463741888e-12
Epoch 313, Training Loss: 1.2726519057343344e-12, Validation Loss: 1.1741468257733811e-12
Epoch 314, Training Loss: 1.179349911999139e-12, Validation Loss: 1.0730386848165074e-12
Epoch 315, Training Loss: 1.093303073941565e-12, Validation Loss: 1.020402729326464e-12
Epoch 316, Training Loss: 1.0185714034369187e-12, Validation Loss: 9.652050209432717e-13
Epoch 317, Training Loss: 9.455923457440951e-13, Validation Loss: 8.867020616018517e-13
Epoch 318, Training Loss: 8.876609300031979e-13, Validation Loss: 8.20905355410767e-13
Epoch 319, Training Loss: 7.722533550136301e-13, Validation Loss: 7.251807661312615e-13
Epoch 320, Training Loss: 7.023319642876502e-13, Validation Loss: 6.492209656157322e-13
Epoch 321, Training Loss: 6.319099432085251e-13, Validation Loss: 5.997380326736024e-13
Epoch 322, Training Loss: 6.029000540995477e-13, Validation Loss: 5.486146476343934e-13
Epoch 323, Training Loss: 5.357995947960492e-13, Validation Loss: 4.926270979685454e-13
Epoch 324, Training Loss: 4.887197417591249e-13, Validation Loss: 4.4246778550111054e-13
Epoch 325, Training Loss: 4.4094702932387375e-13, Validation Loss: 3.885711739350095e-13
Epoch 326, Training Loss: 3.9315726780946025e-13, Validation Loss: 3.807412826857537e-13
Epoch 327, Training Loss: 3.6034204591549324e-13, Validation Loss: 3.6127172217334524e-13
Epoch 328, Training Loss: 3.3618588598724464e-13, Validation Loss: 3.280508460365428e-13
Epoch 329, Training Loss: 3.2898065781966634e-13, Validation Loss: 3.001142899732717e-13
Epoch 330, Training Loss: 3.153680116531332e-13, Validation Loss: 2.693616271871868e-13
Epoch 331, Training Loss: 2.703710194097708e-13, Validation Loss: 2.5031588130400295e-13
Epoch 332, Training Loss: 2.4608635441902837e-13, Validation Loss: 2.317457749138885e-13
Epoch 333, Training Loss: 2.2344739990590168e-13, Validation Loss: 2.1511572633869241e-13
Epoch 334, Training Loss: 2.1057508764032312e-13, Validation Loss: 1.9672502830306998e-13
Epoch 335, Training Loss: 1.8599499111010553e-13, Validation Loss: 1.6788043936781516e-13
Epoch 336, Training Loss: 1.6412492567265125e-13, Validation Loss: 1.6262546051557664e-13
Epoch 337, Training Loss: 1.4913330986798812e-13, Validation Loss: 1.3197417063261913e-13
Epoch 338, Training Loss: 1.4531518349736317e-13, Validation Loss: 1.2689656725579923e-13
Epoch 339, Training Loss: 1.3162355320256447e-13, Validation Loss: 1.1774188937198338e-13
Epoch 340, Training Loss: 1.165853709145931e-13, Validation Loss: 1.1159163057581495e-13
Epoch 341, Training Loss: 1.0404758245307136e-13, Validation Loss: 1.0399537811846618e-13
Epoch 342, Training Loss: 8.811468265104705e-14, Validation Loss: 9.630094437813527e-14
Epoch 343, Training Loss: 8.502180621865196e-14, Validation Loss: 9.048894988351874e-14
Epoch 344, Training Loss: 7.938248447253091e-14, Validation Loss: 8.551866896924776e-14
Epoch 345, Training Loss: 7.942852240728007e-14, Validation Loss: 8.190033395395757e-14
Epoch 346, Training Loss: 7.10092385282704e-14, Validation Loss: 7.251377910676496e-14
Epoch 347, Training Loss: 6.359796451407482e-14, Validation Loss: 6.559690128322276e-14
Epoch 348, Training Loss: 6.684563791164652e-14, Validation Loss: 6.774395362165939e-14
Epoch 349, Training Loss: 5.6397662690117756e-14, Validation Loss: 6.208325276394963e-14
Epoch 350, Training Loss: 5.700735022928782e-14, Validation Loss: 5.902373587714921e-14
Epoch 351, Training Loss: 5.060235135643035e-14, Validation Loss: 5.4186927026574766e-14
Epoch 352, Training Loss: 4.737603335352482e-14, Validation Loss: 5.3097019240156557e-14
Epoch 353, Training Loss: 3.930183069722655e-14, Validation Loss: 4.745993366101625e-14
Epoch 354, Training Loss: 3.9613145798528607e-14, Validation Loss: 3.805896570119316e-14
Epoch 355, Training Loss: 3.704935663817466e-14, Validation Loss: 3.1855462413960325e-14
Epoch 356, Training Loss: 3.276125573083155e-14, Validation Loss: 3.367772166283818e-14
Epoch 357, Training Loss: 2.5908428844694832e-14, Validation Loss: 2.7489797005571248e-14
Epoch 358, Training Loss: 2.5814088009095543e-14, Validation Loss: 1.9033719709398746e-14
Epoch 359, Training Loss: 2.0567215262162243e-14, Validation Loss: 1.8967100568097195e-14
Epoch 360, Training Loss: 2.0586165083258216e-14, Validation Loss: 1.8461094943868737e-14
Epoch 361, Training Loss: 1.6198114288139102e-14, Validation Loss: 1.8449853122592778e-14
Epoch 362, Training Loss: 1.6673828320107852e-14, Validation Loss: 1.5208854344645438e-14
Epoch 363, Training Loss: 1.4096964359180085e-14, Validation Loss: 1.5310569449083523e-14
Epoch 364, Training Loss: 1.4329551136166643e-14, Validation Loss: 1.5525141529347877e-14
Epoch 365, Training Loss: 1.2933765352934803e-14, Validation Loss: 1.4900808790519783e-14
Epoch 366, Training Loss: 1.1605500801093339e-14, Validation Loss: 1.4636963109647752e-14
Epoch 367, Training Loss: 1.20438522097587e-14, Validation Loss: 1.206853813797348e-14
Epoch 368, Training Loss: 1.0775769348819655e-14, Validation Loss: 9.042613730828215e-15
Epoch 369, Training Loss: 9.432159101072785e-15, Validation Loss: 7.360832355153644e-15
Epoch 370, Training Loss: 7.204907142091283e-15, Validation Loss: 8.346555936092521e-15
Epoch 371, Training Loss: 7.654867984331713e-15, Validation Loss: 8.856964437580807e-15
Epoch 372, Training Loss: 9.45070742855176e-15, Validation Loss: 8.72138919107623e-15
Epoch 373, Training Loss: 9.071870248826379e-15, Validation Loss: 7.058056192992858e-15
Epoch 374, Training Loss: 1.0177556564986041e-14, Validation Loss: 7.239401711835267e-15
Epoch 375, Training Loss: 7.124443247266861e-15, Validation Loss: 5.728190748881083e-15
Epoch 376, Training Loss: 8.281903605294495e-15, Validation Loss: 6.3250690323062974e-15
Epoch 377, Training Loss: 5.779898722179169e-15, Validation Loss: 5.2356626893928625e-15
Epoch 378, Training Loss: 5.069729358542219e-15, Validation Loss: 4.370569305637206e-15
Epoch 379, Training Loss: 3.881310369808913e-15, Validation Loss: 4.392186433484083e-15
Epoch 380, Training Loss: 4.9045304052568444e-15, Validation Loss: 3.889283490941418e-15
Epoch 381, Training Loss: 4.937089928232826e-15, Validation Loss: 3.653094282830187e-15
Epoch 382, Training Loss: 5.155264863138326e-15, Validation Loss: 4.762383030114522e-15
Epoch 383, Training Loss: 5.589479362889298e-15, Validation Loss: 5.274393694422539e-15
Epoch 384, Training Loss: 4.896657657528589e-15, Validation Loss: 5.3132246493399916e-15
Epoch 385, Training Loss: 3.515817558892814e-15, Validation Loss: 5.543809463955714e-15
Epoch 386, Training Loss: 3.2366604869497407e-15, Validation Loss: 4.977755980030505e-15
Epoch 387, Training Loss: 4.796977549746282e-15, Validation Loss: 4.837510193854769e-15
Epoch 388, Training Loss: 2.2654821557811138e-15, Validation Loss: 5.879278133265201e-15
Epoch 389, Training Loss: 1.94242336618185e-15, Validation Loss: 4.85779324480972e-15
Epoch 390, Training Loss: 2.288967626551397e-15, Validation Loss: 4.6681743316550044e-15
Epoch 391, Training Loss: 2.5227550727406883e-15, Validation Loss: 5.577302840756044e-15
Epoch 392, Training Loss: 2.476317761956892e-15, Validation Loss: 6.2244881049845855e-15
Epoch 393, Training Loss: 4.8490192540255866e-15, Validation Loss: 6.769591923025354e-15
Epoch 394, Training Loss: 3.758679057287804e-15, Validation Loss: 6.112131725630144e-15
Epoch 395, Training Loss: 2.088406953542287e-15, Validation Loss: 6.1244081976511745e-15
Epoch 396, Training Loss: 1.8531518110136407e-15, Validation Loss: 4.033632728230128e-15
Epoch 397, Training Loss: 1.866495756306448e-15, Validation Loss: 3.199130362881034e-15
Epoch 398, Training Loss: 2.247200855438761e-15, Validation Loss: 3.8656644007237055e-15
Epoch 399, Training Loss: 2.1395145922390064e-15, Validation Loss: 3.8656644007237055e-15
Epoch 400, Training Loss: 1.9330824985977664e-15, Validation Loss: 3.8656644007237055e-15
Epoch 401, Training Loss: 1.87383508503617e-15, Validation Loss: 3.8588593380254645e-15
Epoch 402, Training Loss: 1.987259361178862e-15, Validation Loss: 3.4852263287280145e-15
Epoch 403, Training Loss: 1.9792527822449406e-15, Validation Loss: 4.919842643360834e-15
Epoch 404, Training Loss: 1.902391318545191e-15, Validation Loss: 4.081037350639688e-15
Epoch 405, Training Loss: 2.0144810942794838e-15, Validation Loss: 3.941425145108498e-15
Epoch 406, Training Loss: 1.5549127808348225e-15, Validation Loss: 3.9707820365109114e-15
Epoch 407, Training Loss: 1.86796366440404e-15, Validation Loss: 4.654997040094569e-15
Epoch 408, Training Loss: 2.0120791205993074e-15, Validation Loss: 4.6683411971456135e-15
Epoch 409, Training Loss: 1.9453589706187966e-15, Validation Loss: 4.584607331628316e-15
Epoch 410, Training Loss: 1.8059138423364525e-15, Validation Loss: 5.385782762151216e-15
Epoch 411, Training Loss: 2.3005770601264644e-15, Validation Loss: 5.608127640256049e-15
Epoch 412, Training Loss: 2.1448521703561294e-15, Validation Loss: 5.37393997099918e-15
Epoch 413, Training Loss: 2.1635339055242966e-15, Validation Loss: 3.8687336246080815e-15
Epoch 414, Training Loss: 2.1101577008365933e-15, Validation Loss: 4.5770348570798626e-15
Epoch 415, Training Loss: 2.045839524536259e-15, Validation Loss: 4.67194405178676e-15
Epoch 416, Training Loss: 1.4373519134150956e-15, Validation Loss: 4.1179002245041955e-15
Epoch 417, Training Loss: 1.4340158741523346e-15, Validation Loss: 4.76108198750754e-15
Epoch 418, Training Loss: 1.4046589827499214e-15, Validation Loss: 3.928414719038672e-15
Epoch 419, Training Loss: 1.8164558026397427e-15, Validation Loss: 5.154697774580139e-15
Epoch 420, Training Loss: 2.0016707797434466e-15, Validation Loss: 6.2275573288689615e-15
Epoch 421, Training Loss: 2.2829627982300744e-15, Validation Loss: 5.1367165356593514e-15
Epoch 422, Training Loss: 2.2829627982300744e-15, Validation Loss: 5.1367165356593514e-15
Epoch 423, Training Loss: 3.026492130978162e-15, Validation Loss: 5.120970616686368e-15
Epoch 424, Training Loss: 2.9537671526763285e-15, Validation Loss: 4.408933121884248e-15
Epoch 425, Training Loss: 2.3260640697511095e-15, Validation Loss: 5.3946567028231255e-15
Epoch 426, Training Loss: 2.6890217110560766e-15, Validation Loss: 5.420010093000341e-15
Epoch 427, Training Loss: 1.6065541561674306e-15, Validation Loss: 5.586676954383307e-15
Epoch 428, Training Loss: 2.1568618269987745e-15, Validation Loss: 4.83967859819974e-15
Epoch 429, Training Loss: 3.013014566237925e-15, Validation Loss: 4.83967859819974e-15
Epoch 430, Training Loss: 3.1299082893325707e-15, Validation Loss: 4.01501748514832e-15
Epoch 431, Training Loss: 2.4119995856565577e-15, Validation Loss: 4.0718296789865605e-15
Epoch 432, Training Loss: 1.3384726752844176e-15, Validation Loss: 4.035967574549234e-15
Epoch 433, Training Loss: 2.7710873451837568e-15, Validation Loss: 5.0207568781472905e-15
Epoch 434, Training Loss: 1.6880861595383405e-15, Validation Loss: 3.324130614797377e-15
Epoch 435, Training Loss: 2.3406091077631235e-15, Validation Loss: 4.006544191060462e-15
Epoch 436, Training Loss: 2.0304938286308527e-15, Validation Loss: 3.964377196880248e-15
Epoch 437, Training Loss: 2.0961465053395863e-15, Validation Loss: 4.063790065767696e-15
Epoch 438, Training Loss: 2.157529077202974e-15, Validation Loss: 5.782567299479494e-15
Epoch 439, Training Loss: 1.950029510289957e-15, Validation Loss: 5.665140157386315e-15
Epoch 440, Training Loss: 2.7506710982978496e-15, Validation Loss: 6.121772654635793e-15
Epoch 441, Training Loss: 2.7150425631957287e-15, Validation Loss: 5.847152714674687e-15
Epoch 442, Training Loss: 2.259210512081406e-15, Validation Loss: 6.234462764971452e-15
Epoch 443, Training Loss: 2.3543534878817454e-15, Validation Loss: 4.22325121786837e-15
Epoch 444, Training Loss: 2.06265291678102e-15, Validation Loss: 4.439424613919508e-15
Epoch 445, Training Loss: 1.7681503606907772e-15, Validation Loss: 4.431418034985587e-15
Epoch 446, Training Loss: 2.229853620678993e-15, Validation Loss: 4.283432908770788e-15
Epoch 447, Training Loss: 3.123369830254478e-15, Validation Loss: 4.183819716591314e-15
Epoch 448, Training Loss: 2.9825902015637347e-15, Validation Loss: 4.1030881593555595e-15
Epoch 449, Training Loss: 2.62390287686235e-15, Validation Loss: 3.312187661999328e-15
Epoch 450, Training Loss: 1.9249427237328894e-15, Validation Loss: 3.3137889777861123e-15
Epoch 451, Training Loss: 3.1252379614196473e-15, Validation Loss: 2.6189655218128048e-15
Epoch 452, Training Loss: 2.8870470026958178e-15, Validation Loss: 2.794839843090662e-15
Epoch 453, Training Loss: 2.1520580913966586e-15, Validation Loss: 2.9229423531763237e-15
Epoch 454, Training Loss: 1.880773978940077e-15, Validation Loss: 2.883310740365479e-15
Epoch 455, Training Loss: 1.5994818545743308e-15, Validation Loss: 5.3691694814402436e-15
Epoch 456, Training Loss: 1.9453589706187966e-15, Validation Loss: 5.3691694814402436e-15
Epoch 457, Training Loss: 1.942690181560235e-15, Validation Loss: 5.324733709510809e-15
Epoch 458, Training Loss: 2.2921702581249655e-15, Validation Loss: 5.257480140531765e-15
Epoch 459, Training Loss: 2.284163890949281e-15, Validation Loss: 4.0868086096258055e-15
Epoch 460, Training Loss: 2.147520959414691e-15, Validation Loss: 4.2157117776048594e-15
Epoch 461, Training Loss: 2.174876311962742e-15, Validation Loss: 3.805783406517563e-15
Epoch 462, Training Loss: 2.8698331756252422e-15, Validation Loss: 4.616032677487924e-15
Epoch 463, Training Loss: 2.5373001107527023e-15, Validation Loss: 4.0888101484801674e-15
Epoch 464, Training Loss: 2.25440677647929e-15, Validation Loss: 3.1983631627890583e-15
Epoch 465, Training Loss: 1.902124291408569e-15, Validation Loss: 3.1843519672920513e-15
Epoch 466, Training Loss: 2.3248631887901397e-15, Validation Loss: 2.8854456869090335e-15
Epoch 467, Training Loss: 1.3934500898797868e-15, Validation Loss: 3.599618128254708e-15
Epoch 468, Training Loss: 1.7138400904204891e-15, Validation Loss: 5.248539707773496e-15
Epoch 469, Training Loss: 1.2014295206822499e-15, Validation Loss: 4.615365215525488e-15
Epoch 470, Training Loss: 1.193423047627447e-15, Validation Loss: 3.214642924277049e-15
Epoch 471, Training Loss: 2.5848048948082757e-15, Validation Loss: 3.241331026620901e-15
Epoch 472, Training Loss: 1.9983347404806855e-15, Validation Loss: 2.8506178097003048e-15
Epoch 473, Training Loss: 2.176877850817104e-15, Validation Loss: 2.8143220243939844e-15
Epoch 474, Training Loss: 2.8467481396807735e-15, Validation Loss: 3.5213887063451424e-15
Epoch 475, Training Loss: 1.6758096875173103e-15, Validation Loss: 5.342448133053212e-15
Epoch 476, Training Loss: 1.2466657387468394e-15, Validation Loss: 4.802014854683604e-15
Epoch 477, Training Loss: 2.06852433741315e-15, Validation Loss: 4.614531311588916e-15
Epoch 478, Training Loss: 1.6317743504136906e-15, Validation Loss: 6.91107183620524e-15
Epoch 479, Training Loss: 1.787232318926522e-15, Validation Loss: 6.972854842894442e-15
Epoch 480, Training Loss: 2.3131203475258797e-15, Validation Loss: 6.805387111859847e-15
Epoch 481, Training Loss: 2.568525133320285e-15, Validation Loss: 6.733729818588028e-15
Epoch 482, Training Loss: 2.586139183458438e-15, Validation Loss: 7.926018477340865e-15
Epoch 483, Training Loss: 2.8930518310171403e-15, Validation Loss: 6.5681302187186024e-15
Epoch 484, Training Loss: 2.8877142529000173e-15, Validation Loss: 7.22078646875346e-15
Epoch 485, Training Loss: 2.4863258797451753e-15, Validation Loss: 7.432222833047078e-15
Epoch 486, Training Loss: 2.601484879363844e-15, Validation Loss: 6.344417805920427e-15
Epoch 487, Training Loss: 4.010213961304441e-15, Validation Loss: 6.109195909434961e-15
Epoch 488, Training Loss: 2.7397289149269817e-15, Validation Loss: 6.4179766881588326e-15
Epoch 489, Training Loss: 2.9041274220772007e-15, Validation Loss: 6.010049855925898e-15
Epoch 490, Training Loss: 2.0026048453260312e-15, Validation Loss: 6.028064129131629e-15
Epoch 491, Training Loss: 1.4939305379181307e-15, Validation Loss: 5.911304025484412e-15
Epoch 492, Training Loss: 9.30812658429868e-16, Validation Loss: 5.911304025484412e-15
Epoch 493, Training Loss: 1.8359379839430652e-15, Validation Loss: 5.911304025484412e-15
Epoch 494, Training Loss: 1.346479042460102e-15, Validation Loss: 5.9900336203493314e-15
Epoch 495, Training Loss: 1.0550454984959985e-15, Validation Loss: 5.900362053871781e-15
Epoch 496, Training Loss: 1.7175764586299463e-15, Validation Loss: 5.8555260588747694e-15
Epoch 497, Training Loss: 1.6802132000518486e-15, Validation Loss: 5.8555260588747694e-15
Epoch 498, Training Loss: 1.6802132000518486e-15, Validation Loss: 6.007647670487485e-15
Epoch 499, Training Loss: 2.086405414687925e-15, Validation Loss: 6.007647670487485e-15
Epoch 500, Training Loss: 1.6583289391892313e-15, Validation Loss: 5.863532214292217e-15
