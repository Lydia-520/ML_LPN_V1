Epoch 1, Training Loss: 0.4698888659477234, Validation Loss: 0.46862003207206726
Epoch 2, Training Loss: 0.46862003207206726, Validation Loss: 0.4673793315887451
Epoch 3, Training Loss: 0.4673793613910675, Validation Loss: 0.46615272760391235
Epoch 4, Training Loss: 0.4661526381969452, Validation Loss: 0.46493569016456604
Epoch 5, Training Loss: 0.46493569016456604, Validation Loss: 0.4637165367603302
Epoch 6, Training Loss: 0.4637164771556854, Validation Loss: 0.4624728858470917
Epoch 7, Training Loss: 0.4624728560447693, Validation Loss: 0.461215615272522
Epoch 8, Training Loss: 0.46121564507484436, Validation Loss: 0.45993930101394653
Epoch 9, Training Loss: 0.45993930101394653, Validation Loss: 0.45864829421043396
Epoch 10, Training Loss: 0.45864829421043396, Validation Loss: 0.4573564827442169
Epoch 11, Training Loss: 0.4573564827442169, Validation Loss: 0.4560435116291046
Epoch 12, Training Loss: 0.4560435116291046, Validation Loss: 0.45470353960990906
Epoch 13, Training Loss: 0.45470356941223145, Validation Loss: 0.45337921380996704
Epoch 14, Training Loss: 0.45337921380996704, Validation Loss: 0.4520387053489685
Epoch 15, Training Loss: 0.4520387053489685, Validation Loss: 0.4506796896457672
Epoch 16, Training Loss: 0.4506796896457672, Validation Loss: 0.44931069016456604
Epoch 17, Training Loss: 0.4493107199668884, Validation Loss: 0.44791379570961
Epoch 18, Training Loss: 0.4479137659072876, Validation Loss: 0.44648563861846924
Epoch 19, Training Loss: 0.44648560881614685, Validation Loss: 0.445064514875412
Epoch 20, Training Loss: 0.4450644850730896, Validation Loss: 0.44361329078674316
Epoch 21, Training Loss: 0.44361329078674316, Validation Loss: 0.44211000204086304
Epoch 22, Training Loss: 0.44210997223854065, Validation Loss: 0.4405837655067444
Epoch 23, Training Loss: 0.4405837655067444, Validation Loss: 0.43901005387306213
Epoch 24, Training Loss: 0.43901005387306213, Validation Loss: 0.4373622238636017
Epoch 25, Training Loss: 0.4373621642589569, Validation Loss: 0.4357014000415802
Epoch 26, Training Loss: 0.4357014000415802, Validation Loss: 0.4339975416660309
Epoch 27, Training Loss: 0.4339975416660309, Validation Loss: 0.43222907185554504
Epoch 28, Training Loss: 0.43222901225090027, Validation Loss: 0.43039095401763916
Epoch 29, Training Loss: 0.43039095401763916, Validation Loss: 0.4284687340259552
Epoch 30, Training Loss: 0.4284687340259552, Validation Loss: 0.42644745111465454
Epoch 31, Training Loss: 0.42644742131233215, Validation Loss: 0.42430025339126587
Epoch 32, Training Loss: 0.42430025339126587, Validation Loss: 0.4220469295978546
Epoch 33, Training Loss: 0.4220469295978546, Validation Loss: 0.4196251928806305
Epoch 34, Training Loss: 0.4196252226829529, Validation Loss: 0.4170052111148834
Epoch 35, Training Loss: 0.41700518131256104, Validation Loss: 0.4142167866230011
Epoch 36, Training Loss: 0.4142167866230011, Validation Loss: 0.41126105189323425
Epoch 37, Training Loss: 0.41126105189323425, Validation Loss: 0.4081612825393677
Epoch 38, Training Loss: 0.4081612527370453, Validation Loss: 0.4048501253128052
Epoch 39, Training Loss: 0.4048500955104828, Validation Loss: 0.40131741762161255
Epoch 40, Training Loss: 0.4013174772262573, Validation Loss: 0.39756160974502563
Epoch 41, Training Loss: 0.39756160974502563, Validation Loss: 0.3935460150241852
Epoch 42, Training Loss: 0.39354604482650757, Validation Loss: 0.38925784826278687
Epoch 43, Training Loss: 0.38925784826278687, Validation Loss: 0.3846451938152313
Epoch 44, Training Loss: 0.3846451938152313, Validation Loss: 0.3797057271003723
Epoch 45, Training Loss: 0.3797057867050171, Validation Loss: 0.3744097948074341
Epoch 46, Training Loss: 0.37440982460975647, Validation Loss: 0.3687479794025421
Epoch 47, Training Loss: 0.3687479794025421, Validation Loss: 0.362741082906723
Epoch 48, Training Loss: 0.362741082906723, Validation Loss: 0.35636794567108154
Epoch 49, Training Loss: 0.35636794567108154, Validation Loss: 0.34959277510643005
Epoch 50, Training Loss: 0.34959277510643005, Validation Loss: 0.34241604804992676
Epoch 51, Training Loss: 0.34241607785224915, Validation Loss: 0.3349001109600067
Epoch 52, Training Loss: 0.3349001109600067, Validation Loss: 0.3269498646259308
Epoch 53, Training Loss: 0.3269498348236084, Validation Loss: 0.3186154365539551
Epoch 54, Training Loss: 0.3186154365539551, Validation Loss: 0.30993419885635376
Epoch 55, Training Loss: 0.30993419885635376, Validation Loss: 0.3008928894996643
Epoch 56, Training Loss: 0.3008928894996643, Validation Loss: 0.2915216088294983
Epoch 57, Training Loss: 0.2915215790271759, Validation Loss: 0.2819497585296631
Epoch 58, Training Loss: 0.2819497585296631, Validation Loss: 0.27223682403564453
Epoch 59, Training Loss: 0.27223682403564453, Validation Loss: 0.26254624128341675
Epoch 60, Training Loss: 0.26254624128341675, Validation Loss: 0.2529984414577484
Epoch 61, Training Loss: 0.2529984414577484, Validation Loss: 0.24372290074825287
Epoch 62, Training Loss: 0.24372293055057526, Validation Loss: 0.23492054641246796
Epoch 63, Training Loss: 0.23492054641246796, Validation Loss: 0.2267318069934845
Epoch 64, Training Loss: 0.2267318218946457, Validation Loss: 0.21929378807544708
Epoch 65, Training Loss: 0.21929378807544708, Validation Loss: 0.2127230316400528
Epoch 66, Training Loss: 0.2127230316400528, Validation Loss: 0.20704582333564758
Epoch 67, Training Loss: 0.2070458084344864, Validation Loss: 0.20219285786151886
Epoch 68, Training Loss: 0.20219285786151886, Validation Loss: 0.19796115159988403
Epoch 69, Training Loss: 0.19796119630336761, Validation Loss: 0.19404950737953186
Epoch 70, Training Loss: 0.19404950737953186, Validation Loss: 0.19012631475925446
Epoch 71, Training Loss: 0.19012631475925446, Validation Loss: 0.1859595626592636
Epoch 72, Training Loss: 0.1859595626592636, Validation Loss: 0.18138310313224792
Epoch 73, Training Loss: 0.18138310313224792, Validation Loss: 0.1761900931596756
Epoch 74, Training Loss: 0.1761900931596756, Validation Loss: 0.17045068740844727
Epoch 75, Training Loss: 0.17045067250728607, Validation Loss: 0.16427569091320038
Epoch 76, Training Loss: 0.16427570581436157, Validation Loss: 0.15774944424629211
Epoch 77, Training Loss: 0.15774944424629211, Validation Loss: 0.15105271339416504
Epoch 78, Training Loss: 0.15105271339416504, Validation Loss: 0.14450128376483917
Epoch 79, Training Loss: 0.14450129866600037, Validation Loss: 0.1380167305469513
Epoch 80, Training Loss: 0.1380167454481125, Validation Loss: 0.13163039088249207
Epoch 81, Training Loss: 0.13163039088249207, Validation Loss: 0.12539362907409668
Epoch 82, Training Loss: 0.12539365887641907, Validation Loss: 0.11924666911363602
Epoch 83, Training Loss: 0.11924666911363602, Validation Loss: 0.1130264401435852
Epoch 84, Training Loss: 0.11302643269300461, Validation Loss: 0.10679679363965988
Epoch 85, Training Loss: 0.10679680109024048, Validation Loss: 0.10068787634372711
Epoch 86, Training Loss: 0.10068787634372711, Validation Loss: 0.09450771659612656
Epoch 87, Training Loss: 0.09450771659612656, Validation Loss: 0.08823052048683167
Epoch 88, Training Loss: 0.08823052048683167, Validation Loss: 0.08191584050655365
Epoch 89, Training Loss: 0.08191584050655365, Validation Loss: 0.07563650608062744
Epoch 90, Training Loss: 0.07563652098178864, Validation Loss: 0.06941641867160797
Epoch 91, Training Loss: 0.06941641867160797, Validation Loss: 0.06332195550203323
Epoch 92, Training Loss: 0.06332194805145264, Validation Loss: 0.05734991654753685
Epoch 93, Training Loss: 0.05734992399811745, Validation Loss: 0.051667917519807816
Epoch 94, Training Loss: 0.05166791379451752, Validation Loss: 0.04636330157518387
Epoch 95, Training Loss: 0.046363309025764465, Validation Loss: 0.041488341987133026
Epoch 96, Training Loss: 0.04148833826184273, Validation Loss: 0.037158768624067307
Epoch 97, Training Loss: 0.03715876489877701, Validation Loss: 0.033277444541454315
Epoch 98, Training Loss: 0.033277444541454315, Validation Loss: 0.029851894825696945
Epoch 99, Training Loss: 0.029851896688342094, Validation Loss: 0.02681945264339447
Epoch 100, Training Loss: 0.02681945078074932, Validation Loss: 0.024151910096406937
Epoch 101, Training Loss: 0.024151908233761787, Validation Loss: 0.02176487445831299
Epoch 102, Training Loss: 0.02176487445831299, Validation Loss: 0.019602825865149498
Epoch 103, Training Loss: 0.01960282400250435, Validation Loss: 0.0175962895154953
Epoch 104, Training Loss: 0.01759629137814045, Validation Loss: 0.015756862238049507
Epoch 105, Training Loss: 0.015756862238049507, Validation Loss: 0.014044519513845444
Epoch 106, Training Loss: 0.01404452696442604, Validation Loss: 0.012428012676537037
Epoch 107, Training Loss: 0.012428009882569313, Validation Loss: 0.010912496596574783
Epoch 108, Training Loss: 0.010912499390542507, Validation Loss: 0.009503505192697048
Epoch 109, Training Loss: 0.009503502398729324, Validation Loss: 0.008196459151804447
Epoch 110, Training Loss: 0.008196458220481873, Validation Loss: 0.007024502381682396
Epoch 111, Training Loss: 0.007024503778666258, Validation Loss: 0.005997560452669859
Epoch 112, Training Loss: 0.005997557193040848, Validation Loss: 0.005121828988194466
Epoch 113, Training Loss: 0.005121828522533178, Validation Loss: 0.004396165255457163
Epoch 114, Training Loss: 0.00439616572111845, Validation Loss: 0.0037808751221746206
Epoch 115, Training Loss: 0.0037808746565133333, Validation Loss: 0.00325886276550591
Epoch 116, Training Loss: 0.0032588657923042774, Validation Loss: 0.0028095238376408815
Epoch 117, Training Loss: 0.002809524070471525, Validation Loss: 0.0024274869356304407
Epoch 118, Training Loss: 0.002427486004307866, Validation Loss: 0.0020964774303138256
Epoch 119, Training Loss: 0.002096477197483182, Validation Loss: 0.001804281142540276
Epoch 120, Training Loss: 0.0018042820738628507, Validation Loss: 0.0015510304365307093
Epoch 121, Training Loss: 0.0015510300872847438, Validation Loss: 0.0013345652259886265
Epoch 122, Training Loss: 0.001334563479758799, Validation Loss: 0.0011550970375537872
Epoch 123, Training Loss: 0.0011550976196303964, Validation Loss: 0.0010095771867781878
Epoch 124, Training Loss: 0.0010095757897943258, Validation Loss: 0.0008945240406319499
Epoch 125, Training Loss: 0.0008945239242166281, Validation Loss: 0.0008026561117731035
Epoch 126, Training Loss: 0.0008026558207347989, Validation Loss: 0.0007319267024286091
Epoch 127, Training Loss: 0.0007319269934669137, Validation Loss: 0.0006717812502756715
Epoch 128, Training Loss: 0.0006717809592373669, Validation Loss: 0.0006167949177324772
Epoch 129, Training Loss: 0.0006167955580167472, Validation Loss: 0.0005639109294861555
Epoch 130, Training Loss: 0.0005639123846776783, Validation Loss: 0.0005109799676574767
Epoch 131, Training Loss: 0.0005109806079417467, Validation Loss: 0.00045915215741842985
Epoch 132, Training Loss: 0.00045915221562609076, Validation Loss: 0.00040951385744847357
Epoch 133, Training Loss: 0.00040951400296762586, Validation Loss: 0.00036328911664895713
Epoch 134, Training Loss: 0.00036328937858343124, Validation Loss: 0.0003213794552721083
Epoch 135, Training Loss: 0.000321378989610821, Validation Loss: 0.00028418810688890517
Epoch 136, Training Loss: 0.00028418793226592243, Validation Loss: 0.00025173445465043187
Epoch 137, Training Loss: 0.0002517350949347019, Validation Loss: 0.0002234726562164724
Epoch 138, Training Loss: 0.00022347229241859168, Validation Loss: 0.00019875442376360297
Epoch 139, Training Loss: 0.0001987544383155182, Validation Loss: 0.00017694146663416177
Epoch 140, Training Loss: 0.0001769411755958572, Validation Loss: 0.00015749316662549973
Epoch 141, Training Loss: 0.00015749296289868653, Validation Loss: 0.00014000272494740784
Epoch 142, Training Loss: 0.00014000257942825556, Validation Loss: 0.00012330521713010967
Epoch 143, Training Loss: 0.00012330530444160104, Validation Loss: 0.00010808841761900112
Epoch 144, Training Loss: 0.00010808819206431508, Validation Loss: 9.442138980375603e-05
Epoch 145, Training Loss: 9.442161535844207e-05, Validation Loss: 8.247343794209883e-05
Epoch 146, Training Loss: 8.247353252954781e-05, Validation Loss: 7.232838834170252e-05
Epoch 147, Training Loss: 7.232856296468526e-05, Validation Loss: 6.396679964382201e-05
Epoch 148, Training Loss: 6.396655226126313e-05, Validation Loss: 5.7260705943917856e-05
Epoch 149, Training Loss: 5.726062954636291e-05, Validation Loss: 5.2054081606911495e-05
Epoch 150, Training Loss: 5.2054183470318094e-05, Validation Loss: 4.7965924750315025e-05
Epoch 151, Training Loss: 4.796572102350183e-05, Validation Loss: 4.4680207793135196e-05
Epoch 152, Training Loss: 4.468010229174979e-05, Validation Loss: 4.1927727579604834e-05
Epoch 153, Training Loss: 4.1927876736735925e-05, Validation Loss: 3.9485043089371175e-05
Epoch 154, Training Loss: 3.948490848415531e-05, Validation Loss: 3.716102582984604e-05
Epoch 155, Training Loss: 3.716112769325264e-05, Validation Loss: 3.479783845250495e-05
Epoch 156, Training Loss: 3.479811493889429e-05, Validation Loss: 3.227745764888823e-05
Epoch 157, Training Loss: 3.2277352147502825e-05, Validation Loss: 2.9554455977631733e-05
Epoch 158, Training Loss: 2.955447962449398e-05, Validation Loss: 2.6671923478716053e-05
Epoch 159, Training Loss: 2.6671894374885596e-05, Validation Loss: 2.373937240918167e-05
Epoch 160, Training Loss: 2.373929055465851e-05, Validation Loss: 2.0898749426123686e-05
Epoch 161, Training Loss: 2.089874578814488e-05, Validation Loss: 1.8287886632606387e-05
Epoch 162, Training Loss: 1.8287901184521616e-05, Validation Loss: 1.600815994606819e-05
Epoch 163, Training Loss: 1.60081144713331e-05, Validation Loss: 1.422257446392905e-05
Epoch 164, Training Loss: 1.4222767276805826e-05, Validation Loss: 1.2735945347230881e-05
Epoch 165, Training Loss: 1.2736013559333514e-05, Validation Loss: 1.1488884410937317e-05
Epoch 166, Training Loss: 1.1489018106658477e-05, Validation Loss: 1.041132964019198e-05
Epoch 167, Training Loss: 1.041141149471514e-05, Validation Loss: 9.434018465981353e-06
Epoch 168, Training Loss: 9.434053936274722e-06, Validation Loss: 8.5084548118175e-06
Epoch 169, Training Loss: 8.50842843647115e-06, Validation Loss: 7.61573346608202e-06
Epoch 170, Training Loss: 7.61573346608202e-06, Validation Loss: 6.765029411326395e-06
Epoch 171, Training Loss: 6.765152193111135e-06, Validation Loss: 5.980055902909953e-06
Epoch 172, Training Loss: 5.980053629173199e-06, Validation Loss: 5.289723048917949e-06
Epoch 173, Training Loss: 5.2896939450874925e-06, Validation Loss: 4.7106209422054235e-06
Epoch 174, Training Loss: 4.710661869467003e-06, Validation Loss: 4.241975148033816e-06
Epoch 175, Training Loss: 4.242000613885466e-06, Validation Loss: 3.865817234327551e-06
Epoch 176, Training Loss: 3.865834059979534e-06, Validation Loss: 3.552988118826761e-06
Epoch 177, Training Loss: 3.552898988345987e-06, Validation Loss: 3.2719781302148476e-06
Epoch 178, Training Loss: 3.271962896178593e-06, Validation Loss: 2.9983527838339796e-06
Epoch 179, Training Loss: 2.998385753016919e-06, Validation Loss: 2.7194266749575036e-06
Epoch 180, Training Loss: 2.7193718779017217e-06, Validation Loss: 2.434698444631067e-06
Epoch 181, Training Loss: 2.434748239465989e-06, Validation Loss: 2.153929699488799e-06
Epoch 182, Training Loss: 2.154022922695731e-06, Validation Loss: 1.8911483721240074e-06
Epoch 183, Training Loss: 1.8912078303401358e-06, Validation Loss: 1.6592738347753766e-06
Epoch 184, Training Loss: 1.659267923059815e-06, Validation Loss: 1.466188905396848e-06
Epoch 185, Training Loss: 1.466177423026238e-06, Validation Loss: 1.3131835885360488e-06
Epoch 186, Training Loss: 1.3131755167705705e-06, Validation Loss: 1.1953947023357614e-06
Epoch 187, Training Loss: 1.1954897445320967e-06, Validation Loss: 1.104138391383458e-06
Epoch 188, Training Loss: 1.1041623793062172e-06, Validation Loss: 1.029079044201353e-06
Epoch 189, Training Loss: 1.029117470352503e-06, Validation Loss: 9.610779443391948e-07
Epoch 190, Training Loss: 9.61075443228765e-07, Validation Loss: 8.934096058510477e-07
Epoch 191, Training Loss: 8.934355832934671e-07, Validation Loss: 8.223668146456475e-07
Epoch 192, Training Loss: 8.223235568038945e-07, Validation Loss: 7.46855675970437e-07
Epoch 193, Training Loss: 7.46835667086998e-07, Validation Loss: 6.680363640043652e-07
Epoch 194, Training Loss: 6.680220394628122e-07, Validation Loss: 5.881080937797378e-07
Epoch 195, Training Loss: 5.880962135051959e-07, Validation Loss: 5.098471547171357e-07
Epoch 196, Training Loss: 5.098700057715178e-07, Validation Loss: 4.360452976470697e-07
Epoch 197, Training Loss: 4.360144032489188e-07, Validation Loss: 3.687708272082091e-07
Epoch 198, Training Loss: 3.687696050747036e-07, Validation Loss: 3.0962468144934974e-07
Epoch 199, Training Loss: 3.0963769859226886e-07, Validation Loss: 2.5927860747287923e-07
Epoch 200, Training Loss: 2.5927732849595486e-07, Validation Loss: 2.1757881540906965e-07
Epoch 201, Training Loss: 2.1759286994438298e-07, Validation Loss: 1.8384538691407215e-07
Epoch 202, Training Loss: 1.8384831435014348e-07, Validation Loss: 1.569627983144528e-07
Epoch 203, Training Loss: 1.5695312072239176e-07, Validation Loss: 1.3577974300460482e-07
Epoch 204, Training Loss: 1.357669958679253e-07, Validation Loss: 1.192493357393687e-07
Epoch 205, Training Loss: 1.192447598441504e-07, Validation Loss: 1.0658534677077114e-07
Epoch 206, Training Loss: 1.0658164484311783e-07, Validation Loss: 9.720142912783558e-08
Epoch 207, Training Loss: 9.719988725009898e-08, Validation Loss: 9.065257700058282e-08
Epoch 208, Training Loss: 9.064738293318442e-08, Validation Loss: 8.645886850899842e-08
Epoch 209, Training Loss: 8.646120619459907e-08, Validation Loss: 8.404369822301305e-08
Epoch 210, Training Loss: 8.405520901533237e-08, Validation Loss: 8.274364660110223e-08
Epoch 211, Training Loss: 8.27657729018938e-08, Validation Loss: 8.183761224245245e-08
Epoch 212, Training Loss: 8.184798616639455e-08, Validation Loss: 8.072765211863953e-08
Epoch 213, Training Loss: 8.073118351603625e-08, Validation Loss: 7.900620602185882e-08
Epoch 214, Training Loss: 7.900433729446377e-08, Validation Loss: 7.653674316543402e-08
Epoch 215, Training Loss: 7.653743949731506e-08, Validation Loss: 7.341034802266222e-08
Epoch 216, Training Loss: 7.341278518424588e-08, Validation Loss: 6.983744071931142e-08
Epoch 217, Training Loss: 6.982816813660975e-08, Validation Loss: 6.603065827448518e-08
Epoch 218, Training Loss: 6.603968216722933e-08, Validation Loss: 6.214978753860123e-08
Epoch 219, Training Loss: 6.214678904825632e-08, Validation Loss: 5.8177807460424447e-08
Epoch 220, Training Loss: 5.8169771222083e-08, Validation Loss: 5.402361580308934e-08
Epoch 221, Training Loss: 5.4021381146185377e-08, Validation Loss: 4.957596289045796e-08
Epoch 222, Training Loss: 4.957734844879269e-08, Validation Loss: 4.477070447705955e-08
Epoch 223, Training Loss: 4.476799020380895e-08, Validation Loss: 3.961664774010387e-08
Epoch 224, Training Loss: 3.961742578439953e-08, Validation Loss: 3.426489669777766e-08
Epoch 225, Training Loss: 3.427085104590333e-08, Validation Loss: 2.8936225859865772e-08
Epoch 226, Training Loss: 2.8948033303777265e-08, Validation Loss: 2.388397035701928e-08
Epoch 227, Training Loss: 2.3884803468376958e-08, Validation Loss: 1.9299301712294437e-08
Epoch 228, Training Loss: 1.9301429787788038e-08, Validation Loss: 1.5343720960458995e-08
Epoch 229, Training Loss: 1.5346182991038404e-08, Validation Loss: 1.2070168864397601e-08
Epoch 230, Training Loss: 1.2070256794061152e-08, Validation Loss: 9.465949801779061e-09
Epoch 231, Training Loss: 9.464351080623601e-09, Validation Loss: 7.469669327520023e-09
Epoch 232, Training Loss: 7.467768625701865e-09, Validation Loss: 5.996023233478809e-09
Epoch 233, Training Loss: 5.996897645133004e-09, Validation Loss: 4.9547064229216176e-09
Epoch 234, Training Loss: 4.956087096275041e-09, Validation Loss: 4.255300556366137e-09
Epoch 235, Training Loss: 4.2566150604272934e-09, Validation Loss: 3.811802429254385e-09
Epoch 236, Training Loss: 3.8106073851906785e-09, Validation Loss: 3.5422886845992707e-09
Epoch 237, Training Loss: 3.5438563195100414e-09, Validation Loss: 3.3827771694916464e-09
Epoch 238, Training Loss: 3.3827733947333627e-09, Validation Loss: 3.2659359661124654e-09
Epoch 239, Training Loss: 3.2644815739502064e-09, Validation Loss: 3.1576190551163563e-09
Epoch 240, Training Loss: 3.1569846736800855e-09, Validation Loss: 3.038311158221063e-09
Epoch 241, Training Loss: 3.0375526538506392e-09, Validation Loss: 2.9073001783785912e-09
Epoch 242, Training Loss: 2.9055524652932263e-09, Validation Loss: 2.7755653331240637e-09
Epoch 243, Training Loss: 2.7749433861856687e-09, Validation Loss: 2.656634690012538e-09
Epoch 244, Training Loss: 2.6561650656731217e-09, Validation Loss: 2.560372358573204e-09
Epoch 245, Training Loss: 2.558971923249942e-09, Validation Loss: 2.479740190963753e-09
Epoch 246, Training Loss: 2.480423866302317e-09, Validation Loss: 2.411643995614554e-09
Epoch 247, Training Loss: 2.4128605780049384e-09, Validation Loss: 2.336478788222962e-09
Epoch 248, Training Loss: 2.3367499046855755e-09, Validation Loss: 2.2390962417517812e-09
Epoch 249, Training Loss: 2.239547658433594e-09, Validation Loss: 2.113310415552405e-09
Epoch 250, Training Loss: 2.1139843209283526e-09, Validation Loss: 1.95865945684659e-09
Epoch 251, Training Loss: 1.9574155629698e-09, Validation Loss: 1.7808369223715204e-09
Epoch 252, Training Loss: 1.7809808072755118e-09, Validation Loss: 1.593519871612159e-09
Epoch 253, Training Loss: 1.593288723178432e-09, Validation Loss: 1.4089748257006818e-09
Epoch 254, Training Loss: 1.4088276101276165e-09, Validation Loss: 1.2378758018627423e-09
Epoch 255, Training Loss: 1.2380242386811346e-09, Validation Loss: 1.086248646586796e-09
Epoch 256, Training Loss: 1.0856546772686215e-09, Validation Loss: 9.56082324421459e-10
Epoch 257, Training Loss: 9.557653557479284e-10, Validation Loss: 8.470435464147386e-10
Epoch 258, Training Loss: 8.462877065795738e-10, Validation Loss: 7.57101825676898e-10
Epoch 259, Training Loss: 7.560966852615536e-10, Validation Loss: 6.796055385116517e-10
Epoch 260, Training Loss: 6.793943185812168e-10, Validation Loss: 6.134026619974975e-10
Epoch 261, Training Loss: 6.133344387926343e-10, Validation Loss: 5.537528768861932e-10
Epoch 262, Training Loss: 5.538849379149724e-10, Validation Loss: 4.980795220710377e-10
Epoch 263, Training Loss: 4.981517420787895e-10, Validation Loss: 4.4456521797187065e-10
Epoch 264, Training Loss: 4.4454492864609563e-10, Validation Loss: 3.922129843125788e-10
Epoch 265, Training Loss: 3.9211220381751843e-10, Validation Loss: 3.419197147636055e-10
Epoch 266, Training Loss: 3.415965010855615e-10, Validation Loss: 2.9390054279154754e-10
Epoch 267, Training Loss: 2.9376878707410015e-10, Validation Loss: 2.506063689899918e-10
Epoch 268, Training Loss: 2.508186158767245e-10, Validation Loss: 2.1300967933957082e-10
Epoch 269, Training Loss: 2.1332369204429824e-10, Validation Loss: 1.8192683470807935e-10
Epoch 270, Training Loss: 1.8151416480982618e-10, Validation Loss: 1.559709028597922e-10
Epoch 271, Training Loss: 1.5596655911220836e-10, Validation Loss: 1.3543517696223972e-10
Epoch 272, Training Loss: 1.3529898035269383e-10, Validation Loss: 1.1851133963070026e-10
Epoch 273, Training Loss: 1.182537262556238e-10, Validation Loss: 1.0561528041019841e-10
Epoch 274, Training Loss: 1.0576198250511482e-10, Validation Loss: 9.586855614918122e-11
Epoch 275, Training Loss: 9.522165694830775e-11, Validation Loss: 8.790688316162587e-11
Epoch 276, Training Loss: 8.784786093007924e-11, Validation Loss: 8.201636592097827e-11
Epoch 277, Training Loss: 8.199690926247172e-11, Validation Loss: 7.706035809462719e-11
Epoch 278, Training Loss: 7.701748960808885e-11, Validation Loss: 7.292969700367635e-11
Epoch 279, Training Loss: 7.255088890767425e-11, Validation Loss: 6.795312229579409e-11
Epoch 280, Training Loss: 6.805920410579702e-11, Validation Loss: 6.29335264457076e-11
Epoch 281, Training Loss: 6.277982300684215e-11, Validation Loss: 5.730920946134255e-11
Epoch 282, Training Loss: 5.741395206482203e-11, Validation Loss: 5.192831234457351e-11
Epoch 283, Training Loss: 5.1680597301650977e-11, Validation Loss: 4.6465449543564574e-11
Epoch 284, Training Loss: 4.653880059102278e-11, Validation Loss: 4.216407778478981e-11
Epoch 285, Training Loss: 4.2143163958563434e-11, Validation Loss: 3.884088883854275e-11
Epoch 286, Training Loss: 3.877016763187413e-11, Validation Loss: 3.668024217695631e-11
Epoch 287, Training Loss: 3.688652855382557e-11, Validation Loss: 3.540878701357997e-11
Epoch 288, Training Loss: 3.542843449166888e-11, Validation Loss: 3.437746962098309e-11
Epoch 289, Training Loss: 3.4330611270450007e-11, Validation Loss: 3.3078342148717965e-11
Epoch 290, Training Loss: 3.2982692965699556e-11, Validation Loss: 3.106871010460921e-11
Epoch 291, Training Loss: 3.103810958249298e-11, Validation Loss: 2.8457007583693184e-11
Epoch 292, Training Loss: 2.8267218427080465e-11, Validation Loss: 2.4823268440776758e-11
Epoch 293, Training Loss: 2.4937475695541167e-11, Validation Loss: 2.1386647661159053e-11
Epoch 294, Training Loss: 2.1280364623232906e-11, Validation Loss: 1.7700296089939727e-11
Epoch 295, Training Loss: 1.7538375265968575e-11, Validation Loss: 1.4199561665373395e-11
Epoch 296, Training Loss: 1.424582934256291e-11, Validation Loss: 1.1483088785402273e-11
Epoch 297, Training Loss: 1.1321346637949148e-11, Validation Loss: 9.252129444525803e-12
Epoch 298, Training Loss: 9.3003191953267e-12, Validation Loss: 7.684589076184523e-12
Epoch 299, Training Loss: 7.80130213900998e-12, Validation Loss: 6.723275148418084e-12
Epoch 300, Training Loss: 6.745560707233089e-12, Validation Loss: 5.997367533150388e-12
Epoch 301, Training Loss: 5.9843471324205755e-12, Validation Loss: 5.40626094239216e-12
Epoch 302, Training Loss: 5.401749360312014e-12, Validation Loss: 4.922194162676474e-12
Epoch 303, Training Loss: 4.983911287143039e-12, Validation Loss: 4.630809624650567e-12
Epoch 304, Training Loss: 4.594372191718543e-12, Validation Loss: 4.272835991275814e-12
Epoch 305, Training Loss: 4.238066061285073e-12, Validation Loss: 3.938404290193542e-12
Epoch 306, Training Loss: 3.979656014452271e-12, Validation Loss: 3.645359621801125e-12
Epoch 307, Training Loss: 3.703442500585519e-12, Validation Loss: 3.537373952783307e-12
Epoch 308, Training Loss: 3.5254926148559074e-12, Validation Loss: 3.4055260781512553e-12
Epoch 309, Training Loss: 3.3687759613126866e-12, Validation Loss: 3.2754213837721258e-12
Epoch 310, Training Loss: 3.2569181726560537e-12, Validation Loss: 3.2793960689364576e-12
Epoch 311, Training Loss: 3.1823274484338304e-12, Validation Loss: 3.2664706443169544e-12
Epoch 312, Training Loss: 3.248660888910404e-12, Validation Loss: 3.1004745212198648e-12
Epoch 313, Training Loss: 3.1407884105993933e-12, Validation Loss: 2.946723594299261e-12
Epoch 314, Training Loss: 2.9519841432401606e-12, Validation Loss: 2.7150911727225058e-12
Epoch 315, Training Loss: 2.7075997693915e-12, Validation Loss: 2.455017092395373e-12
Epoch 316, Training Loss: 2.43928878831956e-12, Validation Loss: 2.1908297658662645e-12
Epoch 317, Training Loss: 2.1712757460046195e-12, Validation Loss: 1.8768448167144625e-12
Epoch 318, Training Loss: 1.849587106736439e-12, Validation Loss: 1.5836920533654486e-12
Epoch 319, Training Loss: 1.6028325585185077e-12, Validation Loss: 1.3392114023638713e-12
Epoch 320, Training Loss: 1.2896782166510468e-12, Validation Loss: 1.1419332276649263e-12
Epoch 321, Training Loss: 1.1145620017194435e-12, Validation Loss: 8.837434907135733e-13
Epoch 322, Training Loss: 9.019809096670606e-13, Validation Loss: 7.333787440180761e-13
Epoch 323, Training Loss: 7.163003913970845e-13, Validation Loss: 5.890616228305945e-13
Epoch 324, Training Loss: 6.060704238822212e-13, Validation Loss: 4.689190659032394e-13
Epoch 325, Training Loss: 4.787994003010998e-13, Validation Loss: 3.817732534185797e-13
Epoch 326, Training Loss: 3.880347649101723e-13, Validation Loss: 3.100511113043186e-13
Epoch 327, Training Loss: 3.0909991363334277e-13, Validation Loss: 2.4344092822321806e-13
Epoch 328, Training Loss: 2.382378148924058e-13, Validation Loss: 2.0815932256969955e-13
Epoch 329, Training Loss: 2.086674610228892e-13, Validation Loss: 1.6419008622321762e-13
Epoch 330, Training Loss: 1.713444788614335e-13, Validation Loss: 1.6022423730659152e-13
Epoch 331, Training Loss: 1.51460007730142e-13, Validation Loss: 1.4228105727018964e-13
Epoch 332, Training Loss: 1.4264534920014477e-13, Validation Loss: 1.351266510794466e-13
Epoch 333, Training Loss: 1.5730590387143945e-13, Validation Loss: 1.337690266715874e-13
Epoch 334, Training Loss: 1.3433988622045534e-13, Validation Loss: 1.3847840788557692e-13
Epoch 335, Training Loss: 1.3134175550540833e-13, Validation Loss: 1.3202136053217656e-13
Epoch 336, Training Loss: 1.2067706859839045e-13, Validation Loss: 1.2414610897452938e-13
Epoch 337, Training Loss: 1.2443475069789933e-13, Validation Loss: 1.2368747790304085e-13
Epoch 338, Training Loss: 1.2221496872247967e-13, Validation Loss: 1.2175926499685685e-13
Epoch 339, Training Loss: 1.0248048340922439e-13, Validation Loss: 1.2597838354097557e-13
Epoch 340, Training Loss: 1.1192912238331895e-13, Validation Loss: 1.1486827927644633e-13
Epoch 341, Training Loss: 1.0229660272077085e-13, Validation Loss: 1.0751892675882682e-13
Epoch 342, Training Loss: 9.762606304961063e-14, Validation Loss: 1.0524349810690434e-13
Epoch 343, Training Loss: 9.163032339181212e-14, Validation Loss: 9.164900555049676e-14
Epoch 344, Training Loss: 9.039639967556995e-14, Validation Loss: 8.633541201830824e-14
Epoch 345, Training Loss: 8.02327903550934e-14, Validation Loss: 8.256492278063687e-14
Epoch 346, Training Loss: 7.957786448027637e-14, Validation Loss: 7.424692371332808e-14
Epoch 347, Training Loss: 7.93470107326999e-14, Validation Loss: 7.4844874763981e-14
Epoch 348, Training Loss: 7.401007297248505e-14, Validation Loss: 6.797736879686836e-14
Epoch 349, Training Loss: 7.217806945658198e-14, Validation Loss: 6.970328313019372e-14
Epoch 350, Training Loss: 6.64502768131861e-14, Validation Loss: 5.83184284826295e-14
Epoch 351, Training Loss: 6.284205198315435e-14, Validation Loss: 5.2493626849850483e-14
Epoch 352, Training Loss: 6.053433443528253e-14, Validation Loss: 5.433043134849859e-14
Epoch 353, Training Loss: 5.872034900423345e-14, Validation Loss: 5.156368292958714e-14
Epoch 354, Training Loss: 5.483136663350478e-14, Validation Loss: 4.9796663781397424e-14
Epoch 355, Training Loss: 4.6950385745002376e-14, Validation Loss: 4.672246950768698e-14
Epoch 356, Training Loss: 4.046879137679059e-14, Validation Loss: 4.123994033636627e-14
Epoch 357, Training Loss: 3.1127437595795254e-14, Validation Loss: 3.5535637610663653e-14
Epoch 358, Training Loss: 2.9589672996977595e-14, Validation Loss: 3.016213174404994e-14
Epoch 359, Training Loss: 2.932145493203184e-14, Validation Loss: 3.293862104185481e-14
Epoch 360, Training Loss: 3.017720893051107e-14, Validation Loss: 3.132092702600245e-14
Epoch 361, Training Loss: 2.7108215439096764e-14, Validation Loss: 2.4601941509927276e-14
Epoch 362, Training Loss: 2.677594982487732e-14, Validation Loss: 2.2067910311076265e-14
Epoch 363, Training Loss: 2.2936739110129313e-14, Validation Loss: 2.7032822730527553e-14
Epoch 364, Training Loss: 1.8836520274882577e-14, Validation Loss: 2.429956599435054e-14
Epoch 365, Training Loss: 2.064303487533687e-14, Validation Loss: 2.1692942377853942e-14
Epoch 366, Training Loss: 1.8562300134472576e-14, Validation Loss: 2.01920067715829e-14
Epoch 367, Training Loss: 1.488682258249472e-14, Validation Loss: 1.4415777396131237e-14
Epoch 368, Training Loss: 1.1276194719991601e-14, Validation Loss: 1.217184651138535e-14
Epoch 369, Training Loss: 1.220120297927129e-14, Validation Loss: 1.2391222115493584e-14
Epoch 370, Training Loss: 1.1565893540479728e-14, Validation Loss: 1.1437391019084725e-14
Epoch 371, Training Loss: 1.3160372077313746e-14, Validation Loss: 1.3584578035759961e-14
Epoch 372, Training Loss: 1.0771524019688016e-14, Validation Loss: 1.2884016566843716e-14
Epoch 373, Training Loss: 1.006108784067268e-14, Validation Loss: 1.1954605430304199e-14
Epoch 374, Training Loss: 8.70760288282672e-15, Validation Loss: 1.3654233790177418e-14
Epoch 375, Training Loss: 8.269385305367024e-15, Validation Loss: 1.164515718961789e-14
Epoch 376, Training Loss: 7.071892476186257e-15, Validation Loss: 1.0494368910115778e-14
Epoch 377, Training Loss: 8.125136441482564e-15, Validation Loss: 1.2031600725209615e-14
Epoch 378, Training Loss: 8.14101576814474e-15, Validation Loss: 1.2008248026853813e-14
Epoch 379, Training Loss: 6.577229470154482e-15, Validation Loss: 1.0538136796566303e-14
Epoch 380, Training Loss: 6.634608752550909e-15, Validation Loss: 1.0700133541794582e-14
Epoch 381, Training Loss: 5.9994331449650124e-15, Validation Loss: 9.32569891806418e-15
Epoch 382, Training Loss: 7.138479430235812e-15, Validation Loss: 9.247235715061173e-15
Epoch 383, Training Loss: 6.163831228598758e-15, Validation Loss: 1.0532532826587268e-14
Epoch 384, Training Loss: 6.104984038104739e-15, Validation Loss: 1.2673047764736982e-14
Epoch 385, Training Loss: 5.5636169059107825e-15, Validation Loss: 9.631676864765588e-15
Epoch 386, Training Loss: 3.3282255955808778e-15, Validation Loss: 9.567359111981727e-15
Epoch 387, Training Loss: 3.551471081466879e-15, Validation Loss: 8.92284242505351e-15
Epoch 388, Training Loss: 3.1243288833090067e-15, Validation Loss: 9.293138971571725e-15
Epoch 389, Training Loss: 3.5185113354233195e-15, Validation Loss: 8.835705604670618e-15
Epoch 390, Training Loss: 3.1324686581738837e-15, Validation Loss: 8.770052927961885e-15
Epoch 391, Training Loss: 3.1933173875222645e-15, Validation Loss: 8.31822437807276e-15
Epoch 392, Training Loss: 2.9655349814125325e-15, Validation Loss: 9.030928911320842e-15
Epoch 393, Training Loss: 3.4806144460884517e-15, Validation Loss: 9.591378425267017e-15
Epoch 394, Training Loss: 3.0572082985026814e-15, Validation Loss: 9.580703269032771e-15
Epoch 395, Training Loss: 1.9252345265832185e-15, Validation Loss: 8.47021342902923e-15
Epoch 396, Training Loss: 1.9405802224886247e-15, Validation Loss: 8.585505624578854e-15
Epoch 397, Training Loss: 2.5613444115099365e-15, Validation Loss: 8.459805088173369e-15
Epoch 398, Training Loss: 2.5538716750910222e-15, Validation Loss: 9.127272979840388e-15
Epoch 399, Training Loss: 2.669030674709691e-15, Validation Loss: 8.947128553717185e-15
Epoch 400, Training Loss: 2.7193376555130185e-15, Validation Loss: 1.0033865895813822e-14
Epoch 401, Training Loss: 2.6672959512337143e-15, Validation Loss: 1.1353590661481068e-14
Epoch 402, Training Loss: 2.6352702707727396e-15, Validation Loss: 1.0056017501450416e-14
Epoch 403, Training Loss: 2.348373647032367e-15, Validation Loss: 9.938589935840764e-15
Epoch 404, Training Loss: 2.542796084030962e-15, Validation Loss: 1.0331437887546677e-14
Epoch 405, Training Loss: 1.994223242554713e-15, Validation Loss: 1.0354656754696812e-14
Epoch 406, Training Loss: 1.386402775758631e-15, Validation Loss: 1.042537977062781e-14
Epoch 407, Training Loss: 1.3829333288066775e-15, Validation Loss: 1.0768054572736063e-14
Epoch 408, Training Loss: 1.7151995783008323e-15, Validation Loss: 8.327431626209414e-15
Epoch 409, Training Loss: 1.7456239429750227e-15, Validation Loss: 1.0538003812393584e-14
Epoch 410, Training Loss: 1.792061253758819e-15, Validation Loss: 1.0710674866823162e-14
Epoch 411, Training Loss: 1.4205634027631602e-15, Validation Loss: 1.0207071428033117e-14
Epoch 412, Training Loss: 1.7546978893016028e-15, Validation Loss: 1.0958607339715126e-14
Epoch 413, Training Loss: 1.6037769468916206e-15, Validation Loss: 1.0851187468377283e-14
Epoch 414, Training Loss: 4.1632948377299216e-15, Validation Loss: 1.115863417020923e-14
Epoch 415, Training Loss: 4.3694601159927765e-15, Validation Loss: 1.1273793381586135e-14
Epoch 416, Training Loss: 4.085899319756928e-15, Validation Loss: 9.313555853732343e-15
Epoch 417, Training Loss: 2.5330549933793006e-15, Validation Loss: 6.536663368244579e-15
Epoch 418, Training Loss: 2.4935565764994116e-15, Validation Loss: 6.573092561240092e-15
Epoch 419, Training Loss: 2.1843755747079623e-15, Validation Loss: 6.563218274657475e-15
Epoch 420, Training Loss: 2.2384188178416285e-15, Validation Loss: 5.818621256879373e-15
Epoch 421, Training Loss: 2.0536040638055022e-15, Validation Loss: 6.5067728460853954e-15
Epoch 422, Training Loss: 2.289793271916733e-15, Validation Loss: 5.872931738907898e-15
Epoch 423, Training Loss: 2.7787184767638076e-15, Validation Loss: 5.735755176616538e-15
Epoch 424, Training Loss: 2.730680061951464e-15, Validation Loss: 5.759774066385354e-15
Epoch 425, Training Loss: 1.6019088157264512e-15, Validation Loss: 5.727481782304231e-15
Epoch 426, Training Loss: 1.5458638219801864e-15, Validation Loss: 6.110989078184298e-15
Epoch 427, Training Loss: 1.5451966776551052e-15, Validation Loss: 6.104316999658776e-15
Epoch 428, Training Loss: 1.1668934463238503e-15, Validation Loss: 5.956198465754785e-15
Epoch 429, Training Loss: 1.0554708149146386e-15, Validation Loss: 6.048272217670748e-15
Epoch 430, Training Loss: 2.455926502542929e-15, Validation Loss: 5.9094943395926035e-15
Epoch 431, Training Loss: 9.887507708132462e-16, Validation Loss: 6.3490464174606985e-15
Epoch 432, Training Loss: 1.1432745678643746e-15, Validation Loss: 5.9257738893223576e-15
Epoch 433, Training Loss: 9.291029224258352e-16, Validation Loss: 6.708400992366283e-15
Epoch 434, Training Loss: 8.670532062373662e-16, Validation Loss: 6.735089306468371e-15
Epoch 435, Training Loss: 8.670532062373662e-16, Validation Loss: 6.747098963111016e-15
Epoch 436, Training Loss: 1.476208067562729e-15, Validation Loss: 6.859188527087072e-15
Epoch 437, Training Loss: 1.4895520128555364e-15, Validation Loss: 6.8615907125254855e-15
Epoch 438, Training Loss: 1.4895520128555364e-15, Validation Loss: 6.906426284006024e-15
Epoch 439, Training Loss: 1.3965441953569884e-15, Validation Loss: 6.8487801862312115e-15
Epoch 440, Training Loss: 1.4308383359298285e-15, Validation Loss: 6.7420282003722784e-15
Epoch 441, Training Loss: 1.4788768566212905e-15, Validation Loss: 6.761243566297216e-15
Epoch 442, Training Loss: 2.1288644234767045e-15, Validation Loss: 7.522120133805071e-15
Epoch 443, Training Loss: 9.950224145129538e-16, Validation Loss: 7.344377046087334e-15
Epoch 444, Training Loss: 1.19598341646876e-15, Validation Loss: 6.579764639765614e-15
Epoch 445, Training Loss: 8.350275257763915e-16, Validation Loss: 6.202395791654299e-15
Epoch 446, Training Loss: 1.1411395154417017e-15, Validation Loss: 6.211736447480146e-15
Epoch 447, Training Loss: 1.4742064228292487e-15, Validation Loss: 6.1877171341948554e-15
Epoch 448, Training Loss: 1.7735129262798442e-15, Validation Loss: 7.216408155449102e-15
Epoch 449, Training Loss: 1.5732190686491192e-15, Validation Loss: 7.140880768641278e-15
Epoch 450, Training Loss: 1.5540037027241818e-15, Validation Loss: 7.230285943256917e-15
Epoch 451, Training Loss: 9.970240592464341e-16, Validation Loss: 7.21961078702267e-15
Epoch 452, Training Loss: 9.804773765009398e-16, Validation Loss: 7.488626757004742e-15
Epoch 453, Training Loss: 9.831462714386197e-16, Validation Loss: 7.537999460467248e-15
Epoch 454, Training Loss: 5.909652522995503e-16, Validation Loss: 9.118465531254838e-15
Epoch 455, Training Loss: 6.855744385244418e-16, Validation Loss: 9.139816690756277e-15
Epoch 456, Training Loss: 5.550698488794852e-16, Validation Loss: 8.398155489173359e-15
Epoch 457, Training Loss: 5.015602894421485e-16, Validation Loss: 8.551611601194473e-15
Epoch 458, Training Loss: 5.776212540671837e-16, Validation Loss: 8.598315303840181e-15
Epoch 459, Training Loss: 5.355875616970443e-16, Validation Loss: 5.6020476377606574e-15
Epoch 460, Training Loss: 5.023609473355406e-16, Validation Loss: 5.5860349034092885e-15
Epoch 461, Training Loss: 3.860010138163428e-16, Validation Loss: 5.641279239262161e-15
Epoch 462, Training Loss: 3.7612643606615016e-16, Validation Loss: 5.686115234259173e-15
Epoch 463, Training Loss: 3.7612643606615016e-16, Validation Loss: 5.6308708984063e-15
Epoch 464, Training Loss: 4.054832745290041e-16, Validation Loss: 6.027188720580641e-15
Epoch 465, Training Loss: 7.101274355060614e-16, Validation Loss: 6.091239657986117e-15
Epoch 466, Training Loss: 7.101274355060614e-16, Validation Loss: 4.8893435280290484e-15
Epoch 467, Training Loss: 7.021210153908177e-16, Validation Loss: 4.875331909015568e-15
Epoch 468, Training Loss: 1.4244331786618099e-15, Validation Loss: 6.6487533557371085e-15
Epoch 469, Training Loss: 7.278749992125255e-16, Validation Loss: 6.263111113313487e-15
Epoch 470, Training Loss: 7.045229361314349e-16, Validation Loss: 6.120329734010145e-15
Epoch 471, Training Loss: 6.981177788634163e-16, Validation Loss: 6.120329734010145e-15
Epoch 472, Training Loss: 7.107946327707018e-16, Validation Loss: 6.120329734010145e-15
Epoch 473, Training Loss: 7.107946327707018e-16, Validation Loss: 6.120329734010145e-15
Epoch 474, Training Loss: 7.198685790972819e-16, Validation Loss: 6.1339407064395744e-15
Epoch 475, Training Loss: 7.198685790972819e-16, Validation Loss: 6.155291018908066e-15
Epoch 476, Training Loss: 7.091933699234767e-16, Validation Loss: 6.155291018908066e-15
Epoch 477, Training Loss: 7.029216732842099e-16, Validation Loss: 6.1846479103104795e-15
Epoch 478, Training Loss: 9.627298127944757e-16, Validation Loss: 6.214271617091278e-15
Epoch 479, Training Loss: 1.2739125651985237e-15, Validation Loss: 6.3703967299291904e-15
Epoch 480, Training Loss: 5.678801104759632e-16, Validation Loss: 6.3877439646889585e-15
Epoch 481, Training Loss: 5.678801104759632e-16, Validation Loss: 6.3877439646889585e-15
Epoch 482, Training Loss: 8.826657175211574e-16, Validation Loss: 6.549206655643994e-15
Epoch 483, Training Loss: 9.120226089235706e-16, Validation Loss: 6.549206655643994e-15
Epoch 484, Training Loss: 5.939009626156153e-16, Validation Loss: 6.549206655643994e-15
Epoch 485, Training Loss: 5.905649233528543e-16, Validation Loss: 6.549206655643994e-15
Epoch 486, Training Loss: 2.5055912206140007e-16, Validation Loss: 6.549206655643994e-15
Epoch 487, Training Loss: 2.5055912206140007e-16, Validation Loss: 6.549206655643994e-15
Epoch 488, Training Loss: 2.5055912206140007e-16, Validation Loss: 6.549206655643994e-15
Epoch 489, Training Loss: 5.553367171974295e-16, Validation Loss: 6.574026838580913e-15
Epoch 490, Training Loss: 5.653447291065943e-16, Validation Loss: 6.574026838580913e-15
Epoch 491, Training Loss: 5.653447291065943e-16, Validation Loss: 6.574026838580913e-15
Epoch 492, Training Loss: 2.5789834491200337e-16, Validation Loss: 6.5927085737490804e-15
Epoch 493, Training Loss: 2.5789834491200337e-16, Validation Loss: 6.5927085737490804e-15
Epoch 494, Training Loss: 2.4829063547975505e-16, Validation Loss: 6.5927085737490804e-15
Epoch 495, Training Loss: 2.4829063547975505e-16, Validation Loss: 6.561350143492305e-15
Epoch 496, Training Loss: 5.557370461441256e-16, Validation Loss: 6.561350143492305e-15
Epoch 497, Training Loss: 5.557370461441256e-16, Validation Loss: 6.561350143492305e-15
Epoch 498, Training Loss: 5.557370461441256e-16, Validation Loss: 6.561350143492305e-15
Epoch 499, Training Loss: 5.605408876253599e-16, Validation Loss: 6.561350143492305e-15
Epoch 500, Training Loss: 5.853607529249238e-16, Validation Loss: 6.561350143492305e-15
