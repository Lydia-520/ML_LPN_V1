Epoch 1, Training Loss: 0.2825302481651306, Validation Loss: 0.25419220328330994
Epoch 2, Training Loss: 0.28147566318511963, Validation Loss: 0.2531915605068207
Epoch 3, Training Loss: 0.2804502546787262, Validation Loss: 0.2522067427635193
Epoch 4, Training Loss: 0.2794433832168579, Validation Loss: 0.2512596845626831
Epoch 5, Training Loss: 0.2784700095653534, Validation Loss: 0.25033217668533325
Epoch 6, Training Loss: 0.2775155007839203, Validation Loss: 0.24941405653953552
Epoch 7, Training Loss: 0.27657097578048706, Validation Loss: 0.24849838018417358
Epoch 8, Training Loss: 0.2756240963935852, Validation Loss: 0.24757052958011627
Epoch 9, Training Loss: 0.27466580271720886, Validation Loss: 0.24663443863391876
Epoch 10, Training Loss: 0.2736990451812744, Validation Loss: 0.24569006264209747
Epoch 11, Training Loss: 0.2727217674255371, Validation Loss: 0.2447275072336197
Epoch 12, Training Loss: 0.2717287540435791, Validation Loss: 0.24374547600746155
Epoch 13, Training Loss: 0.27071428298950195, Validation Loss: 0.24274654686450958
Epoch 14, Training Loss: 0.2696814239025116, Validation Loss: 0.24172784388065338
Epoch 15, Training Loss: 0.2686311602592468, Validation Loss: 0.2406826615333557
Epoch 16, Training Loss: 0.2675522267818451, Validation Loss: 0.2396029531955719
Epoch 17, Training Loss: 0.26644644141197205, Validation Loss: 0.23848718404769897
Epoch 18, Training Loss: 0.2653065621852875, Validation Loss: 0.23733732104301453
Epoch 19, Training Loss: 0.2641340494155884, Validation Loss: 0.23616120219230652
Epoch 20, Training Loss: 0.2629414498806, Validation Loss: 0.23497341573238373
Epoch 21, Training Loss: 0.26174020767211914, Validation Loss: 0.23374363780021667
Epoch 22, Training Loss: 0.2605096399784088, Validation Loss: 0.2324686199426651
Epoch 23, Training Loss: 0.25924405455589294, Validation Loss: 0.23117032647132874
Epoch 24, Training Loss: 0.2579503655433655, Validation Loss: 0.22981923818588257
Epoch 25, Training Loss: 0.2566036880016327, Validation Loss: 0.22839835286140442
Epoch 26, Training Loss: 0.25519734621047974, Validation Loss: 0.2269153743982315
Epoch 27, Training Loss: 0.25374889373779297, Validation Loss: 0.22534477710723877
Epoch 28, Training Loss: 0.25221914052963257, Validation Loss: 0.2237137407064438
Epoch 29, Training Loss: 0.25061362981796265, Validation Loss: 0.22198858857154846
Epoch 30, Training Loss: 0.24891358613967896, Validation Loss: 0.22015824913978577
Epoch 31, Training Loss: 0.2471187561750412, Validation Loss: 0.21822386980056763
Epoch 32, Training Loss: 0.24521617591381073, Validation Loss: 0.21616335213184357
Epoch 33, Training Loss: 0.2431899607181549, Validation Loss: 0.21398402750492096
Epoch 34, Training Loss: 0.24104224145412445, Validation Loss: 0.21167205274105072
Epoch 35, Training Loss: 0.23875971138477325, Validation Loss: 0.2092113196849823
Epoch 36, Training Loss: 0.23631654679775238, Validation Loss: 0.20659783482551575
Epoch 37, Training Loss: 0.23371000587940216, Validation Loss: 0.20381082594394684
Epoch 38, Training Loss: 0.23092161118984222, Validation Loss: 0.20085766911506653
Epoch 39, Training Loss: 0.22793824970722198, Validation Loss: 0.19772396981716156
Epoch 40, Training Loss: 0.22474195063114166, Validation Loss: 0.19438941776752472
Epoch 41, Training Loss: 0.22133226692676544, Validation Loss: 0.19085921347141266
Epoch 42, Training Loss: 0.21771538257598877, Validation Loss: 0.18711945414543152
Epoch 43, Training Loss: 0.21388447284698486, Validation Loss: 0.18317516148090363
Epoch 44, Training Loss: 0.20984390377998352, Validation Loss: 0.17904244363307953
Epoch 45, Training Loss: 0.2056136578321457, Validation Loss: 0.17473316192626953
Epoch 46, Training Loss: 0.20120210945606232, Validation Loss: 0.17027616500854492
Epoch 47, Training Loss: 0.19661574065685272, Validation Loss: 0.1656932532787323
Epoch 48, Training Loss: 0.19185686111450195, Validation Loss: 0.16104070842266083
Epoch 49, Training Loss: 0.1869945377111435, Validation Loss: 0.15637926757335663
Epoch 50, Training Loss: 0.18208295106887817, Validation Loss: 0.15179860591888428
Epoch 51, Training Loss: 0.1771969497203827, Validation Loss: 0.14740565419197083
Epoch 52, Training Loss: 0.1724247932434082, Validation Loss: 0.14331702888011932
Epoch 53, Training Loss: 0.16788718104362488, Validation Loss: 0.13963592052459717
Epoch 54, Training Loss: 0.1636824607849121, Validation Loss: 0.13650546967983246
Epoch 55, Training Loss: 0.15993285179138184, Validation Loss: 0.1340469866991043
Epoch 56, Training Loss: 0.15676575899124146, Validation Loss: 0.13231202960014343
Epoch 57, Training Loss: 0.15424266457557678, Validation Loss: 0.13126905262470245
Epoch 58, Training Loss: 0.15233050286769867, Validation Loss: 0.1307823657989502
Epoch 59, Training Loss: 0.15092885494232178, Validation Loss: 0.1306469738483429
Epoch 60, Training Loss: 0.1498676985502243, Validation Loss: 0.13058564066886902
Epoch 61, Training Loss: 0.14890480041503906, Validation Loss: 0.1303074210882187
Epoch 62, Training Loss: 0.14779409766197205, Validation Loss: 0.12963251769542694
Epoch 63, Training Loss: 0.1463984102010727, Validation Loss: 0.12854963541030884
Epoch 64, Training Loss: 0.14471037685871124, Validation Loss: 0.12711456418037415
Epoch 65, Training Loss: 0.14276166260242462, Validation Loss: 0.12542690336704254
Epoch 66, Training Loss: 0.14063625037670135, Validation Loss: 0.12363364547491074
Epoch 67, Training Loss: 0.1384650468826294, Validation Loss: 0.12186918407678604
Epoch 68, Training Loss: 0.13636484742164612, Validation Loss: 0.12024352699518204
Epoch 69, Training Loss: 0.13442854583263397, Validation Loss: 0.11882929503917694
Epoch 70, Training Loss: 0.13271646201610565, Validation Loss: 0.11765460669994354
Epoch 71, Training Loss: 0.13126003742218018, Validation Loss: 0.1166963279247284
Epoch 72, Training Loss: 0.13004927337169647, Validation Loss: 0.1158810406923294
Epoch 73, Training Loss: 0.1289956122636795, Validation Loss: 0.1152176707983017
Epoch 74, Training Loss: 0.12806400656700134, Validation Loss: 0.11471755802631378
Epoch 75, Training Loss: 0.12721586227416992, Validation Loss: 0.11431532353162766
Epoch 76, Training Loss: 0.12642867863178253, Validation Loss: 0.11398183554410934
Epoch 77, Training Loss: 0.12566950917243958, Validation Loss: 0.11369624733924866
Epoch 78, Training Loss: 0.12492775171995163, Validation Loss: 0.11345057934522629
Epoch 79, Training Loss: 0.12419750541448593, Validation Loss: 0.11325377970933914
Epoch 80, Training Loss: 0.12348982691764832, Validation Loss: 0.11309991031885147
Epoch 81, Training Loss: 0.12281236052513123, Validation Loss: 0.11299823224544525
Epoch 82, Training Loss: 0.12217391282320023, Validation Loss: 0.11296889185905457
Epoch 83, Training Loss: 0.12159324437379837, Validation Loss: 0.11299898475408554
Epoch 84, Training Loss: 0.12107377499341965, Validation Loss: 0.1130765900015831
Epoch 85, Training Loss: 0.12064380198717117, Validation Loss: 0.1131916418671608
Epoch 86, Training Loss: 0.1202700212597847, Validation Loss: 0.11331261694431305
Epoch 87, Training Loss: 0.11993787437677383, Validation Loss: 0.11341819912195206
Epoch 88, Training Loss: 0.11962790787220001, Validation Loss: 0.1134849339723587
Epoch 89, Training Loss: 0.11932113021612167, Validation Loss: 0.11350783705711365
Epoch 90, Training Loss: 0.11901047825813293, Validation Loss: 0.11348418146371841
Epoch 91, Training Loss: 0.11869417876005173, Validation Loss: 0.11340847611427307
Epoch 92, Training Loss: 0.11836547404527664, Validation Loss: 0.11329160630702972
Epoch 93, Training Loss: 0.11803293973207474, Validation Loss: 0.11315084993839264
Epoch 94, Training Loss: 0.11770108342170715, Validation Loss: 0.11300138384103775
Epoch 95, Training Loss: 0.11737570911645889, Validation Loss: 0.11285460740327835
Epoch 96, Training Loss: 0.11706183850765228, Validation Loss: 0.11272583901882172
Epoch 97, Training Loss: 0.11676869541406631, Validation Loss: 0.112611785531044
Epoch 98, Training Loss: 0.11648785322904587, Validation Loss: 0.11251523345708847
Epoch 99, Training Loss: 0.11621563881635666, Validation Loss: 0.11243034154176712
Epoch 100, Training Loss: 0.11594568938016891, Validation Loss: 0.11235484480857849
Epoch 101, Training Loss: 0.11567602306604385, Validation Loss: 0.11229009926319122
Epoch 102, Training Loss: 0.11540509015321732, Validation Loss: 0.11223858594894409
Epoch 103, Training Loss: 0.11512835323810577, Validation Loss: 0.11219535768032074
Epoch 104, Training Loss: 0.11485131084918976, Validation Loss: 0.11215461790561676
Epoch 105, Training Loss: 0.11457235366106033, Validation Loss: 0.11211782693862915
Epoch 106, Training Loss: 0.11429660767316818, Validation Loss: 0.11208155006170273
Epoch 107, Training Loss: 0.11402647942304611, Validation Loss: 0.11204246431589127
Epoch 108, Training Loss: 0.11375938355922699, Validation Loss: 0.11199885606765747
Epoch 109, Training Loss: 0.11349549889564514, Validation Loss: 0.11194998770952225
Epoch 110, Training Loss: 0.1132374033331871, Validation Loss: 0.11188855767250061
Epoch 111, Training Loss: 0.11297894269227982, Validation Loss: 0.11181554943323135
Epoch 112, Training Loss: 0.11272025853395462, Validation Loss: 0.11173352599143982
Epoch 113, Training Loss: 0.11246015131473541, Validation Loss: 0.11163913458585739
Epoch 114, Training Loss: 0.11219679564237595, Validation Loss: 0.11153525859117508
Epoch 115, Training Loss: 0.1119302287697792, Validation Loss: 0.11141607910394669
Epoch 116, Training Loss: 0.11165867000818253, Validation Loss: 0.11129000037908554
Epoch 117, Training Loss: 0.1113833487033844, Validation Loss: 0.11116013675928116
Epoch 118, Training Loss: 0.11111538857221603, Validation Loss: 0.111033134162426
Epoch 119, Training Loss: 0.1108567863702774, Validation Loss: 0.11091325432062149
Epoch 120, Training Loss: 0.11059240251779556, Validation Loss: 0.11080371588468552
Epoch 121, Training Loss: 0.11031917482614517, Validation Loss: 0.11070457845926285
Epoch 122, Training Loss: 0.11004243791103363, Validation Loss: 0.11060664057731628
Epoch 123, Training Loss: 0.10977394878864288, Validation Loss: 0.1105167344212532
Epoch 124, Training Loss: 0.10950616747140884, Validation Loss: 0.11042866855859756
Epoch 125, Training Loss: 0.109233558177948, Validation Loss: 0.11034546047449112
Epoch 126, Training Loss: 0.10896534472703934, Validation Loss: 0.11025191098451614
Epoch 127, Training Loss: 0.10869207233190536, Validation Loss: 0.11015298217535019
Epoch 128, Training Loss: 0.1084253117442131, Validation Loss: 0.11006394028663635
Epoch 129, Training Loss: 0.10815749317407608, Validation Loss: 0.10996963828802109
Epoch 130, Training Loss: 0.10787788033485413, Validation Loss: 0.10987478494644165
Epoch 131, Training Loss: 0.10759057104587555, Validation Loss: 0.10977593064308167
Epoch 132, Training Loss: 0.10730845481157303, Validation Loss: 0.10967201739549637
Epoch 133, Training Loss: 0.10701878368854523, Validation Loss: 0.1095631793141365
Epoch 134, Training Loss: 0.10672499984502792, Validation Loss: 0.10944274067878723
Epoch 135, Training Loss: 0.10643002390861511, Validation Loss: 0.10931389778852463
Epoch 136, Training Loss: 0.10612505674362183, Validation Loss: 0.10916820168495178
Epoch 137, Training Loss: 0.10580620169639587, Validation Loss: 0.10900583863258362
Epoch 138, Training Loss: 0.10548029094934464, Validation Loss: 0.1088380292057991
Epoch 139, Training Loss: 0.10516149550676346, Validation Loss: 0.10866136103868484
Epoch 140, Training Loss: 0.1048329621553421, Validation Loss: 0.10847450792789459
Epoch 141, Training Loss: 0.10448949784040451, Validation Loss: 0.10826252400875092
Epoch 142, Training Loss: 0.10413537919521332, Validation Loss: 0.10801799595355988
Epoch 143, Training Loss: 0.10375550389289856, Validation Loss: 0.1077582985162735
Epoch 144, Training Loss: 0.10336203128099442, Validation Loss: 0.10752299427986145
Epoch 145, Training Loss: 0.1029791533946991, Validation Loss: 0.10731031745672226
Epoch 146, Training Loss: 0.10260384529829025, Validation Loss: 0.10708881914615631
Epoch 147, Training Loss: 0.10220582783222198, Validation Loss: 0.1068408340215683
Epoch 148, Training Loss: 0.1017918810248375, Validation Loss: 0.10658875107765198
Epoch 149, Training Loss: 0.1013917401432991, Validation Loss: 0.10629898309707642
Epoch 150, Training Loss: 0.1009715348482132, Validation Loss: 0.10598541796207428
Epoch 151, Training Loss: 0.10053286701440811, Validation Loss: 0.1056249737739563
Epoch 152, Training Loss: 0.1000574603676796, Validation Loss: 0.1052638441324234
Epoch 153, Training Loss: 0.09957069903612137, Validation Loss: 0.10487384349107742
Epoch 154, Training Loss: 0.09905976802110672, Validation Loss: 0.10446317493915558
Epoch 155, Training Loss: 0.09852726757526398, Validation Loss: 0.10401525348424911
Epoch 156, Training Loss: 0.09795715659856796, Validation Loss: 0.10353631526231766
Epoch 157, Training Loss: 0.09736596792936325, Validation Loss: 0.1030300036072731
Epoch 158, Training Loss: 0.09676018357276917, Validation Loss: 0.10249403119087219
Epoch 159, Training Loss: 0.09612804651260376, Validation Loss: 0.10192396491765976
Epoch 160, Training Loss: 0.0954742282629013, Validation Loss: 0.10131141543388367
Epoch 161, Training Loss: 0.09478771686553955, Validation Loss: 0.10066210478544235
Epoch 162, Training Loss: 0.09406568855047226, Validation Loss: 0.0999949723482132
Epoch 163, Training Loss: 0.09333401173353195, Validation Loss: 0.09931023418903351
Epoch 164, Training Loss: 0.09258142113685608, Validation Loss: 0.09861250221729279
Epoch 165, Training Loss: 0.0917944386601448, Validation Loss: 0.09786748886108398
Epoch 166, Training Loss: 0.0910017341375351, Validation Loss: 0.09708463400602341
Epoch 167, Training Loss: 0.09017812460660934, Validation Loss: 0.09628384560346603
Epoch 168, Training Loss: 0.0893460288643837, Validation Loss: 0.09549937397241592
Epoch 169, Training Loss: 0.0884946882724762, Validation Loss: 0.09474071860313416
Epoch 170, Training Loss: 0.08763926476240158, Validation Loss: 0.09396199136972427
Epoch 171, Training Loss: 0.08676766604185104, Validation Loss: 0.09317086637020111
Epoch 172, Training Loss: 0.08588599413633347, Validation Loss: 0.0923621654510498
Epoch 173, Training Loss: 0.0849807932972908, Validation Loss: 0.09151673316955566
Epoch 174, Training Loss: 0.08407916128635406, Validation Loss: 0.09066453576087952
Epoch 175, Training Loss: 0.08315873146057129, Validation Loss: 0.08979174494743347
Epoch 176, Training Loss: 0.08225598931312561, Validation Loss: 0.08890428394079208
Epoch 177, Training Loss: 0.08133216202259064, Validation Loss: 0.08800235390663147
Epoch 178, Training Loss: 0.08040135353803635, Validation Loss: 0.0871434211730957
Epoch 179, Training Loss: 0.07946398109197617, Validation Loss: 0.08625656366348267
Epoch 180, Training Loss: 0.07853453606367111, Validation Loss: 0.0853637233376503
Epoch 181, Training Loss: 0.07762160897254944, Validation Loss: 0.0844535231590271
Epoch 182, Training Loss: 0.07670831680297852, Validation Loss: 0.08352304995059967
Epoch 183, Training Loss: 0.07579758763313293, Validation Loss: 0.08260630816221237
Epoch 184, Training Loss: 0.07487493753433228, Validation Loss: 0.08171166479587555
Epoch 185, Training Loss: 0.07395179569721222, Validation Loss: 0.08082294464111328
Epoch 186, Training Loss: 0.07300230115652084, Validation Loss: 0.07992830872535706
Epoch 187, Training Loss: 0.07207484543323517, Validation Loss: 0.07903774082660675
Epoch 188, Training Loss: 0.07119312137365341, Validation Loss: 0.07814545184373856
Epoch 189, Training Loss: 0.07035274058580399, Validation Loss: 0.07732389867305756
Epoch 190, Training Loss: 0.06951998919248581, Validation Loss: 0.07651662081480026
Epoch 191, Training Loss: 0.0686742290854454, Validation Loss: 0.07571326196193695
Epoch 192, Training Loss: 0.06780719012022018, Validation Loss: 0.0748620331287384
Epoch 193, Training Loss: 0.06694576889276505, Validation Loss: 0.07398393005132675
Epoch 194, Training Loss: 0.06606914848089218, Validation Loss: 0.07309583574533463
Epoch 195, Training Loss: 0.06517616659402847, Validation Loss: 0.07227426767349243
Epoch 196, Training Loss: 0.06427933275699615, Validation Loss: 0.07144959270954132
Epoch 197, Training Loss: 0.06335756927728653, Validation Loss: 0.07057547569274902
Epoch 198, Training Loss: 0.06240670382976532, Validation Loss: 0.06966464221477509
Epoch 199, Training Loss: 0.06143208593130112, Validation Loss: 0.06875266879796982
Epoch 200, Training Loss: 0.060439616441726685, Validation Loss: 0.06785038858652115
Epoch 201, Training Loss: 0.059423111379146576, Validation Loss: 0.06694086641073227
Epoch 202, Training Loss: 0.05840783566236496, Validation Loss: 0.06603718549013138
Epoch 203, Training Loss: 0.05740043893456459, Validation Loss: 0.06521545350551605
Epoch 204, Training Loss: 0.05638251081109047, Validation Loss: 0.06438799202442169
Epoch 205, Training Loss: 0.05536617711186409, Validation Loss: 0.0634516030550003
Epoch 206, Training Loss: 0.054345473647117615, Validation Loss: 0.062484368681907654
Epoch 207, Training Loss: 0.05332518741488457, Validation Loss: 0.061538707464933395
Epoch 208, Training Loss: 0.05231998860836029, Validation Loss: 0.06064344570040703
Epoch 209, Training Loss: 0.051339153200387955, Validation Loss: 0.059734832495450974
Epoch 210, Training Loss: 0.05039346590638161, Validation Loss: 0.0588238500058651
Epoch 211, Training Loss: 0.04945168271660805, Validation Loss: 0.057927194982767105
Epoch 212, Training Loss: 0.04852085933089256, Validation Loss: 0.05706595629453659
Epoch 213, Training Loss: 0.04761211946606636, Validation Loss: 0.056207772344350815
Epoch 214, Training Loss: 0.04673837497830391, Validation Loss: 0.05530943349003792
Epoch 215, Training Loss: 0.045875728130340576, Validation Loss: 0.054406218230724335
Epoch 216, Training Loss: 0.04503394663333893, Validation Loss: 0.05347657576203346
Epoch 217, Training Loss: 0.044213131070137024, Validation Loss: 0.05254116654396057
Epoch 218, Training Loss: 0.043398547917604446, Validation Loss: 0.051559384912252426
Epoch 219, Training Loss: 0.04260212928056717, Validation Loss: 0.05057862773537636
Epoch 220, Training Loss: 0.041823454201221466, Validation Loss: 0.04962775483727455
Epoch 221, Training Loss: 0.04108076170086861, Validation Loss: 0.04864662513136864
Epoch 222, Training Loss: 0.04034121334552765, Validation Loss: 0.04761526361107826
Epoch 223, Training Loss: 0.039585985243320465, Validation Loss: 0.046568043529987335
Epoch 224, Training Loss: 0.03885027393698692, Validation Loss: 0.04554884508252144
Epoch 225, Training Loss: 0.03813068941235542, Validation Loss: 0.04457280784845352
Epoch 226, Training Loss: 0.03742477670311928, Validation Loss: 0.04361516237258911
Epoch 227, Training Loss: 0.036751143634319305, Validation Loss: 0.04265240579843521
Epoch 228, Training Loss: 0.03606950864195824, Validation Loss: 0.04166568070650101
Epoch 229, Training Loss: 0.03539144620299339, Validation Loss: 0.040672432631254196
Epoch 230, Training Loss: 0.03472704812884331, Validation Loss: 0.039679981768131256
Epoch 231, Training Loss: 0.03406108543276787, Validation Loss: 0.038754161447286606
Epoch 232, Training Loss: 0.03342693671584129, Validation Loss: 0.037850212305784225
Epoch 233, Training Loss: 0.03281106799840927, Validation Loss: 0.03694385290145874
Epoch 234, Training Loss: 0.03219766542315483, Validation Loss: 0.03607744723558426
Epoch 235, Training Loss: 0.03160930424928665, Validation Loss: 0.03525713458657265
Epoch 236, Training Loss: 0.03105568327009678, Validation Loss: 0.03446604311466217
Epoch 237, Training Loss: 0.030511045828461647, Validation Loss: 0.033710282295942307
Epoch 238, Training Loss: 0.029986340552568436, Validation Loss: 0.03296784311532974
Epoch 239, Training Loss: 0.029489940032362938, Validation Loss: 0.03224807232618332
Epoch 240, Training Loss: 0.02901003137230873, Validation Loss: 0.031555213034152985
Epoch 241, Training Loss: 0.028536653146147728, Validation Loss: 0.030875926837325096
Epoch 242, Training Loss: 0.02808569371700287, Validation Loss: 0.0302346870303154
Epoch 243, Training Loss: 0.02766706421971321, Validation Loss: 0.02965494804084301
Epoch 244, Training Loss: 0.027262959629297256, Validation Loss: 0.029109224677085876
Epoch 245, Training Loss: 0.026868004351854324, Validation Loss: 0.02857760153710842
Epoch 246, Training Loss: 0.02650500275194645, Validation Loss: 0.028041977435350418
Epoch 247, Training Loss: 0.02615308202803135, Validation Loss: 0.027490250766277313
Epoch 248, Training Loss: 0.02580653876066208, Validation Loss: 0.026930678635835648
Epoch 249, Training Loss: 0.025461990386247635, Validation Loss: 0.02639198489487171
Epoch 250, Training Loss: 0.02512289583683014, Validation Loss: 0.025868911296129227
Epoch 251, Training Loss: 0.024778390303254128, Validation Loss: 0.025381211191415787
Epoch 252, Training Loss: 0.02444218285381794, Validation Loss: 0.024878237396478653
Epoch 253, Training Loss: 0.02408948913216591, Validation Loss: 0.024406231939792633
Epoch 254, Training Loss: 0.02376994863152504, Validation Loss: 0.023970352485775948
Epoch 255, Training Loss: 0.023465868085622787, Validation Loss: 0.023571589961647987
Epoch 256, Training Loss: 0.023158477619290352, Validation Loss: 0.02319641411304474
Epoch 257, Training Loss: 0.02284887805581093, Validation Loss: 0.022852493450045586
Epoch 258, Training Loss: 0.022565362975001335, Validation Loss: 0.02250933274626732
Epoch 259, Training Loss: 0.02226186729967594, Validation Loss: 0.022183753550052643
Epoch 260, Training Loss: 0.021973170340061188, Validation Loss: 0.021872881799936295
Epoch 261, Training Loss: 0.021681783720850945, Validation Loss: 0.021583084017038345
Epoch 262, Training Loss: 0.02138313092291355, Validation Loss: 0.021316714584827423
Epoch 263, Training Loss: 0.021079663187265396, Validation Loss: 0.021076539531350136
Epoch 264, Training Loss: 0.020786330103874207, Validation Loss: 0.02084396965801716
Epoch 265, Training Loss: 0.020500972867012024, Validation Loss: 0.020609771832823753
Epoch 266, Training Loss: 0.02022165060043335, Validation Loss: 0.020359618589282036
Epoch 267, Training Loss: 0.019940361380577087, Validation Loss: 0.020106181502342224
Epoch 268, Training Loss: 0.019662564620375633, Validation Loss: 0.019850198179483414
Epoch 269, Training Loss: 0.019376615062355995, Validation Loss: 0.019605061039328575
Epoch 270, Training Loss: 0.01908709481358528, Validation Loss: 0.019383469596505165
Epoch 271, Training Loss: 0.018793025985360146, Validation Loss: 0.019149601459503174
Epoch 272, Training Loss: 0.01848950982093811, Validation Loss: 0.01889539510011673
Epoch 273, Training Loss: 0.018185531720519066, Validation Loss: 0.018637945875525475
Epoch 274, Training Loss: 0.01787826046347618, Validation Loss: 0.01837201975286007
Epoch 275, Training Loss: 0.017587164416909218, Validation Loss: 0.01813030242919922
Epoch 276, Training Loss: 0.017300965264439583, Validation Loss: 0.01791752129793167
Epoch 277, Training Loss: 0.017015479505062103, Validation Loss: 0.01770000346004963
Epoch 278, Training Loss: 0.016716262325644493, Validation Loss: 0.017489466816186905
Epoch 279, Training Loss: 0.016416000202298164, Validation Loss: 0.017274942249059677
Epoch 280, Training Loss: 0.016124647110700607, Validation Loss: 0.017041638493537903
Epoch 281, Training Loss: 0.015822216868400574, Validation Loss: 0.016818275675177574
Epoch 282, Training Loss: 0.015525225549936295, Validation Loss: 0.016611559316515923
Epoch 283, Training Loss: 0.015228789299726486, Validation Loss: 0.016413317993283272
Epoch 284, Training Loss: 0.014938808977603912, Validation Loss: 0.016193393617868423
Epoch 285, Training Loss: 0.014645345509052277, Validation Loss: 0.015949759632349014
Epoch 286, Training Loss: 0.01435091719031334, Validation Loss: 0.01568746194243431
Epoch 287, Training Loss: 0.014056538231670856, Validation Loss: 0.015418603084981441
Epoch 288, Training Loss: 0.013764462433755398, Validation Loss: 0.015148963779211044
Epoch 289, Training Loss: 0.01346675306558609, Validation Loss: 0.014868324622511864
Epoch 290, Training Loss: 0.013174958527088165, Validation Loss: 0.014598673209547997
Epoch 291, Training Loss: 0.012894931249320507, Validation Loss: 0.014344490133225918
Epoch 292, Training Loss: 0.012613501399755478, Validation Loss: 0.014105292968451977
Epoch 293, Training Loss: 0.012325852178037167, Validation Loss: 0.013858119025826454
Epoch 294, Training Loss: 0.01204709056764841, Validation Loss: 0.013590551912784576
Epoch 295, Training Loss: 0.011779583990573883, Validation Loss: 0.013317218981683254
Epoch 296, Training Loss: 0.0115070641040802, Validation Loss: 0.013053481467068195
Epoch 297, Training Loss: 0.011240707710385323, Validation Loss: 0.012769931927323341
Epoch 298, Training Loss: 0.010980475693941116, Validation Loss: 0.012489636428654194
Epoch 299, Training Loss: 0.010724939405918121, Validation Loss: 0.01222587376832962
Epoch 300, Training Loss: 0.010473089292645454, Validation Loss: 0.011970944702625275
Epoch 301, Training Loss: 0.010226249694824219, Validation Loss: 0.011732404120266438
Epoch 302, Training Loss: 0.009984368458390236, Validation Loss: 0.011483174748718739
Epoch 303, Training Loss: 0.009744975715875626, Validation Loss: 0.011243700981140137
Epoch 304, Training Loss: 0.009514565579593182, Validation Loss: 0.01098790392279625
Epoch 305, Training Loss: 0.009293834678828716, Validation Loss: 0.01071762852370739
Epoch 306, Training Loss: 0.009070748463273048, Validation Loss: 0.010457353666424751
Epoch 307, Training Loss: 0.008857056498527527, Validation Loss: 0.0101802172139287
Epoch 308, Training Loss: 0.008652190677821636, Validation Loss: 0.009905471466481686
Epoch 309, Training Loss: 0.008459305390715599, Validation Loss: 0.00962568074464798
Epoch 310, Training Loss: 0.008261067792773247, Validation Loss: 0.009365138597786427
Epoch 311, Training Loss: 0.00807120744138956, Validation Loss: 0.009112297557294369
Epoch 312, Training Loss: 0.007890726439654827, Validation Loss: 0.008855258114635944
Epoch 313, Training Loss: 0.007716132327914238, Validation Loss: 0.008581748232245445
Epoch 314, Training Loss: 0.007541865576058626, Validation Loss: 0.008320257067680359
Epoch 315, Training Loss: 0.007373232860118151, Validation Loss: 0.008061443455517292
Epoch 316, Training Loss: 0.007209272589534521, Validation Loss: 0.00782025046646595
Epoch 317, Training Loss: 0.007060436997562647, Validation Loss: 0.007572973147034645
Epoch 318, Training Loss: 0.00690822210162878, Validation Loss: 0.007330595050007105
Epoch 319, Training Loss: 0.006760546006262302, Validation Loss: 0.007105686701834202
Epoch 320, Training Loss: 0.006613590754568577, Validation Loss: 0.006888953968882561
Epoch 321, Training Loss: 0.00647233659401536, Validation Loss: 0.00666195061057806
Epoch 322, Training Loss: 0.006335377227514982, Validation Loss: 0.006451797671616077
Epoch 323, Training Loss: 0.006204316858202219, Validation Loss: 0.00624823896214366
Epoch 324, Training Loss: 0.006074389908462763, Validation Loss: 0.006051369942724705
Epoch 325, Training Loss: 0.005947234574705362, Validation Loss: 0.005859746597707272
Epoch 326, Training Loss: 0.005826118867844343, Validation Loss: 0.005686872638761997
Epoch 327, Training Loss: 0.00571428332477808, Validation Loss: 0.005512325093150139
Epoch 328, Training Loss: 0.005599962547421455, Validation Loss: 0.0053484211675822735
Epoch 329, Training Loss: 0.005490011535584927, Validation Loss: 0.005194082856178284
Epoch 330, Training Loss: 0.005383663810789585, Validation Loss: 0.005028408486396074
Epoch 331, Training Loss: 0.005285989493131638, Validation Loss: 0.004893116652965546
Epoch 332, Training Loss: 0.005180479492992163, Validation Loss: 0.004762267228215933
Epoch 333, Training Loss: 0.005084097385406494, Validation Loss: 0.004607351962476969
Epoch 334, Training Loss: 0.004986335523426533, Validation Loss: 0.004474335815757513
Epoch 335, Training Loss: 0.004896330181509256, Validation Loss: 0.004362061154097319
Epoch 336, Training Loss: 0.004805614240467548, Validation Loss: 0.0042589688673615456
Epoch 337, Training Loss: 0.004717785399407148, Validation Loss: 0.004148098174482584
Epoch 338, Training Loss: 0.004627010319381952, Validation Loss: 0.004039123188704252
Epoch 339, Training Loss: 0.004542389418929815, Validation Loss: 0.003938991576433182
Epoch 340, Training Loss: 0.0044632586650550365, Validation Loss: 0.0038631565403193235
Epoch 341, Training Loss: 0.004390446003526449, Validation Loss: 0.0037682978436350822
Epoch 342, Training Loss: 0.004313734360039234, Validation Loss: 0.003687792457640171
Epoch 343, Training Loss: 0.004244182724505663, Validation Loss: 0.003630720777437091
Epoch 344, Training Loss: 0.0041732182726264, Validation Loss: 0.0035683889873325825
Epoch 345, Training Loss: 0.004105542320758104, Validation Loss: 0.0034800563007593155
Epoch 346, Training Loss: 0.0040356675162911415, Validation Loss: 0.0034080937039107084
Epoch 347, Training Loss: 0.003967394586652517, Validation Loss: 0.0033688137773424387
Epoch 348, Training Loss: 0.00391029566526413, Validation Loss: 0.003309363266453147
Epoch 349, Training Loss: 0.0038488951977342367, Validation Loss: 0.003231616923585534
Epoch 350, Training Loss: 0.0037836262490600348, Validation Loss: 0.0031717722304165363
Epoch 351, Training Loss: 0.0037311313208192587, Validation Loss: 0.003112202975898981
Epoch 352, Training Loss: 0.0036566155031323433, Validation Loss: 0.003088475903496146
Epoch 353, Training Loss: 0.003611903404816985, Validation Loss: 0.0030286856926977634
Epoch 354, Training Loss: 0.0035505120176821947, Validation Loss: 0.0029572988860309124
Epoch 355, Training Loss: 0.0034872558899223804, Validation Loss: 0.0028914862778037786
Epoch 356, Training Loss: 0.0034266551956534386, Validation Loss: 0.0028252005577087402
Epoch 357, Training Loss: 0.00335334287956357, Validation Loss: 0.0027845411095768213
Epoch 358, Training Loss: 0.0033053355291485786, Validation Loss: 0.002713909838348627
Epoch 359, Training Loss: 0.0032362944912165403, Validation Loss: 0.0026568209286779165
Epoch 360, Training Loss: 0.003179658902809024, Validation Loss: 0.002607099711894989
Epoch 361, Training Loss: 0.0031146551482379436, Validation Loss: 0.0025586204137653112
Epoch 362, Training Loss: 0.003055369947105646, Validation Loss: 0.002503317315131426
Epoch 363, Training Loss: 0.0029942383989691734, Validation Loss: 0.0024392735213041306
Epoch 364, Training Loss: 0.002930324524641037, Validation Loss: 0.0023864496033638716
Epoch 365, Training Loss: 0.0028708407189697027, Validation Loss: 0.002329175127670169
Epoch 366, Training Loss: 0.002814539708197117, Validation Loss: 0.0022837857250124216
Epoch 367, Training Loss: 0.002760163974016905, Validation Loss: 0.002226470271125436
Epoch 368, Training Loss: 0.0027006843592971563, Validation Loss: 0.00217628525570035
Epoch 369, Training Loss: 0.002648930298164487, Validation Loss: 0.00212671747431159
Epoch 370, Training Loss: 0.0025919887702912092, Validation Loss: 0.0020923817064613104
Epoch 371, Training Loss: 0.0025412801187485456, Validation Loss: 0.0020354290027171373
Epoch 372, Training Loss: 0.002477528527379036, Validation Loss: 0.001993293408304453
Epoch 373, Training Loss: 0.0024260457139462233, Validation Loss: 0.0019570414442569017
Epoch 374, Training Loss: 0.0023690734524279833, Validation Loss: 0.0019105880055576563
Epoch 375, Training Loss: 0.002313695615157485, Validation Loss: 0.0018712764140218496
Epoch 376, Training Loss: 0.0022586220875382423, Validation Loss: 0.0018299658549949527
Epoch 377, Training Loss: 0.0022051138803362846, Validation Loss: 0.0017796293832361698
Epoch 378, Training Loss: 0.0021494929678738117, Validation Loss: 0.0017364408122375607
Epoch 379, Training Loss: 0.002096888143569231, Validation Loss: 0.0016928944969549775
Epoch 380, Training Loss: 0.002049392554908991, Validation Loss: 0.0016579930670559406
Epoch 381, Training Loss: 0.0020005248952656984, Validation Loss: 0.0016126540722325444
Epoch 382, Training Loss: 0.0019485220545902848, Validation Loss: 0.0015714869368821383
Epoch 383, Training Loss: 0.0019020584877580404, Validation Loss: 0.0015269297873601317
Epoch 384, Training Loss: 0.0018428928451612592, Validation Loss: 0.0014958352549001575
Epoch 385, Training Loss: 0.0018004501471295953, Validation Loss: 0.0014437761856243014
Epoch 386, Training Loss: 0.0017494703643023968, Validation Loss: 0.0014005184639245272
Epoch 387, Training Loss: 0.0017008217982947826, Validation Loss: 0.0013680084375664592
Epoch 388, Training Loss: 0.0016538107302039862, Validation Loss: 0.0013164323754608631
Epoch 389, Training Loss: 0.0016026926459744573, Validation Loss: 0.0012702386593446136
Epoch 390, Training Loss: 0.0015551717951893806, Validation Loss: 0.001233275979757309
Epoch 391, Training Loss: 0.001509539783000946, Validation Loss: 0.0011837668716907501
Epoch 392, Training Loss: 0.0014565098099410534, Validation Loss: 0.0011487985029816628
Epoch 393, Training Loss: 0.0014125665184110403, Validation Loss: 0.0011137379333376884
Epoch 394, Training Loss: 0.0013688725885003805, Validation Loss: 0.0010705719469115138
Epoch 395, Training Loss: 0.0013237394159659743, Validation Loss: 0.0010299526620656252
Epoch 396, Training Loss: 0.001274589914828539, Validation Loss: 0.000999159412458539
Epoch 397, Training Loss: 0.0012353328056633472, Validation Loss: 0.0009559427853673697
Epoch 398, Training Loss: 0.0011916642542928457, Validation Loss: 0.0009185145027004182
Epoch 399, Training Loss: 0.001149146119132638, Validation Loss: 0.0008888150914572179
Epoch 400, Training Loss: 0.0011091222986578941, Validation Loss: 0.0008508378523401916
Epoch 401, Training Loss: 0.0010647585149854422, Validation Loss: 0.0008195969858206809
Epoch 402, Training Loss: 0.001025324105285108, Validation Loss: 0.0007891410496085882
Epoch 403, Training Loss: 0.0009872897062450647, Validation Loss: 0.0007561103557236493
Epoch 404, Training Loss: 0.0009502151515334845, Validation Loss: 0.0007255043019540608
Epoch 405, Training Loss: 0.0009109639213420451, Validation Loss: 0.0006975860451348126
Epoch 406, Training Loss: 0.0008739657350815833, Validation Loss: 0.0006651471485383809
Epoch 407, Training Loss: 0.0008376820478588343, Validation Loss: 0.0006363854627124965
Epoch 408, Training Loss: 0.0008037793450057507, Validation Loss: 0.0006080423481762409
Epoch 409, Training Loss: 0.0007713434752076864, Validation Loss: 0.0005762306973338127
Epoch 410, Training Loss: 0.0007381638861261308, Validation Loss: 0.0005479136598296463
Epoch 411, Training Loss: 0.0007038646726869047, Validation Loss: 0.0005228332011029124
Epoch 412, Training Loss: 0.0006721422541886568, Validation Loss: 0.0004976979689672589
Epoch 413, Training Loss: 0.000642065133433789, Validation Loss: 0.0004755382251460105
Epoch 414, Training Loss: 0.000613599899224937, Validation Loss: 0.0004617575614247471
Epoch 415, Training Loss: 0.0005893480265513062, Validation Loss: 0.0004354681877885014
Epoch 416, Training Loss: 0.0005582281155511737, Validation Loss: 0.00041276824777014554
Epoch 417, Training Loss: 0.0005371786537580192, Validation Loss: 0.0003876554546877742
Epoch 418, Training Loss: 0.0005072947242297232, Validation Loss: 0.00037427505594678223
Epoch 419, Training Loss: 0.0004851047706324607, Validation Loss: 0.000351040594978258
Epoch 420, Training Loss: 0.0004598280065692961, Validation Loss: 0.00032434126478619874
Epoch 421, Training Loss: 0.0004347065987531096, Validation Loss: 0.0003057649591937661
Epoch 422, Training Loss: 0.00041221838910132647, Validation Loss: 0.0002911732590291649
Epoch 423, Training Loss: 0.00039002278936095536, Validation Loss: 0.00027428011526353657
Epoch 424, Training Loss: 0.00037026635254733264, Validation Loss: 0.00025300984270870686
Epoch 425, Training Loss: 0.00034862005850300193, Validation Loss: 0.00023652413801755756
Epoch 426, Training Loss: 0.0003308846789877862, Validation Loss: 0.00022155353508424014
Epoch 427, Training Loss: 0.00031237848452292383, Validation Loss: 0.0002070719638140872
Epoch 428, Training Loss: 0.00029530140454880893, Validation Loss: 0.00019129620341118425
Epoch 429, Training Loss: 0.00027638315805234015, Validation Loss: 0.00017823856614995748
Epoch 430, Training Loss: 0.0002578204439487308, Validation Loss: 0.0001697538245934993
Epoch 431, Training Loss: 0.00024091872910503298, Validation Loss: 0.0001581633259775117
Epoch 432, Training Loss: 0.0002230881218565628, Validation Loss: 0.00014530174667015672
Epoch 433, Training Loss: 0.00020698482694569975, Validation Loss: 0.00013555787154473364
Epoch 434, Training Loss: 0.000193332540220581, Validation Loss: 0.00012815018999390304
Epoch 435, Training Loss: 0.00018105420167557895, Validation Loss: 0.0001193407442769967
Epoch 436, Training Loss: 0.00016966427210718393, Validation Loss: 0.00010936710896203294
Epoch 437, Training Loss: 0.00015863128646742553, Validation Loss: 0.00010156611097045243
Epoch 438, Training Loss: 0.00014849701256025583, Validation Loss: 9.513392433291301e-05
Epoch 439, Training Loss: 0.00013723289885092527, Validation Loss: 9.004433377413079e-05
Epoch 440, Training Loss: 0.0001281857694266364, Validation Loss: 8.199238072847947e-05
Epoch 441, Training Loss: 0.00011793985322583467, Validation Loss: 7.549504516646266e-05
Epoch 442, Training Loss: 0.00011057033407269046, Validation Loss: 6.929681694600731e-05
Epoch 443, Training Loss: 0.00010212558117927983, Validation Loss: 6.429742643376812e-05
Epoch 444, Training Loss: 9.497233986621723e-05, Validation Loss: 5.91029274801258e-05
Epoch 445, Training Loss: 8.840228110784665e-05, Validation Loss: 5.270971087156795e-05
Epoch 446, Training Loss: 8.091817289823666e-05, Validation Loss: 4.8617082939017564e-05
Epoch 447, Training Loss: 7.600122626172379e-05, Validation Loss: 4.374630589154549e-05
Epoch 448, Training Loss: 6.944249616935849e-05, Validation Loss: 4.0740684198681265e-05
Epoch 449, Training Loss: 6.543858035001904e-05, Validation Loss: 3.703234324348159e-05
Epoch 450, Training Loss: 6.0025224229320884e-05, Validation Loss: 3.3368898584740236e-05
Epoch 451, Training Loss: 5.522232095245272e-05, Validation Loss: 3.096790533163585e-05
Epoch 452, Training Loss: 5.1684692152775824e-05, Validation Loss: 2.829168261087034e-05
Epoch 453, Training Loss: 4.7611945774406195e-05, Validation Loss: 2.5962506697396748e-05
Epoch 454, Training Loss: 4.401409751153551e-05, Validation Loss: 2.361351653235033e-05
Epoch 455, Training Loss: 4.075355900567956e-05, Validation Loss: 2.1129169908817858e-05
Epoch 456, Training Loss: 3.7405257899081334e-05, Validation Loss: 1.951010199263692e-05
Epoch 457, Training Loss: 3.487759022391401e-05, Validation Loss: 1.7942875274457037e-05
Epoch 458, Training Loss: 3.228472269256599e-05, Validation Loss: 1.6517746189492755e-05
Epoch 459, Training Loss: 2.97411679639481e-05, Validation Loss: 1.5563096894766204e-05
Epoch 460, Training Loss: 2.7649248295347206e-05, Validation Loss: 1.448702641937416e-05
Epoch 461, Training Loss: 2.5539215130265802e-05, Validation Loss: 1.3350608242035378e-05
Epoch 462, Training Loss: 2.3557062377221882e-05, Validation Loss: 1.2421253813954536e-05
Epoch 463, Training Loss: 2.1852469217265025e-05, Validation Loss: 1.1556036042748019e-05
Epoch 464, Training Loss: 2.014584606513381e-05, Validation Loss: 1.0789999578264542e-05
Epoch 465, Training Loss: 1.8619646652950905e-05, Validation Loss: 1.0091523108712863e-05
Epoch 466, Training Loss: 1.728177085169591e-05, Validation Loss: 9.385851626575459e-06
Epoch 467, Training Loss: 1.599910137883853e-05, Validation Loss: 8.736484232940711e-06
Epoch 468, Training Loss: 1.4841894881101325e-05, Validation Loss: 8.124154192046262e-06
Epoch 469, Training Loss: 1.3753467101196293e-05, Validation Loss: 7.537219971709419e-06
Epoch 470, Training Loss: 1.2689724826486781e-05, Validation Loss: 7.082428510329919e-06
Epoch 471, Training Loss: 1.17627096187789e-05, Validation Loss: 6.606785973417573e-06
Epoch 472, Training Loss: 1.0906459465331864e-05, Validation Loss: 6.1244263633852825e-06
Epoch 473, Training Loss: 1.010342839435907e-05, Validation Loss: 5.710533514502458e-06
Epoch 474, Training Loss: 9.359569048683625e-06, Validation Loss: 5.330258318281267e-06
Epoch 475, Training Loss: 8.656917998450808e-06, Validation Loss: 4.980366156814853e-06
Epoch 476, Training Loss: 8.029596756387036e-06, Validation Loss: 4.62508296550368e-06
Epoch 477, Training Loss: 7.431252925016452e-06, Validation Loss: 4.271985744708218e-06
Epoch 478, Training Loss: 6.859909717604751e-06, Validation Loss: 3.955431566282641e-06
Epoch 479, Training Loss: 6.34206116956193e-06, Validation Loss: 3.6704750527860597e-06
Epoch 480, Training Loss: 5.869725100637879e-06, Validation Loss: 3.413046442801715e-06
Epoch 481, Training Loss: 5.430593773780856e-06, Validation Loss: 3.176289737893967e-06
Epoch 482, Training Loss: 5.018929641664727e-06, Validation Loss: 2.949220743175829e-06
Epoch 483, Training Loss: 4.622239885065937e-06, Validation Loss: 2.743361392276711e-06
Epoch 484, Training Loss: 4.26327642344404e-06, Validation Loss: 2.5623094188631512e-06
Epoch 485, Training Loss: 3.940917849831749e-06, Validation Loss: 2.391910811638809e-06
Epoch 486, Training Loss: 3.630261971920845e-06, Validation Loss: 2.2285089471552055e-06
Epoch 487, Training Loss: 3.3397939205315197e-06, Validation Loss: 2.069831680273637e-06
Epoch 488, Training Loss: 3.0727710509381723e-06, Validation Loss: 1.920960357892909e-06
Epoch 489, Training Loss: 2.8242450298421318e-06, Validation Loss: 1.7915727994477493e-06
Epoch 490, Training Loss: 2.5998836008511716e-06, Validation Loss: 1.6741422541599604e-06
Epoch 491, Training Loss: 2.3961099486768944e-06, Validation Loss: 1.5546862641713233e-06
Epoch 492, Training Loss: 2.2014341993781272e-06, Validation Loss: 1.4370934877661057e-06
Epoch 493, Training Loss: 2.0188272173982114e-06, Validation Loss: 1.3300207228894578e-06
Epoch 494, Training Loss: 1.8533563661549124e-06, Validation Loss: 1.2341409956206917e-06
Epoch 495, Training Loss: 1.7015152025123825e-06, Validation Loss: 1.1480223065518658e-06
Epoch 496, Training Loss: 1.5617692952218931e-06, Validation Loss: 1.0609484206725028e-06
Epoch 497, Training Loss: 1.427640995643742e-06, Validation Loss: 9.77173385763308e-07
Epoch 498, Training Loss: 1.3032856713834917e-06, Validation Loss: 9.064643222700397e-07
Epoch 499, Training Loss: 1.1952745353482896e-06, Validation Loss: 8.377990639019117e-07
Epoch 500, Training Loss: 1.0931188398899394e-06, Validation Loss: 7.689306471547752e-07
