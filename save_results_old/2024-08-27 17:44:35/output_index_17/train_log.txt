Epoch 1, Training Loss: 0.24527418613433838, Validation Loss: 0.22639407217502594
Epoch 2, Training Loss: 0.24432684481143951, Validation Loss: 0.2254767119884491
Epoch 3, Training Loss: 0.24340981245040894, Validation Loss: 0.2245667278766632
Epoch 4, Training Loss: 0.242496058344841, Validation Loss: 0.2236514538526535
Epoch 5, Training Loss: 0.24157875776290894, Validation Loss: 0.22272583842277527
Epoch 6, Training Loss: 0.24065309762954712, Validation Loss: 0.22178949415683746
Epoch 7, Training Loss: 0.23972013592720032, Validation Loss: 0.22084541618824005
Epoch 8, Training Loss: 0.23877976834774017, Validation Loss: 0.21987776458263397
Epoch 9, Training Loss: 0.23782071471214294, Validation Loss: 0.21889728307724
Epoch 10, Training Loss: 0.23684635758399963, Validation Loss: 0.21790772676467896
Epoch 11, Training Loss: 0.235856831073761, Validation Loss: 0.21691182255744934
Epoch 12, Training Loss: 0.23485258221626282, Validation Loss: 0.21590247750282288
Epoch 13, Training Loss: 0.23383429646492004, Validation Loss: 0.21488289535045624
Epoch 14, Training Loss: 0.232807919383049, Validation Loss: 0.21384210884571075
Epoch 15, Training Loss: 0.23176135122776031, Validation Loss: 0.21277964115142822
Epoch 16, Training Loss: 0.23069408535957336, Validation Loss: 0.21169497072696686
Epoch 17, Training Loss: 0.22961317002773285, Validation Loss: 0.21058985590934753
Epoch 18, Training Loss: 0.22850948572158813, Validation Loss: 0.20947125554084778
Epoch 19, Training Loss: 0.22739312052726746, Validation Loss: 0.2083214819431305
Epoch 20, Training Loss: 0.22625593841075897, Validation Loss: 0.20714250206947327
Epoch 21, Training Loss: 0.22510379552841187, Validation Loss: 0.20594622194766998
Epoch 22, Training Loss: 0.22393007576465607, Validation Loss: 0.20470228791236877
Epoch 23, Training Loss: 0.22270222008228302, Validation Loss: 0.20340806245803833
Epoch 24, Training Loss: 0.22141310572624207, Validation Loss: 0.20207133889198303
Epoch 25, Training Loss: 0.22007150948047638, Validation Loss: 0.20067495107650757
Epoch 26, Training Loss: 0.2186771184206009, Validation Loss: 0.1992114931344986
Epoch 27, Training Loss: 0.21721619367599487, Validation Loss: 0.19766253232955933
Epoch 28, Training Loss: 0.21567180752754211, Validation Loss: 0.19603057205677032
Epoch 29, Training Loss: 0.214042067527771, Validation Loss: 0.19430167973041534
Epoch 30, Training Loss: 0.21232782304286957, Validation Loss: 0.19248126447200775
Epoch 31, Training Loss: 0.21051999926567078, Validation Loss: 0.1905609518289566
Epoch 32, Training Loss: 0.2086111456155777, Validation Loss: 0.18852637708187103
Epoch 33, Training Loss: 0.20659147202968597, Validation Loss: 0.18636995553970337
Epoch 34, Training Loss: 0.20444151759147644, Validation Loss: 0.1841052621603012
Epoch 35, Training Loss: 0.20217052102088928, Validation Loss: 0.18170185387134552
Epoch 36, Training Loss: 0.19976159930229187, Validation Loss: 0.17914552986621857
Epoch 37, Training Loss: 0.19721369445323944, Validation Loss: 0.17643067240715027
Epoch 38, Training Loss: 0.19449830055236816, Validation Loss: 0.17354972660541534
Epoch 39, Training Loss: 0.19161182641983032, Validation Loss: 0.1704980432987213
Epoch 40, Training Loss: 0.18853096663951874, Validation Loss: 0.1672608107328415
Epoch 41, Training Loss: 0.1853121519088745, Validation Loss: 0.1638714075088501
Epoch 42, Training Loss: 0.1819327175617218, Validation Loss: 0.16028131544589996
Epoch 43, Training Loss: 0.17836496233940125, Validation Loss: 0.15648746490478516
Epoch 44, Training Loss: 0.17458318173885345, Validation Loss: 0.15253233909606934
Epoch 45, Training Loss: 0.1706429272890091, Validation Loss: 0.14848576486110687
Epoch 46, Training Loss: 0.16658659279346466, Validation Loss: 0.14437024295330048
Epoch 47, Training Loss: 0.16244544088840485, Validation Loss: 0.14023812115192413
Epoch 48, Training Loss: 0.15827803313732147, Validation Loss: 0.13614054024219513
Epoch 49, Training Loss: 0.15412774682044983, Validation Loss: 0.13214361667633057
Epoch 50, Training Loss: 0.1500561237335205, Validation Loss: 0.12835457921028137
Epoch 51, Training Loss: 0.14617060124874115, Validation Loss: 0.12488870322704315
Epoch 52, Training Loss: 0.14257122576236725, Validation Loss: 0.12186325341463089
Epoch 53, Training Loss: 0.1393665373325348, Validation Loss: 0.1193922683596611
Epoch 54, Training Loss: 0.13666009902954102, Validation Loss: 0.1175927221775055
Epoch 55, Training Loss: 0.1345490664243698, Validation Loss: 0.11651816219091415
Epoch 56, Training Loss: 0.13309015333652496, Validation Loss: 0.11614580452442169
Epoch 57, Training Loss: 0.1322481483221054, Validation Loss: 0.11633867770433426
Epoch 58, Training Loss: 0.1318890005350113, Validation Loss: 0.11686435341835022
Epoch 59, Training Loss: 0.13179968297481537, Validation Loss: 0.11743411421775818
Epoch 60, Training Loss: 0.13170656561851501, Validation Loss: 0.11782001703977585
Epoch 61, Training Loss: 0.13140279054641724, Validation Loss: 0.1178668811917305
Epoch 62, Training Loss: 0.1307688057422638, Validation Loss: 0.11753374338150024
Epoch 63, Training Loss: 0.12978185713291168, Validation Loss: 0.11691223084926605
Epoch 64, Training Loss: 0.12858256697654724, Validation Loss: 0.11603750288486481
Epoch 65, Training Loss: 0.12723229825496674, Validation Loss: 0.1150958463549614
Epoch 66, Training Loss: 0.1258362978696823, Validation Loss: 0.11421391367912292
Epoch 67, Training Loss: 0.12451693415641785, Validation Loss: 0.11345914006233215
Epoch 68, Training Loss: 0.12334828078746796, Validation Loss: 0.11287296563386917
Epoch 69, Training Loss: 0.12236304581165314, Validation Loss: 0.11245634406805038
Epoch 70, Training Loss: 0.12155649811029434, Validation Loss: 0.11220798641443253
Epoch 71, Training Loss: 0.12092424184083939, Validation Loss: 0.11208771914243698
Epoch 72, Training Loss: 0.12042497098445892, Validation Loss: 0.11206300556659698
Epoch 73, Training Loss: 0.12001986056566238, Validation Loss: 0.11207316815853119
Epoch 74, Training Loss: 0.11963024735450745, Validation Loss: 0.11211540549993515
Epoch 75, Training Loss: 0.1192515641450882, Validation Loss: 0.11217016726732254
Epoch 76, Training Loss: 0.11886430531740189, Validation Loss: 0.11221473664045334
Epoch 77, Training Loss: 0.11844927072525024, Validation Loss: 0.112246572971344
Epoch 78, Training Loss: 0.11800089478492737, Validation Loss: 0.11226795613765717
Epoch 79, Training Loss: 0.11752700060606003, Validation Loss: 0.11227931082248688
Epoch 80, Training Loss: 0.11704365909099579, Validation Loss: 0.11227836459875107
Epoch 81, Training Loss: 0.11655395478010178, Validation Loss: 0.11227824538946152
Epoch 82, Training Loss: 0.11607329547405243, Validation Loss: 0.11229541152715683
Epoch 83, Training Loss: 0.11562211811542511, Validation Loss: 0.11233021318912506
Epoch 84, Training Loss: 0.11521440744400024, Validation Loss: 0.11239507049322128
Epoch 85, Training Loss: 0.11485249549150467, Validation Loss: 0.11248205602169037
Epoch 86, Training Loss: 0.11452306807041168, Validation Loss: 0.11258868128061295
Epoch 87, Training Loss: 0.11422696709632874, Validation Loss: 0.11270679533481598
Epoch 88, Training Loss: 0.11395368725061417, Validation Loss: 0.11281398683786392
Epoch 89, Training Loss: 0.11368413269519806, Validation Loss: 0.1129012182354927
Epoch 90, Training Loss: 0.11341467499732971, Validation Loss: 0.112935870885849
Epoch 91, Training Loss: 0.11313004046678543, Validation Loss: 0.11290939152240753
Epoch 92, Training Loss: 0.11282322555780411, Validation Loss: 0.11283915489912033
Epoch 93, Training Loss: 0.1124981939792633, Validation Loss: 0.11275738477706909
Epoch 94, Training Loss: 0.11217426508665085, Validation Loss: 0.112669438123703
Epoch 95, Training Loss: 0.11184898018836975, Validation Loss: 0.11256126314401627
Epoch 96, Training Loss: 0.11151871830224991, Validation Loss: 0.112446129322052
Epoch 97, Training Loss: 0.11119074374437332, Validation Loss: 0.11232242733240128
Epoch 98, Training Loss: 0.11086798459291458, Validation Loss: 0.11217676848173141
Epoch 99, Training Loss: 0.11056291311979294, Validation Loss: 0.11202280968427658
Epoch 100, Training Loss: 0.11026056110858917, Validation Loss: 0.1118755042552948
Epoch 101, Training Loss: 0.10996998846530914, Validation Loss: 0.11171535402536392
Epoch 102, Training Loss: 0.10967549681663513, Validation Loss: 0.1115594282746315
Epoch 103, Training Loss: 0.10938475281000137, Validation Loss: 0.11140524595975876
Epoch 104, Training Loss: 0.10908721387386322, Validation Loss: 0.11123570799827576
Epoch 105, Training Loss: 0.10878084599971771, Validation Loss: 0.11106406897306442
Epoch 106, Training Loss: 0.10846708714962006, Validation Loss: 0.11089147627353668
Epoch 107, Training Loss: 0.10814725607633591, Validation Loss: 0.1107034981250763
Epoch 108, Training Loss: 0.10782632231712341, Validation Loss: 0.11052241921424866
Epoch 109, Training Loss: 0.10750392824411392, Validation Loss: 0.11034443974494934
Epoch 110, Training Loss: 0.10717616975307465, Validation Loss: 0.1101575419306755
Epoch 111, Training Loss: 0.10685019940137863, Validation Loss: 0.10995343327522278
Epoch 112, Training Loss: 0.10650839656591415, Validation Loss: 0.10974057018756866
Epoch 113, Training Loss: 0.10615555197000504, Validation Loss: 0.10952907800674438
Epoch 114, Training Loss: 0.10580184310674667, Validation Loss: 0.10929536074399948
Epoch 115, Training Loss: 0.10543162375688553, Validation Loss: 0.1090378612279892
Epoch 116, Training Loss: 0.10504227876663208, Validation Loss: 0.10877877473831177
Epoch 117, Training Loss: 0.10463986545801163, Validation Loss: 0.10852310806512833
Epoch 118, Training Loss: 0.10421329736709595, Validation Loss: 0.10826562345027924
Epoch 119, Training Loss: 0.10376209020614624, Validation Loss: 0.10801079124212265
Epoch 120, Training Loss: 0.10329964011907578, Validation Loss: 0.10774164646863937
Epoch 121, Training Loss: 0.10281939059495926, Validation Loss: 0.10744282603263855
Epoch 122, Training Loss: 0.10232227295637131, Validation Loss: 0.10713310539722443
Epoch 123, Training Loss: 0.10183292627334595, Validation Loss: 0.10680357366800308
Epoch 124, Training Loss: 0.10131218284368515, Validation Loss: 0.10646206885576248
Epoch 125, Training Loss: 0.10077131539583206, Validation Loss: 0.10615690052509308
Epoch 126, Training Loss: 0.10023216158151627, Validation Loss: 0.1058422103524208
Epoch 127, Training Loss: 0.09968447685241699, Validation Loss: 0.10550064593553543
Epoch 128, Training Loss: 0.09912865608930588, Validation Loss: 0.10517751425504684
Epoch 129, Training Loss: 0.09859564155340195, Validation Loss: 0.10480081290006638
Epoch 130, Training Loss: 0.09803794324398041, Validation Loss: 0.10438396781682968
Epoch 131, Training Loss: 0.0974588617682457, Validation Loss: 0.10393191128969193
Epoch 132, Training Loss: 0.09685541689395905, Validation Loss: 0.10343606770038605
Epoch 133, Training Loss: 0.09623892605304718, Validation Loss: 0.10287526994943619
Epoch 134, Training Loss: 0.09558891505002975, Validation Loss: 0.10229159146547318
Epoch 135, Training Loss: 0.09491724520921707, Validation Loss: 0.10168077796697617
Epoch 136, Training Loss: 0.09421145170927048, Validation Loss: 0.10104575008153915
Epoch 137, Training Loss: 0.0934695303440094, Validation Loss: 0.10040906071662903
Epoch 138, Training Loss: 0.09269830584526062, Validation Loss: 0.0997958779335022
Epoch 139, Training Loss: 0.09192919731140137, Validation Loss: 0.09914816915988922
Epoch 140, Training Loss: 0.09113489091396332, Validation Loss: 0.09847507625818253
Epoch 141, Training Loss: 0.09031417965888977, Validation Loss: 0.09780336916446686
Epoch 142, Training Loss: 0.08947549760341644, Validation Loss: 0.09713657200336456
Epoch 143, Training Loss: 0.08862068504095078, Validation Loss: 0.0964607372879982
Epoch 144, Training Loss: 0.08775575459003448, Validation Loss: 0.0957861840724945
Epoch 145, Training Loss: 0.08688171207904816, Validation Loss: 0.09509820491075516
Epoch 146, Training Loss: 0.08597934246063232, Validation Loss: 0.09433382004499435
Epoch 147, Training Loss: 0.08503644913434982, Validation Loss: 0.09352658689022064
Epoch 148, Training Loss: 0.0840916782617569, Validation Loss: 0.09269794821739197
Epoch 149, Training Loss: 0.08314769715070724, Validation Loss: 0.09185952693223953
Epoch 150, Training Loss: 0.08219566196203232, Validation Loss: 0.09102271497249603
Epoch 151, Training Loss: 0.0812327191233635, Validation Loss: 0.09021253883838654
Epoch 152, Training Loss: 0.08026669919490814, Validation Loss: 0.08941403031349182
Epoch 153, Training Loss: 0.07929611206054688, Validation Loss: 0.08862462639808655
Epoch 154, Training Loss: 0.07832534611225128, Validation Loss: 0.08788273483514786
Epoch 155, Training Loss: 0.07737734168767929, Validation Loss: 0.08715984225273132
Epoch 156, Training Loss: 0.07642772793769836, Validation Loss: 0.08643757551908493
Epoch 157, Training Loss: 0.07545983791351318, Validation Loss: 0.08570759743452072
Epoch 158, Training Loss: 0.07447772473096848, Validation Loss: 0.08496814221143723
Epoch 159, Training Loss: 0.0735018253326416, Validation Loss: 0.084219790995121
Epoch 160, Training Loss: 0.07251985371112823, Validation Loss: 0.08345267921686172
Epoch 161, Training Loss: 0.07151274383068085, Validation Loss: 0.08267182856798172
Epoch 162, Training Loss: 0.07050205767154694, Validation Loss: 0.08188293874263763
Epoch 163, Training Loss: 0.06946692615747452, Validation Loss: 0.0811033770442009
Epoch 164, Training Loss: 0.06843014806509018, Validation Loss: 0.08027695119380951
Epoch 165, Training Loss: 0.06739132106304169, Validation Loss: 0.07938650995492935
Epoch 166, Training Loss: 0.06633366644382477, Validation Loss: 0.07845105975866318
Epoch 167, Training Loss: 0.0652589425444603, Validation Loss: 0.07746277004480362
Epoch 168, Training Loss: 0.06416578590869904, Validation Loss: 0.07647155225276947
Epoch 169, Training Loss: 0.06305284798145294, Validation Loss: 0.07543951272964478
Epoch 170, Training Loss: 0.06194128841161728, Validation Loss: 0.07433612644672394
Epoch 171, Training Loss: 0.06079455837607384, Validation Loss: 0.07320079207420349
Epoch 172, Training Loss: 0.05963122099637985, Validation Loss: 0.07203139364719391
Epoch 173, Training Loss: 0.058457184582948685, Validation Loss: 0.07086905837059021
Epoch 174, Training Loss: 0.0573151670396328, Validation Loss: 0.06970030069351196
Epoch 175, Training Loss: 0.05618538334965706, Validation Loss: 0.0685398206114769
Epoch 176, Training Loss: 0.05505670979619026, Validation Loss: 0.06740473955869675
Epoch 177, Training Loss: 0.05395127460360527, Validation Loss: 0.06633805483579636
Epoch 178, Training Loss: 0.052905429154634476, Validation Loss: 0.06534154713153839
Epoch 179, Training Loss: 0.05192114785313606, Validation Loss: 0.06441812217235565
Epoch 180, Training Loss: 0.050985950976610184, Validation Loss: 0.06352820247411728
Epoch 181, Training Loss: 0.05010194331407547, Validation Loss: 0.06269427388906479
Epoch 182, Training Loss: 0.049295928329229355, Validation Loss: 0.061927832663059235
Epoch 183, Training Loss: 0.04855926334857941, Validation Loss: 0.06119101494550705
Epoch 184, Training Loss: 0.04788563400506973, Validation Loss: 0.06047738716006279
Epoch 185, Training Loss: 0.04726378619670868, Validation Loss: 0.0597757026553154
Epoch 186, Training Loss: 0.04667460918426514, Validation Loss: 0.05909566953778267
Epoch 187, Training Loss: 0.046121615916490555, Validation Loss: 0.058418918401002884
Epoch 188, Training Loss: 0.04558746516704559, Validation Loss: 0.0577717088162899
Epoch 189, Training Loss: 0.04506942257285118, Validation Loss: 0.057180073112249374
Epoch 190, Training Loss: 0.044571392238140106, Validation Loss: 0.05662911757826805
Epoch 191, Training Loss: 0.044106580317020416, Validation Loss: 0.05607765540480614
Epoch 192, Training Loss: 0.04362909868359566, Validation Loss: 0.055521294474601746
Epoch 193, Training Loss: 0.04314209148287773, Validation Loss: 0.05496407672762871
Epoch 194, Training Loss: 0.042648542672395706, Validation Loss: 0.05441984906792641
Epoch 195, Training Loss: 0.042163264006376266, Validation Loss: 0.053913287818431854
Epoch 196, Training Loss: 0.04170464724302292, Validation Loss: 0.05344289168715477
Epoch 197, Training Loss: 0.04127060994505882, Validation Loss: 0.05299023538827896
Epoch 198, Training Loss: 0.04084453359246254, Validation Loss: 0.05255316570401192
Epoch 199, Training Loss: 0.040429260581731796, Validation Loss: 0.05210372433066368
Epoch 200, Training Loss: 0.040010858327150345, Validation Loss: 0.051652196794748306
Epoch 201, Training Loss: 0.039588093757629395, Validation Loss: 0.05122440680861473
Epoch 202, Training Loss: 0.03919051215052605, Validation Loss: 0.05078912526369095
Epoch 203, Training Loss: 0.03880857303738594, Validation Loss: 0.05035557225346565
Epoch 204, Training Loss: 0.03844095766544342, Validation Loss: 0.049921486526727676
Epoch 205, Training Loss: 0.03807703033089638, Validation Loss: 0.049473341554403305
Epoch 206, Training Loss: 0.03771631419658661, Validation Loss: 0.04904189705848694
Epoch 207, Training Loss: 0.037364013493061066, Validation Loss: 0.048628952354192734
Epoch 208, Training Loss: 0.03702099621295929, Validation Loss: 0.04824236035346985
Epoch 209, Training Loss: 0.03667992353439331, Validation Loss: 0.04786788672208786
Epoch 210, Training Loss: 0.03633842244744301, Validation Loss: 0.0474976971745491
Epoch 211, Training Loss: 0.03599642589688301, Validation Loss: 0.04713091999292374
Epoch 212, Training Loss: 0.03565342351794243, Validation Loss: 0.04674571752548218
Epoch 213, Training Loss: 0.035305578261613846, Validation Loss: 0.046336326748132706
Epoch 214, Training Loss: 0.03495069965720177, Validation Loss: 0.04594210162758827
Epoch 215, Training Loss: 0.034608129411935806, Validation Loss: 0.04555169492959976
Epoch 216, Training Loss: 0.034261010587215424, Validation Loss: 0.04515143856406212
Epoch 217, Training Loss: 0.03390879929065704, Validation Loss: 0.04472620040178299
Epoch 218, Training Loss: 0.03354402258992195, Validation Loss: 0.04430144652724266
Epoch 219, Training Loss: 0.033184170722961426, Validation Loss: 0.043884292244911194
Epoch 220, Training Loss: 0.03283283859491348, Validation Loss: 0.04345541074872017
Epoch 221, Training Loss: 0.03247293829917908, Validation Loss: 0.043026406317949295
Epoch 222, Training Loss: 0.03211104869842529, Validation Loss: 0.042595893144607544
Epoch 223, Training Loss: 0.031748104840517044, Validation Loss: 0.04216829687356949
Epoch 224, Training Loss: 0.03138414025306702, Validation Loss: 0.041751615703105927
Epoch 225, Training Loss: 0.031017236411571503, Validation Loss: 0.041343946009874344
Epoch 226, Training Loss: 0.030653996393084526, Validation Loss: 0.04093364626169205
Epoch 227, Training Loss: 0.03029068186879158, Validation Loss: 0.04052465781569481
Epoch 228, Training Loss: 0.029931578785181046, Validation Loss: 0.040098290890455246
Epoch 229, Training Loss: 0.02956594154238701, Validation Loss: 0.03965821489691734
Epoch 230, Training Loss: 0.029193250462412834, Validation Loss: 0.03923419862985611
Epoch 231, Training Loss: 0.028828678652644157, Validation Loss: 0.038804955780506134
Epoch 232, Training Loss: 0.028469406068325043, Validation Loss: 0.03838948905467987
Epoch 233, Training Loss: 0.02811027131974697, Validation Loss: 0.03798048570752144
Epoch 234, Training Loss: 0.02775448188185692, Validation Loss: 0.037550002336502075
Epoch 235, Training Loss: 0.027391528710722923, Validation Loss: 0.03711704909801483
Epoch 236, Training Loss: 0.027025330811738968, Validation Loss: 0.036677222698926926
Epoch 237, Training Loss: 0.026661032810807228, Validation Loss: 0.03622583672404289
Epoch 238, Training Loss: 0.02630661614239216, Validation Loss: 0.035787321627140045
Epoch 239, Training Loss: 0.025958074256777763, Validation Loss: 0.03536112979054451
Epoch 240, Training Loss: 0.025606118142604828, Validation Loss: 0.03493209183216095
Epoch 241, Training Loss: 0.02524464577436447, Validation Loss: 0.034501951187849045
Epoch 242, Training Loss: 0.024883216246962547, Validation Loss: 0.03405787795782089
Epoch 243, Training Loss: 0.024525217711925507, Validation Loss: 0.03358585759997368
Epoch 244, Training Loss: 0.024166040122509003, Validation Loss: 0.03309481590986252
Epoch 245, Training Loss: 0.02379300445318222, Validation Loss: 0.032615501433610916
Epoch 246, Training Loss: 0.02342701517045498, Validation Loss: 0.03213585913181305
Epoch 247, Training Loss: 0.023059308528900146, Validation Loss: 0.03164633363485336
Epoch 248, Training Loss: 0.022684678435325623, Validation Loss: 0.031146463006734848
Epoch 249, Training Loss: 0.022308094426989555, Validation Loss: 0.03064270131289959
Epoch 250, Training Loss: 0.021926049143075943, Validation Loss: 0.03013245016336441
Epoch 251, Training Loss: 0.02153737097978592, Validation Loss: 0.029619134962558746
Epoch 252, Training Loss: 0.021149996668100357, Validation Loss: 0.02909855917096138
Epoch 253, Training Loss: 0.020764317363500595, Validation Loss: 0.028568901121616364
Epoch 254, Training Loss: 0.020374715328216553, Validation Loss: 0.02800404652953148
Epoch 255, Training Loss: 0.019976332783699036, Validation Loss: 0.027437033131718636
Epoch 256, Training Loss: 0.019578086212277412, Validation Loss: 0.02685593068599701
Epoch 257, Training Loss: 0.019191067665815353, Validation Loss: 0.026263142004609108
Epoch 258, Training Loss: 0.018797937780618668, Validation Loss: 0.025708887726068497
Epoch 259, Training Loss: 0.01842406764626503, Validation Loss: 0.025189125910401344
Epoch 260, Training Loss: 0.018058979883790016, Validation Loss: 0.02467714063823223
Epoch 261, Training Loss: 0.01768900454044342, Validation Loss: 0.02415967546403408
Epoch 262, Training Loss: 0.017314277589321136, Validation Loss: 0.02365042082965374
Epoch 263, Training Loss: 0.01694655418395996, Validation Loss: 0.02315635047852993
Epoch 264, Training Loss: 0.01658635213971138, Validation Loss: 0.022666439414024353
Epoch 265, Training Loss: 0.016232440248131752, Validation Loss: 0.022185470908880234
Epoch 266, Training Loss: 0.015890836715698242, Validation Loss: 0.0217044185847044
Epoch 267, Training Loss: 0.015558315441012383, Validation Loss: 0.02123570814728737
Epoch 268, Training Loss: 0.015237045474350452, Validation Loss: 0.0207529217004776
Epoch 269, Training Loss: 0.014920657500624657, Validation Loss: 0.020276600494980812
Epoch 270, Training Loss: 0.014618683606386185, Validation Loss: 0.019807683303952217
Epoch 271, Training Loss: 0.01432767789810896, Validation Loss: 0.01936768926680088
Epoch 272, Training Loss: 0.01405108068138361, Validation Loss: 0.018969209864735603
Epoch 273, Training Loss: 0.013780303299427032, Validation Loss: 0.01861805096268654
Epoch 274, Training Loss: 0.013515266589820385, Validation Loss: 0.018276989459991455
Epoch 275, Training Loss: 0.01326488796621561, Validation Loss: 0.01791919209063053
Epoch 276, Training Loss: 0.013021939434111118, Validation Loss: 0.0175483375787735
Epoch 277, Training Loss: 0.012783248908817768, Validation Loss: 0.01718343235552311
Epoch 278, Training Loss: 0.01255609467625618, Validation Loss: 0.01683017611503601
Epoch 279, Training Loss: 0.012337561696767807, Validation Loss: 0.016491372138261795
Epoch 280, Training Loss: 0.012121313251554966, Validation Loss: 0.016153324395418167
Epoch 281, Training Loss: 0.011906679719686508, Validation Loss: 0.015824131667613983
Epoch 282, Training Loss: 0.011698881164193153, Validation Loss: 0.01548613328486681
Epoch 283, Training Loss: 0.011488718912005424, Validation Loss: 0.015150962397456169
Epoch 284, Training Loss: 0.011279758997261524, Validation Loss: 0.014818442054092884
Epoch 285, Training Loss: 0.011072246357798576, Validation Loss: 0.014474165625870228
Epoch 286, Training Loss: 0.010863639414310455, Validation Loss: 0.014135781675577164
Epoch 287, Training Loss: 0.010656937025487423, Validation Loss: 0.013806072995066643
Epoch 288, Training Loss: 0.010455611161887646, Validation Loss: 0.013482509180903435
Epoch 289, Training Loss: 0.010262109339237213, Validation Loss: 0.013175376690924168
Epoch 290, Training Loss: 0.010068203322589397, Validation Loss: 0.01285863108932972
Epoch 291, Training Loss: 0.009866339154541492, Validation Loss: 0.012531731277704239
Epoch 292, Training Loss: 0.009666690602898598, Validation Loss: 0.012194324284791946
Epoch 293, Training Loss: 0.009473755955696106, Validation Loss: 0.011849111877381802
Epoch 294, Training Loss: 0.009289368987083435, Validation Loss: 0.011533659882843494
Epoch 295, Training Loss: 0.009126512333750725, Validation Loss: 0.011244501918554306
Epoch 296, Training Loss: 0.00895866472274065, Validation Loss: 0.010987577959895134
Epoch 297, Training Loss: 0.008791649714112282, Validation Loss: 0.010741119273006916
Epoch 298, Training Loss: 0.008631043136119843, Validation Loss: 0.010474639013409615
Epoch 299, Training Loss: 0.008464260958135128, Validation Loss: 0.010209177620708942
Epoch 300, Training Loss: 0.008301972411572933, Validation Loss: 0.009940141811966896
Epoch 301, Training Loss: 0.008145632222294807, Validation Loss: 0.00968034565448761
Epoch 302, Training Loss: 0.007991914637386799, Validation Loss: 0.009436904452741146
Epoch 303, Training Loss: 0.007844301871955395, Validation Loss: 0.00919277686625719
Epoch 304, Training Loss: 0.00770186074078083, Validation Loss: 0.008923976682126522
Epoch 305, Training Loss: 0.007556694559752941, Validation Loss: 0.008660498075187206
Epoch 306, Training Loss: 0.007423774804919958, Validation Loss: 0.008404272608458996
Epoch 307, Training Loss: 0.007292706985026598, Validation Loss: 0.00817400123924017
Epoch 308, Training Loss: 0.007165160030126572, Validation Loss: 0.007959146983921528
Epoch 309, Training Loss: 0.00703523401170969, Validation Loss: 0.007756383623927832
Epoch 310, Training Loss: 0.006910504307597876, Validation Loss: 0.0075592827051877975
Epoch 311, Training Loss: 0.006786409765481949, Validation Loss: 0.007371464278548956
Epoch 312, Training Loss: 0.006668675225228071, Validation Loss: 0.007177992258220911
Epoch 313, Training Loss: 0.0065556843765079975, Validation Loss: 0.006986404303461313
Epoch 314, Training Loss: 0.006447347346693277, Validation Loss: 0.006806448567658663
Epoch 315, Training Loss: 0.00633735628798604, Validation Loss: 0.006629410665482283
Epoch 316, Training Loss: 0.006229638122022152, Validation Loss: 0.006460667122155428
Epoch 317, Training Loss: 0.006127749104052782, Validation Loss: 0.0062834168784320354
Epoch 318, Training Loss: 0.006024633534252644, Validation Loss: 0.006108865141868591
Epoch 319, Training Loss: 0.005931183695793152, Validation Loss: 0.005949735175818205
Epoch 320, Training Loss: 0.00583626888692379, Validation Loss: 0.0058081140741705894
Epoch 321, Training Loss: 0.0057481564581394196, Validation Loss: 0.005642659030854702
Epoch 322, Training Loss: 0.005656893830746412, Validation Loss: 0.005482531618326902
Epoch 323, Training Loss: 0.005573540925979614, Validation Loss: 0.005340461619198322
Epoch 324, Training Loss: 0.005490782205015421, Validation Loss: 0.005221948958933353
Epoch 325, Training Loss: 0.005411030258983374, Validation Loss: 0.005110935773700476
Epoch 326, Training Loss: 0.005336412228643894, Validation Loss: 0.004994043614715338
Epoch 327, Training Loss: 0.005262708757072687, Validation Loss: 0.004881863482296467
Epoch 328, Training Loss: 0.005188706796616316, Validation Loss: 0.00477489223703742
Epoch 329, Training Loss: 0.005115534644573927, Validation Loss: 0.004670645110309124
Epoch 330, Training Loss: 0.0050462097860872746, Validation Loss: 0.004563611466437578
Epoch 331, Training Loss: 0.004974191542714834, Validation Loss: 0.004469648934900761
Epoch 332, Training Loss: 0.004905943293124437, Validation Loss: 0.00437960447743535
Epoch 333, Training Loss: 0.0048364982940256596, Validation Loss: 0.004293724428862333
Epoch 334, Training Loss: 0.004766435362398624, Validation Loss: 0.004220254719257355
Epoch 335, Training Loss: 0.004691423382610083, Validation Loss: 0.0041749621741473675
Epoch 336, Training Loss: 0.004637714009732008, Validation Loss: 0.004112857393920422
Epoch 337, Training Loss: 0.004575906787067652, Validation Loss: 0.004039908293634653
Epoch 338, Training Loss: 0.004514968488365412, Validation Loss: 0.003974206279963255
Epoch 339, Training Loss: 0.004458438139408827, Validation Loss: 0.003909253515303135
Epoch 340, Training Loss: 0.004390978254377842, Validation Loss: 0.003851748537272215
Epoch 341, Training Loss: 0.004328199662268162, Validation Loss: 0.003786926157772541
Epoch 342, Training Loss: 0.004266868345439434, Validation Loss: 0.003709613811224699
Epoch 343, Training Loss: 0.004199287388473749, Validation Loss: 0.0036462151911109686
Epoch 344, Training Loss: 0.004141121171414852, Validation Loss: 0.003582070814445615
Epoch 345, Training Loss: 0.004071512259542942, Validation Loss: 0.0035273083485662937
Epoch 346, Training Loss: 0.004010577220469713, Validation Loss: 0.0034621392842382193
Epoch 347, Training Loss: 0.0039489236660301685, Validation Loss: 0.003399961395189166
Epoch 348, Training Loss: 0.003890223568305373, Validation Loss: 0.0033506460022181273
Epoch 349, Training Loss: 0.003827046835795045, Validation Loss: 0.003299474250525236
Epoch 350, Training Loss: 0.003766164416447282, Validation Loss: 0.003243701998144388
Epoch 351, Training Loss: 0.003703186521306634, Validation Loss: 0.0031966292299330235
Epoch 352, Training Loss: 0.0036384069826453924, Validation Loss: 0.0031560715287923813
Epoch 353, Training Loss: 0.003579893382266164, Validation Loss: 0.0031096586026251316
Epoch 354, Training Loss: 0.0035203490406274796, Validation Loss: 0.0030654415022581816
Epoch 355, Training Loss: 0.003460016567260027, Validation Loss: 0.003017767798155546
Epoch 356, Training Loss: 0.0033993669785559177, Validation Loss: 0.0029572260100394487
Epoch 357, Training Loss: 0.003335352521389723, Validation Loss: 0.00289383577182889
Epoch 358, Training Loss: 0.0032686565537005663, Validation Loss: 0.0028386665508151054
Epoch 359, Training Loss: 0.003206766676157713, Validation Loss: 0.002786438912153244
Epoch 360, Training Loss: 0.003141144523397088, Validation Loss: 0.002727715065702796
Epoch 361, Training Loss: 0.003077286994084716, Validation Loss: 0.002661589067429304
Epoch 362, Training Loss: 0.0030070883221924305, Validation Loss: 0.002603925298899412
Epoch 363, Training Loss: 0.0029487800784409046, Validation Loss: 0.002542241010814905
Epoch 364, Training Loss: 0.0028778251726180315, Validation Loss: 0.0024835881777107716
Epoch 365, Training Loss: 0.0028141578659415245, Validation Loss: 0.0024242070503532887
Epoch 366, Training Loss: 0.0027487047482281923, Validation Loss: 0.002365514636039734
Epoch 367, Training Loss: 0.0026843801606446505, Validation Loss: 0.002307003363966942
Epoch 368, Training Loss: 0.0026184821035712957, Validation Loss: 0.002240861998870969
Epoch 369, Training Loss: 0.0025515900924801826, Validation Loss: 0.0021786189172416925
Epoch 370, Training Loss: 0.0024891055654734373, Validation Loss: 0.0021234445739537477
Epoch 371, Training Loss: 0.002427623840048909, Validation Loss: 0.0020530654583126307
Epoch 372, Training Loss: 0.002360803773626685, Validation Loss: 0.0019820481538772583
Epoch 373, Training Loss: 0.0022982594091445208, Validation Loss: 0.0019141827942803502
Epoch 374, Training Loss: 0.002230993239209056, Validation Loss: 0.0018590368563309312
Epoch 375, Training Loss: 0.0021681610960513353, Validation Loss: 0.0017934623174369335
Epoch 376, Training Loss: 0.0021031401120126247, Validation Loss: 0.0017301704501733184
Epoch 377, Training Loss: 0.0020406420808285475, Validation Loss: 0.0016702834982424974
Epoch 378, Training Loss: 0.0019819370936602354, Validation Loss: 0.0016163564287126064
Epoch 379, Training Loss: 0.0019201006507501006, Validation Loss: 0.0015527710784226656
Epoch 380, Training Loss: 0.0018580998294055462, Validation Loss: 0.0014837610069662333
Epoch 381, Training Loss: 0.0017986306920647621, Validation Loss: 0.0014206677442416549
Epoch 382, Training Loss: 0.0017383095109835267, Validation Loss: 0.0013715800596401095
Epoch 383, Training Loss: 0.0016772334929555655, Validation Loss: 0.0013175149215385318
Epoch 384, Training Loss: 0.0016197419026866555, Validation Loss: 0.0012550650862976909
Epoch 385, Training Loss: 0.0015616866294294596, Validation Loss: 0.0011973846703767776
Epoch 386, Training Loss: 0.0015068193897604942, Validation Loss: 0.001152531593106687
Epoch 387, Training Loss: 0.001451281365007162, Validation Loss: 0.001110178418457508
Epoch 388, Training Loss: 0.0013978255447000265, Validation Loss: 0.0010634151985868812
Epoch 389, Training Loss: 0.0013440944021567702, Validation Loss: 0.001014096662402153
Epoch 390, Training Loss: 0.0012927439529448748, Validation Loss: 0.0009698906796984375
Epoch 391, Training Loss: 0.0012441029539331794, Validation Loss: 0.0009328665910288692
Epoch 392, Training Loss: 0.0011955726658925414, Validation Loss: 0.0008890653261914849
Epoch 393, Training Loss: 0.0011448919540271163, Validation Loss: 0.0008426503045484424
Epoch 394, Training Loss: 0.0010979746002703905, Validation Loss: 0.0008001024252735078
Epoch 395, Training Loss: 0.0010502845980226994, Validation Loss: 0.0007613958441652358
Epoch 396, Training Loss: 0.0010027834214270115, Validation Loss: 0.000725382415112108
Epoch 397, Training Loss: 0.0009595201699994504, Validation Loss: 0.0006901260931044817
Epoch 398, Training Loss: 0.0009166386444121599, Validation Loss: 0.0006526680663228035
Epoch 399, Training Loss: 0.0008730010595172644, Validation Loss: 0.0006181552889756858
Epoch 400, Training Loss: 0.0008323882357217371, Validation Loss: 0.0005876857903786004
Epoch 401, Training Loss: 0.0007927676779218018, Validation Loss: 0.000556919549126178
Epoch 402, Training Loss: 0.0007543859537690878, Validation Loss: 0.0005291434936225414
Epoch 403, Training Loss: 0.0007203471614047885, Validation Loss: 0.0005058184033259749
Epoch 404, Training Loss: 0.0006865330506116152, Validation Loss: 0.0004777030844707042
Epoch 405, Training Loss: 0.0006515764980576932, Validation Loss: 0.0004472647560760379
Epoch 406, Training Loss: 0.0006184816011227667, Validation Loss: 0.00042008823947981
Epoch 407, Training Loss: 0.0005875718779861927, Validation Loss: 0.00039701766218058765
Epoch 408, Training Loss: 0.0005590751534327865, Validation Loss: 0.00037442342727445066
Epoch 409, Training Loss: 0.0005313324509188533, Validation Loss: 0.0003511435352265835
Epoch 410, Training Loss: 0.0005041516269557178, Validation Loss: 0.0003291666507720947
Epoch 411, Training Loss: 0.00047761734458617866, Validation Loss: 0.00030944356694817543
Epoch 412, Training Loss: 0.000453026092145592, Validation Loss: 0.0002926653251051903
Epoch 413, Training Loss: 0.00043024809565395117, Validation Loss: 0.00027650236734189093
Epoch 414, Training Loss: 0.0004086992412339896, Validation Loss: 0.0002602059976197779
Epoch 415, Training Loss: 0.00038758126902393997, Validation Loss: 0.0002453394699841738
Epoch 416, Training Loss: 0.00036758731584995985, Validation Loss: 0.00023146922467276454
Epoch 417, Training Loss: 0.0003482403408270329, Validation Loss: 0.0002187007194152102
Epoch 418, Training Loss: 0.00033071846701204777, Validation Loss: 0.00020579485862981528
Epoch 419, Training Loss: 0.00031381877488456666, Validation Loss: 0.00019286989117972553
Epoch 420, Training Loss: 0.0002975007810164243, Validation Loss: 0.00018099778390023857
Epoch 421, Training Loss: 0.00028194685000926256, Validation Loss: 0.00016991241136565804
Epoch 422, Training Loss: 0.0002667222870513797, Validation Loss: 0.00016017314919736236
Epoch 423, Training Loss: 0.00025303984875790775, Validation Loss: 0.0001504210667917505
Epoch 424, Training Loss: 0.00023976547527126968, Validation Loss: 0.0001415280858054757
Epoch 425, Training Loss: 0.0002274305879836902, Validation Loss: 0.000132973917061463
Epoch 426, Training Loss: 0.00021515398111660033, Validation Loss: 0.00012521307507995516
Epoch 427, Training Loss: 0.0002037109952652827, Validation Loss: 0.00011802693188656121
Epoch 428, Training Loss: 0.00019310691277496517, Validation Loss: 0.00011094436922576278
Epoch 429, Training Loss: 0.00018285613623447716, Validation Loss: 0.00010470337292645127
Epoch 430, Training Loss: 0.0001734047255013138, Validation Loss: 9.89160398603417e-05
Epoch 431, Training Loss: 0.0001640460832277313, Validation Loss: 9.367159509565681e-05
Epoch 432, Training Loss: 0.000155365327373147, Validation Loss: 8.84282126207836e-05
Epoch 433, Training Loss: 0.00014702879707328975, Validation Loss: 8.315045124618337e-05
Epoch 434, Training Loss: 0.00013902808132115752, Validation Loss: 7.8126038715709e-05
Epoch 435, Training Loss: 0.00013150596350897104, Validation Loss: 7.3433002398815e-05
Epoch 436, Training Loss: 0.00012434243399184197, Validation Loss: 6.910781667102128e-05
Epoch 437, Training Loss: 0.00011759140761569142, Validation Loss: 6.492558895843104e-05
Epoch 438, Training Loss: 0.0001110709854401648, Validation Loss: 6.07144356763456e-05
Epoch 439, Training Loss: 0.00010468051914358512, Validation Loss: 5.702168709831312e-05
Epoch 440, Training Loss: 9.903524914989248e-05, Validation Loss: 5.341339419828728e-05
Epoch 441, Training Loss: 9.341233817394823e-05, Validation Loss: 5.0240738346474245e-05
Epoch 442, Training Loss: 8.820145740173757e-05, Validation Loss: 4.734640970127657e-05
Epoch 443, Training Loss: 8.323822839884087e-05, Validation Loss: 4.4393804273568094e-05
Epoch 444, Training Loss: 7.84518415457569e-05, Validation Loss: 4.144856575294398e-05
Epoch 445, Training Loss: 7.390558312181383e-05, Validation Loss: 3.876405753544532e-05
Epoch 446, Training Loss: 6.966511864447966e-05, Validation Loss: 3.631292565842159e-05
Epoch 447, Training Loss: 6.57082418911159e-05, Validation Loss: 3.4015429264400154e-05
Epoch 448, Training Loss: 6.185848178574815e-05, Validation Loss: 3.183192529832013e-05
Epoch 449, Training Loss: 5.8205398090649396e-05, Validation Loss: 2.9777947929687798e-05
Epoch 450, Training Loss: 5.4770975111750886e-05, Validation Loss: 2.7819103706860915e-05
Epoch 451, Training Loss: 5.156477709533647e-05, Validation Loss: 2.5923924113158137e-05
Epoch 452, Training Loss: 4.848800381296314e-05, Validation Loss: 2.4179329557227902e-05
Epoch 453, Training Loss: 4.56535053672269e-05, Validation Loss: 2.2551495931111276e-05
Epoch 454, Training Loss: 4.2832776671275496e-05, Validation Loss: 2.1076031771372072e-05
Epoch 455, Training Loss: 4.025784437544644e-05, Validation Loss: 1.9678487660712563e-05
Epoch 456, Training Loss: 3.783963620662689e-05, Validation Loss: 1.8351644030190073e-05
Epoch 457, Training Loss: 3.5515422496246174e-05, Validation Loss: 1.7131507775047794e-05
Epoch 458, Training Loss: 3.330919935251586e-05, Validation Loss: 1.605690340511501e-05
Epoch 459, Training Loss: 3.130643744952977e-05, Validation Loss: 1.4950122022128198e-05
Epoch 460, Training Loss: 2.9352133424254134e-05, Validation Loss: 1.3844984096067492e-05
Epoch 461, Training Loss: 2.7513078748597763e-05, Validation Loss: 1.2844730918004643e-05
Epoch 462, Training Loss: 2.5824376280070283e-05, Validation Loss: 1.1905267456313595e-05
Epoch 463, Training Loss: 2.4174694772227667e-05, Validation Loss: 1.1085682672273833e-05
Epoch 464, Training Loss: 2.264449358335696e-05, Validation Loss: 1.0282018592988607e-05
Epoch 465, Training Loss: 2.119888631568756e-05, Validation Loss: 9.53616836341098e-06
Epoch 466, Training Loss: 1.9863857232849114e-05, Validation Loss: 8.863962648320012e-06
Epoch 467, Training Loss: 1.8591023035696708e-05, Validation Loss: 8.267111297755037e-06
Epoch 468, Training Loss: 1.736757803882938e-05, Validation Loss: 7.723657290625852e-06
Epoch 469, Training Loss: 1.6266674720100127e-05, Validation Loss: 7.168165211624e-06
Epoch 470, Training Loss: 1.5215055100270547e-05, Validation Loss: 6.6390816755301785e-06
Epoch 471, Training Loss: 1.4224721780919936e-05, Validation Loss: 6.1333180383371655e-06
Epoch 472, Training Loss: 1.3266645510157105e-05, Validation Loss: 5.648500518873334e-06
Epoch 473, Training Loss: 1.2333320228208322e-05, Validation Loss: 5.197925929678604e-06
Epoch 474, Training Loss: 1.146663271356374e-05, Validation Loss: 4.791836090589641e-06
Epoch 475, Training Loss: 1.066380809788825e-05, Validation Loss: 4.382639872346772e-06
Epoch 476, Training Loss: 9.90227908914676e-06, Validation Loss: 4.020533651782898e-06
Epoch 477, Training Loss: 9.195596248900983e-06, Validation Loss: 3.680610461742617e-06
Epoch 478, Training Loss: 8.524068107362837e-06, Validation Loss: 3.367922317920602e-06
Epoch 479, Training Loss: 7.88449415267678e-06, Validation Loss: 3.1061920253705466e-06
Epoch 480, Training Loss: 7.308396561711561e-06, Validation Loss: 2.8516287784441374e-06
Epoch 481, Training Loss: 6.776078407710884e-06, Validation Loss: 2.6030841127067106e-06
Epoch 482, Training Loss: 6.263645900617121e-06, Validation Loss: 2.3721354409644846e-06
Epoch 483, Training Loss: 5.783969754702412e-06, Validation Loss: 2.1677569748135284e-06
Epoch 484, Training Loss: 5.345562385628e-06, Validation Loss: 1.9743504253710853e-06
Epoch 485, Training Loss: 4.926766450807918e-06, Validation Loss: 1.7924173789651832e-06
Epoch 486, Training Loss: 4.542039278021548e-06, Validation Loss: 1.6243041045527207e-06
Epoch 487, Training Loss: 4.183947112323949e-06, Validation Loss: 1.4754064068256412e-06
Epoch 488, Training Loss: 3.85276644010446e-06, Validation Loss: 1.3429446426016511e-06
Epoch 489, Training Loss: 3.547980440998799e-06, Validation Loss: 1.2178021506770165e-06
Epoch 490, Training Loss: 3.260358653278672e-06, Validation Loss: 1.1015030167982331e-06
Epoch 491, Training Loss: 2.993111820615013e-06, Validation Loss: 9.961624982679496e-07
Epoch 492, Training Loss: 2.749005489022238e-06, Validation Loss: 8.972697855824663e-07
Epoch 493, Training Loss: 2.5207793896697694e-06, Validation Loss: 8.073658364082803e-07
Epoch 494, Training Loss: 2.310846184627735e-06, Validation Loss: 7.248127076309174e-07
Epoch 495, Training Loss: 2.115588358719833e-06, Validation Loss: 6.513290600196342e-07
Epoch 496, Training Loss: 1.9369222172826994e-06, Validation Loss: 5.841790766680788e-07
Epoch 497, Training Loss: 1.7714114619593602e-06, Validation Loss: 5.251185939414427e-07
Epoch 498, Training Loss: 1.6204930943786167e-06, Validation Loss: 4.7149697479653696e-07
Epoch 499, Training Loss: 1.478660010434396e-06, Validation Loss: 4.2553006096568424e-07
Epoch 500, Training Loss: 1.3500580280378927e-06, Validation Loss: 3.8235319266277656e-07
